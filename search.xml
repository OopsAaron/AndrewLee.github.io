<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2020-08-16-服务器检修</title>
    <url>/2020/08/16/2020-08-16-%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%A3%80%E4%BF%AE/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>实验室的服务器总是出故障，于是和师兄一起考虑将实验室重装系统，并进行一系列操作。因为之前接触的少，这次是一个很好的实践机会，过程中记录笔记如下</p>
<h3 id="服务器检修">服务器检修</h3>
<h4 id="实验室的服务器">实验室的服务器</h4>
<p>实验室有三台机架式服务器</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Dell poweredge R730</th>
<th>Dell poweredge R740</th>
<th>thinkserver rd650</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>系统</td>
<td>ubuntu 16.04</td>
<td>ubuntu 18.04</td>
<td>windows server 2008</td>
</tr>
</tbody>
</table>
<h4 id="制作ubuntu安装u盘">制作ubuntu安装U盘</h4>
<p>大部分内容参考自<a href="https://blog.csdn.net/zjx2014430/article/details/49303785" target="_blank" rel="noopener">使用UltraISO制作ubuntu安装u盘启动盘图文教程</a>，内容很详细，我的操作就是按照博客里的步骤</p>
<p>Ubuntu基于Debian发行版和GNOME桌面环境，在下载得到Ubuntu的光盘镜像后，可以选择刻盘引导安装或利用unetbootin工具用U盘引导安装。</p>
<p><strong>如何用u盘装ubuntu？</strong></p>
<p>先在网上下载<code>ubuntu16.04镜像</code> 和 <code>UltraISO软件</code></p>
<p>1、首先打开UltraISO软件，尽量下载最新版的，旧版可能会不能识别磁盘，安装失败!</p>
<p><img src="https://i.loli.net/2020/08/26/xim8TtON9MqyIYH.jpg" alt="点击查看大图" style="zoom:67%;"></p>
<p>2、点击工具栏中的第二个打开镜像文件工具，如图红色方框标志按钮，然后在打开的“打开ISO文件”对话框中找到我们下载好的Ubuntu镜像文件，之后点右下方的“打开”按钮</p>
<p><img src="https://i.loli.net/2020/08/26/hpUG4TbYoAHdDLQ.jpg" alt="点击查看大图" style="zoom:67%;"></p>
<p>3、打开镜像文件之后，在上方的列表中就会出现对打开的镜像文件的预览左边显示的是具体的目录，右边显示的目录和具体文件</p>
<p><img src="https://i.loli.net/2020/08/26/kzGMHAhBT1Y3tVg.jpg" alt="点击查看大图" style="zoom:67%;"></p>
<p>4、下面就开始制作启动盘了，点击菜单栏的“启动”，然后再弹出才按中选择“写入硬盘映像...”，打开“写入硬盘映像”对话框</p>
<p><img src="https://i.loli.net/2020/08/26/PuEeokUWv7qyhrd.jpg" alt="点击查看大图" style="zoom:67%;"></p>
<p>5、在写入硬盘映像对话框中，硬盘驱动器选择我们要写入的U盘，写入方式可以选择USB-HDD也可以选择USB-HDD+，两种方式小编都有尝试过，均可以</p>
<p><img src="https://i.loli.net/2020/08/26/28JSil4sBk9pCxO.jpg" alt="点击查看大图" style="zoom:67%;"></p>
<p>6、现在的这一步是非常关键的，关系到我们最后制作的硬盘映像能否启动电脑并安装系统，点击“便捷启动”，然后再弹出的菜单中依次选择“写入新的驱动器引导扇区”，再选择“Syslinux”，这一步的没有选择的话，那么我们最后制作的U盘映像将不能识别硬盘，不能安装系统</p>
<p><img src="https://i.loli.net/2020/08/26/HEQYiB7gqk4ep61.jpg" alt="点击查看大图" style="zoom:67%;"></p>
<p>7、在选择“Syslinux”后，会弹出如下图所示的提示框，毫无疑问，这里我们应该选择“是”</p>
<p><img src="https://i.loli.net/2020/08/26/tdT2jmYGVAMQhpN.jpg" alt="点击查看大图" style="zoom:67%;"></p>
<p>8、将Syslinux引导神曲写入设置的过程非常快，写入完成后，会弹出写入成功的提示框，若是没有写入成功，那么我们要重复上面的6、7步</p>
<p><img src="https://i.loli.net/2020/08/26/I8rhwpq3iVfCFsv.jpg" alt="点击查看大图" style="zoom:67%;"></p>
<p>9、现在就到了将ISO内的文件写入到U盘的时候了，点击下面的“写入”按钮，会弹出警告提示框，点击“是”就开始U盘安装盘的写入了</p>
<p><img src="https://i.loli.net/2020/08/26/HrdAoOFwvIg8SmP.jpg" alt="点击查看大图" style="zoom:67%;"></p>
<p>10、做完上面一些设置后，点击下面的“写入”按钮，这样就开始了U盘安装盘的制作过程，小编这里用的DVD的镜像文件，文件比较大，所以也比较耗时，在制作完成后，会自动关闭这个“写入硬盘映像”的对话框</p>
<p><img src="https://i.loli.net/2020/08/26/1DnsEjZBrzQtAc8.jpg" alt="点击查看大图" style="zoom:67%;"></p>
<p>11、制作完成，打开我的电脑，我们可以看到U盘的磁盘图标和名称都已经改变，其实这些信息是从我们的镜像文件中提取出来的</p>
<p>制作完成，现在安全弹出U盘，重启电脑，设置冲U盘启动就可以从U盘安装Ubuntu了，具体安装过程请看小编手续的经验文档</p>
<p><img src="https://i.loli.net/2020/08/26/OEzD8hnmBUrkj2J.jpg" alt="点击查看大图" style="zoom:67%;"></p>
<ol type="1">
<li><p>在进行U盘安装系统之前，我们还需要设置BIOS选项，因为默认的是硬盘启动，因此我们需要进行设置为U盘启动，不同的主板设置U盘启动的方式也不同，因此小编就不在此详述怎么更改BIOS设置，大家查找自己的主板型号然后在网上找相关的设置教程即可。</p>
<p><a href="http://jingyan.baidu.com/album/a3761b2b66fe141577f9aa51.html?picindex=8" target="_blank" rel="noopener"><img src="https://i.loli.net/2020/08/26/pD2yrl37uQwefsa.jpg" alt="怎么用u盘安装ubuntu"></a></p></li>
<li><p>完成BIOS设置后我们就可以插入U盘，重启电脑了，我们就可以使用U盘进行Ubuntu操作系统的安装了，具体的安装步骤小编就不在详述了，网上有很多相关的教程，大家可以参考下。</p>
<p><a href="http://jingyan.baidu.com/album/a3761b2b66fe141577f9aa51.html?picindex=9" target="_blank" rel="noopener"><img src="https://i.loli.net/2020/08/26/wbGayoYzurPMnkR.png" alt="怎么用u盘安装ubuntu"></a></p></li>
</ol>
<h4 id="安装系统流程">安装系统流程</h4>
<p>在bios界面选择USB：data traveler字样的设备，就是U盘，点击就可以进入U盘的ubuntu系统 在ubuntu界面里，选择try ubuntu，就可以在U盘里暂时不安装系统就可以体验。 在try ubuntu中，左侧文件夹目录会显示各个硬盘和U盘的项目。其中computer选项，/home就是U盘里的。可以正常的进行ubuntu操作。 好像会重启格式化还原，也就是向里面拷数据，重启之后再通过U盘进入ubuntu界面，拷的数据就不存在了。而且在自己笔记本上打开U盘，里面的目录是和ubuntu目录不一样的，也没有拷的数据。</p>
<p>因为要将系统安装在新的硬盘里，所以考虑将新硬盘里的数据拷出来。然而拷进U盘会重置无法读取，旧的硬盘又无法操作（无法在旧硬盘新建文件夹）所以最后就用了另一个数据U盘，找到U盘路径，最终将数据拷到U盘里，再对新硬盘格式化。</p>
<p>安装ubuntu过程中，在ubuntu主界面正常选择硬盘安装即可。 我们选择的是清空硬盘数据安装（对硬盘格式化）。安装完毕会重启</p>
<p>在bios界面里，可以调整开机默认启动项（默认进入的系统）。我们想要将新装的系统设为默认。</p>
<p>F11： boot manager。一般在这里面进行操作。 选择one-shot 启动（U盘系统启动），以及调整默认启动项。</p>
<ul>
<li>显示不出挂载的硬盘。 硬盘没插好。需要用劲将硬盘按进去 ，使其完全固定，才会插好。并且在开机的时候，硬盘位置处会亮灯的</li>
</ul>
<p>服务器上硬盘是有顺序的。根据服务器版面上的提示，按照从上到下，从左到右依次编号为0,1,2...， 优先级也是依次降低的。所以在启动界面，会优先加载优先级高的硬盘里的系统。 因为旧硬盘之前在上面。新硬盘在下面，后来更换位置，就可以正常加载新装的ubuntu系统。</p>
<p>sudo -i ： 升级到最高权限。 一些提示没有权限的操作需要进行升级 在文件/夹中， 右键属性，可以看到绝对位置路径。这样方便进行命令行操作。</p>
<h4 id="配置网络以及远程ssh连接">配置网络以及远程ssh连接</h4>
<p>本章节的大部分内容参考自<a href="https://blog.51cto.com/tangyade/2330627" target="_blank" rel="noopener">ubuntu16.04的网络配置</a></p>
<p>截图来自于实际服务器操作</p>
<p>参考博客 <a href="https://blog.csdn.net/weixin_43162402/article/details/88419024" target="_blank" rel="noopener">远程ssh连接ubuntu</a></p>
<h5 id="配置网络">配置网络</h5>
<p>打开ubuntu网络设置</p>
<p>在IPv4设置中，增加地址和DNS服务器</p>
<p><img src="https://i.loli.net/2020/08/25/zFQvdOa4rJZ8NCM.png" alt="image-20200825000649093"></p>
<p>重启系统 <code>shutdown  -r  now</code></p>
<p>如下 <code>ping www.baidu.com</code> , 如果可以ping通，则网络配置正确</p>
<p><img src="https://i.loli.net/2020/08/25/sNwuUrzBJ354xAd.png" alt="image-20200825000941898"></p>
<h5 id="配置ssh">配置ssh</h5>
<h6 id="检查ssh服务并安装">检查ssh服务，并安装</h6>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">ps -e|grep ssh <span class="comment">#抓取是否有ssh运行程序</span></span><br><span class="line">sudo apt-get update <span class="comment">#更新依赖</span></span><br><span class="line">sudo apt-get install openssh-sever  <span class="comment"># 安装ssh服务</span></span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2020/08/25/cfUBayIj59q7OSY.png" alt="image-20200825002257791"></p>
<p><img src="https://i.loli.net/2020/08/25/Xn8RufD3AlKEhBC.png" alt="image-20200825002523612"></p>
<h6 id="启动ssh">启动ssh</h6>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">/etc/init.d/ssh start  <span class="comment">#启动ssh</span></span><br><span class="line">sudo netstat -tlp</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2020/08/25/HJWKQDbFqnUCk9f.png" alt="image-20200825002331284"></p>
<p><img src="https://i.loli.net/2020/08/25/1zbncv7DyP43mHN.png" alt="image-20200825002625207"></p>
<h6 id="重启系统">重启系统</h6>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">shutdown  -r  now</span><br></pre></td></tr></tbody></table></figure>
<h4 id="语言设置">语言设置</h4>
<p>参考<a href="https://zhuanlan.zhihu.com/p/40755318" target="_blank" rel="noopener">ubuntu的语言设置（中文-&gt;英文）</a></p>
<h4 id="安装软件">安装软件</h4>
<h5 id="下载">下载</h5>
<p>浏览器搜狗输入法的linux版本安装包。 选择<code>save file</code>选项</p>
<h5 id="安装">安装</h5>
<ul>
<li><p>首先找到安装包所在文件夹，复制路径 。如路径<code>/home/dell2/Downloads/</code></p></li>
<li><p>在安装包右键属性，复制文件名，如 ：<code>sougou_64.deb</code></p></li>
<li><p>在terminal中命令行 <code>cd /home/dell2/Downloads/</code> 切换到当前文件夹，便于操作</p></li>
<li><p>继续执行 <code>sudo dpkg -i sougou_64.deb</code> 需要root权限，所以要输入密码</p>
<blockquote>
<p>dpkg是linux的deb包管理。</p>
<p>dpkg： 是Debian packager的简称，是由Debian开发出来的包管理器，软件包在发布时打包成.deb格式</p>
<p>适用于Dpkg (Debian系)：Ubuntu 注：RPM (Red Hat系)：CentOS、Fedora</p>
<p>dpkg支持 tar 包。 tar 只是一种压缩文件格式，所以，它只是把文件压缩打包而已</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">dpkg -i *.deb     deb文件的安装</span><br><span class="line">dpkg -r *.deb     deb文件的卸载</span><br><span class="line">dpkg -l           查看当前系统中已经安装的软件包的信息</span><br></pre></td></tr></tbody></table></figure>
</blockquote></li>
</ul>
<h5 id="更新依赖">更新依赖</h5>
<blockquote>
<p>dpkg常用命令行dpkg和rpm命令虽然可以解决安装，卸载和查询，但是对于软件包直接的依赖，比如安装的软件包依赖于很多其他的软件包，这两个软件只会将依赖打印出来告诉用户，需要用户一个一个的手动去先安装依赖，当依赖包又依赖其他包时，对于用户实在是不够友好，于是apt和yum出现了，他们的能够自动将依赖下载安装</p>
<p>apt的全称是Advanced Packaging Tool是Linux系统下的一款安装包管理工具。</p>
</blockquote>
<p>一般如果提示软件安装失败，那么应该就是缺少依赖。这时候应该更新依赖并且修复依赖。</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt-get update  <span class="comment">#更新依赖</span></span><br><span class="line">sudo apt-get install -f  <span class="comment">#修复依赖.使用此命令可修复依赖关系，假如有软件因依赖关系不满足而无法安装，就可以运行此命令自动修复安装程序包所依赖的包。特别是在使用dpkg命令安装deb软件包时出现依赖问题常需要此命令来修复。</span></span><br><span class="line"><span class="comment">#修复依赖之后如果还是出错，那么就再次运行此命令。注意提示</span></span><br></pre></td></tr></tbody></table></figure>
<h5 id="安装完毕">安装完毕</h5>
<p>打开ubuntu搜索栏就可以搜索到软件，就可以使用啦</p>
<h4 id="卸载软件">卸载软件</h4>
<p>参考自<a href="https://blog.csdn.net/luckydog612/article/details/80877179" target="_blank" rel="noopener">ubuntu命令卸载</a></p>
<p>打开终端，输入<code>dpkg --list</code> ,按下Enter键，终端输出以下内容，显示的是你电脑上安装的所有软件。</p>
<p>2.在终端中找到你需要卸载的软件的名称，列表是按照首字母排序的。 <img src="https://i.loli.net/2020/08/25/I8ctzH3LJlbNS4p.jpg" alt="找到要卸载的软件包"> 3.在终端上输入命令<code>sudo apt-get --purge remove 包名</code>（<code>--purge</code>是可选项，写上这个属性是将软件及其配置文件一并删除，如不需要删除配置文件，可执行<code>sudo apt-get remove 包名</code>） ，此处我要删除的是<code>polipo</code> ，那么在终端输入<code>sudo apt-get --purge remove polipo</code>，按下回车，输入密码，再次回车。</p>
<p>4.执行过程中，会提示你是否真的要删除（继续执行删除命令），在终端输入<code>y</code> ，然后回车，删除程序继续执行。 <img src="https://i.loli.net/2020/08/25/zt1kIJoTsn7AlFf.png" alt="确认删除"></p>
<p>5.正常情况下，再次出现输入命令行删除成功。 <img src="https://i.loli.net/2020/08/25/PRcrVmlbD3NOf65.png" alt="删除成功"></p>
<p>总结如下：</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">dpkg --list  <span class="comment"># 找到要删除的软件 按顺序排列</span></span><br><span class="line">sudo apt-get --purge remove polipo  <span class="comment">#配置文件一起删除</span></span><br></pre></td></tr></tbody></table></figure>
<h4 id="解决向日葵连接断开问题">解决向日葵连接断开问题</h4>
<p>实验室740服务器本来是ubuntu16.04，之后升级到ubuntu18.04，在windows上连接ubuntu的向日葵，总是显示正在连接，马上就是连接已断开，于是记录下解决方案。向日葵的客服的官方解答如下：</p>
<p>1、检查桌面环境是否有启动，若没有请先启动。需开启显示器使用</p>
<p>2、需要安装lightdm插件否则会提示连接停止</p>
<p>3、设备终端运行 xhost +再重新发起远程桌面测试能否显示画面</p>
<p>本次是方案2解决的。</p>
<blockquote>
<p>猜测：之前版本是ubuntu16.04支持的是lightdm，所以向日葵是可以正常运行的。而Ubuntu 16.10和更高版本中的默认显示管理器gdm，导致向日葵总是连接断开。所以切换到lightdm就可以了。</p>
</blockquote>
<p>将Display Manager切换为lightdm，<strong>重新启动系统</strong>即可：</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt-get update </span><br><span class="line">sudo apt-get upgrade </span><br><span class="line">sudo apt-get install lightdm #安装lightdm</span><br><span class="line">sudo dpkg-reconfigure lightdm # 将Display Manage从gdm3切换为lightdm</span><br></pre></td></tr></tbody></table></figure>
<p>输入用户名和密码后，将出现以下窗口，大致了解显示管理器在系统中的运行方式。</p>
<p><img src="https://i.loli.net/2020/08/26/VXeSndcL2ybKsW5.jpg" alt="Switch to gdm3" style="zoom:67%;"></p>
<p>按Enter键确定；将出现以下窗口。可以通过向上和向下箭头键配置新的显示管理器，然后按Enter进行确定。</p>
<p><img src="https://i.loli.net/2020/08/26/C6mfYuHpz1JyxX8.jpg" alt="Set default display manager"></p>
<p>重新启动系统时，选择的显示管理器将被配置为默认显示管理器。</p>
<hr>
<p>也可再切换为gdm3，并将lightdm删除</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">sudo dpkg-reconfigure gdm3 #也可切换为gdm3</span><br><span class="line">sudo apt-get remove lightdm #删除lightdm</span><br></pre></td></tr></tbody></table></figure>
<p>要检查当前正在使用哪个显示管理器，请运行以下命令：</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">cat /etc/X11/default-display-manager</span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<p><code>gdm3</code>，<code>kdm</code>和<code>lightdm</code>都是<strong>显示管理器</strong>（Display Manager），它们提供图形化登录，并且处理用户身份验证。</p>
<p>显示管理器：向用户显示登录屏幕，当用户成功输入用户名和密码的有效组合时，会话开始。</p>
<p><img src="https://i.loli.net/2020/08/26/uoEHl4bhSxaF2gj.jpg" alt="Ubuntu LightDM Display manager" style="zoom: 67%;"></p>
<p>LightDM的登录屏幕</p>
</blockquote>
<h4 id="将向日葵设置为开机自启动">将向日葵设置为开机自启动</h4>
<p>想将向日葵设置为自启动，这样以后重启服务器之后，就可以直接连接向日葵。在向日葵软件里设置并没有效果，于是想着在ubuntu开机启动项里设置。参考自<a href="https://www.cnblogs.com/end/archive/2012/10/12/2721059.html" target="_blank" rel="noopener">linux开机自启动</a></p>
<blockquote>
<p>linux随机启动的服务程序都在/etc/init.d这个文件夹里，里面的文件全部都是脚本文件（脚本程序简单的说就是把要运行的程序写到一个文件里让系统能够按顺序执行，类似windows下的autorun.dat文件）</p>
<p>另外在/etc这个文件夹里还有诸如名为rc1.d, rc2.d一直到rc6.d的文件夹，这些都是linux不同的runlevel，我们一般进入的X windows多用户的运行级别是第5级，也就是rc5.d，在这个文件夹下的脚本文件就是运行第5级时要随机启动的服务程序。</p>
<p>需要注意的是，在每个rc (1-6).d文件夹下的文件其实都是/etc/init.d文件夹下的文件的一个软连接（类似windows中的快捷方式），也就是说，<strong>在 /etc/init.d文件夹下是全部的服务程序，而每个rc(1-6).d只链接它自己启动需要的相应的服务程序！</strong></p>
<p>在本次操作中，目的就是写入运行向日葵脚本到/etc/init.d，然后软链接到rc5.d中即可开机自启动</p>
</blockquote>
<h5 id="找到系统中名字">找到系统中名字</h5>
<p>我们不确定向日葵（sunlogin）在系统中的名字，于是如下操作：</p>
<p>打开终端，输入<code>dpkg --list</code> ,按下Enter键，终端输出以下内容，显示的是你电脑上安装的所有软件。（按照首字母排列的）</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">dpkg --list <span class="comment"># 显示所有的软件名称</span></span><br></pre></td></tr></tbody></table></figure>
<p>找到向日葵名称，为<code>sunloginclient</code></p>
<h5 id="确定向日葵的位置">确定向日葵的位置</h5>
<p>要知道<code>sunloginclient</code>在哪里，用locate命令可以找到。</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">locate sunloginclient</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2020/08/26/AGgtMOySf2jd5ca.png" alt="image-20200826221019492"></p>
<p>选择<code>/usr/local/sunlogin/bin/sunloginclient</code>,这就是向日葵执行文件位置所在。</p>
<p>其中usr表 示是属于用户的，bin在linux里表示可以执行的程序。</p>
<h5 id="验证文件位置可忽略">验证文件位置（可忽略）</h5>
<p>验证是否这个位置可以打开向日葵，ubuntu用命令行的方式启动向日葵</p>
<ul>
<li>绝对路径：</li>
</ul>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/sunlogin/bin/sunloginclient <span class="comment">#直接在终端输入绝对路径即可</span></span><br></pre></td></tr></tbody></table></figure>
<p>如果可以启动向日葵，则表明路径正确</p>
<ul>
<li>如果已经在执行文件所在的文件夹，如<code>/usr/local/sunlogin/bin</code>，则</li>
</ul>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">./sunloginclient  <span class="comment"># 执行文件</span></span><br></pre></td></tr></tbody></table></figure>
<h5 id="编写sh脚本">编写sh脚本</h5>
<p>这样，我就可以编写一个脚本程序，把它放到<code>/etc/init.d</code>里，然后在<code>rc5.d</code>里做一个相应的软链接就可以了。</p>
<p>在<code>/etc/init.d</code>里新建sunlogin.sh脚本，</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/init.d <span class="comment">#cd到该目录下</span></span><br><span class="line">sudo vim sunlogin.sh <span class="comment">#新建脚本</span></span><br></pre></td></tr></tbody></table></figure>
<p>脚本内容如下：</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh </span></span><br><span class="line">/usr/<span class="built_in">local</span>/sunlogin/bin</span><br></pre></td></tr></tbody></table></figure>
<p>第一行<strong>#!/bin/sh</strong>是指此脚本使用<strong>/bin/sh</strong>来解释执行，<strong>#!</strong>是特殊的表示符，其后面根的是此解释此脚本的shell的路径。</p>
<p>第二行就是要运行的命令，也就是打开向日葵。</p>
<blockquote>
<p>才开始用的是<code>#!/bin/bash</code> ，发现没有效果。后参照rc5.d里sh文件里格式是sh，于是将其改为<code>#!/bin/sh</code> 。重启有效果。</p>
<p>#!/bin/sh 和 #!/bin/bash 的区别可以参考<a href="https://www.cnblogs.com/EasonJim/p/6850319.html" target="_blank" rel="noopener">区别</a></p>
</blockquote>
<h5 id="建立软链接">建立软链接</h5>
<p>建立启动项从<code>/etc/init.d</code>到<code>/etc/rc5.d</code>的软链接</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">ln -s  /etc/init.d/sunlogin.sh  /etc/rc5.d/S04sunlogin.sh</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2020/08/26/Xeo5zuxMsv8nkba.png" alt="rc5.d中内容"></p>
<blockquote>
<p>建立软链接： ln -s 原目录 映射目录</p>
<p>删除软链接的方法： sudo rm -rf 映射目录</p>
</blockquote>
<blockquote>
<p>软链接相当于windows中的快捷方式，不必重复的占用磁盘空间</p>
<p>ln命令会保持每一处链接文件的同步性，和快捷方式一样</p>
<p>当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在 其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。</p>
<p>具体参考<a href="https://www.runoob.com/linux/linux-comm-ln.html" target="_blank" rel="noopener">链接</a></p>
<p>还需要注意的一点是，在rc5.d里，每个链接的名字都是以S或者K开头的，S开头的表示是系统启动是要随机启动的，K开头的是不随机启动的。</p>
<p>如果我要哪个服务随机启动，就把它名字第一个字母K改成S就可以了，当然，把S改成K后，这个服务就不能随机启动了。因此，我这个链接 还要起名为SXXX，这样系统才能让它随机启动。</p>
</blockquote>
<h5 id="完成开机自启动">完成开机自启动</h5>
<p>重启系统后，等一下就可以启动向日葵，完成操作</p>
<h4 id="挂载硬盘">挂载硬盘</h4>
<h3 id="计算机启动过程boot">计算机启动过程（boot）</h3>
<p>计算机启动过程分成四个阶段。 大部分内容参考自博客<a href="http://www.ruanyifeng.com/blog/2013/02/booting.html" target="_blank" rel="noopener">计算机是如何启动的？</a></p>
<h4 id="一第一阶段bios"><strong>一、第一阶段：BIOS</strong></h4>
<p>是一组<strong>固化到计算机内主板上一个ROM芯片上的程序</strong>，计算机通电后，第一件事就是读取它。</p>
<p>它保存着计算机最重要的基本输入输出的程序、系统设置信息、开机后自检程序和系统自启动程序。其主要功能是为计算机提供最底层的、最直接的硬件设置和控制。</p>
<p>一般设置都是在这个过程中进行的</p>
<p><img src="https://i.loli.net/2020/08/25/KVNMtAZLJSs5c3H.jpg" alt="img"></p>
<p>这块芯片里的程序叫做"<strong>基本输入输出系统</strong>"（Basic Input/Output System），简称为<a href="http://en.wikipedia.org/wiki/BIOS" target="_blank" rel="noopener">BIOS</a>。</p>
<h5 id="硬件自检"><strong>1.1 硬件自检</strong></h5>
<p>BIOS程序首先检查，计算机硬件能否满足运行的基本条件，这叫做"硬件自检"（Power-On Self-Test），缩写为<a href="http://en.wikipedia.org/wiki/Power-on_self-test" target="_blank" rel="noopener">POST</a>。</p>
<p>如果硬件出现问题，主板会发出不同含义的<a href="http://en.wikipedia.org/wiki/Power-on_self-test#Original_IBM_POST_beep_codes" target="_blank" rel="noopener">蜂鸣</a>，启动中止。<strong>如果没有问题，屏幕就会显示出CPU、内存、硬盘等信息。</strong></p>
<p><img src="https://i.loli.net/2020/08/25/Atdr1chebHjRwpM.png" alt="img"></p>
<h5 id="启动顺序"><strong>1.2 启动顺序</strong></h5>
<p>硬件自检完成后，BIOS把控制权转交给下一阶段的启动程序。</p>
<p>这时，BIOS需要知道，"下一阶段的启动程序"具体存放在哪一个设备。也就是说，BIOS需要有一个<strong>外部储存设备</strong>的排序，排在前面的设备就是优先转交控制权的设备。这种排序叫做<strong>"启动顺序"（Boot Sequence）</strong>。</p>
<p>打开BIOS的操作界面，里面有一项就是"设定启动顺序"。 （可以自己设置）</p>
<p><img src="http://www.ruanyifeng.com/blogimg/asset/201302/bg2013021504.jpg" alt="img"></p>
<h4 id="二第二阶段主引导记录mbr"><strong>二、第二阶段：主引导记录</strong>（MBR）</h4>
<p>BIOS按照"启动顺序"，把控制权转交给排在第一位的储存设备。（已安装的硬盘/U盘）</p>
<p>这时，计算机读取该设备的第一个扇区，也就是读取最前面的512个字节。如果这512个字节的最后两个字节是0x55和0xAA，表明这个设备可以用于启动；如果不是，表明设备不能用于启动，控制权于是被转交给"启动顺序"中的下一个设备。</p>
<p>这最前面的512个字节，就叫做<a href="http://en.wikipedia.org/wiki/Master_boot_record" target="_blank" rel="noopener">"主引导记录"</a>（Master boot record，缩写为MBR）。</p>
<h5 id="主引导记录的结构"><strong>2.1 主引导记录的结构</strong></h5>
<p>"主引导记录"只有512个字节，放不了太多东西。它的<strong>主要作用是，告诉计算机到硬盘的哪一个位置去找操作系统。</strong></p>
<p>主引导记录由三个部分组成：</p>
<blockquote>
<p>　　（1） 第1-446字节：调用操作系统的机器码。</p>
<p>　　（2） 第447-510字节：分区表（Partition table）。</p>
<p>　　（3） 第511-512字节：主引导记录签名（0x55和0xAA）。</p>
</blockquote>
<p>其中，第二部分"分区表"的作用，是将硬盘分成若干个区。</p>
<h5 id="分区表"><strong>2.2 分区表</strong></h5>
<p>硬盘分区有很多<a href="http://en.wikipedia.org/wiki/Disk_partitioning#Benefits_of_multiple_partitions" target="_blank" rel="noopener">好处</a>。考虑到<strong>每个区可以安装不同的操作系统</strong>，"主引导记录"因此必须知道将控制权转交给哪个区。</p>
<p>分区表的长度只有64个字节，里面又分成四项，每项16个字节。所以，<strong>一个硬盘最多只能分四个一级分区</strong>，又叫做<strong>"主分区"</strong>。</p>
<p>每个主分区代表一个操作系统，最多只能装4个操作系统。 在操作系统中的区划分是在该主分区下进行的。</p>
<p>每个主分区的16个字节，由6个部分组成：</p>
<blockquote>
<p>　　（1） 第1个字节：如果为0x80，就表示该主分区是激活分区，控制权要转交给这个分区。四个主分区里面只能有一个是激活的。</p>
<p>　　（2） 第2-4个字节：主分区第一个扇区的物理位置（柱面、磁头、扇区号等等）。</p>
<p>　　（3） 第5个字节：<a href="http://en.wikipedia.org/wiki/Partition_type" target="_blank" rel="noopener">主分区类型</a>。</p>
<p>　　（4） 第6-8个字节：主分区最后一个扇区的物理位置。</p>
<p>　　（5） 第9-12字节：该主分区第一个扇区的逻辑地址。</p>
<p>　　（6） 第13-16字节：主分区的扇区总数。</p>
</blockquote>
<p>最后的四个字节（"主分区的扇区总数"），决定了这个主分区的长度。也就是说，一个主分区的扇区总数最多不超过2的32次方。</p>
<p>如果每个扇区为512个字节，就意味着单个分区最大不超过2TB。再考虑到扇区的逻辑地址也是32位，所以单个硬盘可利用的空间最大也不超过2TB。如果想使用更大的硬盘，只有2个方法：一是提高每个扇区的字节数，二是<a href="http://en.wikipedia.org/wiki/GUID_Partition_Table" target="_blank" rel="noopener">增加扇区总数</a>。</p>
<h4 id="三第三阶段硬盘启动"><strong>三、第三阶段：硬盘启动</strong></h4>
<p>这时，计算机的控制权就要转交给硬盘的某个分区了，这里又分成三种情况。</p>
<h5 id="情况a卷引导记录"><strong>3.1 情况A：卷引导记录</strong></h5>
<p>上一节提到，四个主分区里面，只有一个是激活的。计算机会<strong>读取激活分区的第一个扇区</strong>，叫做<a href="http://en.wikipedia.org/wiki/Volume_Boot_Record" target="_blank" rel="noopener">"卷引导记录</a>"（Volume boot record，缩写为VBR）。</p>
<p>"卷引导记录"的主要作用是，告诉计算机，操作系统在这个分区里的位置。然后，计算机就会加载操作系统了。</p>
<h5 id="情况b扩展分区和逻辑分区"><strong>3.2 情况B：扩展分区和逻辑分区</strong></h5>
<p>主分区的其中一个被定义为<strong>扩展分区</strong>，扩展分区下可以设置多个分区，被称为<strong>逻辑分区</strong></p>
<p>随着硬盘越来越大，四个主分区已经不够了，需要更多的分区。但是，<strong>分区表只有四项，因此规定有且仅有一个区可以被定义成"扩展分区"（Extended partition）。</strong></p>
<p>所谓<strong>"扩展分区"，就是指这个区里面又分成多个区</strong>。这种分区里面的分区，就叫做"<strong>逻辑分区</strong>"（logical partition）。</p>
<p>计算机先读取扩展分区的第一个扇区，叫做<a href="http://en.wikipedia.org/wiki/Extended_partition" target="_blank" rel="noopener">"扩展引导记录"</a>（Extended boot record，缩写为EBR）。它里面也包含一张64字节的分区表，但是最多只有两项（也就是两个逻辑分区）。</p>
<p>计算机接着读取第二个逻辑分区的第一个扇区，再从里面的分区表中找到第三个逻辑分区的位置，以此类推，直到某个逻辑分区的分区表只包含它自身为止（即只有一个分区项）。因此，<strong>扩展分区可以包含无数个逻辑分区。</strong></p>
<p>但是，似乎很少通过这种方式启动操作系统。如果操作系统确实安装在扩展分区，一般采用下一种方式启动。</p>
<h5 id="情况c启动管理器常用"><strong>3.3 情况C：启动管理器</strong>（常用）</h5>
<p>在这种情况下，计算机读取"主引导记录"前面446字节的机器码之后，不再把控制权转交给某一个分区，而是运行事先安装的<a href="http://en.wikipedia.org/wiki/Boot_loader#Modern_boot_loaders" target="_blank" rel="noopener">"启动管理器"</a>（boot loader），由用户选择启动哪一个操作系统。</p>
<p>Linux环境中，目前最流行的启动管理器是<a href="http://en.wikipedia.org/wiki/GNU_GRUB" target="_blank" rel="noopener">Grub</a>。</p>
<p><img src="https://i.loli.net/2020/08/25/Ao5JqKFpgmXWOfw.png" alt="img"></p>
<h4 id="四第四阶段操作系统"><strong>四、第四阶段：操作系统</strong></h4>
<p>控制权转交给操作系统后，操作系统的内核首先被载入内存。</p>
<p>以Linux系统为例，先载入<strong>/boot目录下面的kernel</strong>。内核加载成功后，第一个运行的程序是<strong>/sbin/init</strong>。它根据配置文件（Debian系统是/etc/initab）产生init进程。这是Linux启动后的第一个进程，pid进程编号为1，其他进程都是它的后代。</p>
<p><strong>然后，init线程加载系统的各个模块，比如窗口程序和网络程序，直至执行/bin/login程序，跳出登录界面，等待用户输入用户名和密码。</strong></p>
<p>至此，全部启动过程完成。</p>
<h3 id="bios和uefi的区别">BIOS和UEFI的区别</h3>
<blockquote>
<p>BOOT设置是说电脑一按开机键后，出现那段黑屏界面BOOT运行时，你按<strong>快捷键</strong>调出各种BOOT后的程序，例如BIOS的这个按键过程。</p>
<p><a href="http://www.udangjia.com/bios/" target="_blank" rel="noopener">BIOS设置</a>是，你必须按对快捷键，<strong>从BOOT进入BIOS程序后</strong>，在BIOS程序中的设置的这个过程。</p>
</blockquote>
<blockquote>
<p><strong>UEFI</strong>它其实和BIOS是同一个性质的东西，同一种程序，是随着发展出现的BIOS升级版。因为硬件发展迅速，传统式（<strong>Legacy</strong>）BIOS成为进步的包袱，现在已发展出最新的UEFI。理论上说是比BIOS更先进的UEFI，却还是诸多支持不足，往往很多是UEFI启动电脑，到头来还是切换回BIOS。</p>
</blockquote>
<p><img src="https://i.loli.net/2020/08/17/dkj8VXRMyTQ1UsI.png" alt="image-20200817235333172"></p>
<p><strong>现在的笔记本默认是UEFI+GPT</strong>，主流趋势也是使用UEFI进行引导。如果改legacy，必须在Security选项，找到Secure Boot，关闭。</p>
<h3 id="bios设置">BIOS设置</h3>
<h4 id="u盘启动">U盘启动</h4>
<p>按下电源键后,按照显示器上的提示进入BIOS，例如：按F2、F9、F11、F12或者Delete键。</p>
<p>方法1.直接选择带有USB：data traveler字样的enter进入即可。只是一次进入，下次还需要选择</p>
<p>方法2.将U盘项设置为First Boot，默认进入。一般在<strong>boot（启动）选项</strong>中进入设置</p>
<p>有的需要<strong>F10保存</strong>并退出</p>
<blockquote>
<p>参考</p>
<p><a href="https://blog.csdn.net/yuk1007/article/details/95217457" target="_blank" rel="noopener">基础的BIOS操作</a></p>
<p><a href="http://www.kqidong.com/bios/2771.html" target="_blank" rel="noopener">常见bios设置操作教程</a></p>
</blockquote>
<h3 id="计算机存储术语-扇区磁盘块页">计算机存储术语: 扇区，磁盘块，页</h3>
<blockquote>
<p><strong>扇区（sector）</strong>：硬盘的读写以扇区为基本单位。</p>
<p>磁盘上的每个磁道被等分为若干个弧段，这些弧段称之为扇区。</p>
<p>通常情况下每个扇区的大小是 512 字节。linux 下可以使用 <code>fdisk -l</code> 了解扇区大小</p>
<p>注意，扇区是磁盘物理层面的概念，操作系统是不直接与扇区交互的，而是与多个连续扇区组成的磁盘块交互。由于扇区是物理层面的概念，所以无法在系统中进行大小的更改。</p>
</blockquote>
<blockquote>
<p>簇：由于操作系统无法对数目众多的扇区进行寻址，所以操作系统就将相邻的扇区组合在一起，形成一个<strong>簇</strong>，然后再对簇进行管理。每个簇可以包括2、4、8、16、32或64个扇区。<strong>操作系统是通过块簇来做为单位读取等操作数据的</strong>。</p>
<p>为了更好地管理磁盘空间和更高效地从硬盘读取数据，操作系统规定<strong>一个簇中只能放置一个文件的内容</strong>，因此文件所占用的空间，只能是簇的整数倍；而如果文件实际大小小于一簇，它也要占一簇的空间。</p>
<p>所以，一般情况下文件所占空间要略大于文件的实际大小</p>
</blockquote>
<blockquote>
<p><strong>磁盘块（IO Block）</strong>：<strong>文件系统</strong>读写数据的最小单位，也叫磁盘簇。磁盘块的大小可以通过命令 <code>stat /boot</code> 来查看。</p>
<p>在Windows下如NTFS等文件系统中叫做簇；在Linux下如Ext4等文件系统中叫做块（block）。</p>
</blockquote>
<blockquote>
<p><strong>页，page</strong></p>
<p>内存的最小存储单位。页的大小通常为磁盘块大小的 2^n 倍，可以通过命令 <code>getconf PAGE_SIZE</code> 来获取页的大小</p>
<p>总结也就是</p>
<ul>
<li>页，内存操作的基本单位</li>
<li>磁盘块，磁盘操作的基本单位</li>
</ul>
</blockquote>
<blockquote>
<p><strong>命令索引</strong></p>
<ul>
<li>扇区大小，<code>fdisk -l</code> 查看磁盘分区情况</li>
<li>磁盘块大小，<code>stat /boot</code></li>
<li>内存页大小，<code>getconf PAGE_SIZE</code></li>
</ul>
</blockquote>
<h3 id="linux磁盘分区">linux磁盘分区</h3>
<p>更多内容参考自</p>
<p><a href="https://wizardforcel.gitbooks.io/vbird-linux-basic-4e/content/20.html" target="_blank" rel="noopener">鸟哥的linux私房菜 | 磁盘分区</a></p>
<p><a href="https://jasonhzy.github.io/2019/02/07/linux-mount/" target="_blank" rel="noopener">Linux分区与挂载</a></p>
<h3 id="poweredge-r740-机架式服务器基本操作">PowerEdge R740 机架式服务器基本操作</h3>
<h4 id="设置开机启动顺序">设置开机启动顺序</h4>
<p>开机按F2进入系统启动设置，也可以<strong>按F11进入快速启动配置</strong></p>
<p><img src="https://i.loli.net/2020/08/18/XZFykAOdgmHjJDe.png" alt="image-20200818151126884"></p>
<p><img src="https://i.loli.net/2020/08/18/OCK5cRzksAWIhyp.png" alt="image-20200818151216211"></p>
<p><img src="https://i.loli.net/2020/08/18/FpgEyq8vGzBlPXD.png" alt="image-20200818151323442"></p>
<p><img src="https://i.loli.net/2020/08/18/Rdf19rWcvAOHSp7.png" alt="image-20200818151824019"></p>
<p>在<strong>Boot Sequence</strong>处将<strong>Hard drive C</strong>设置到第一位，即优先级最高</p>
<h4 id="运行硬件检测">运行硬件检测</h4>
<p>怀疑硬件故障了，运行了一下硬件检测。可以看到有哪些硬件。来验证所连接的硬件是否正常工作，排除故障。</p>
<p>1.开机出现DELL LOGO标志时按2下F10键，等待大概5分钟会进入lifecycle controller界面；</p>
<p>2.鼠标单击选择左侧的“Hardware Diagnostics”硬件诊断，再单击右侧的“Run Hardware Diagnostics”运行硬件诊断；</p>
<p><img src="https://i.loli.net/2020/08/18/FNegH5CnmJiRWAa.jpg" alt="img"></p>
<p>3.自动进入检测</p>
<p><img src="https://i.loli.net/2020/08/18/oEsxlPruV6DmSw2.jpg" alt="img"></p>
<p>4.大概5分钟后完成快速检测，出现如下界面，再单击“YES”继续完整检测，大概需要几个小时</p>
<p><img src="https://i.loli.net/2020/08/18/DKRFHVjpEZo27kW.jpg" alt="img"></p>
<ol start="5" type="1">
<li>检测完成后请单击“Result”结果一列，拍照这个页面，可能需要拖动滚动条拍照未在一屏显示出的其他内容。</li>
</ol>
<p><img src="https://i.loli.net/2020/08/18/Yij4DdNxZ3w6RBF.jpg" alt="img"></p>
<p>6、如果检测出现问题，会弹出红框，点击继续，最后查看一下原因。</p>
<p><img src="https://i.loli.net/2020/08/18/tYB8e7lsuUyP9fc.jpg" alt="img"></p>
<p>查一下ERROR CODE，应该是事件日志有历史告警导致的，清除告警之后，再次运行检测程序，没有告警了。</p>
<h3 id="交换空间">交换空间</h3>
<p>当今无论什么操作系统 <em>交换(Swap)</em>空间是非常常见的。Linux 使用交换空间来增加主机可用的虚拟内存。</p>
<p>典型计算机中有<strong>两种基本类型的内存</strong>。第一种类型，<strong>随机存取存储器 (RAM)</strong>，用于存储计算机使用的数据和程序。只有程序和数据存储在 RAM 中，计算机才能使用它们。</p>
<p><strong>交换空间</strong>是现代 Linux 系统中的第二种内存类型。交换空间的主要功能是当全部的 RAM 被占用并且需要更多内存时，用磁盘空间代替 RAM 内存。</p>
<p>例如，假设你有一个 8GB RAM 的计算机。如果你启动的程序没有填满 RAM，一切都好，不需要交换。假设你在处理电子表格，当添加更多的行时，你电子表格会增长，加上所有正在运行的程序，将会占用全部的 RAM 。如果这时没有可用的交换空间，你将不得不停止处理电子表格，直到关闭一些其他程序来释放一些 RAM 。</p>
<p>内核使用一个内存管理程序来检测最近没有使用的内存块（内存页）。内存管理程序将这些相对不经常使用的内存页交换到硬盘上专门指定用于“分页”或交换的特殊分区。这会释放 RAM，为输入电子表格更多数据腾出了空间。那些换出到硬盘的内存页面被内核的内存管理代码跟踪，如果需要，可以被分页回 RAM。</p>
<p>Linux 计算机中的内存总量是 RAM + 交换分区，交换分区被称为虚拟内存.</p>
<h4 id="什么是swap"><strong>什么是swap?</strong></h4>
<p>swap space是磁盘上的一块区域，可以是一个分区，也可以是一个文件，或者是他们的组合。简单点说，当系统物理内存吃紧时，Linux会将内存中不常访问的数据保存到swap上，这样系统就有更多的物理内存为各个进程服务，而当系统需要访问swap上存储的内容时，再将swap上的数据加载到内存中，这就是我们常说的swap out和swap in。</p>
<p>很多发行版(如ubuntu)的休眠功能依赖于swap分区，当系统休眠的时候，会将内存中的数据保存到swap分区上，等下次系统启动的时候，再将数据加载到内存中，这样可以加快系统的启动速度，所以如果要使用休眠的功能，必须要配置swap分区，并且大小一定要大于等于物理内存</p>
<p>swap是存放在磁盘上的，磁盘的速度和内存比较起来慢了好几个数量级，如果不停的读写swap，那么对系统的性能肯定有影响，尤其是当系统内存很吃紧的时候，读写swap空间发生的频率会很高，导致系统运行很慢，像死了一样，这个时候添加物理内存是唯一的解决办法。</p>
<h4 id="参考">参考</h4>
<blockquote>
<p><a href="https://segmentfault.com/a/1190000008125116" target="_blank" rel="noopener">Linux交换空间（swap space）</a></p>
</blockquote>
<h3 id="服务器ubuntu基本操作">服务器ubuntu基本操作</h3>
<h4 id="关机">关机</h4>
<p>立即关机</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># shutdown -h now</span><br></pre></td></tr></tbody></table></figure>
<p>指定 10 分钟后关机</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># shutdown -h 10</span><br></pre></td></tr></tbody></table></figure>
<p>重新启动计算机</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># shutdown -r now</span><br></pre></td></tr></tbody></table></figure>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>故障排除</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-07-28-transformer解读-pytorch版本</title>
    <url>/2020/07/28/2020-07-28-transformer-pytorch/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>最近几天都在阅读哈佛pytorch实现transformer的代码，代码风格很好，很值得参考和研读。和实验室师兄又在一起讨论了几次，代码思路和实现过程基本都了解了，对于原论文 <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">“Attention is All You Need”</a> 中关于transformer模型的理解又深入了许多。果然要想了解模型，还是要好好研读实现代码。以便于后面自己结合模型的研究。</p>
<p>本篇是对实现代码的注释，加上了自己的理解，也会有一些函数的介绍扩充。</p>
<h4 id="参考链接">参考链接</h4>
<blockquote>
<p>解读的是哈佛的一篇transformer的pytorch版本实现</p>
<p>http://nlp.seas.harvard.edu/2018/04/03/attention.html</p>
<p>参考另一篇博客</p>
<p>http://fancyerii.github.io/2019/03/09/transformer-codes/</p>
<p>Transformer注解及PyTorch实现（上）</p>
<p>https://www.jiqizhixin.com/articles/2018-11-06-10</p>
<p>Transformer注解及PyTorch实现（下）</p>
<p>https://www.jiqizhixin.com/articles/2018-11-06-18</p>
<p>训练过程中的 Mask实现</p>
<p>https://www.cnblogs.com/wevolf/p/12484972.html</p>
<p>transformer综述</p>
<p><a href="https://libertydream.github.io/2020/05/03/Transformer-综述/" target="_blank" rel="noopener">https://libertydream.github.io/2020/05/03/Transformer-%E7%BB%BC%E8%BF%B0/</a></p>
</blockquote>
<h3 id="the-annotated-transformer">The Annotated Transformer</h3>
<p><img src="https://i.loli.net/2020/07/28/NUAyXWJ5DzHmjuv.png" alt="这是一张图片"></p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># !pip install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl numpy matplotlib spacy torchtext seaborn </span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> math, copy, time</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn</span><br><span class="line">seaborn.set_context(context=<span class="string">"talk"</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>Transformer使用了Self-Attention机制，它在编码每一词的时候都能够注意(attend to)整个句子，从而可以解决长距离依赖的问题，同时计算Self-Attention可以用矩阵乘法一次计算所有的时刻，因此可以充分利用计算资源(CPU/GPU上的矩阵运算都是充分优化和高度并行的)。</p>
<h3 id="模型结构">模型结构</h3>
<p>Most competitive neural sequence transduction models have an encoder-decoder structure <a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="noopener">(cite)</a>. Here, <code>the encoder maps an input sequence of symbol representations (x1,…,xn)(x1,…,xn) to a sequence of continuous representations z=(z1,…,zn)z=(z1,…,zn). Given z, the decoder then generates an output sequence (y1,…,ym)(y1,…,ym) of symbols one element at a time.</code> At each step the model is auto-regressive <a href="https://arxiv.org/abs/1308.0850" target="_blank" rel="noopener">(cite)</a>, consuming the previously generated symbols as additional input when generating the next.</p>
<p><strong>EncoderDecoder定义了一种通用的Encoder-Decoder架构</strong>，具体的Encoder、Decoder、src_embed、target_embed和generator都是构造函数传入的参数。这样我们<strong>做实验更换不同的组件就会更加方便</strong>。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderDecoder</span><span class="params">(nn.Module)</span>:</span> <span class="comment">#定义的是整个模型 ，不包括generator</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">   标准的Encoder-Decoder架构。这是很多模型的基础</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    class里， init函数是实例化一个对象的时候用于初始化对象用的</span></span><br><span class="line"><span class="string">    forward函数是在执行调用对象的时候使用， 需要传入正确的参数 </span></span><br><span class="line"><span class="string">    在执行时候调用__call__方法，然后再call里再调用forward</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, encoder, decoder, src_embed, tgt_embed, generator)</span>:</span></span><br><span class="line">        super(EncoderDecoder, self).__init__()</span><br><span class="line">        <span class="comment"># encoder和decoder都是构造的时候传入的，这样会非常灵活</span></span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line">        <span class="comment"># 源语言和目标语言的embedding，包括embedding层和position encode层</span></span><br><span class="line">        self.src_embed = src_embed <span class="comment">#源数据集的嵌入</span></span><br><span class="line">        self.tgt_embed = tgt_embed <span class="comment">#目标数据集的嵌入，作为decoder的输入</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        generator后面会讲到，就是根据Decoder的隐状态输出当前时刻的词</span></span><br><span class="line"><span class="string">	    基本的实现就是隐状态输入一个全连接层，全连接层的输出大小是词的个数</span></span><br><span class="line"><span class="string">		然后接一个softmax变成概率</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.generator = generator</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, src, tgt, src_mask, tgt_mask)</span>:</span></span><br><span class="line">        <span class="comment">#首先调用encode方法对输入进行编码，然后调用decode方法解码</span></span><br><span class="line">        <span class="keyword">return</span> self.decode(self.encode(src, src_mask), src_mask,</span><br><span class="line">                            tgt, tgt_mask)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">encode</span><span class="params">(self, src, src_mask)</span>:</span></span><br><span class="line">        <span class="comment"># 调用encoder来进行编码，传入的参数embedding的src和src_mask</span></span><br><span class="line">        <span class="keyword">return</span> self.encoder(self.src_embed(src), src_mask)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decode</span><span class="params">(self, memory, src_mask, tgt, tgt_mask)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask) <span class="comment">#目标是输入的一部分</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span>  <span class="comment">#decoder后面的linear+softmax</span></span><br><span class="line">    <span class="comment"># 根据Decoder的隐状态输出一个词</span></span><br><span class="line">	<span class="comment"># d_model是Decoder输出的大小，vocab是词典大小 （数据语料有多少词 ）</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, vocab)</span>:</span></span><br><span class="line">        super(Generator, self).__init__()</span><br><span class="line">        self.proj = nn.Linear(d_model, vocab) <span class="comment">#全连接，作为softmax的输入。</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(self.proj(x), dim=<span class="number">-1</span>) <span class="comment">#softmax的log值</span></span><br></pre></td></tr></tbody></table></figure>
<p>注：<code>Generator返回的是softmax的log值</code>。在PyTorch里为了计算交叉熵损失，有两种方法。第一种方法是使用<strong>nn.CrossEntropyLoss()</strong>，一种是使用<strong>NLLLoss()</strong>。很多开源代码里第二种更常见，</p>
<p>我们先看CrossEntropyLoss，它就是计算交叉熵损失函数，比如：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">y = torch.empty(<span class="number">1</span>, dtype=torch.long).random_(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">loss = criterion(x, y)</span><br></pre></td></tr></tbody></table></figure>
<p>比如上面的代码，假设是5分类问题，x表示模型的输出logits(batch=1)，而y是真实分类的下标(0-4)。实际的计算过程为：<img src="https://i.loli.net/2020/08/06/KyPspa4Cqef6m8Q.png" alt="image-20200806000621448" style="zoom: 67%;"></p>
<p>比如logits是[0,1,2,3,4]，真实分类是3，那么上式就是：</p>
<p><img src="https://i.loli.net/2020/08/06/i7mfUWAeHE5P1zd.png" alt="image-20200806000641945" style="zoom:67%;"></p>
<p>因此我们也可以使用NLLLoss()配合F.log_softmax函数(或者nn.LogSoftmax，这不是一个函数而是一个Module了)来实现一样的效果：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">m = nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">criterion = nn.NLLLoss()</span><br><span class="line">x = torch.randn(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">y = torch.empty(<span class="number">1</span>, dtype=torch.long).random_(<span class="number">5</span>)</span><br><span class="line">loss = criterion(m(x), y)</span><br></pre></td></tr></tbody></table></figure>
<p>NLLLoss(Negative Log Likelihood Loss)是计算负log似然损失。它输入的x是log_softmax之后的结果(长度为5的数组)，y是真实分类(0-4)，输出就是x[y]。因此上面的代码为：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">criterion(m(x), y)=m(x)[y]</span><br></pre></td></tr></tbody></table></figure>
<p>The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1, respectively.</p>
<p><img src="https://i.loli.net/2020/07/28/P3fSgRhrmFtlpxY.png" alt="png"></p>
<h3 id="encoder-and-decoder-stacks">Encoder and Decoder Stacks</h3>
<h4 id="encoder">Encoder</h4>
<p>Encoder和Decoder都是由N个相同结构的Layer堆积(stack)而成。<strong>因此我们首先定义clones函数，用于克隆相同的SubLayer。</strong></p>
<p>这里使用了<strong>nn.ModuleList</strong>，ModuleList就像一个普通的Python的List，我们可以使用下标来访问它，它的好处是传入的ModuleList的所有Module都会注册的PyTorch里，这样Optimizer就能找到这里面的参数，从而能够用梯度下降更新这些参数。但是nn.ModuleList并不是Module(的子类)，因此它没有forward等方法，我们通常把它放到某个Module里。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clones</span><span class="params">(module, N)</span>:</span>  <span class="comment">#克隆N层，是个层数的列表。 copy.deepcopy是深复制， 一个改变不会影响另一个</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> nn.ModuleList([copy.deepcopy(module) <span class="keyword">for</span> _ <span class="keyword">in</span> range(N)]) <span class="comment">#复制N=6层</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span><span class="params">(nn.Module)</span>:</span>  <span class="comment">#定义编码器 </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Encoder是N个EncoderLayer的stack</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, layer, N)</span>:</span> <span class="comment"># 根据make_model定义，layer = encoderlayer （sublayer）</span></span><br><span class="line">        super(Encoder, self).__init__()</span><br><span class="line">        self.layers = clones(layer, N) <span class="comment">#编码器有6层编码层，根据上述函数的定义，module=layer</span></span><br><span class="line">        self.norm = LayerNorm(layer.size) <span class="comment">#调用下面的LayerNorm。 分开定义是因为 LayerNorm = 2* layer</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, mask)</span>:</span> </span><br><span class="line">      	 <span class="comment">#逐层进行处理</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers: <span class="comment"># x 在每一层中传递</span></span><br><span class="line">            x = layer(x, mask)</span><br><span class="line">        <span class="keyword">return</span> self.norm(x) <span class="comment">#最终encoder的返回值</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LayerNorm</span><span class="params">(nn.Module)</span>:</span> <span class="comment">#add &amp; norm部分  作为每一个子层的输出</span></span><br><span class="line">    <span class="string">"Construct a layernorm module (See citation for details)."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, features, eps=<span class="number">1e-6</span>)</span>:</span> <span class="comment">#feature = layer.size layer的形状</span></span><br><span class="line">        super(LayerNorm, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.a_2 = nn.Parameter(torch.ones(features))  <span class="comment">#将后面的tensor转换为可优化的参数</span></span><br><span class="line">        self.b_2 = nn.Parameter(torch.zeros(features))</span><br><span class="line">        self.eps = eps <span class="comment">#很小的值</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span> <span class="comment"># 平均值和标准差</span></span><br><span class="line">        mean = x.mean(<span class="number">-1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        std = x.std(<span class="number">-1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> self.a_2 * (x - mean) / (std + self.eps) + self.b_2 <span class="comment">#输出</span></span><br></pre></td></tr></tbody></table></figure>
<p><strong>不管是Self-Attention还是全连接层，都首先是LayerNorm，然后是Self-Attention/Dense，然后是Dropout，最好是残差连接。这里面有很多可以重用的代码，我们把它封装成SublayerConnection。</strong></p>
<hr>
<p>That is, <code>the output of each sub-layer is LayerNorm(x+Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer itself.</code> We apply dropout <a href="http://jmlr.org/papers/v15/srivastava14a.html" target="_blank" rel="noopener">(cite)</a> to the output of each sub-layer, before it is added to the sub-layer input and normalized.</p>
<p>To facilitate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of dimension <code>dmodel=512</code>.</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SublayerConnection</span><span class="params">(nn.Module)</span>:</span> <span class="comment">#每一个编码层中的两个子层之间的连接</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">	LayerNorm + sublayer(Self-Attenion/Dense) + dropout + 残差连接</span></span><br><span class="line"><span class="string">	为了简单，把LayerNorm放到了前面，这和原始论文稍有不同，原始论文LayerNorm在最后。</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, dropout)</span>:</span></span><br><span class="line">        super(SublayerConnection, self).__init__()</span><br><span class="line">        self.norm = LayerNorm(size)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, sublayer)</span>:</span></span><br><span class="line">       <span class="comment">#sublayer是传入的参数，参考DecoderLayer，它可以当成函数调用，这个函数的有一个输入参数</span></span><br><span class="line">        <span class="keyword">return</span> x + self.dropout(sublayer(self.norm(x))) <span class="comment">#调用layernorm ，正则化之后再相加</span></span><br></pre></td></tr></tbody></table></figure>
<p>这个类会构造LayerNorm和Dropout，但是Self-Attention或者Dense并不在这里构造，还是放在了EncoderLayer里，在forward的时候由EncoderLayer传入。这样的好处是更加通用，比如Decoder也是类似的需要在Self-Attention、Attention或者Dense前面后加上LayerNorm和Dropout以及残差连接，我们就可以复用代码。但是这里要求传入的sublayer可以使用一个参数来调用的函数(或者有__call__)。</p>
<hr>
<p>forward调用sublayer[0] (这是SublayerConnection对象)的__call__方法，最终会调到它的forward方法，而这个方法需要两个参数，<strong>一个是输入Tensor，一个是一个callable，并且这个callable可以用一个参数来调用</strong>。而<strong>self_attn函数需要4个参数(Query的输入,Key的输入,Value的输入和Mask)</strong>，因此这里我们使用lambda的技巧把它变成一个参数x的函数(mask可以看成已知的数)。</p>
<p>Callable 类型是可以被执行调用操作的类型。包含自定义函数等。自定义的函数比如使用def、lambda所定义的函数</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderLayer</span><span class="params">(nn.Module)</span>:</span> <span class="comment">#每一个编码层</span></span><br><span class="line">    <span class="string">"Encoder is made up of self-attn and feed forward (defined below)"</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, self_attn, feed_forward, dropout)</span>:</span></span><br><span class="line">        super(EncoderLayer, self).__init__()</span><br><span class="line">        self.self_attn = self_attn</span><br><span class="line">        self.feed_forward = feed_forward</span><br><span class="line">        self.sublayer = clones(SublayerConnection(size, dropout), <span class="number">2</span>) <span class="comment">#每一层有2子层</span></span><br><span class="line">        self.size = size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, mask)</span>:</span></span><br><span class="line">      <span class="comment">#attention层，括号里面是参数。接收来自attention的输出</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">     lambda : atten()SublayerConnection里是作为sublayer出现的，而它的参数是norm(x),norm(x)的输出是一个向量x，</span></span><br><span class="line"><span class="string">   所以atten的参数是只有一个x， 而在muitihead里面，k、q、v在函数里是要被重新根据x计算的</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">        x = self.sublayer[<span class="number">0</span>](x, <span class="keyword">lambda</span> x: self.self_attn(x, x, x, mask)) </span><br><span class="line">        <span class="keyword">return</span> self.sublayer[<span class="number">1</span>](x, self.feed_forward) <span class="comment">#x是atten+norm之后的输出，再ff输出</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    可以理解为</span></span><br><span class="line"><span class="string">    z = lambda y: self.self_attn(y, y, y, mask)</span></span><br><span class="line"><span class="string">	x = self.sublayer[0](x, z)</span></span><br><span class="line"><span class="string">    """</span></span><br></pre></td></tr></tbody></table></figure>
<h4 id="decoder">Decoder</h4>
<p>The decoder is also composed of a stack of <code>N=6</code> identical layers.</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Generic N layer decoder with masking."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, layer, N)</span>:</span></span><br><span class="line">        super(Decoder, self).__init__()</span><br><span class="line">        self.layers = clones(layer, N)</span><br><span class="line">        self.norm = LayerNorm(layer.size)</span><br><span class="line">     <span class="comment">#memory: 编码器的输出 x是输入</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, memory, src_mask, tgt_mask)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = layer(x, memory, src_mask, tgt_mask)</span><br><span class="line">        <span class="keyword">return</span> self.norm(x)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecoderLayer</span><span class="params">(nn.Module)</span>:</span> <span class="comment">#每一层解码层</span></span><br><span class="line">    <span class="string">"Decoder is made of self-attn, src-attn, and feed forward (defined below)"</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, self_attn, src_attn, feed_forward, dropout)</span>:</span></span><br><span class="line">        super(DecoderLayer, self).__init__()</span><br><span class="line">        self.size = size</span><br><span class="line">        self.self_attn = self_attn</span><br><span class="line">        self.src_attn = src_attn</span><br><span class="line">        self.feed_forward = feed_forward</span><br><span class="line">        self.sublayer = clones(SublayerConnection(size, dropout), <span class="number">3</span>) <span class="comment">#每一层有3个子层</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, memory, src_mask, tgt_mask)</span>:</span></span><br><span class="line">        <span class="string">"Follow Figure 1 (right) for connections."</span></span><br><span class="line">        m = memory</span><br><span class="line">        x = self.sublayer[<span class="number">0</span>](x, <span class="keyword">lambda</span> x: self.self_attn(x, x, x, tgt_mask)) <span class="comment">#第一子层</span></span><br><span class="line">        x = self.sublayer[<span class="number">1</span>](x, <span class="keyword">lambda</span> x: self.src_attn(x, m, m, src_mask)) <span class="comment">#第二子层 </span></span><br><span class="line">        <span class="keyword">return</span> self.sublayer[<span class="number">2</span>](x, self.feed_forward) <span class="comment">#第三子层</span></span><br></pre></td></tr></tbody></table></figure>
<p><strong>src-attn和self-attn的实现是一样的，只不过使用的Query，Key和Value的输入不同。</strong>普通的Attention(src-attn)的Query是下层输入进来的(来自self-attn的输出)，Key和Value是Encoder最后一层的输出memory；而Self-Attention的Query，Key和Value都是来自下层输入进来的。</p>
<hr>
<p>Decoder和Encoder有一个关键的不同：Decoder在解码第t个时刻的时候只能使用<strong>1…t时刻</strong>的输入，而不能使用t+1时刻及其之后的输入。因此我们需要一个函数来产生一个Mask矩阵，所以代码如下：</p>
<p>注意： t时刻包括t时刻的输入</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">subsequent_mask</span><span class="params">(size)</span>:</span>  <span class="comment">#将i后面的mask掉</span></span><br><span class="line">    <span class="string">"Mask out subsequent positions."</span></span><br><span class="line">    attn_shape = (<span class="number">1</span>, size, size)</span><br><span class="line">    subsequent_mask = np.triu(np.ones(attn_shape), k=<span class="number">1</span>).astype(<span class="string">'uint8'</span>) <span class="comment">#triu 上三角</span></span><br><span class="line">    <span class="keyword">return</span> torch.from_numpy(subsequent_mask) == <span class="number">0</span> <span class="comment">#将numpy格式转换为tensor格式，判断是否为0， 输出布尔值</span></span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2020/08/08/7brnPfDJxsLBtvh.png" alt="png"></p>
<p>它的输出：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">print(subsequent_mask(5))</span><br><span class="line"># 输出</span><br><span class="line">  1  0  0  0  0</span><br><span class="line">  1  1  0  0  0</span><br><span class="line">  1  1  1  0  0</span><br><span class="line">  1  1  1  1  0</span><br><span class="line">  1  1  1  1  1</span><br></pre></td></tr></tbody></table></figure>
<p>我们发现它输出的是一个方阵，对角线和下面都是1。<strong>第一行只有第一列是1，它的意思是时刻1只能attend to输入1</strong>，第三行说明时刻3可以attend to {1,2,3}而不能attend to{4,5}的输入，因为在真正Decoder的时候这是属于Future的信息。代码首先使用triu产生一个上三角阵：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">0 1 1 1 1</span><br><span class="line">0 0 1 1 1</span><br><span class="line">0 0 0 1 1</span><br><span class="line">0 0 0 0 1</span><br><span class="line">0 0 0 0 0</span><br></pre></td></tr></tbody></table></figure>
<p>然后需要把0变成1，把1变成0，这可以使用 matrix == 0来实现。</p>
<p>因为：布尔值True被索引求值为1，而False就等于0。</p>
<h4 id="attention">Attention</h4>
<p>An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.</p>
<p>We call our particular attention “<code>Scaled Dot-Product Attention</code>”. The input consists of queries and keys of dimension <code>dk</code>, and values of dimension <code>dv</code>. We compute the dot products of the query with all keys, divide each by <code>√dk</code>, and apply a softmax function to obtain the weights on the values.</p>
<p><img src="https://i.loli.net/2020/08/06/O3UNSGF7Poa1w4Q.png" alt="image-20200806015122441"></p>
<p><strong>Attention可以看成一个函数，它的输入是Query,Key,Value和Mask，输出是一个Tensor</strong>。其中输出是Value的加权平均，而权重来自Query和Key的计算。具体的计算如下图所示，计算公式为：</p>
<p><img src="https://i.loli.net/2020/07/28/WaSfHnNdt2L1AXU.png" alt="image-20200728212241453" style="zoom:50%;"></p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention</span><span class="params">(query, key, value, mask=None, dropout=None)</span>:</span></span><br><span class="line">    <span class="string">"Compute 'Scaled Dot Product Attention'"</span></span><br><span class="line">    d_k = query.size(<span class="number">-1</span>) <span class="comment"># query.size的最后一维</span></span><br><span class="line">    scores = torch.matmul(query, key.transpose(<span class="number">-2</span>, <span class="number">-1</span>)) / math.sqrt(d_k)</span><br><span class="line">    <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:<span class="comment"># 如果有mask</span></span><br><span class="line">        scores = scores.masked_fill(mask == <span class="number">0</span>, <span class="number">-1e9</span>)</span><br><span class="line">    p_attn = F.softmax(scores, dim = <span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">if</span> dropout <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: <span class="comment">#对p_attn进行dropout</span></span><br><span class="line">        p_attn = dropout(p_attn)</span><br><span class="line">    <span class="keyword">return</span> torch.matmul(p_attn, value), p_attn</span><br></pre></td></tr></tbody></table></figure>
<p>我们知道, 在训练的时候, 我们是以 batch_size 为单位的, 那么就会有 padding, 一般我们取 pad == 0, 那么就会造成在 Attention 的时候, query 的值为 0, query 的值为 0, 所以我们计算的对应的 scores 的值也是 0, 那么就会导致 softmax 很可能分配给该单词一个相对不是很小的比例, 因此, 我们将 pad 对应的 score 取值为<strong>负无穷</strong>（普通的计算，score可以为负数？）, 以此来减小 pad 的影响.</p>
<p>很容易想到, 在 decoder, <strong>未预测的单词</strong>也是用 padding 的方式加入到 batch 的, 所以使用的mask 机制与 padding 时mask 的机制是相同的, 本质上都是query 的值为0, 只是 mask 矩阵不同, 我们可以根据 decoder 部分的代码发现这一点.</p>
<hr>
<p>我们使用一个<strong>实际的例子跟踪一些不同Tensor的shape</strong>，然后对照公式就很容易理解。比如<strong>Q是(30,8,33,64)，其中30是batch，8是head个数，33是序列长度，64是每个时刻的特征数（size）。K和Q的shape必须相同的，而V可以不同，但是这里的实现shape也是相同的。</strong></p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">scores = torch.matmul(query, key.transpose(<span class="number">-2</span>, <span class="number">-1</span>)) \</span><br><span class="line">/ math.sqrt(d_k)</span><br></pre></td></tr></tbody></table></figure>
<p>上面的代码实现<img src="https://i.loli.net/2020/08/06/rLCJ7VFBAsmQb4x.png" alt="image-20200806014945713" style="zoom:50%;">，和公式里稍微不同的是，这里的Q和K都是4d的Tensor，包括batch和head维度。<strong>matmul会把query和key的最后两维进行矩阵乘法</strong>，这样效率更高，如果我们要用标准的矩阵(二维Tensor)乘法来实现，那么需要遍历batch维和head维：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">batch_num = query.size(<span class="number">0</span>) <span class="comment"># query.size(0)返回的是0维的数</span></span><br><span class="line">head_num = query.size(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(batch_num):</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> range(head_num):</span><br><span class="line">		scores[i,j] = torch.matmul(query[i,j], key[i,j].transpose())</span><br></pre></td></tr></tbody></table></figure>
<p>而上面的写法一次完成所有这些循环，效率更高。<strong>输出的score是(30, 8, 33, 33)</strong>，前面两维不看，那<strong>么是一个(33, 33)的attention矩阵a，aij表示时刻 i关注 j 的得分</strong>(还没有经过softmax变成概率)。</p>
<p><strong>在编码器的attention中src_mask的作用！！！</strong></p>
<p>接下来是<code>scores.masked_fill(mask == 0, -1e9)</code>，用于<strong>把mask是0的变成一个很小的数</strong>，这样后面经过softmax之后的概率就很接近零(但是理论上还是用来很少一点点未来的信息)。</p>
<blockquote>
<p>masked_fill_(mask, value)：掩码操作 masked_fill方法有两个参数，maske和value，mask是一个pytorch张量（Tensor），<strong>元素是布尔值，value是要填充的值</strong>，填充规则是mask中取值为True位置对应于self的相应位置用value填充。</p>
<p>注：参数mask必须与score的size相同或者两者是可广播(broadcasting-semantics)的</p>
<p>pytorch masked_fill方法简单理解</p>
<p>https://blog.csdn.net/jianyingyao7658/article/details/103382654</p>
<p>pytorch 广播语义(Broadcasting semantics)</p>
<p>https://blog.csdn.net/qq_35012749/article/details/88308657</p>
</blockquote>
<p>这里<strong>mask是(30, 1, 1, 33)的tensor</strong>，因为8个head的mask都是一样的，所有第二维是1，masked_fill时使用broadcasting就可以了。这里是self-attention的mask，所以每个时刻都可以attend到所有其它时刻，所有第三维也是1，也使用broadcasting。如果是普通的mask，那么mask的shape是(30, 1, 33, 33)。</p>
<p>这样讲有点抽象，我们可以举一个例子，为了简单，我们假设batch=2, head=8。第一个序列长度为3，第二个为4，那么self-attention的mask为(2, 1, 1, 4)，我们可以用两个向量表示：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">1 1 1 0</span><br><span class="line">1 1 1 1</span><br></pre></td></tr></tbody></table></figure>
<p>它的意思是在self-attention里，第一个序列的任一时刻可以attend to 前3个时刻(因为第4个时刻是padding的)；而第二个序列的可以attend to所有时刻的输入。而Decoder的src-attention的mask为(2, 1, 4, 4)，我们需要用2个矩阵表示：(一个序列对应一个一维src_mask（1×4）， 一个序列对应一个二维的tgt_mask（4×4）)</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">第一个序列的mask矩阵</span><br><span class="line">1 0 0 0</span><br><span class="line">1 1 0 0</span><br><span class="line">1 1 1 0</span><br><span class="line">1 1 1 0</span><br><span class="line"></span><br><span class="line">第二个序列的mask矩阵</span><br><span class="line">1 0 0 0</span><br><span class="line">1 1 0 0 </span><br><span class="line">1 1 1 0</span><br><span class="line">1 1 1 1</span><br></pre></td></tr></tbody></table></figure>
<p>接下来对score求softmax，把得分变成概率p_attn，如果有dropout还对p_attn进行Dropout(这也是原始论文没有的)。最后把p_attn和value相乘。p_attn是(30, 8, 33, 33)，value是(30, 8, 33, 64)，我们<strong>只看后两维，(33x33) x (33x64)最终得到33x64。</strong></p>
<hr>
<p>接下来就是输入怎么变成Q,K和V了，<strong>对于每一个Head，都使用三个矩阵WQ,WK,WV把输入转换成Q，K和V。</strong>然后<strong>分别用每一个Head进行Self-Attention的计算，最后把N个Head的输出拼接起来，最后用一个矩阵WO把输出压缩一下。</strong>具体计算过程为：</p>
<p><img src="https://i.loli.net/2020/08/06/1IbPcFJeK8tsHqN.png" alt="image-20200806023820900" style="zoom: 67%;"></p>
<p>详细结构如下图所示，输入Q，K和V经过多个线性变换后得到N(8)组Query，Key和Value，然后使用Self-Attention计算得到N个向量，然后拼接起来，<strong>最后使用一个线性变换进行降维。</strong></p>
<p><img src="https://i.loli.net/2020/08/08/a2gozSYGn8NOkpH.png" alt="png" style="zoom:67%;"></p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiHeadedAttention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, h, d_model, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        <span class="string">"Take in model size and number of heads."</span></span><br><span class="line">        super(MultiHeadedAttention, self).__init__()</span><br><span class="line">        <span class="keyword">assert</span> d_model % h == <span class="number">0</span>  <span class="comment"># 不能整除就报错</span></span><br><span class="line">        <span class="comment"># We assume d_v always equals d_k</span></span><br><span class="line">        self.d_k = d_model // h</span><br><span class="line">        self.h = h</span><br><span class="line">        self.linears = clones(nn.Linear(d_model, d_model), <span class="number">4</span>)</span><br><span class="line">        self.attn = <span class="literal">None</span></span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, query, key, value, mask=None)</span>:</span></span><br><span class="line">        <span class="string">"Implements Figure 2"</span></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># # 所有h个head的mask都是相同的 </span></span><br><span class="line">            mask = mask.unsqueeze(<span class="number">1</span>) <span class="comment">#在维度为1的位置添加一个维度，数字为1</span></span><br><span class="line">        nbatches = query.size(<span class="number">0</span>) <span class="comment">#就是有多少batch的值</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 1) 首先使用线性变换，然后把d_model分配给h个Head，每个head为d_k=d_model/h </span></span><br><span class="line">        query, key, value = \</span><br><span class="line">            [l(x).view(nbatches, <span class="number">-1</span>, self.h, self.d_k).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">             <span class="keyword">for</span> l, x <span class="keyword">in</span> zip(self.linears, (query, key, value))]</span><br><span class="line">           <span class="comment">#.view()表示重构张量的维度</span></span><br><span class="line">         <span class="comment">#注：因为每个Linear学习到的参数是不一样的。所以qkv三个也是不一样的</span></span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 2)使用attention函数计算 </span></span><br><span class="line">        x, self.attn = attention(query, key, value, mask=mask, </span><br><span class="line">                                 dropout=self.dropout)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3) 把8个head的64维向量拼接成一个512的向量。然后再使用一个线性变换(512,521)，shape不变。 </span></span><br><span class="line">        x = x.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous() \</span><br><span class="line">             .view(nbatches, <span class="number">-1</span>, self.h * self.d_k)</span><br><span class="line">        <span class="keyword">return</span> self.linears[<span class="number">-1</span>](x)</span><br></pre></td></tr></tbody></table></figure>
<p>我们先看构造函数，这里<strong>d_model(512)是Multi-Head的输出大小</strong>，因为有h(8)个head，因此每个head的d_k=512/8=64。接着我们构造4个(d_model ， d_model)的矩阵，后面我们会看到它的用处。最后是构造一个Dropout层。</p>
<p>然后我们来看forward方法。<strong>输入的mask是(batch, 1, time)的，因为每个head的mask都是一样的，所以先用unsqueeze(1)变成(batch, 1, 1, time)</strong>，mask我们前面已经详细分析过了。</p>
<p>接下来是<strong>根据输入query，key和value计算变换后的Multi-Head的query，key和value</strong>。这是通过下面的语句来实现的：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">query, key, value = \</span><br><span class="line">		[l(x).view(nbatches, <span class="number">-1</span>, self.h, self.d_k).transpose(<span class="number">1</span>, <span class="number">2</span>)	</span><br><span class="line">			<span class="keyword">for</span> l, x <span class="keyword">in</span> zip(self.linears, (query, key, value))] <span class="comment"># l(x): 调用nn.Linear函数</span></span><br></pre></td></tr></tbody></table></figure>
<p><strong>zip(self.linears, (query, key, value))是把(self.linears[0],self.linears[1],self.linears[2])和(query, key, value)放到一起然后遍历。我们只看一个self.linears[0] (query)。根据构造函数的定义，self.linears[0]是一个(512, 512)的矩阵，而query是(batch, time, 512)，相乘之后得到的新query还是512(d_model)维的向量，然后用view把它变成(batch, time, 8, 64)。然后transponse成(batch, 8,time,64)，这是attention函数要求的shape。分别对应8个Head，每个Head的Query都是64维。</strong></p>
<blockquote>
<p>1.一般来说，矩阵相乘，[a,b] x [b,c] = [a,c]</p>
<p>所以不同维度要进行处理，必须降维。例如 A 矩阵 [a,b,c], B 矩阵是[c,d]</p>
<p>这个时候就需要将 A 矩阵看成是 [axb, c] 与 [c,d] 进行相乘，得到结果。</p>
<ol start="2" type="1">
<li>Linear函数l(x)，应该就是 (batch*time,512)**(512,512)</li>
</ol>
</blockquote>
<p>Key和Value的运算完全相同，因此我们也分别得到8个Head的64维的Key和64维的Value。接下来<strong>调用attention函数，得到x和self.attn。其中x的shape是(batch, 8, time, 64)，而attn是(batch, 8, time, time)。</strong></p>
<p><strong>x.transpose(1, 2)把x变成(batch, time, 8, 64)，然后把它view成(batch, time, 512)，其实就是把最后8个64维的向量拼接成512的向量。最后使用self.linears[-1]对x进行线性变换，self.linears[-1]是(512, 512)的，因此最终的输出还是(batch, time, 512)。我们最初构造了4个(512, 512)的矩阵，前3个用于对query，key和value进行变换，而最后一个对8个head拼接后的向量再做一次变换。</strong></p>
<h4 id="a0ttention在模型中的应用">A0ttention在模型中的应用</h4>
<p>在Transformer里，有3个地方用到了MultiHeadedAttention：</p>
<ul>
<li><p>Encoder的Self-Attention层</p>
<p><strong>query，key和value都是相同的值</strong>，来自下层的输入。Mask都是1(当然padding的不算)。</p></li>
<li><p>Decoder的Self-Attention层</p>
<p><strong>query，key和value都是相同的值</strong>，来自下层的输入。但是Mask使得它不能访问未来的输入。</p></li>
<li><p>Encoder-Decoder的普通Attention</p>
<p><strong>query来自下层的输入，而key和value相同</strong>，是Encoder最后一层的输出，而Mask都是1。</p></li>
</ul>
<h3 id="position-wise-前馈网络">Position-wise 前馈网络</h3>
<p>In addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully connected feed-forward network, which is applied to each position separately and identically. <code>This consists of two linear transformations with a ReLU activation in between.</code></p>
<p>全连接层有两个线性变换以及它们之间的ReLU激活组成：</p>
<p><img src="https://i.loli.net/2020/08/08/PU96rciRsWxOCKp.png" alt="image-20200728231445307" style="zoom:50%;"></p>
<p>全连接层的输入和输出都是d_model(512)维的，中间隐单元的个数是d_ff(2048)维</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionwiseFeedForward</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Implements FFN equation."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, d_ff, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        super(PositionwiseFeedForward, self).__init__()</span><br><span class="line">        self.w_1 = nn.Linear(d_model, d_ff)</span><br><span class="line">        self.w_2 = nn.Linear(d_ff, d_model)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.w_2(self.dropout(F.relu(self.w_1(x))))</span><br></pre></td></tr></tbody></table></figure>
<h3 id="embeddings-和-softmax">Embeddings 和 Softmax</h3>
<p><strong>输入的词序列都是ID序列，我们需要Embedding</strong>。源语言和目标语言都需要Embedding，此外我们需要一个线性变换把隐变量变成输出概率，这可以通过前面的类Generator来实现。我们这里实现Embedding：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Embeddings</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, vocab)</span>:</span></span><br><span class="line">        super(Embeddings, self).__init__()</span><br><span class="line">        self.lut = nn.Embedding(vocab, d_model) <span class="comment">#将字典vocab大小映射到d_model大小</span></span><br><span class="line">        self.d_model = d_model</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.lut(x) * math.sqrt(self.d_model)</span><br></pre></td></tr></tbody></table></figure>
<p>注意的就是forward处理使用nn.Embedding对输入x进行Embedding之外，还除以了sqrt(d_model) （开方）</p>
<h3 id="位置编码">位置编码</h3>
<p>位置编码的公式为：</p>
<p><img src="https://i.loli.net/2020/08/08/WUpXhHsK3S1jCqn.png" alt="image-20200728232133981" style="zoom:50%;"></p>
<p><img src="https://i.loli.net/2020/08/08/XOZPy89KVi1xjTh.png" alt="image-20200728232255029" style="zoom:50%;"></p>
<p>where <code>pos</code> is the position and <code>i</code> is the dimension. That is, each dimension of the positional encoding corresponds to a sinusoid.</p>
<p>假设输入是ID序列长度为10，<strong>如果输入Embedding之后是(10, 512)，那么位置编码的输出也是(10, 512)。</strong>上式中pos就是位置(0-9)，512维的偶数维使用sin函数，而奇数维使用cos函数。这种位置编码的好处是：PE_pos+k可以表示成 PE_pos的线性函数，这样网络就能容易的学到相对位置的关系。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">5</span>))</span><br><span class="line">pe = PositionalEncoding(<span class="number">20</span>, <span class="number">0</span>)</span><br><span class="line">y = pe.forward(Variable(torch.zeros(<span class="number">1</span>, <span class="number">100</span>, <span class="number">20</span>)))</span><br><span class="line">plt.plot(np.arange(<span class="number">100</span>), y[<span class="number">0</span>, :, <span class="number">4</span>:<span class="number">8</span>].data.numpy())</span><br><span class="line">plt.legend([<span class="string">"dim %d"</span>%p <span class="keyword">for</span> p <span class="keyword">in</span> [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>]])</span><br></pre></td></tr></tbody></table></figure>
<p>图是一个示例，向量的大小d_model=20，我们这里画出来第4、5、6和7维(下标从零开始)维的图像，最大的位置是100。我们可以看到它们都是正弦(余弦)函数，而且周期越来越长。</p>
<p><img src="https://i.loli.net/2020/08/08/TfDHKvnM3emYysL.png" alt="png"></p>
<p>前面我们提到位置编码的好处是PE_pos+k可以表示成 P_Epos的线性函数，我们下面简单的验证一下。我们以第i维为例，为了简单，我们把<img src="https://i.loli.net/2020/08/06/iEoDOvKzB42N6Xe.png" alt="image-20200806104700979" style="zoom: 67%;">记作Wi，这是一个常量。</p>
<p><img src="https://i.loli.net/2020/08/06/E9h2vXIDK1MAjUg.png" alt="image-20200806104725624" style="zoom:67%;"></p>
<p>我们发现PE_pos+k 确实可以表示成 PE_pos的线性函数。</p>
<p>In addition, we apply dropout to the sums of the embeddings and the positional encodings in both the encoder and decoder stacks. For the base model, we use a rate of <code>Pdrop=0.1</code>.</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionalEncoding</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Implement the PE function."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, dropout, max_len=<span class="number">5000</span>)</span>:</span></span><br><span class="line">        super(PositionalEncoding, self).__init__()</span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute the positional encodings once in log space.</span></span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        <span class="comment">#之所以用log再exp,可能是考虑到数值过大溢出的问题</span></span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>) *</span><br><span class="line">                             -(math.log(<span class="number">10000.0</span>) / d_model))</span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        self.register_buffer(<span class="string">'pe'</span>, pe)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = x + Variable(self.pe[:, :x.size(<span class="number">1</span>)], </span><br><span class="line">                         requires_grad=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">return</span> self.dropout(x)</span><br></pre></td></tr></tbody></table></figure>
<p>代码可以参考公式，调用了<code>Module.register_buffer函数</code>。这个函数的作用是创建一个buffer，比如这里把pe保存下来。register_buffer通常用于保存一些模型参数之外的值，比如在BatchNorm中，我们需要保存running_mean(Moving Average)，它不是模型的参数(不用梯度下降)，但是模型会修改它，而且在预测的时候也要使用它。这里也是类似的，pe是一个提前计算好的常量，我们在forward要用到它。我们在构造函数里并没有把pe保存到self里，但是在forward的时候我们却可以直接使用它(self.pe)。如果我们保存(序列化)模型到磁盘的话，PyTorch框架也会帮我们保存buffer里的数据到磁盘，这样反序列化的时候能恢复它们</p>
<h3 id="完整模型">完整模型</h3>
<blockquote>
<p>Here we <code>define a function that takes in hyperparameters and produces a full model.</code></p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_model</span><span class="params">(src_vocab, tgt_vocab, N=<span class="number">6</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">               d_model=<span class="number">512</span>, d_ff=<span class="number">2048</span>, h=<span class="number">8</span>, dropout=<span class="number">0.1</span>)</span>:</span> <span class="comment">#d_ff： feedforward的维度</span></span><br><span class="line">    <span class="string">"Helper: Construct a model from hyperparameters."</span></span><br><span class="line">    c = copy.deepcopy</span><br><span class="line">    attn = MultiHeadedAttention(h, d_model)</span><br><span class="line">    ff = PositionwiseFeedForward(d_model, d_ff, dropout)</span><br><span class="line">    position = PositionalEncoding(d_model, dropout)</span><br><span class="line">    model = EncoderDecoder(</span><br><span class="line">        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),</span><br><span class="line">        Decoder(DecoderLayer(d_model, c(attn), c(attn), </span><br><span class="line">                             c(ff), dropout), N),</span><br><span class="line">        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),</span><br><span class="line">        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),</span><br><span class="line">        Generator(d_model, tgt_vocab))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># This was important from their code. </span></span><br><span class="line">    <span class="comment"># Initialize parameters with Glorot / fan_avg. 随机初始化参数，这非常重要</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters():</span><br><span class="line">        <span class="keyword">if</span> p.dim() &gt; <span class="number">1</span>:</span><br><span class="line">            nn.init.xavier_uniform(p)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例: 对model简单输入参数</span></span><br><span class="line">tmp_model = make_model(<span class="number">10</span>, <span class="number">10</span>, <span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>首先把copy.deepcopy命名为c，这样使下面的代码简洁一点。然后构造MultiHeadedAttention，PositionwiseFeedForward和PositionalEncoding对象。接着就是构造EncoderDecoder对象。它需要5个参数：Encoder、Decoder、src-embed、tgt-embed和Generator。</p>
<p>我们先看后面三个简单的参数，Generator直接构造就行了，它的作用是把模型的隐单元变成输出词的概率。而src-embed是一个Embeddings层和一个位置编码层c(position)，tgt-embed也是类似的。</p>
<p>最后我们来看Decoder(Encoder和Decoder类似的)。Decoder由N个DecoderLayer组成，而DecoderLayer需要传入self-attn, src-attn，全连接层和Dropout。因为所有的MultiHeadedAttention都是一样的，因此我们直接deepcopy就行；同理所有的PositionwiseFeedForward也是一样的网络结果，我们可以deepcopy而不要再构造一个。</p>
<h3 id="训练">训练</h3>
<p>This section describes the training regime for our models.</p>
<blockquote>
<p>We stop for a quick interlude to introduce some of the tools needed to train a standard encoder decoder model. First <code>we define a batch object that holds the src and target sentences for training, as well as constructing the masks.</code></p>
</blockquote>
<h4 id="batches-和-masking">Batches 和 Masking</h4>
<p><code>mask 矩阵来自 batch</code></p>
<p><code>self.src_mask = (src != pad).unsqueeze(-2)</code> 也就是说, 源语言的 <strong>mask 矩阵的维度是 (batch_size, 1, length)</strong>, 那么为什么 <code>attn_shape = (batch_size, size, size)</code> 呢? 可以这么解释, <strong>在 encoder 阶段的 Self_Attention 阶段, 所有的 Attention 是可以同时进行的, 把所有的 Attention_result 算出来, 然后用同一个 mask vector * Attention_result 就可以了</strong>, 但是在 decoder 阶段却不能这么做, 我们需要关注的问题是:</p>
<blockquote>
<p>根据已经预测出来的单词预测下面的单词, 这一过程<strong>是序列的</strong>,</p>
<p>而我们的计算是<strong>并行</strong>的, 所以这一过程中, 必须要引入矩阵. 也就是上面的 subsequent_mask() 函数获得的矩阵.</p>
</blockquote>
<p>这个矩阵也很形象, 分别表示已经预测的单词的个数为, 1, 2, 3, 4, 5.</p>
<p>然后我们将以上过程反过来过一篇, 就很明显了, 在 batch阶段获得 mask 矩阵, 然后和 batch 一起训练, 在 encoder 与 deocder 阶段实现 mask 机制.</p>
<blockquote>
<ul>
<li><p>mask在Batch中定义，src_mask.size (30,1,10) , trg_mask.size(30,10,10)</p></li>
<li><p>然后在MultiHeadedAttention中<code>mask = mask.unsqueeze(1)</code>又扩维了，</p>
<p>其中src_mask.size(30,1,1,10) ,trg_mask.size(30,1,10,10)</p></li>
<li><p>src_mask.size满足attention中的维度，所以可以对score进行mask</p>
<p>src_mask还在解码器的第1子层用到，相同的原理</p></li>
<li><p>trg_mask在解码器的第0子层用到，满足要求</p></li>
</ul>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Batch</span>:</span> <span class="comment">#定义每一个batch中的src、tgt、mask</span></span><br><span class="line">    <span class="comment">#trg = tgt: 真实的标签序列  out ： 预测的单词  </span></span><br><span class="line">    <span class="string">"Object for holding a batch of data with mask during training."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, src, trg=None, pad=<span class="number">0</span>)</span>:</span> </span><br><span class="line">        self.src = src</span><br><span class="line">        self.src_mask = (src != pad).unsqueeze(<span class="number">-2</span>) <span class="comment">#扩充维度 倒数第二维增加值为1 size=(30,1,10)</span></span><br><span class="line">        <span class="comment">#并且非零值全部赋值为1</span></span><br><span class="line">        </span><br><span class="line">         <span class="comment"># 在预测的时候是没有 tgt 的,此时为 None 此时trg是tgt的形参</span></span><br><span class="line">        <span class="keyword">if</span> trg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.trg = trg[:, :<span class="number">-1</span>] <span class="comment">#trg.size(30,9) ，在预测中，会提前输入起始符到ys中</span></span><br><span class="line">            <span class="string">"""</span></span><br><span class="line"><span class="string">              trg.size(30,9) 这里去掉的最后一个单词, 不是真正的单词, 而是标志 '&lt;eos&gt;' , 						输入与输出都还有一个 '&lt;sos&gt;' 在句子的开头,  是decoder的输入，</span></span><br><span class="line"><span class="string">            需要进行mask，使得Self-Attention不能访问未来的输入。最后一个词不需要用到trg</span></span><br><span class="line"><span class="string">            """</span></span><br><span class="line">    	    self.trg_y = trg[:, <span class="number">1</span>:] <span class="comment"># trg_y.size(30,9) </span></span><br><span class="line">            <span class="comment">#trg_y: 最后的结果。用于loss中的比较。 去掉开头的'&lt;sos&gt;'，是decoder的输出</span></span><br><span class="line">            self.trg_mask = \</span><br><span class="line">                self.make_std_mask(self.trg, pad)</span><br><span class="line">            self.ntokens = (self.trg_y != pad).data.sum() <span class="comment">#不为0的总数 30*9 = 270</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_std_mask</span><span class="params">(tgt, pad)</span>:</span> <span class="comment">#tgt_mask.size(30,9,9)，每一个序列都是一个9*9的矩阵</span></span><br><span class="line">        <span class="string">"Create a mask to hide padding and future words."</span></span><br><span class="line">        <span class="comment">#"创建Mask，使得我们不能attend to未来的词"</span></span><br><span class="line">        tgt_mask = (tgt != pad).unsqueeze(<span class="number">-2</span>)</span><br><span class="line">        tgt_mask = tgt_mask &amp; Variable(</span><br><span class="line">            subsequent_mask(tgt.size(<span class="number">-1</span>)).type_as(tgt_mask.data))</span><br><span class="line">        <span class="keyword">return</span> tgt_mask</span><br></pre></td></tr></tbody></table></figure>
<p>Batch构造函数的输入是src和trg，后者可以为None，因为再预测的时候是没有tgt的。</p>
<p>我们用一个例子来说明Batch的代码，这是训练阶段的一个Batch，<strong>src是(48, 20)</strong>，48是batch大小，而20是最长的句子长度，其它的不够长的都padding成20了。而<strong>trg是(48, 25)</strong>，表示翻译后的最长句子是25个词，不足的也padding过了。</p>
<p>我们首先看src_mask怎么得到，(src != pad)把src中大于0的时刻置为1，这样表示它可以attend to的范围。然后unsqueeze(-2)把src_mask变成(48/batch, 1, 20/time)。它的用法参考前面的attention函数。</p>
<p>对于训练来说(Teaching Forcing模式)，Decoder有一个输入和一个输出。<strong>比如句子”<sos> it is a good day <eos>”，输入会变成”<sos> it is a good day”，而输出为”it is a good day <eos>”。对应到代码里，self.trg就是输入，而self.trg_y就是输出。</eos></sos></eos></sos></strong>接着对输入self.trg进行mask，使得Self-Attention不能访问未来的输入。这是通过make_std_mask函数实现的，这个函数会调用我们之前详细介绍过的subsequent_mask函数。最终得到的<strong>trg_mask的shape是(48/batch, 24, 24)</strong>，表示24个时刻的Mask矩阵，这是一个对角线以及之下都是1的矩阵，前面已经介绍过了。</p>
<p>注意<strong>src_mask的shape是(batch, 1, time)</strong>，而<strong>trg_mask是(batch, time, time)</strong>。因为src_mask的每一个时刻都能attend to所有时刻(padding的除外)，一次只需要一个向量就行了，而trg_mask需要一个矩阵。</p>
<h4 id="training-loop">Training Loop</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_epoch</span><span class="params">(data_iter, model, loss_compute)</span>:</span> <span class="comment">#返回total_loss / total_tokens 。是一个数值，损失计算</span></span><br><span class="line">    <span class="comment">#遍历一个epoch的数据</span></span><br><span class="line">    <span class="string">"Standard Training and Logging Function"</span></span><br><span class="line">    start = time.time() <span class="comment">#开始时间，计算用时</span></span><br><span class="line">    total_tokens = <span class="number">0</span> </span><br><span class="line">    total_loss = <span class="number">0</span> </span><br><span class="line">    tokens = <span class="number">0</span> </span><br><span class="line">    <span class="keyword">for</span> i, batch <span class="keyword">in</span> enumerate(data_iter): <span class="comment">#每一步data_iter（gen_data），实例化batch数据用于学习.进行20次</span></span><br><span class="line">        <span class="comment">#gen_data返回的是20个Batch，通过enumerate实例化20个batch </span></span><br><span class="line">        out = model.forward(batch.src, batch.trg, </span><br><span class="line">                            batch.src_mask, batch.trg_mask) <span class="comment">#调用EncoderDecoder的实例化model，解码器作为输出</span></span><br><span class="line">        loss = loss_compute(out, batch.trg_y, batch.ntokens) <span class="comment">#计算出一个batch中的loss。 trg_y是标准值。ntokens作为norm</span></span><br><span class="line">        total_loss += loss <span class="comment">#loss叠加。进行20次</span></span><br><span class="line">        total_tokens += batch.ntokens </span><br><span class="line">        tokens += batch.ntokens</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">1</span>: <span class="comment">#i从0开始的，当i=1的时候，进行了一次batch，所以这里计算的就是一次batch所用的时间。而要进行20次。  50是随机设置</span></span><br><span class="line">            elapsed = time.time() - start <span class="comment">#计算一共用时</span></span><br><span class="line">            print(<span class="string">"Epoch Step: %d Loss: %f Tokens per Sec: %f"</span> % </span><br><span class="line">                    (i, loss / batch.ntokens, tokens / elapsed)) <span class="comment">#所有batch中的loss和ntoken,即一个epoch中</span></span><br><span class="line">            start = time.time() <span class="comment"># 重置时间</span></span><br><span class="line">            tokens = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> total_loss / total_tokens</span><br></pre></td></tr></tbody></table></figure>
<p>它遍历一个epoch的数据，然后调用forward，接着用loss_compute函数计算梯度，更新参数并且返回loss。这里的loss_compute是一个函数，它的输入是模型的预测out，真实的标签序列batch.trg_y和batch的词个数。实际的实现是MultiGPULossCompute类，这是一个callable。本来计算损失和更新参数比较简单，但是这里为了实现多GPU的训练，这个类就比较复杂了。</p>
<h4 id="training-data-和-batching">Training Data 和 Batching</h4>
<p>We trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million sentence pairs. Sentences were encoded using byte-pair encoding, which has a shared source-target vocabulary of about 37000 tokens. For English- French, we used the significantly larger WMT 2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece vocabulary.</p>
<p>Sentence pairs were batched together by approximate sequence length. Each training batch contained a set of sentence pairs containing approximately 25000 source tokens and 25000 target tokens.</p>
<blockquote>
<p>We will use torch text for batching. This is discussed in more detail below. Here we create batches in a torchtext function that ensures our batch size padded to the maximum batchsize does not surpass a threshold (25000 if we have 8 gpus).</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">global</span> max_src_in_batch, max_tgt_in_batch</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_size_fn</span><span class="params">(new, count, sofar)</span>:</span></span><br><span class="line">    <span class="string">"Keep augmenting batch and calculate total number of tokens + padding."</span></span><br><span class="line">    <span class="keyword">global</span> max_src_in_batch, max_tgt_in_batch</span><br><span class="line">    <span class="keyword">if</span> count == <span class="number">1</span>:</span><br><span class="line">        max_src_in_batch = <span class="number">0</span></span><br><span class="line">        max_tgt_in_batch = <span class="number">0</span></span><br><span class="line">    max_src_in_batch = max(max_src_in_batch,  len(new.src))</span><br><span class="line">    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + <span class="number">2</span>)</span><br><span class="line">    src_elements = count * max_src_in_batch</span><br><span class="line">    tgt_elements = count * max_tgt_in_batch</span><br><span class="line">    <span class="keyword">return</span> max(src_elements, tgt_elements)</span><br></pre></td></tr></tbody></table></figure>
<h4 id="硬件-和-训练进度">硬件 和 训练进度</h4>
<p>We trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using the hyperparameters described throughout the paper, each training step took about 0.4 seconds. We trained the base models for a total of 100,000 steps or 12 hours. For our big models, step time was 1.0 seconds. The big models were trained for 300,000 steps (3.5 days).</p>
<h4 id="optimizer">Optimizer</h4>
<p>We used the <code>Adam optimizer</code> <a href="https://arxiv.org/abs/1412.6980" target="_blank" rel="noopener">(cite)</a> with β1=0.9β1=0.9, β2=0.98β2=0.98 and ϵ=10−9ϵ=10−9. We varied the learning rate over the course of training, according to the formula: lrate=d−0.5model⋅min(step_num−0.5,step_num⋅warmup_steps−1.5)lrate=dmodel−0.5⋅min(step_num−0.5,step_num⋅warmup_steps−1.5) This corresponds to increasing the learning rate linearly for the first warmupstepswarmupsteps training steps, and decreasing it thereafter proportionally to the inverse square root of the step number. We used warmupsteps=4000warmupsteps=4000.</p>
<blockquote>
<p>Note: This part is very important. Need to train with this setup of the model.</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NoamOpt</span>:</span></span><br><span class="line">    <span class="string">"Optim wrapper that implements rate."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, model_size, factor, warmup, optimizer)</span>:</span></span><br><span class="line">        self.optimizer = optimizer</span><br><span class="line">        self._step = <span class="number">0</span></span><br><span class="line">        self.warmup = warmup</span><br><span class="line">        self.factor = factor</span><br><span class="line">        self.model_size = model_size</span><br><span class="line">        self._rate = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"Update parameters and rate"</span></span><br><span class="line">        self._step += <span class="number">1</span></span><br><span class="line">        rate = self.rate()</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> self.optimizer.param_groups:</span><br><span class="line">            p[<span class="string">'lr'</span>] = rate</span><br><span class="line">        self._rate = rate</span><br><span class="line">        self.optimizer.step()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rate</span><span class="params">(self, step = None)</span>:</span></span><br><span class="line">        <span class="string">"Implement `lrate` above"</span></span><br><span class="line">        <span class="keyword">if</span> step <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            step = self._step</span><br><span class="line">        <span class="keyword">return</span> self.factor * \</span><br><span class="line">            (self.model_size ** (<span class="number">-0.5</span>) *</span><br><span class="line">            min(step ** (<span class="number">-0.5</span>), step * self.warmup ** (<span class="number">-1.5</span>)))</span><br><span class="line">        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_std_opt</span><span class="params">(model)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> NoamOpt(model.src_embed[<span class="number">0</span>].d_model, <span class="number">2</span>, <span class="number">4000</span>,</span><br><span class="line">            torch.optim.Adam(model.parameters(), lr=<span class="number">0</span>, betas=(<span class="number">0.9</span>, <span class="number">0.98</span>), eps=<span class="number">1e-9</span>))</span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<p>Example of the curves of this model for different model sizes and for optimization hyperparameters.</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># Three settings of the lrate hyperparameters.</span></span><br><span class="line">opts = [NoamOpt(<span class="number">512</span>, <span class="number">1</span>, <span class="number">4000</span>, <span class="literal">None</span>), </span><br><span class="line">        NoamOpt(<span class="number">512</span>, <span class="number">1</span>, <span class="number">8000</span>, <span class="literal">None</span>),</span><br><span class="line">        NoamOpt(<span class="number">256</span>, <span class="number">1</span>, <span class="number">4000</span>, <span class="literal">None</span>)]</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, <span class="number">20000</span>), [[opt.rate(i) <span class="keyword">for</span> opt <span class="keyword">in</span> opts] <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">20000</span>)])</span><br><span class="line">plt.legend([<span class="string">"512:4000"</span>, <span class="string">"512:8000"</span>, <span class="string">"256:4000"</span>])</span><br><span class="line"><span class="literal">None</span></span><br></pre></td></tr></tbody></table></figure>
<p><img src="http://nlp.seas.harvard.edu/images/the-annotated-transformer_69_0.png" alt="png"></p>
<h4 id="regularization">Regularization</h4>
<h5 id="label-smoothing">Label Smoothing</h5>
<p>During training, we employed label smoothing of value ϵls=0.1ϵls=0.1 <a href="https://arxiv.org/abs/1512.00567" target="_blank" rel="noopener">(cite)</a>. This hurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.</p>
<blockquote>
<p>We implement label smoothing using the KL div loss. Instead of using a one-hot target distribution, we create a distribution that has <code>confidence</code> of the correct word and the rest of the <code>smoothing</code> mass distributed throughout the vocabulary.</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LabelSmoothing</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Implement label smoothing."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, padding_idx, smoothing=<span class="number">0.0</span>)</span>:</span></span><br><span class="line">        super(LabelSmoothing, self).__init__()</span><br><span class="line">        self.criterion = nn.KLDivLoss(size_average=<span class="literal">False</span>)  <span class="comment">#KL散度</span></span><br><span class="line">        self.padding_idx = padding_idx</span><br><span class="line">        self.confidence = <span class="number">1.0</span> - smoothing</span><br><span class="line">        self.smoothing = smoothing</span><br><span class="line">        self.size = size</span><br><span class="line">        self.true_dist = <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, target)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> x.size(<span class="number">1</span>) == self.size</span><br><span class="line">        true_dist = x.data.clone()</span><br><span class="line">        true_dist.fill_(self.smoothing / (self.size - <span class="number">2</span>))</span><br><span class="line">        true_dist.scatter_(<span class="number">1</span>, target.data.unsqueeze(<span class="number">1</span>), self.confidence)</span><br><span class="line">        true_dist[:, self.padding_idx] = <span class="number">0</span></span><br><span class="line">        mask = torch.nonzero(target.data == self.padding_idx)</span><br><span class="line">        <span class="keyword">if</span> mask.dim() &gt; <span class="number">0</span>:</span><br><span class="line">            true_dist.index_fill_(<span class="number">0</span>, mask.squeeze(), <span class="number">0.0</span>)</span><br><span class="line">        self.true_dist = true_dist</span><br><span class="line">        <span class="keyword">return</span> self.criterion(x, Variable(true_dist, requires_grad=<span class="literal">False</span>))</span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<p>Here we can see an example of how the mass is distributed to the words based on confidence.</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># Example of label smoothing.</span></span><br><span class="line">crit = LabelSmoothing(<span class="number">5</span>, <span class="number">0</span>, <span class="number">0.4</span>)</span><br><span class="line">predict = torch.FloatTensor([[<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>],</span><br><span class="line">                             [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>], </span><br><span class="line">                             [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>]])</span><br><span class="line">v = crit(Variable(predict.log()), </span><br><span class="line">         Variable(torch.LongTensor([<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>])))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show the target distributions expected by the system.</span></span><br><span class="line">plt.imshow(crit.true_dist)</span><br><span class="line"><span class="literal">None</span></span><br></pre></td></tr></tbody></table></figure>
<p><img src="http://nlp.seas.harvard.edu/images/the-annotated-transformer_74_0.png" alt="png"></p>
<blockquote>
<p>Label smoothing actually starts to penalize the model if it gets very confident about a given choice.</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">crit = LabelSmoothing(<span class="number">5</span>, <span class="number">0</span>, <span class="number">0.1</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(x)</span>:</span></span><br><span class="line">    d = x + <span class="number">3</span> * <span class="number">1</span></span><br><span class="line">    predict = torch.FloatTensor([[<span class="number">0</span>, x / d, <span class="number">1</span> / d, <span class="number">1</span> / d, <span class="number">1</span> / d],</span><br><span class="line">                                 ])</span><br><span class="line">    <span class="comment">#print(predict)</span></span><br><span class="line">    <span class="keyword">return</span> crit(Variable(predict.log()),</span><br><span class="line">                 Variable(torch.LongTensor([<span class="number">1</span>]))).data[<span class="number">0</span>]</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, <span class="number">100</span>), [loss(x) <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">100</span>)])</span><br><span class="line"><span class="literal">None</span></span><br></pre></td></tr></tbody></table></figure>
<p><img src="http://nlp.seas.harvard.edu/images/the-annotated-transformer_76_0.png" alt="png"></p>
<h3 id="总结"><strong>总结</strong></h3>
<p>transformer模型主要分为两大部分, 分别是编码器和解码器, 编码器负责把自然语言序列映射成为隐藏层(下图中第2步用九宫格比喻的部分), 含有自然语言序列的数学表达. 然后解码器把隐藏层再映射为自然语言序列, 从而使我们可以解决各种问题, 如情感分类, 命名实体识别, 语义关系抽取, 摘要生成, 机 器翻译等等, 下面我们简单说一下下图的每一步都做了什么:</p>
<blockquote>
<p>1.输入自然语言序列到编码器: Why do we work?(为什么要工作);</p>
<p>2.编码器输出的隐藏层, 再输入到解码器;</p>
<p>3.输入&lt;𝑠𝑡𝑎𝑟𝑡&gt;<start>(起始)符号到解码器;</start></p>
<p>4.得到第一个字"为";</p>
<p>5.将得到的第一个字"为"落下来再输入到解码器;</p>
<p>6.得到第二个字"什";</p>
<p>7.将得到的第二字再落下来, 直到解码器输出&lt;𝑒𝑛𝑑&gt;<end>(终止符), 即序列生成完成.</end></p>
</blockquote>
<p><img src="https://i.loli.net/2020/08/06/1pea3WSThisHBql.png" alt="image-20200806233205808" style="zoom:67%;"></p>
<p><img src="https://i.loli.net/2020/08/07/ZGa1snNULJtjFWS.png" alt="transformer"></p>
<p>原始data数据是：(30,10)</p>
<p>src: (30,10) trg:(30,10)</p>
<p>在encoder中，</p>
<p>embedding： 参数x就是 src （30,10） 经过处理之后， x:（30,10,512） -&gt; 即输入给encoder的x：(30,10,512)</p>
<p>经过encoder各个层处理之后，输出的（30，10,512） memory是encoder的输出，但是为什么memory：（1,10,512） ??? 因为在预测时 ，src是（1,10），不是（30,10）所以memory是（1,10,512）</p>
<p>decoder中：输入来自 memory 和 trg_emd</p>
<p>embedding ： 参数x是trg（30,9），经过处理之后，x：（30,9,512)</p>
<p>经过decoder各个层处理之后，输出的（30，9 , 512）</p>
<p>再经过generator层之后，x：（30,9,11）</p>
<p>在预测的时候是（1，1,512），不是（1,9,512），在预测完generator之后，（1,11），选一个最大的。</p>
<p>因为是一个数字一个数字预测输出的，所以是1，不是9</p>
<h3 id="第一个例子">第一个例子</h3>
<blockquote>
<p>We can begin by trying out a simple copy-task. Given a random set of input symbols from a small vocabulary, the goal is to generate back those same symbols.</p>
</blockquote>
<h4 id="synthetic-data">Synthetic Data</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_gen</span><span class="params">(V, batch, nbatches)</span>:</span> <span class="comment"># batch=30:一次输入多少， nbatch=20：输入多少次</span></span><br><span class="line">    <span class="string">"Generate random data for a src-tgt copy task."</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(nbatches): <span class="comment">#一共循环nbatches个，在每一个是一个batch</span></span><br><span class="line">		<span class="comment">#from_numpy ： 将numpy数据转换为tensor</span></span><br><span class="line">		<span class="comment">#注：生成返回的tensor会和ndarry共享数据，任何对tensor的操作都会影响到ndarry</span></span><br><span class="line">        data = torch.from_numpy(np.random.randint(<span class="number">1</span>, V, size=(batch, <span class="number">10</span>))) <span class="comment">#1是产生的最小值，V=11是最大值，size是形状（batch，10）。生成（batch，10）的矩阵，矩阵的每一个元素都是1~V-1之间  （取不到V）</span></span><br><span class="line">        data[:, <span class="number">0</span>] = <span class="number">1</span> <span class="comment">#将第0列的值赋值为1</span></span><br><span class="line">        <span class="comment"># Variable 就是一个存放值， 里面的值会不停的变化.  存放的是Torch 的 Tensor . 如果用一个 Variable 进行计算, 那返回的也是一个同类型的 Variable.  </span></span><br><span class="line">        <span class="comment">#requires_grad： 是否参与误差反向传播, 要不要计算梯度</span></span><br><span class="line">        src = Variable(data, requires_grad=<span class="literal">False</span>) <span class="comment">#size(batch,10) 和data的值完全一样</span></span><br><span class="line">        tgt = Variable(data, requires_grad=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">yield</span> Batch(src, tgt, <span class="number">0</span>)<span class="comment">#yield就是return一个值，并且记住这个返回的位置，下次迭代就从这个位置后(下一行)开始</span></span><br><span class="line">        <span class="comment">#batch返回的是trg_mask</span></span><br></pre></td></tr></tbody></table></figure>
<h4 id="loss-computation">Loss Computation</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleLossCompute</span>:</span> <span class="comment">#loss计算以及更新。调用LabelSmoothing，使用KL散度</span></span><br><span class="line">    <span class="string">"A simple loss compute and train function."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, generator, criterion, opt=None)</span>:</span></span><br><span class="line">        self.generator = generator <span class="comment">#解码器后的生成函数</span></span><br><span class="line">        self.criterion = criterion <span class="comment"># LabelSmoothing（计算loss KLDivLoss KL散度）的实例化</span></span><br><span class="line">        self.opt = opt <span class="comment"># NoamOpt（优化）的实例化</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, x, y, norm)</span>:</span></span><br><span class="line">        x = self.generator(x) <span class="comment">#解码器的输出</span></span><br><span class="line">        loss = self.criterion(x.contiguous().view(<span class="number">-1</span>, x.size(<span class="number">-1</span>)), </span><br><span class="line">                              y.contiguous().view(<span class="number">-1</span>)) / norm  <span class="comment">#计算loss</span></span><br><span class="line">        loss.backward() <span class="comment">#将loss反向传播。loss是标量，根据链式法则自动计算出叶子节点的梯度值</span></span><br><span class="line">        <span class="keyword">if</span> self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: <span class="comment">#存在优化</span></span><br><span class="line">            self.opt.step() <span class="comment">#调用opt的step函数。 adam优化，，更新参数</span></span><br><span class="line">            self.opt.optimizer.zero_grad() <span class="comment">#把梯度置零，也就是把loss关于weight的导数变成0.</span></span><br><span class="line">        <span class="keyword">return</span> loss.data[<span class="number">0</span>] * norm</span><br></pre></td></tr></tbody></table></figure>
<h4 id="greedy-decoding">Greedy Decoding</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># Train the simple copy task.</span></span><br><span class="line">V = <span class="number">11</span></span><br><span class="line">criterion = LabelSmoothing(size=V, padding_idx=<span class="number">0</span>, smoothing=<span class="number">0.0</span>) <span class="comment">#LabelSmoothing是KL散度实现的</span></span><br><span class="line">model = make_model(V, V, N=<span class="number">2</span>) <span class="comment">#src_vocab=11, tgt_vocab=11，覆盖N=2</span></span><br><span class="line"><span class="comment"># 对模型参数进行更新优化，使用Adam优化</span></span><br><span class="line">model_opt = NoamOpt(model.src_embed[<span class="number">0</span>].d_model, <span class="number">1</span>, <span class="number">400</span>,</span><br><span class="line">        torch.optim.Adam(model.parameters(), lr=<span class="number">0</span>, betas=(<span class="number">0.9</span>, <span class="number">0.98</span>), eps=<span class="number">1e-9</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#model.eval()，pytorch会自动把BN和DropOut固定住，不会取平均，而是用训练好的值。</span></span><br><span class="line"><span class="comment">#model.train() 让model变成训练模式，此时dropout和batch normalization的操作在训练起到防止网络过拟合的问题</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>): <span class="comment">#一共10大份， model.train()打印1行，model.eval()打印1行</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="comment">#调用run_epoch(data_iter, model, loss_compute)函数</span></span><br><span class="line">    <span class="comment">#返回total_loss / total_tokens 。返回值可以没有接收，不会报错</span></span><br><span class="line">    run_epoch(data_gen(V, <span class="number">30</span>, <span class="number">20</span>), model, </span><br><span class="line">              SimpleLossCompute(model.generator, criterion, model_opt))</span><br><span class="line">    model.eval()</span><br><span class="line">    <span class="comment">#print接收run_epoch的返回值 在输出的第三行</span></span><br><span class="line">    print(run_epoch(data_gen(V, <span class="number">30</span>, <span class="number">5</span>), model, </span><br><span class="line">                    SimpleLossCompute(model.generator, criterion, <span class="literal">None</span>)))</span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">3.023465</span> Tokens per Sec: <span class="number">403.074173</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.920030</span> Tokens per Sec: <span class="number">641.689380</span></span><br><span class="line"><span class="number">1.9274832487106324</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.940011</span> Tokens per Sec: <span class="number">432.003378</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.699767</span> Tokens per Sec: <span class="number">641.979665</span></span><br><span class="line"><span class="number">1.657595729827881</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.860276</span> Tokens per Sec: <span class="number">433.320240</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.546011</span> Tokens per Sec: <span class="number">640.537198</span></span><br><span class="line"><span class="number">1.4888023376464843</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.682198</span> Tokens per Sec: <span class="number">432.092305</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.313169</span> Tokens per Sec: <span class="number">639.441857</span></span><br><span class="line"><span class="number">1.3485562801361084</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.278768</span> Tokens per Sec: <span class="number">433.568756</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.062384</span> Tokens per Sec: <span class="number">642.542067</span></span><br><span class="line"><span class="number">0.9853351473808288</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.269471</span> Tokens per Sec: <span class="number">433.388727</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.590709</span> Tokens per Sec: <span class="number">642.862135</span></span><br><span class="line"><span class="number">0.5686767101287842</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.997076</span> Tokens per Sec: <span class="number">433.009746</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.343118</span> Tokens per Sec: <span class="number">642.288427</span></span><br><span class="line"><span class="number">0.34273059368133546</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.459483</span> Tokens per Sec: <span class="number">434.594030</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.290385</span> Tokens per Sec: <span class="number">642.519464</span></span><br><span class="line"><span class="number">0.2612409472465515</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.031042</span> Tokens per Sec: <span class="number">434.557008</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.437069</span> Tokens per Sec: <span class="number">643.630322</span></span><br><span class="line"><span class="number">0.4323212027549744</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.617165</span> Tokens per Sec: <span class="number">436.652626</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.258793</span> Tokens per Sec: <span class="number">644.372296</span></span><br><span class="line"><span class="number">0.27331129014492034</span></span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<p>This code predicts a translation using greedy decoding for simplicity.</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#预测过程</span></span><br><span class="line"><span class="comment">#预测的时候没有用tgt（标准值），而是每次解码器的输入都是ys，是预测的值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greedy_decode</span><span class="params">(model, src, src_mask, max_len, start_symbol)</span>:</span></span><br><span class="line">    memory = model.encode(src, src_mask) <span class="comment">#memory是编码器的输出 。是一个矩阵</span></span><br><span class="line">    ys = torch.ones(<span class="number">1</span>, <span class="number">1</span>).fill_(start_symbol).type_as(src.data) <span class="comment">#填充输出开始符，和src的类型一样。对预测的句子进行初始化 ys =1 （1,1）</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(max_len<span class="number">-1</span>): <span class="comment">#0~8 对每一个词都进行预测</span></span><br><span class="line">        out = model.decode(memory, src_mask, </span><br><span class="line">                           Variable(ys), </span><br><span class="line">                           Variable(subsequent_mask(ys.size(<span class="number">1</span>))</span><br><span class="line">                                    .type_as(src.data)))</span><br><span class="line">         <span class="comment"># ys 的维度是 batch_size * times （固定的）,   所以target_mask 矩阵必须是ys.size(1),所以是 times * times</span></span><br><span class="line">        <span class="comment"># 根据 decoder 的训练步骤, 这里的 out 输出就应该是 batch_size * (times+1) 的矩阵</span></span><br><span class="line">        </span><br><span class="line">        prob = model.generator(out[:, <span class="number">-1</span>]) <span class="comment">#generator返回的是softmax</span></span><br><span class="line">          <span class="comment"># out[:, -1] 这里是最新的一个单词的 embedding 向量</span></span><br><span class="line">        <span class="comment"># generator 就是产生最后的 vocabulary 的概率, 是一个全连接层</span></span><br><span class="line">        </span><br><span class="line">        _, next_word = torch.max(prob, dim = <span class="number">1</span>) <span class="comment"># torch.max:按维度dim 返回最大值，并且会返回索引。next_data接收											#索引</span></span><br><span class="line">        next_word = next_word.data[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 将句子拼接起来  .type_as: 将tensor强制转换为src.data 格式的</span></span><br><span class="line">        ys = torch.cat([ys, </span><br><span class="line">                        torch.ones(<span class="number">1</span>, <span class="number">1</span>).type_as(src.data).fill_(next_word)], dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> ys</span><br><span class="line"></span><br><span class="line">model.eval()</span><br><span class="line">src = Variable(torch.LongTensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>]]) )</span><br><span class="line">src_mask = Variable(torch.ones(<span class="number">1</span>, <span class="number">1</span>, <span class="number">10</span>) )</span><br><span class="line">print(greedy_decode(model, src, src_mask, max_len=<span class="number">10</span>, start_symbol=<span class="number">1</span>))</span><br><span class="line">    <span class="number">1</span>     <span class="number">2</span>     <span class="number">3</span>     <span class="number">4</span>     <span class="number">5</span>     <span class="number">6</span>     <span class="number">7</span>     <span class="number">8</span>     <span class="number">9</span>    <span class="number">10</span></span><br><span class="line">[torch.LongTensor of size <span class="number">1</span>x10]</span><br></pre></td></tr></tbody></table></figure>
<h3 id="真实例子">真实例子</h3>
<blockquote>
<p>Now we consider a real-world example using the IWSLT German-English Translation task. This task is much smaller than the WMT task considered in the paper, but it illustrates the whole system. We also show how to use multi-gpu processing to make it really fast.</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#!pip install torchtext spacy</span></span><br><span class="line"><span class="comment">#!python -m spacy download en</span></span><br><span class="line"><span class="comment">#!python -m spacy download de</span></span><br></pre></td></tr></tbody></table></figure>
<h4 id="data-loading">Data Loading</h4>
<blockquote>
<p>We will load the dataset using torchtext and spacy for tokenization.</p>
<p>用torchtext来加载数据集 ， 用spacy来分词</p>
</blockquote>
<p><img src="https://i.loli.net/2020/08/07/teSG1hufEjF4Zkv.png" alt="image-20200807001353729" style="zoom: 67%;"></p>
<p>torchtext组件流程：</p>
<blockquote>
<ul>
<li>定义Field：声明如何处理数据，主要包含以下数据预处理的配置信息，比如指定分词方法，是否转成小写，起始字符，结束字符，补全字符以及词典等等</li>
<li>定义Dataset：用于得到数据集，继承自pytorch的Dataset。此时数据集里每一个样本是一个 经过 Field声明的预处理 预处理后的 wordlist</li>
<li>建立vocab：在这一步建立词汇表，词向量(word embeddings)</li>
<li>构造迭代器Iterator：: 主要是数据输出的模型的迭代器。构造迭代器，支持batch定制用来分批次训练模型。</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># For data loading.</span></span><br><span class="line"><span class="keyword">from</span> torchtext <span class="keyword">import</span> data, datasets</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">import</span> spacy</span><br><span class="line">    spacy_de = spacy.load(<span class="string">'de'</span>) <span class="comment">#加载德语语言模型</span></span><br><span class="line">    spacy_en = spacy.load(<span class="string">'en'</span>) <span class="comment">#加载英语语言模型</span></span><br><span class="line">	</span><br><span class="line">    </span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">   在文本处理的过程中，spaCy首先对文本分词，原始文本在空格处分割，类似于text.split(' ')，然后分词器（Tokenizer）从左向右依次处理token</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenize_de</span><span class="params">(text)</span>:</span> <span class="comment">#Tokenizer:分词器  进行德语分词  </span></span><br><span class="line">        <span class="comment">#text：输入的段落句子  tok.text：分后的token词</span></span><br><span class="line">        <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> spacy_de.tokenizer(text)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenize_en</span><span class="params">(text)</span>:</span> <span class="comment"># 进行英语分词</span></span><br><span class="line">        <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> spacy_en.tokenizer(text)]</span><br><span class="line"></span><br><span class="line">    BOS_WORD = <span class="string">'&lt;s&gt;'</span>  <span class="comment">#开始符</span></span><br><span class="line">    EOS_WORD = <span class="string">'&lt;/s&gt;'</span> <span class="comment">#终止符</span></span><br><span class="line">    BLANK_WORD = <span class="string">"&lt;blank&gt;"</span> <span class="comment">#空格</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 构建Filed对象，声明如何处理数据。主要包含以下数据预处理的配置信息，比如指定分词方法，是否转成小写，		#起始字符，结束字符，补全字符以及词典等等</span></span><br><span class="line">    SRC = data.Field(tokenize=tokenize_de, pad_token=BLANK_WORD) <span class="comment">#得到源句子</span></span><br><span class="line">    TGT = data.Field(tokenize=tokenize_en, init_token = BOS_WORD,  </span><br><span class="line">                     eos_token = EOS_WORD, pad_token=BLANK_WORD)</span><br><span class="line"></span><br><span class="line">    MAX_LEN = <span class="number">100</span> <span class="comment">#最大长度</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># https://s3.amazonaws.com/opennmt-models/iwslt.pt 数据集</span></span><br><span class="line">    <span class="comment">#同时对训练集和验证集还有测试集的构建，此时数据集里每一个样本是一个 经过 Field声明的预处理 预处理后的 	#wordlist</span></span><br><span class="line">    train, val, test = datasets.IWSLT.splits(</span><br><span class="line">        exts=(<span class="string">'.de'</span>, <span class="string">'.en'</span>)   <span class="comment"># 构建数据集所需的数据集</span></span><br><span class="line">        , fields=(SRC, TGT),  <span class="comment">#如何赋值给train那三个的？？？？</span></span><br><span class="line">        filter_pred=<span class="keyword">lambda</span> x: len(vars(x)[<span class="string">'src'</span>]) &lt;= MAX_LEN <span class="keyword">and</span> </span><br><span class="line">            len(vars(x)[<span class="string">'trg'</span>]) &lt;= MAX_LEN)  <span class="comment">#源句子和目标句子长度小于100的筛选出来</span></span><br><span class="line">    </span><br><span class="line">    MIN_FREQ = <span class="number">2</span> <span class="comment">#定义最小频率</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#建立词汇表，词向量(word embeddings)。即需要给每个单词编码，然后输入模型</span></span><br><span class="line">    <span class="comment">#bulid_vocab()方法中传入用于构建词表的数据集</span></span><br><span class="line">    SRC.build_vocab(train.src, min_freq=MIN_FREQ) </span><br><span class="line">    TGT.build_vocab(train.trg, min_freq=MIN_FREQ)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#一旦运行了这些代码行，SRC.vocab.stoi将是一个词典，其词汇表中的标记作为键，而其对应的索引作为值； 	#SRC.vocab.itos将是相同的字典，其中的键和值被交换。</span></span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<p>批训练对于速度来说很重要。希望批次分割非常均匀并且填充最少。 要做到这一点，我们<strong>必须修改torchtext默认的批处理函数</strong>。 这部分代码修补其默认批处理函数，以确保我们搜索足够多的句子以构建紧密批处理。 一般来说直接调用<code>BucketIterator</code> （训练用）和 <code>Iterator</code>（测试用） 即可</p>
<p><code>BucketIterator</code>和<code>Iterator</code>的区别是，BucketIterator尽可能的把长度相似的句子放在一个batch里面。</p>
</blockquote>
<h4 id="iterators">Iterators</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">定义一个迭代器，该迭代器将相似长度的示例批处理在一起。 在为每个新纪元(epoch)生产新鲜改组的批次时，最大程度地减少所需的填充量。</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyIterator</span><span class="params">(data.Iterator)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">create_batches</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#在train的时候，要进行sort，尽量减少padding</span></span><br><span class="line">        <span class="comment">#目的是自动进行shuffle和padding，并且为了训练效率期间，尽量把句子长度相似的shuffle在一起。</span></span><br><span class="line">        <span class="keyword">if</span> self.train:</span><br><span class="line">            <span class="function"><span class="keyword">def</span> <span class="title">pool</span><span class="params">(d, random_shuffler)</span>:</span></span><br><span class="line">                <span class="keyword">for</span> p <span class="keyword">in</span> data.batch(d, self.batch_size * <span class="number">100</span>):</span><br><span class="line">                    p_batch = data.batch(</span><br><span class="line">                        sorted(p, key=self.sort_key), <span class="comment">#按照词的数大小排序</span></span><br><span class="line">                        self.batch_size, self.batch_size_fn)</span><br><span class="line">                    <span class="keyword">for</span> b <span class="keyword">in</span> random_shuffler(list(p_batch)):</span><br><span class="line">                        <span class="keyword">yield</span> b <span class="comment">#b就是batch， 类比上述的gen_data函数</span></span><br><span class="line">            self.batches = pool(self.data(), self.random_shuffler) <span class="comment">#调用pool</span></span><br><span class="line">            </span><br><span class="line">         <span class="comment">#在valid+test(验证集和测试集)的时候  和上面具体区别在哪？？？？</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.batches = []</span><br><span class="line">            <span class="keyword">for</span> b <span class="keyword">in</span> data.batch(self.data(), self.batch_size,</span><br><span class="line">                                          self.batch_size_fn):</span><br><span class="line">                self.batches.append(sorted(b, key=self.sort_key))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rebatch</span><span class="params">(pad_idx, batch)</span>:</span>  <span class="comment">#pad_idx：空格键</span></span><br><span class="line">    <span class="string">"Fix order in torchtext to match ours"</span></span><br><span class="line">    src, trg = batch.src.transpose(<span class="number">0</span>, <span class="number">1</span>), batch.trg.transpose(<span class="number">0</span>, <span class="number">1</span>)<span class="comment">#为什么要进行</span></span><br><span class="line">    <span class="keyword">return</span> Batch(src, trg, pad_idx) <span class="comment">#调用上述的Batch类   pad_idx就是pad</span></span><br></pre></td></tr></tbody></table></figure>
<h4 id="multi-gpu-training">Multi-GPU Training</h4>
<blockquote>
<p>最后为了真正地快速训练，将使用多个GPU。 这部分代码实现了多GPU字生成，它不是Transformer特有的。 其<strong>思想是将训练时的单词生成分成块，以便在许多不同的GPU上并行处理。</strong> 我们使用PyTorch并行原语来做到这一点：</p>
<ul>
<li>replicate -复制 - 将模块拆分到不同的GPU上</li>
<li>scatter -分散 - 将批次拆分到不同的GPU上</li>
<li>parallel_apply -并行应用 - 在不同GPU上将模块应用于批处理</li>
<li>gather - 聚集 - 将分散的数据聚集到一个GPU上</li>
<li>nn.DataParallel - 一个特殊的模块包装器，在评估之前调用它们。</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># Skip if not interested in multigpu.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiGPULossCompute</span>:</span></span><br><span class="line">    <span class="string">"A multi-gpu loss compute and train function."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, generator, criterion, devices, opt=None, chunk_size=<span class="number">5</span>)</span>:</span></span><br><span class="line">        <span class="comment"># Send out to different gpus.</span></span><br><span class="line">        self.generator = generator</span><br><span class="line">        self.criterion = nn.parallel.replicate(criterion, </span><br><span class="line">                                               devices=devices)</span><br><span class="line">        self.opt = opt</span><br><span class="line">        self.devices = devices</span><br><span class="line">        self.chunk_size = chunk_size</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, out, targets, normalize)</span>:</span></span><br><span class="line">        total = <span class="number">0.0</span></span><br><span class="line">        generator = nn.parallel.replicate(self.generator, </span><br><span class="line">                                                devices=self.devices)</span><br><span class="line">        out_scatter = nn.parallel.scatter(out, </span><br><span class="line">                                          target_gpus=self.devices)</span><br><span class="line">        out_grad = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> out_scatter]</span><br><span class="line">        targets = nn.parallel.scatter(targets, </span><br><span class="line">                                      target_gpus=self.devices)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Divide generating into chunks.</span></span><br><span class="line">        chunk_size = self.chunk_size</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, out_scatter[<span class="number">0</span>].size(<span class="number">1</span>), chunk_size):</span><br><span class="line">            <span class="comment"># Predict distributions</span></span><br><span class="line">            out_column = [[Variable(o[:, i:i+chunk_size].data, </span><br><span class="line">                                    requires_grad=self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>)] </span><br><span class="line">                           <span class="keyword">for</span> o <span class="keyword">in</span> out_scatter]</span><br><span class="line">            gen = nn.parallel.parallel_apply(generator, out_column)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Compute loss. </span></span><br><span class="line">            y = [(g.contiguous().view(<span class="number">-1</span>, g.size(<span class="number">-1</span>)), </span><br><span class="line">                  t[:, i:i+chunk_size].contiguous().view(<span class="number">-1</span>)) </span><br><span class="line">                 <span class="keyword">for</span> g, t <span class="keyword">in</span> zip(gen, targets)]</span><br><span class="line">            loss = nn.parallel.parallel_apply(self.criterion, y)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Sum and normalize loss</span></span><br><span class="line">            l = nn.parallel.gather(loss, </span><br><span class="line">                                   target_device=self.devices[<span class="number">0</span>])</span><br><span class="line">            l = l.sum()[<span class="number">0</span>] / normalize</span><br><span class="line">            total += l.data[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Backprop loss to output of transformer</span></span><br><span class="line">            <span class="keyword">if</span> self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                l.backward()</span><br><span class="line">                <span class="keyword">for</span> j, l <span class="keyword">in</span> enumerate(loss):</span><br><span class="line">                    out_grad[j].append(out_column[j][<span class="number">0</span>].grad.data.clone())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Backprop all loss through transformer.            </span></span><br><span class="line">        <span class="keyword">if</span> self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            out_grad = [Variable(torch.cat(og, dim=<span class="number">1</span>)) <span class="keyword">for</span> og <span class="keyword">in</span> out_grad]</span><br><span class="line">            o1 = out</span><br><span class="line">            o2 = nn.parallel.gather(out_grad, </span><br><span class="line">                                    target_device=self.devices[<span class="number">0</span>])</span><br><span class="line">            o1.backward(gradient=o2)</span><br><span class="line">            self.opt.step()</span><br><span class="line">            self.opt.optimizer.zero_grad()</span><br><span class="line">        <span class="keyword">return</span> total * normalize</span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<p>Now we create our model, criterion, optimizer, data iterators, and paralelization</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># GPUs to use</span></span><br><span class="line">devices = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="keyword">if</span> <span class="literal">True</span>:</span><br><span class="line">    pad_idx = TGT.vocab.stoi[<span class="string">"&lt;blank&gt;"</span>]</span><br><span class="line">    model = make_model(len(SRC.vocab), len(TGT.vocab), N=<span class="number">6</span>)</span><br><span class="line">    model.cuda()</span><br><span class="line">    criterion = LabelSmoothing(size=len(TGT.vocab), padding_idx=pad_idx, smoothing=<span class="number">0.1</span>)</span><br><span class="line">    criterion.cuda()</span><br><span class="line">    BATCH_SIZE = <span class="number">12000</span></span><br><span class="line">    train_iter = MyIterator(train, batch_size=BATCH_SIZE, device=<span class="number">0</span>,</span><br><span class="line">                            repeat=<span class="literal">False</span>, sort_key=<span class="keyword">lambda</span> x: (len(x.src), len(x.trg)),</span><br><span class="line">                            batch_size_fn=batch_size_fn, train=<span class="literal">True</span>)</span><br><span class="line">    valid_iter = MyIterator(val, batch_size=BATCH_SIZE, device=<span class="number">0</span>,</span><br><span class="line">                            repeat=<span class="literal">False</span>, sort_key=<span class="keyword">lambda</span> x: (len(x.src), len(x.trg)),</span><br><span class="line">                            batch_size_fn=batch_size_fn, train=<span class="literal">False</span>)</span><br><span class="line">    model_par = nn.DataParallel(model, device_ids=devices)</span><br><span class="line"><span class="literal">None</span></span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<p>Now we <strong>train the model</strong>. I will play with the warmup steps a bit, but everything else uses the default parameters. On an AWS p3.8xlarge with 4 Tesla V100s, this runs at ~27,000 tokens per second with a batch size of 12,000</p>
<p>在具有4个Tesla V100 GPU的AWS p3.8xlarge机器上，每秒运行约27,000个词，批训练大小为12,000。</p>
</blockquote>
<h4 id="training-the-system">Training the System</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#!wget https://s3.amazonaws.com/opennmt-models/iwslt.pt</span></span><br><span class="line"><span class="comment">#进行train和eval</span></span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: <span class="comment"># false存在的意义在哪？？？ 使用GPU？</span></span><br><span class="line">    model_opt = NoamOpt(model.src_embed[<span class="number">0</span>].d_model, <span class="number">1</span>, <span class="number">2000</span>,</span><br><span class="line">            torch.optim.Adam(model.parameters(), lr=<span class="number">0</span>, betas=(<span class="number">0.9</span>, <span class="number">0.98</span>), eps=<span class="number">1e-9</span>))</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        model_par.train()</span><br><span class="line">        run_epoch((rebatch(pad_idx, b) <span class="keyword">for</span> b <span class="keyword">in</span> train_iter), </span><br><span class="line">                  model_par, </span><br><span class="line">                  MultiGPULossCompute(model.generator, criterion, </span><br><span class="line">                                      devices=devices, opt=model_opt))</span><br><span class="line">        model_par.eval()</span><br><span class="line">        loss = run_epoch((rebatch(pad_idx, b) <span class="keyword">for</span> b <span class="keyword">in</span> valid_iter), </span><br><span class="line">                          model_par, </span><br><span class="line">                          MultiGPULossCompute(model.generator, criterion, </span><br><span class="line">                          devices=devices, opt=<span class="literal">None</span>))</span><br><span class="line">        print(loss)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    model = torch.load(<span class="string">"iwslt.pt"</span>) <span class="comment">#加载所有的tensor到CPU</span></span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<p>Once trained we can decode the model to produce a set of translations. Here we simply translate the first sentence in the validation set. This dataset is pretty small so the translations with greedy search are reasonably accurate.</p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#类比于run_epoch函数  </span></span><br><span class="line"><span class="keyword">for</span> i, batch <span class="keyword">in</span> enumerate(valid_iter):</span><br><span class="line">    src = batch.src.transpose(<span class="number">0</span>, <span class="number">1</span>)[:<span class="number">1</span>]</span><br><span class="line">    src_mask = (src != SRC.vocab.stoi[<span class="string">"&lt;blank&gt;"</span>]).unsqueeze(<span class="number">-2</span>)</span><br><span class="line">    out = greedy_decode(model, src, src_mask, </span><br><span class="line">                        max_len=<span class="number">60</span>, start_symbol=TGT.vocab.stoi[<span class="string">"&lt;s&gt;"</span>])</span><br><span class="line">    print(<span class="string">"Translation:"</span>, end=<span class="string">"\t"</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, out.size(<span class="number">1</span>)):</span><br><span class="line">        sym = TGT.vocab.itos[out[<span class="number">0</span>, i]]</span><br><span class="line">        <span class="keyword">if</span> sym == <span class="string">"&lt;/s&gt;"</span>: <span class="keyword">break</span></span><br><span class="line">        print(sym, end =<span class="string">" "</span>)</span><br><span class="line">    print()</span><br><span class="line">    print(<span class="string">"Target:"</span>, end=<span class="string">"\t"</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, batch.trg.size(<span class="number">0</span>)):</span><br><span class="line">        sym = TGT.vocab.itos[batch.trg.data[i, <span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">if</span> sym == <span class="string">"&lt;/s&gt;"</span>: <span class="keyword">break</span></span><br><span class="line">        print(sym, end =<span class="string">" "</span>)</span><br><span class="line">    print()</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">Translation:	&lt;unk&gt; &lt;unk&gt; . In my language , that means , thank you very much . </span><br><span class="line">Gold:	&lt;unk&gt; &lt;unk&gt; . It means <span class="keyword">in</span> my language , thank you very much .</span><br></pre></td></tr></tbody></table></figure>
<h3 id="理解qkv">理解QKV</h3>
<p>作者：繁华里流浪 链接：https://www.zhihu.com/question/298810062/answer/1336554776 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<p>我认为attention主要分为两个核心步骤：1. 计算注意力权重 2. 加权求和</p>
<p>其中Q(query)，K(key)用来计算对应的注意力权重atten_i，V(value)用来进行加权求和也就是求最后attention的结果。</p>
<p><img src="E:\myBlog\source_posts\image-20200904164236348.png" alt="image-20200904164236348"></p>
<p>在理解attention的时候我想了一个买水果的例子。今天你要去水果摊买水果，首先你脑袋里会想出一个买水果的标准（个大、成色好、价格美丽等）作为 query，然后你就去各个水果摊逛了，水果摊主上来给你拿出水果一顿介绍（我这香甜可口，新鲜美味，性价比高）这就是 key，然后你会通过水果的情况 key 和自己心中标准 query 权衡给这个水果摊子打个分，当你一条水果街都走完了，你就对整条街的水果摊都有了一个性价比分数（atten），然后根据这个性价比分数就开始买了，这个水果摊好分数高，我买多点，那个水果摊性价比分数低不能满足我的需求我就少买点，最后我就从不同的水果摊采购了不同数量的水果（value）放进了自己的推推车里（output）</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>transformer</category>
      </categories>
      <tags>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-07-25-服务器心得</title>
    <url>/2020/07/25/2020-07-25-%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BF%83%E5%BE%97/</url>
    <content><![CDATA[<p>目前使用的是Xshell + FileZilla（连接+传输） ， MobaXterm也可用于ssh连接的备用软件。</p>
<p>MobaXterm（<a href="https://link.zhihu.com/?target=https%3A//mobaxterm.mobatek.net/">https://mobaxterm.mobatek.net/</a>）：功能很全，免费，有免安装版，支持多标签，同时自带文件传输系统，唯一的不足是对Z-moderm支持较差。</p>
<h3 id="linux后台执行命令和nohup">linux后台执行命令：&amp;和nohup</h3>
<p>在用本机Xshell连接服务器跑实验时，如果关闭本机电脑，Xshell不再运行时，那么linux终端会话就会关闭，跑的实验就会终止。有时候更希望它能够在每天的非负荷高峰时间段运行(例如凌晨)。为了使这些进程能够在后台运行，也就是说不在终端屏幕上运行，有几种选择方法可供使用。</p>
<h4 id="使用">&amp;使用</h4>
<p>在执行文件的时候，可以在命令后面加上<code>&amp;</code>，这样可以实现将进程挂到后台运行。例如： <code>python main.py &amp;</code></p>
<p>在使用&amp;之后，系统会返回一个进程号PID，需要记下此进程的PID</p>
<h4 id="nohup使用">nohup使用</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">nohup python main.py &amp;</span><br></pre></td></tr></tbody></table></figure>
<p>这样执行的时候会将代码放在服务器后台执行，你的终端是看不到运行过程的，<strong>期间运行的结果</strong>（代码运行过程中打印出来的）会在一个生成的<code>nohup.out文件</code>中保存。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">nohup python main.py &gt;test.log  <span class="number">2</span>&gt;&amp;<span class="number">1</span> &amp;</span><br><span class="line"><span class="comment"># nohup和&amp; 一起使用。 &amp; 放后台</span></span><br><span class="line"><span class="comment"># &gt;表示将标准输出（STDOUT）重定向到test.log文件</span></span><br><span class="line"><span class="comment">#2&gt;&amp;1 ：把标准输出和标准错误一起重定向到一个文件中。1是标准输出的文件描述符，2是标准错误的文件描述符；</span></span><br></pre></td></tr></tbody></table></figure>
<p>可以实现运行main.py ，并将输出结果打印到<code>test.log文件</code>中（如果这个文件不存在, 那就创建, 否则就覆盖）</p>
<p>要想使ssh连接断掉也可以继续后台运行，需要用<code>exit命令</code>断开，否则其它关闭行为视为断开异常（如直接关掉xsheel软件），不会后台运行</p>
<h4 id="nohup与session的关系">nohup与session的关系</h4>
<p><code>如果我们在 session 中执行了 nohup 等类似的命令，当 session 消亡时，相关的进程并不会随着 session 结束，原因是这些进程不再受 SIGHUP 信号的影响。</code>比如我们执行下面的命令：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">$ nohup sleep <span class="number">1000</span> &gt;/dev/null <span class="number">2</span>&gt;&amp;<span class="number">1</span> &amp;</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2020/07/29/cAzPToGdLKmRZ2e.png" alt="img"></p>
<p>此时 sleep 进程的 sid 和其它进程是相同的，还可以通过 pstree 命令看到进程间的父子关系：</p>
<p><img src="https://i.loli.net/2020/07/29/8ZQDMlkmTHy1a2G.png" alt="img"></p>
<p><code>如果我们退出当前 session 的领头进程(bash)，sleep 进程并不会退出，这样我们就可以放心的等待该进程运行结果了。</code> nohup 并不改变进程的 sid，同时也说明在这种情况中，虽然 session 的领头进程退出了，但是 session 依然没有被销毁(至少 sid 还在被引用)。重新建立连接，通过下面的命令查看 sleep 进程的信息，发现进程的 sid 依然是 7837：</p>
<p><img src="https://i.loli.net/2020/07/29/5O83jJ2Hfsdoyil.png" alt="img"></p>
<p>但是<code>此时的 sleep 已经被系统的 1 号进程 systemd 收养了</code>：</p>
<p><img src="https://i.loli.net/2020/07/29/9quLvTHCNnES4F7.png" alt="img"></p>
<h5 id="参考">参考</h5>
<blockquote>
<p>https://www.cnblogs.com/sparkdev/p/12146305.html</p>
</blockquote>
<h4 id="忘记进程">忘记进程</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">ps -ef | grep main.py  <span class="comment">#其中main.py是要查找的关键字</span></span><br><span class="line">ps -ef | grep main.py  | grep -v grep <span class="comment">#grep -v 排除进程。此时是排除grep自身的进程</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">ps命令将某个进程显示出来</span><br><span class="line"></span><br><span class="line">grep命令是查找</span><br><span class="line"></span><br><span class="line">中间的|是管道命令 是指ps命令与grep同时执行</span><br><span class="line"></span><br><span class="line">字段含义如下：</span><br><span class="line">UID    PID    PPID    C   STIME   TTY    TIME     CMD</span><br><span class="line"></span><br><span class="line">zzw   <span class="number">14124</span>  <span class="number">13991</span>   <span class="number">0</span>   <span class="number">00</span>:<span class="number">38</span>   pts/<span class="number">0</span>   <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>  grep --color=auto dae</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">UID   ：程序被该 UID 所拥有</span><br><span class="line"></span><br><span class="line">PID   ：就是这个程序的 ID </span><br><span class="line"></span><br><span class="line">PPID  ：则是其上级父程序的ID</span><br><span class="line"></span><br><span class="line">C     ：CPU使用的资源百分比</span><br><span class="line"></span><br><span class="line">STIME ：系统启动时间</span><br><span class="line"></span><br><span class="line">TTY   ：登入者的终端机位置</span><br><span class="line"></span><br><span class="line">TIME  ：使用掉的CPU时间。</span><br><span class="line"></span><br><span class="line">CMD  ：所下达的是什么指令</span><br></pre></td></tr></tbody></table></figure>
<p>这里是两个shell命令通过管道进行了结合，第一个ps能够列出当前系统所有活跃的进程，然后通过grep 关键字查找就能找到带有关键字的进程。<code>找到PID</code>（PID是输出的第二列那个数字）再杀掉。</p>
<h4 id="关闭进程">关闭进程</h4>
<p><code>kill -9 PID</code> . 用普通的ctrl+C是关不掉的</p>
<h4 id="疑问">疑问：</h4>
<p>在根指令行可以进行nohup，但是我用tmux建立会话之后，在tmux中是不可以运用notop，会弹出 <code>exit 1</code> 的错误指令？？？？</p>
<p>一种方法就是在后台运行之后，再进入tmux操作</p>
<h3 id="htop使用">htop使用</h3>
<h4 id="功能介绍">功能介绍</h4>
<p>监视内存，线程，CPU运行状态</p>
<p>htop是Linux系统下一个基本文本模式的、交互式的进程查看器，主要用于控制台或shell中，可以替代top，或者说是top的高级版。</p>
<h4 id="安装htop">安装htop</h4>
<p>Ubuntu <code>sudo apt-get install htop</code></p>
<h4 id="使用htop">使用htop</h4>
<h5 id="界面概述">界面概述</h5>
<p>安装完成后，命令行中直接敲击 htop 命令，即可进入 htop 的界面</p>
<p><img src="https://i.loli.net/2020/09/05/6URqObNc7Efkm5H.png" alt="image-20200905224348455"></p>
<p>各项从上至下分别说明如下：</p>
<p><a href="https://blog.xiewenlong.com/2018/12/htop/base.png" target="_blank" rel="noopener"><img src="https://blog.xiewenlong.com/2018/12/htop/base.png" alt="img"></a></p>
<p>左边部分从上至下，分别为，cpu、内存、交换分区的使用情况，右边部分为：Tasks 为进程总数，当前运行的进程数、Load average 为系统 1 分钟，5 分钟，10 分钟的平均负载情况、Uptime 为系统运行的时间。</p>
<p><a href="https://blog.xiewenlong.com/2018/12/htop/process.png" target="_blank" rel="noopener"><img src="https://blog.xiewenlong.com/2018/12/htop/process.png" alt="img"></a></p>
<p>以上各项分别为：</p>
<ul>
<li><strong>PID：</strong>进程的标识号</li>
<li><strong>USER：</strong>运行此进程的用户</li>
<li><strong>PRI：</strong>进程的优先级</li>
<li><strong>NI：</strong>进程的优先级别值，默认的为 0，可以进行调整</li>
<li><strong>VIRT：</strong>进程占用的虚拟内存值</li>
<li><strong>RES：</strong>进程占用的物理内存值</li>
<li><strong>SHR：</strong>进程占用的共享内存值</li>
<li><strong>S：</strong>进程的运行状况，R 表示正在运行、S 表示休眠，等待唤醒、Z 表示僵死状态</li>
<li><strong>%CPU：</strong>该进程占用的CPU使用率</li>
<li><strong>%MEM：</strong>该进程占用的物理内存和总内存的百分比</li>
<li><strong>TIME+：</strong>该进程启动后占用的总的 CPU 时间</li>
<li><strong>COMMAND：</strong>进程启动的启动命令名称</li>
</ul>
<h4 id="操作说明">操作说明</h4>
<p><code>htop</code> 界面底部给出了 F1 ~ F10 按键的简单说明。</p>
<p><a href="https://blog.xiewenlong.com/2018/12/htop/bottom.png" target="_blank" rel="noopener"><img src="https://blog.xiewenlong.com/2018/12/htop/bottom.png" alt="img"></a></p>
<h5 id="标注进程条目">标注进程条目</h5>
<p>在系统中运行着的实时进程视图中，要追踪某个进程是个大问题。因为整个列表在不停的刷新着，进程的排列顺序也在变动着。为了这个问题， <code>htop</code> 提供了一个很简单的解决方案：颜色标注。是的，你可以标注一个进程条目，它会以不同的颜色显示，因此要追踪它就变得容易了。</p>
<p>要标注某个进程条目，需要做的就是选中此条目，然后按下<code>空格</code>键。例如，在下面的截图示例中，我已经颜色标注了两个进程条目（黄色高亮显示的两行）:</p>
<p><img src="https://blog.xiewenlong.com/2018/12/htop/tag.png" alt="img"></p>
<h5 id="命令行选项">命令行选项</h5>
<p>除了上面介绍的一些热键，<code>htop</code> 还提供了很有用的命令行选项。下面是其中一部分:</p>
<ul>
<li><code>-s 选项</code> : 按指定的列排序。例如，<code>htop -s PID</code> 命令会按 PID 列的大小排序来显示。</li>
<li><code>-u 选项</code> : 显示指定的用户的进程信息列表。例如，<code>htop -u vagrant</code> 命令会只显示出用户名为 vagrant 的相关进程。</li>
<li><code>-d 选项</code> : 设置刷新的延迟时间。例如，<code>htop -d 100</code> 命令会使输出在 1 秒后才会刷新（参数 -d 的单位是 10 微秒）。</li>
<li><code>-p 选项</code>：只显示给定的PIDs。例如， <code>htop -p PID</code></li>
</ul>
<h5 id="常用命令">常用命令</h5>
<p><strong>shift + m</strong> ： 按照内存大小排序。 <strong>shift + h</strong> ： 收缩线程。 <strong>q</strong> ： 退出</p>
<p><strong>上下键</strong> 或 <strong>PgUP，PgDn</strong> : 选定想要的进程， <strong>左右键</strong> 或 <strong>Home，End</strong> : 移动字段，当然也可以直接用鼠标选定进程； <strong>Space</strong> 标记/取消标记一个进程（类似 windows 按着 Ctrl 多选一样 ）。命令可以作用于多个进程，例如 "kill"，将应用于所有已标记的进程</p>
<h4 id="参考-1">参考</h4>
<blockquote>
<p>https://blog.xiewenlong.com/2018/12/htop/</p>
</blockquote>
<h3 id="nvidia-smi使用">nvidia-smi使用</h3>
<p><code>nvidia-smi</code> 显示出当前GPU的所有基础信息，监控GPU状态和使用情况。命令判断哪几块GPU空闲</p>
<p><img src="https://i.loli.net/2020/07/22/u1CtU8Xgor45inh.png" alt="image-20200722153957282"></p>
<h4 id="解释相关参数含义">解释相关参数含义</h4>
<p>GPU：本机中的GPU编号</p>
<p>Name：GPU 类型</p>
<p>Persistence-M：</p>
<p>Fan：风扇转速</p>
<p>Temp：温度，单位摄氏度</p>
<p>Perf：表征性能状态，从P0到P12，P0表示最大性能，P12表示状态最小性能</p>
<p>Pwr:Usage/Cap：能耗表示</p>
<p>Bus-Id：涉及GPU总线的相关信息；</p>
<p>Disp.A：Display Active，表示GPU的显示是否初始化</p>
<p>Memory-Usage：显存使用率</p>
<p>Volatile GPU-Util：浮动的GPU利用率</p>
<p>Uncorr. ECC：关于ECC的东西</p>
<p>Compute M.：计算模式</p>
<p>Processes 显示每块GPU上每个进程所使用的显存情况</p>
<h3 id="tmux使用">Tmux使用</h3>
<h4 id="安装tmux--linux">安装tmux -linux</h4>
<p><code>sudo apt-get install tmux</code></p>
<h4 id="基本概念">基本概念</h4>
<p>tmux采用C/S模型构建，<code>输入tmux命令就相当于开启了一个服务器</code>，此时默认将新建一个会话，然后会话中默认新建一个窗口，窗口中默认新建一个面板。会话、窗口、面板之间的联系如下：</p>
<p><img src="https://i.loli.net/2020/07/27/l4YyAISG8d1Lcp9.png" alt="image-20200726233552371"></p>
<p>一个tmux <code>session</code>（会话）可以包含多个<code>window</code>（窗口），窗口默认充满会话界面，因此这些窗口中可以运行相关性不大的任务。</p>
<p>一个<code>window</code>又可以包含多个<code>pane</code>（面板），窗口下的面板，都处于同一界面下，这些面板适合运行相关性高的任务，以便同时观察到它们的运行情况。</p>
<p>一般在一个<code>session</code>里进行新建<code>windows</code>和<code>pane</code>操作即可</p>
<p>一个session显示如图</p>
<p><img src="https://i.loli.net/2020/07/27/3bWsR57zZTUODF6.png" alt="img"></p>
<h4 id="会话">会话</h4>
<h5 id="新建会话">新建会话</h5>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">tmux  <span class="comment"># 新建一个无名称的会话 </span></span><br><span class="line"></span><br><span class="line">tmux new -s s1 <span class="comment"># 新建一个名称为s1的会话</span></span><br></pre></td></tr></tbody></table></figure>
<h5 id="断开当前会话">断开当前会话</h5>
<p>暂时断开会话，可以进入到原始命令行界面进行操作。也可以<code>Ctrl+B  +d</code>进行断开</p>
<p>操作如 <code>tmux new -s demo</code></p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">tmux detach <span class="comment"># 断开当前会话，会话在后台运行</span></span><br></pre></td></tr></tbody></table></figure>
<h5 id="进入之前的会话">进入之前的会话</h5>
<p>断开会话后，想要接着上次留下的现场继续工作，就要使用到tmux的attach命令了，语法为<code>tmux attach-session -t session-name</code>，可简写为<code>tmux a -t session-name</code> 或 <code>tmux a</code>。通常我们使用如下两种方式之一即可：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">tmux a <span class="comment"># 默认进入第一个会话dd</span></span><br><span class="line">tmux a -t demo <span class="comment"># 进入到名称为demo的会话</span></span><br></pre></td></tr></tbody></table></figure>
<h5 id="关闭会话">关闭会话</h5>
<p>会话的使命完成后，一定是要关闭的。我们可以使用tmux的kill命令</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">tmux kill-session -t demo <span class="comment"># 关闭demo会话 </span></span><br><span class="line"></span><br><span class="line">tmux kill-server <span class="comment"># 关闭服务器，即关闭所有会话</span></span><br><span class="line"></span><br><span class="line">tmux kill-session -a -t s1　　<span class="comment">#关闭除s1外的所有会话</span></span><br></pre></td></tr></tbody></table></figure>
<h5 id="查看所有会话">查看所有会话</h5>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">tmux ls <span class="comment"># 查看所有会话，显示会话列表</span></span><br></pre></td></tr></tbody></table></figure>
<h5 id="重命名会话s1为s2">重命名会话S1为S2</h5>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">tmux rename -t s1 s2</span><br></pre></td></tr></tbody></table></figure>
<h4 id="tmux快捷指令">Tmux快捷指令</h4>
<p>tmux的所有指令，都包含同一个前缀，默认为<code>Ctrl+b</code>，输入完前缀过后，控制台激活，命令按键才能生效。</p>
<p><strong>表一：常用指令</strong></p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">前缀</th>
<th style="text-align: center;">指令</th>
<th style="text-align: center;">描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>s</code></td>
<td style="text-align: center;">显示会话列表用于选择并切换 （上下键选择+回车）</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>d</code></td>
<td style="text-align: center;">断开当前会话</td>
</tr>
<tr class="odd">
<td style="text-align: center;">===</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>c</code></td>
<td style="text-align: center;">新建窗口（windows）</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>&amp;</code></td>
<td style="text-align: center;">关闭当前窗口（关闭前需输入<code>y</code> or <code>n</code>确认）</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>w</code></td>
<td style="text-align: center;">打开窗口列表，用于且切换窗口</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>,</code></td>
<td style="text-align: center;">重命名当前窗口</td>
</tr>
<tr class="even">
<td style="text-align: center;">===</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>"</code></td>
<td style="text-align: center;">当前面板上下一分为二，下侧新建面板</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>%</code></td>
<td style="text-align: center;">当前面板左右一分为二，右侧新建面板</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>x</code></td>
<td style="text-align: center;">关闭当前面板（关闭前需输入<code>y</code> or <code>n</code>确认）</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>z</code></td>
<td style="text-align: center;">最大化当前面板，再重复一次按键后恢复正常（v1.8版本新增）</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>方向键</code></td>
<td style="text-align: center;">移动光标切换面板</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>Ctrl+o</code></td>
<td style="text-align: center;">顺时针旋转当前窗口中的所有面板</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>t</code></td>
<td style="text-align: center;">显示时钟</td>
</tr>
</tbody>
</table>
<p>表二：系统指令</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">前缀</th>
<th style="text-align: center;">指令</th>
<th style="text-align: center;">描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>?</code></td>
<td style="text-align: center;">显示快捷键帮助文档</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>d</code></td>
<td style="text-align: center;">断开当前会话</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>D</code></td>
<td style="text-align: center;">选择要断开的会话</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>Ctrl+z</code></td>
<td style="text-align: center;">挂起当前会话</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>r</code></td>
<td style="text-align: center;">强制重载当前会话</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>s</code></td>
<td style="text-align: center;">显示会话列表用于选择并切换</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>:</code></td>
<td style="text-align: center;">进入命令行模式，此时可直接输入<code>ls</code>等命令</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>[</code></td>
<td style="text-align: center;">进入复制模式，按<code>q</code>退出</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>]</code></td>
<td style="text-align: center;">粘贴复制模式中复制的文本</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>~</code></td>
<td style="text-align: center;">列出提示信息缓存</td>
</tr>
</tbody>
</table>
<p>表三：窗口（window）指令</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">前缀</th>
<th style="text-align: center;">指令</th>
<th style="text-align: center;">描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>c</code></td>
<td style="text-align: center;">新建窗口</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>&amp;</code></td>
<td style="text-align: center;">关闭当前窗口（关闭前需输入<code>y</code> or <code>n</code>确认）</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>0~9</code></td>
<td style="text-align: center;">切换到指定窗口</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>p</code></td>
<td style="text-align: center;">切换到上一窗口</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>n</code></td>
<td style="text-align: center;">切换到下一窗口</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>w</code></td>
<td style="text-align: center;">打开窗口列表，用于且切换窗口</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>,</code></td>
<td style="text-align: center;">重命名当前窗口</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>.</code></td>
<td style="text-align: center;">修改当前窗口编号（适用于窗口重新排序）</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>f</code></td>
<td style="text-align: center;">快速定位到窗口（输入关键字匹配窗口名称）</td>
</tr>
</tbody>
</table>
<p>表四：面板（pane）指令</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">前缀</th>
<th style="text-align: center;">指令</th>
<th style="text-align: left;">描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>"</code></td>
<td style="text-align: left;">当前面板上下一分为二，下侧新建面板</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>%</code></td>
<td style="text-align: left;">当前面板左右一分为二，右侧新建面板</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>x</code></td>
<td style="text-align: left;">关闭当前面板（关闭前需输入<code>y</code> or <code>n</code>确认）</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>z</code></td>
<td style="text-align: left;">最大化当前面板，再重复一次按键后恢复正常（v1.8版本新增）</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>!</code></td>
<td style="text-align: left;">将当前面板移动到新的窗口打开（原窗口中存在两个及以上面板有效）</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>;</code></td>
<td style="text-align: left;">切换到最后一次使用的面板</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>q</code></td>
<td style="text-align: left;">显示面板编号，在编号消失前输入对应的数字可切换到相应的面板</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>{</code></td>
<td style="text-align: left;">向前置换当前面板</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>}</code></td>
<td style="text-align: left;">向后置换当前面板</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>Ctrl+o</code></td>
<td style="text-align: left;">顺时针旋转当前窗口中的所有面板</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>方向键</code></td>
<td style="text-align: left;">移动光标切换面板</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>o</code></td>
<td style="text-align: left;">选择下一面板</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>空格键</code></td>
<td style="text-align: left;">在自带的面板布局中循环切换</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>Alt+方向键</code></td>
<td style="text-align: left;">以5个单元格为单位调整当前面板边缘</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>Ctrl+方向键</code></td>
<td style="text-align: left;">以1个单元格为单位调整当前面板边缘（Mac下被系统快捷键覆盖）</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>Ctrl+b</code></td>
<td style="text-align: center;"><code>t</code></td>
<td style="text-align: left;">显示时钟</td>
</tr>
</tbody>
</table>
<h4 id="tmux用于代码后台运行">tmux用于代码后台运行</h4>
<p>要想使代码后台运行，我用nohup训练模型时重定向到log文件发现日志显示不全，影响实验结果的呈现，而tmux可以解决这个问题。</p>
<p>在进入tmux，新建一个session的时候，实际上tmux在服务器创建了虚拟终端自己连自己。所以用ctrl+B +D退出tmux，并且断掉ssh连接时后台实验是一直在运行的。下次连接ssh后，再打开tmux的session即可，session不会断掉。并且不需要重定向，结果直接显示在屏幕上。</p>
<h4 id="tmux的个性化设置----待完成">tmux的个性化设置 -- 待完成</h4>
<p>比如通过写脚本，在新建session的时候就自动建多个pane，并运行命令</p>
<h4 id="参考-2">参考</h4>
<blockquote>
<p>http://louiszhai.github.io/2017/09/30/tmux/</p>
<p>https://harttle.land/2015/11/06/tmux-startup.html</p>
</blockquote>
<h3 id="zsh">zsh</h3>
<h4 id="安装">安装</h4>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt install git-core zsh</span><br></pre></td></tr></tbody></table></figure>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-09-06-如何保持高效学习工作</title>
    <url>/2020/09/06/2020-09-06-%E5%A6%82%E4%BD%95%E4%BF%9D%E6%8C%81%E9%AB%98%E6%95%88%E5%AD%A6%E4%B9%A0%E5%B7%A5%E4%BD%9C/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>多做总结，提高学习效率，不要拖延</p>
<h3 id="怎样从熬夜中恢复过来">怎样从熬夜中恢复过来</h3>
<p>1． 不要打盹，5min不能够得到休息</p>
<p>2． 吃早餐 一个小时内吃早餐（全谷物和蛋白质） ，可以充满活力，认知能力可以提高，最好不摄入糖，会让人发困</p>
<p>3． 出去走。自然光可以让身体发热</p>
<p>4． 开始办公时候，喝一杯咖啡</p>
<p>5． 工作：首先完成最困难的部分，最开始的几个小时是一天中效率最高的时候</p>
<p>6． 会议之前可以喝一杯咖啡，有效时间是半小时</p>
<p>7． 午饭不吃过多的糖，会犯困</p>
<p>8． 下午可以喝一杯咖啡这时候是最困的时候。三点之后不能摄入咖啡，有效时间7 小时</p>
<p>9． 下午可以做一下简单的事情</p>
<h3 id="在家寝室学习">在家&amp;寝室学习</h3>
<ol type="1">
<li><p>行为影响态度。换掉睡衣，接近类似学校的状态。希望自己成为什么样子， 就穿成什么样子</p></li>
<li></li>
</ol>
<p><img src="https://i.loli.net/2020/09/06/QDutkAwlLGgKTBo.png"></p>
<ol start="3" type="1">
<li>先做一道题再说。（计划太多，无从下手。过分犹豫）不要想太多，直接动手</li>
</ol>
<p><img src="https://i.loli.net/2020/09/06/CerZI164jAU85qO.png"></p>
<ol start="4" type="1">
<li>拒绝含糖食物</li>
</ol>
<p>自控力需要能量的供给，学习前可以吃块糖，可以补充能量。但是减少高gi食物，如酸奶果汁薯片，或者碳水类食物（米饭面条土豆）。多吃瘦肉、蔬菜、水果，能够增强自控力，还能瘦</p>
<ol start="5" type="1">
<li><p>不要用时间做计划，用学习量做计划。（因为会拖延）拒绝整点学习、计划学习时间，采用今天背多少单词等，一个清晰明确的目标会事半功倍</p></li>
<li><p>保持工作区的整洁，不放无关的物品。使手机飞行模式、黑白模式</p></li>
</ol>
<p><img src="https://i.loli.net/2020/09/06/UO5JydTCmLIKa12.png"></p>
<h3 id="戒掉手机避免用意志力来克制">戒掉手机（避免用意志力来克制）</h3>
<p>1． 替代法 并不是真正想做，而是习惯了某种行为。可以买一个手机模型，终止大脑的无意识行为，给大脑一个选择的机会</p>
<p>2． 心理暗示。‘我不玩手机‘ 而不是’我不能玩手机‘</p>
<p>3． 优化环境。环境的影响很大。搭建一个良好的环境。睡觉前把手机放在客厅，学习时增加获得手机的难度</p>
<p>4． 负面反馈。人们对于损失和负面事件的敏感度高于正面事件的敏感</p>
<p>5． 看实时学习视频，看到别人学习 自己也不好意思玩</p>
<p>休息放空自己，会使得注意力更集中</p>
<p>把社交软件放在小文件夹里再放到手指不容易碰到的地方，如果一段时间又习惯了点这个位置的社交软件，就再更换桌面排布</p>
<h3 id="自己习惯">自己习惯</h3>
<p>对于我自己来说，习惯睡觉前进行一些文字记录的工作，比如写博客做总结，就是不会再去接触一些新知识。把第二天要做的事情列好，或者直接找好第二天最难工作内容的参考资料，对第二天工作内容有一个大概的印象，这样第二天一早就可以直攻克艰难的部分，避免其它琐碎的事情</p>
<p>起床的时候，提前找好第二天要穿的衣服，同时可以适量补充水分</p>
<p>在进行学习的时候，先设置5分钟，休息5分钟，再逐渐增加时间，进入状态，多学习时间不休息</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
  </entry>
  <entry>
    <title>2020-09-06-不确定性研究</title>
    <url>/2020/09/06/2020-09-06-%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%A0%94%E7%A9%B6/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>近日，旷视上海研究院长危夷晨在将门技术社群做了一次题为《Uncertainty Learning for Visual Recognition》(不确定性学习在视觉计算中的应用) Online Talk，共分为4个部分：</p>
<ol type="1">
<li>Preliminary（基础知识）</li>
<li>Uncertainty in Deep Learning（深度学习中的不确定性问题）</li>
<li>Uncertainty in Computer Vision（不确定性的计算机视觉应用）</li>
<li>Summary（总结）</li>
</ol>
<p>我主要参考了前三部分的内容</p>
<h3 id="基础知识">基础知识</h3>
<h4 id="何为不确定性估计">何为不确定性估计</h4>
<p>要理解何为不确定性估计，我们可以先从<strong>确定性预测（deterministic prediction）</strong>开始。假设要对两张人脸进行对比，验证是否是同一个人的照片，那么可以使用人脸识别系统分别对这两张人脸图片提取特征，并使用某种度量指标衡量所提取的两个特征的相似程度，根据所预测出的相似程度来判断两张人脸图像是否从属同一个人。如果相似度很高（比如95%），则可以判断这两张人脸属于同一个人。这种通过预测一个确定性的人脸特征用来判断的方式被称为确定性预测（deterministic prediction）。</p>
<p>然而这个<strong>相似度分数并不总是有效</strong>，以下图中第二个例子为例，可以看到在输入图像中，一张非常清晰，另一张十分模糊，然而这个时候人脸识别系统依然给二者打出很高的相似度分数，那么面对这种情况，我们是否要相信系统给出的答案，我们是否有办法来判断系统给出这个分数的可靠程度？</p>
<p>为此，人们提出了另一个<strong>辅助判断的指标</strong>，即判断机器给出的答案是否可信，可信程度多少的分数被称为<strong>confidence score（置信度分数）</strong>。如下图第二行中，系统给出相似度95%，然而confidence score却只有10%，表明<strong>系统给出的相似度分数的可信度很低，因此我们在采纳系统给出的这个判断答案的时候需要十分谨慎。</strong></p>
<p>从这个案例可以知道，<strong>在confidence score分数背后存在一个核心思想，即很多时候机器学习系统给出的判断不一定是靠谱的，即，系统对于给出的判断具有一定程度的“不确定性”。</strong>那么此时人们就需要知道系统给出这个判断到底有几成把握，因此我们需要诸如置信度分数或者“不确定性”分数这样的额外信息来帮助我们做出更好的决策。</p>
<p><img src="https://i.loli.net/2020/09/06/xBqNOnrsRiM7o85.jpg" alt="img"></p>
<h4 id="为何不确定性重要">为何不确定性重要</h4>
<p>上面介绍完之后，我们再来谈谈它为什么重要。简单来讲，不确定性估计在深度学习之中有着广泛的应用场景，为其落地发挥着不可替代的重要作用，下面讲一些比较要代表性的场景：</p>
<ol type="1">
<li><strong>高风险应用场景</strong>。这类场景<strong>需要非常精确的估计</strong>，因为一旦估计错误，可能出现严重的后果，例如医疗图像诊断、自动驾驶。</li>
<li><strong>大量机器学习场景</strong>。比如，在主动学习（Active Learning）这种技术框架中，模型需要确定哪些样本更值得被打标签。这也涉及到系统对于估计样本“价值程度”不确定性。同时，研究人员往往也会发现单纯使用机器学习系统进行判断时，会存在少量样本系统无法做出很好的判断，因此这时人们会邀请专家来标记这部分困难样本，以训练模型。</li>
<li><strong>强化学习</strong>。强化学习由于经常要权衡exploration和exploitation操作，因此如何确定每一台机器的概率分布是否被准确估计，就是对这台机器模型参数的不确定性估计。</li>
<li><strong>对处于训练数据分布之外情况的检测</strong>。由于很多时候测试数据并不在训练数据中，因此如果测试数据超出了训练数据的数据分布，那这样的预测是没有准确度可言的，这时候就需要一个额外的不确定性估计来确认对当前的预测有多大把握。</li>
</ol>
<h4 id="两种不确定性">两种不确定性</h4>
<p>接下来，我们界定一下不确定性的分类问题。一般来讲，不确定性可以分为两类：</p>
<ol type="1">
<li><strong>数据的不确定性</strong>：也被称为偶然（Aleatoric）不确定性，它描述的是<strong>数据中内在的噪声，即无法避免的误差，这个现象不能通过增加采样数据来削弱。</strong>例如有时候拍照的手稍微颤抖画面便会模糊，这种数据是不能通过增加拍照次数来消除的。因此解决这个问题的方法一般是提升数据采集时候的稳定性，或者提升衡量指标的精度以囊括各类客观影响因素。</li>
<li><strong>模型的不确定性</strong>：也被称为认知（Epistemic）不确定性。它指出，<strong>模型自身对输入数据的估计可能因为训练不佳、训练数据不够等原因而不准确，与某一单独的数据无关</strong>。因此，认知不确定性测量的，是训练过程本身所估计的模型参数的不确定性。这种不确定性是可以通过有针对性的调整（增加训练数据等方式）来缓解甚至解决的。</li>
</ol>
<h3 id="深度学习中的不确定性问题">深度学习中的不确定性问题</h3>
<p><strong>如果单看深度学习网络本身，它是确定性的，例如简单的多层前馈网络，在训练好以后，其结构、权重以及对某一个样本所输出类别的概率都是确定的。因此，在深度神经网络中引入不确定性的一个方法就是引入贝叶斯法则，从而得到贝叶斯神经网络（BNN）。</strong></p>
<p>简单而言，如下图，贝叶斯神经网络的<strong>权重不像普通神经网络是一个具体数值，而是一个概率分布，表示每一个权重w遵循一个分布，而非之前是一个确定的数值</strong>。因此在训练和推理中，网络的权重会变化，<strong>根据分布来随机采样</strong>。通过这种方法可以建模各个参数本身存在的不确定性。</p>
<p><img src="https://i.loli.net/2020/09/06/6IRjbGw4cfT8mSB.jpg" alt="img"></p>
<p>然而，由于在实际应用中参数量十分巨大，要严格根据贝叶斯公式计算后验概率几乎不现实，因此为了将网络应用于大型数据集，就<strong>需要高效的近似计算方法</strong>。早期比较有名的方法是通过马尔科夫链蒙特卡洛采样法（MCMC-sampling）来逼近假定的参数分布，但是由于这种方法很慢，因此发展出了一系列更好的<strong>近似计算后验概率</strong>的方法，如下：</p>
<h4 id="变分推断">变分推断</h4>
<p>变分推断的基本方法就是<strong>引入变分分布对BNN优化过程中涉及到的后验概率进行近似估计，这种方法较为高效。</strong></p>
<p><img src="https://i.loli.net/2020/09/06/nQzKO2i1PYNkvuU.jpg"></p>
<h4 id="dropoutbnnvi">Dropout=BNN+VI</h4>
<p><img src="https://i.loli.net/2020/09/06/aQRWjzwDKIJl6eL.jpg" alt="img"></p>
<p>这种<strong>dropout方法</strong>也称为蒙特卡洛dropout，进一步简化了对后验概率分布的近似计算，它认为常见的dropout技术实际上等于在贝叶斯网络中进行变分推断。通过上图的对比，我们可以直观理解标准神经网络经过dropout之后，在每一层随机取消一些神经元，把连接变稀疏的网络是什么样子。</p>
<p>可以证明，<strong>在假设每一个神经元都服从一个离散的伯努利分布的情况下，经dropout方法处理的神经网络的优化过程实际上等价于在一个贝叶斯网络中进行变分推断。</strong>由于这种结构中每个节点的权重是被多个子网络共享的，因此它的训练和推理相对高效。这项理论成果近年来得到了较多的应用。</p>
<p>我们在前向传播的时候，让某个神经元的激活值以<strong>一定的概率p停止工作</strong>（每一个批次都是随机），这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征。</p>
<p><strong>dropout掉不同的隐藏神经元就类似在训练不同的网络，随机删掉一半隐藏神经元导致网络结构已经不同，整个dropout过程就相当于对很多个不同的神经网络取平均。而不同的网络产生不同的过拟合，一些互为“反向”的拟合相互抵消就可以达到整体上减少过拟合。</strong></p>
<h5 id="dropout具体工作流程">Dropout具体工作流程</h5>
<p>假设我们要训练这样一个神经网络，如图所示。</p>
<p><img src="https://i.loli.net/2020/09/06/SetbpsjYxEX1yQZ.jpg" alt="标准的神经网络"></p>
<p>输入是x输出是y，正常的流程是：我们首先把x通过网络前向传播，然后把误差反向传播以决定如何更新参数让网络进行学习。使用Dropout之后，过程变成如下：</p>
<p>（1）首先<strong>随机（临时）</strong>删掉网络中一半（dropout=0.5时）的隐藏神经元，输入输出神经元保持不变（图中虚线为部分临时被删除的神经元）</p>
<p><img src="https://i.loli.net/2020/09/06/GnirX4u39lSmyUg.jpg" alt="部分临时被删除的神经元"></p>
<p>（2） 然后把输入x通过修改后的网络前向传播，然后把得到的损失结果通过修改的网络反向传播。一小批训练样本执行完这个过程后，在<strong>没有被删除的神经元上</strong>按照随机梯度下降法更新对应的参数（w，b）。</p>
<p>（3）然后继续重复这一过程：</p>
<ul>
<li><strong>恢复被删掉的神经元</strong>（此时被删除的神经元保持原样，而没有被删除的神经元已经有所更新）</li>
<li>从隐藏层神经元中<strong>随机选择</strong>一个一半大小的子集临时删除掉（备份被删除神经元的参数）。</li>
<li>对一小批训练样本，先前向传播然后反向传播损失并根据随机梯度下降法更新参数（w，b） （没有被删除的那一部分参数得到更新，删除的神经元参数保持被删除前的结果）。</li>
</ul>
<p>不断重复这一过程。</p>
<h5 id="参考">参考</h5>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/38200980" target="_blank" rel="noopener">深度学习中Dropout原理解析</a></p>
</blockquote>
<h4 id="模型融合">模型融合</h4>
<p>这也是一种进行不确定性估计的基本方法，其大致思路是，<strong>从一个数据集中进行多次随机采样，分别训练模型，然后再将这些模型的推理结果综合，其均值作为预测结果，方差作为预测的不确定性。</strong>另外需要强调的是，蒙特卡洛dropout可以认为是一种特殊的模型融合方法。</p>
<p><img src="https://i.loli.net/2020/09/06/noXFIR2ACtwpmk1.jpg" alt="img"></p>
<h3 id="回归问题中的数据不确定性">回归问题中的数据不确定性</h3>
<p>这是一种数据估计的标准做法。<strong>给定输入x_i，解一个函数f(x_i)，使得它逼近ground truth y_i。假设这个函数f(x_i)遵循一个高斯分布，那么其均值就是y_i，方差就是σ（也依赖于x_i）。</strong></p>
<p><strong>这时，如果对这个高斯分布取似然度，再取负的log值，那么就可以得到下图中的损失函数L。因此在优化的时候，除了希望优化f(x_i)逼近y_i，同时也需要优化σ(x_i)，它表示这个高斯分布的不确定性，σ越大越不确定。</strong></p>
<p>因此当f很容易逼近y的时候，那么公式中第一项L2范数就会很小，这时即便σ也小，但结果依然不会很大；当f很难逼近y，即f很难学习的时候，第一项中的L2范数就会很大，这时优化过程就会使得σ也变大，从而使得整个第一项减小，因此学到的σ会随着数据学习的难度做自我调整。</p>
<p><img src="https://i.loli.net/2020/09/06/nlD62kW1pXygAV4.jpg" alt="img"></p>
<h4 id="简单例子">简单例子</h4>
<p>我们借助一个直观例子来理解模型不确定性与数据不确定性。首先这里的<strong>ground truth函数为一个正弦函数</strong>，即图中橙色的点是测试数据，而<strong>训练数据是从[-5，+5]区间采样的蓝色点，研究人员对每一个蓝色点都添加了高斯噪声，因此可以看到这些蓝色点明显偏离ground truth。</strong></p>
<p>下方左图是用贝叶斯网络加dropout进行的<strong>模型不确定性估计</strong>。<strong>红色曲线为估计出来的预测值，延其上下分布的黄色面积则为每一个点对应的方差</strong>。在进行模型不确定性估计时，系统会对每个输入点估计多次，每次会随机采样模型的权重，以求出对每个输入点多次预测所得到的均值和方差。可以发现，蓝色点区域之外的部分预测的方差很大，这是因为模型没有见过这样的数据。（<strong>因为蓝色是训练数据</strong>，其它是测试数据，没见过的，所以方差就会较大，也就是不确定性较高）</p>
<p>下方右图中红色曲线为估计出来的预测值，是<strong>数据不确定性估计</strong>，曲线上下的黄色跨度就是每一个点通过数据不确定性估计方法所学出的方差。可以发现，原本输入数据中有噪声的部分，其预测出的方差比较大，反映出模型对这样的输出拥有较大的不确定性。</p>
<p><img src="https://i.loli.net/2020/09/06/EjFQnPko6pVhYH5.jpg" alt="img"></p>
<h3 id="不确定性的计算机视觉应用">不确定性的计算机视觉应用</h3>
<p><img src="https://i.loli.net/2020/09/06/Gw6pNAvuisDe18a.png" alt="img"></p>
<p>尽管不确定性在机器学习中已经有很长历史，但是直到2017年（就我所知）随着NeurlPS论文<em>What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision</em>的提出，它才开始真正应用在基于深度学习的视觉预测任务中。这篇论文本身没有太多方法创新，通过将已知的方法 用于语义分割与深度回归任务，取得了不错的结果。<strong>通过在模型中引入不确定性估计的已有理论成果，使得原本任务的精度得到了显著提升。</strong></p>
<p>通过论文给出的定性结果可以较为直观的理解模型不确定性和数据不确定性。如下图，系统估计出来的不确定性是有明确含义即很容易理解的，图中上半部分做语义分割，下半部分做深度估计。</p>
<p><img src="https://picb.zhimg.com/80/v2-cf9cf0d7715af33b38dc8fa8b71b8aa0_1440w.jpg" alt="img"></p>
<p><strong>整张图的第4、5列分别是数据不确定性和模型不确定性的结果。红色部分表示不确定程度较大，蓝色部分表示较为确定。从数据不确定性结果（第4列）可以看到，红色部分往往出现在物体边界处，表示这些区域的像素更加具有二义性，系统不太清楚这部分像素究竟属于前景还是背景，另外这部分信息在训练数据中（即ground truth）往往也较模糊。可以发现，系统给出的数据不确定结果符合人类直观理解。</strong></p>
<p><strong>从模型不确定性结果（第5列）可以看到，模型对出现人的部分给出了很高的不确定性，这是因为模型在训练中很少遇到人的数据，因此模型很难估计出人所处位置的深度，将该区域标记为高度不确定。</strong></p>
<h4 id="物体检测中的数据不确定性">物体检测中的数据不确定性</h4>
<p><img src="https://i.loli.net/2020/09/06/RrKDqx7kFG8mJyl.jpg" alt="img"></p>
<p>在物体检测任务中，很大一部分不确定性来源于标注数据的不确定。上图给出了几个典型例子，可以看到，在标注边界框的时候，由于存在各种物体角度、遮挡，所以往往很难评价一个边界框标注的好坏。由于标注规则不一、数据本身存在的各种不确定性，因此具有二义性的数据标注会导致具有二义性的学习结果，从而将不确定性引入了模型，进一步输出结果也是不确定的。</p>
<p>针对这个问题，有研究人员在CVPR 2019、ICCV 2019提出了两篇颇有价值的论文，其核心思想类似，将每一个边界框的4个坐标均认为呈高斯分布，然后分别估计其均值和方差。用上述介绍的数据不确定性回归公式来替代传统的L1损失，将原来所需要预测的4个变量扩充为8个变量。</p>
<p>因此，这种方法除了可以估计边界框每一个坐标之外，还让它们都带有了一个不确定性参数。利用这些不确定性数据，可以进一步做很多事情（比如在NMS中作为权重来对边界框位置进行投票）。</p>
<h4 id="人脸识别中的模型不确定性">人脸识别中的模型不确定性</h4>
<p><img src="https://i.loli.net/2020/09/06/nWDBsXI2dNfaHTV.jpg" alt="img"></p>
<p>对于在人脸识别任务中如何估计模型不确定性，推荐大家上图中的论文工作，其核心思想是，将BNN+dropout用到人脸识别任务中，如图所示，dropout层（红色）被加在每一个卷积block之后，从而构建了一个蒙特卡洛Dropout网络。在训练过程中，每当流程到达这些层的时候，就会随机丢掉一些神经元，从而实现模拟参数分布的效果。在测试过程中，每一个图像都会经过该网络多次，进而可以多这些结果估计均值与方差，将方差作为预测结果的不确定性。</p>
<h4 id="人脸识别中的数据不确定性pfe方法">人脸识别中的数据不确定性：PFE方法</h4>
<p><img src="https://i.loli.net/2020/09/06/qPMvAkWN1UHK2e9.jpg" alt="img"></p>
<p>PFE方法全称为Probabilistic Face Embeddings，其核心思想是用概率分布来替代传统确定的人脸嵌入特征。传统的方法会将输入图像映射到一个高维空间中，得到一个表示特征的向量，然而对于这些方法而言，输出的向量都是确定的，因此被称为deterministic embedding。PFE引入了不确定性，将输出向量认为是一个概率分布，而不再是一个确定的向量，它有一个均值μ、方差σ。</p>
<p>均值代表对图像的嵌入，方差描述了模型对输入数据的不确定性。该方法希望同时估计μ和σ，并且σ能够根据输入图像的质量、包含噪声的程度进行自适应的学习。在上图右方的示例中可以看到，每一个输出的特征z不再是一个点，而是一个高斯形状的概率分布（椭圆），椭圆的大小就描述了估计的不确定性。</p>
<p><img src="https://i.loli.net/2020/09/06/O8mvS1VTIHodxZ5.png" alt="img"></p>
<p>从具体实现方法来看，PFE的创新值得借鉴，它并不直接去估计每一个均值μ，而是通过一个事先已经训练好的人脸识别模型来抽取每个样本的特征μ_i，然后研究人员再在网络中加入一个小分支，来对每个样本输出一个方差（比如假设μ_i是一个512维的向量，那么此时也会输出一个对μ_i的每一维度单独估计方差的512维方差向量）。</p>
<p>进一步，论文提出了一种新的metric——mutual likelihood score（MLS），来衡量两个分布间的距离。上图公式中x_i和x_j是两个样本在特定空间中的高斯分布，两个分布所得到的MLS数值就代表了其相似度。在训练过程中，针对所有positive 样本，计算负的MLS数值作为损失，并最小化该损失目标函数，进而可以估计新增加分支（估计方差的分支）的参数。</p>
<p><img src="https://picb.zhimg.com/80/v2-b2a72843a1b2199fb213df0e93e9d570_1440w.jpg" alt="img"></p>
<p>上图是论文对方差的解释，较为直观。可以发现红框标注出来的（方差超过一定阈值）图片都是姿态有较大变化、模糊、或者有遮挡的图片，系统都认为它们识别起来有较大不确定性；而正面、高清的图片不确定性普遍较小。为了进一步验证学习出来的不确定性是否能够有效解释图像质量，PFE在下方左图中进行了有关在低质量图像之间使用传统cosine相似度计算是否可靠的研究。</p>
<p>研究人员对清晰图片添加了不同程度的噪声，蓝色线代表原图与模糊图之间的相似度分数，而红色代表两张来自不同ID的图随模糊程度的增加所计算的相似度。可以发现对于同一ID（蓝线），随着模糊程度增加，相似度也逐渐降低；而对于不同ID，随着模糊程度增加相似度却在增加。这说明依据该相似度可能会将两张来自不同ID的模糊图像错认为是同一张图。这一现象在其它很多论文中也同样被观测到。</p>
<p><img src="https://picb.zhimg.com/80/v2-e38487eb964f4dc56b7ba89689ea5158_1440w.jpg" alt="img"></p>
<p>然而在经过PFE论文提出的MLS相似度修正之后，情况得到了很大改善。如右图，当图片模糊度增加时，对同样ID的图来说，其相似度没有变得太小，而不同ID图像的相似度也没有变得太大。这个实验证明这种计算图像相似度的新metric在面对低质量图片时更加鲁棒。</p>
<h4 id="pfe方法的缺陷">PFE方法的缺陷</h4>
<p>虽然PFE方法取得了重要进展，但是缺点也很明显，因为它并没有学习身份特征（identity-feature），每一个identity的特征嵌入是确定的，PFE只是增加了一个估计方差的小网络分支，这导致必须用一个新的metric（即MLS）来计算所有样本对的距离。而使用MLS这个度量函数带来的缺陷在实际工业应用中是代价较高的：第一，我们需要额外存储方差向量；第二，相比传统的余弦相似度，MLS相似度的计算资源消耗也更大。</p>
<p>受此启发，我们团队在投递给CVPR 2020的新论文中不仅做到了估计方差，同时也能更新每个样本的特征。下图为传统方法、PFE与我们团队方法的对比。</p>
<p><img src="https://i.loli.net/2020/09/06/pYSInMZ9R64euEC.jpg" alt="img"></p>
<p>可以发现，在图（a）中，虚线框出的蓝色椭圆代表一个类别，圈外存在一个正样本和负样本，而对于传统相似度计算方法来说，很难将负样本和正样本区分开来；而（b）中PFE方法对每个样本估计了一个分布，在带有分布的特征表示下，利用MLS就能够有效将正样本和负样本区分开来，但是PFE中正负样本本身是确定的；在（c）中，我们团队方法能够在估计正负样本方差的同时，也让特征本身修正得更好。</p>
<p><img src="https://i.loli.net/2020/09/06/ayVXfSxm1DYk5dG.png" alt="img"></p>
<p>上图是三种方法的对比，可以看到在最后计算相似度的时候，由于特征本身经过了调整，只需要使用cosine相似度来计算两个均值向量就可以得出答案。具体而言，我们团队提出了两种实现方法，如下：</p>
<h3 id="法1从头学习一个分类模型"><strong>法1：从头学习一个分类模型</strong></h3>
<p><img src="https://i.loli.net/2020/09/06/yZWVciHGd8bwK74.jpg" alt="img"></p>
<p>这种方法的主要部分与通用识别模型的结构一致，区别在于，在输出特征的位置，我们让模型输出一个有关每个样本特征的均值μ，以及一个方差σ。进一步，对于每个样本的每一次迭代而言，都随机采样一个ε（如上图最下方）。</p>
<p>通过这种方式得到的新样本特征s_i就是遵从均值μ、方差为σ的高斯分布采出的值，它可以模拟一个服从高斯分布的特征。通过这种简单的重新采样的技巧，就可以很好进行模型训练。在测试的时候不再需要采样，仅需要将已经得到的均值μ作为特征来计算相似度即可。</p>
<p><img src="https://i.loli.net/2020/09/06/8PcKyqBlErgUQAm.png" alt="img"></p>
<p>该方法的损失函数除了包含softmax以及其一切合理变种之外，还有一个KL损失，它使得每一个学出来特征的分布尽可能逼近单位高斯分布。这个损失项的引入来自于2016年一篇名为<em>Deep variational information bottleneck</em>的论文。进一步整个损失函数就可以用标准SGD方法来优化。下图解释了整个损失函数中softmax与kl损失是如何起到平衡的作用的。</p>
<p><img src="https://i.loli.net/2020/09/06/9wxoyQuj8M2AWem.jpg" alt="img"></p>
<h3 id="法2从现有模型出发学习回归模型"><strong>法2：从现有模型出发学习回归模型</strong></h3>
<p><img src="https://i.loli.net/2020/09/06/k8rDhcJY5ZaMQnU.jpg" alt="img"></p>
<p>这种方法假设输出的特征μ遵循高斯分布，目的是让它逼近期望的特征w。与PFE类似，假设输入的模型已经固定，且输出的特征μ属于类别c，则让μ逼近这个类别c的特征中心w_c（w_c来自事先训练好的人脸分类模型）。这种方法适用于当已经有一个训练好的模型，但依然希望做不确定性估计的情况。相对于PFE而言，它多做了样本特征的学习。下图解释了该损失函数中σ起到的平衡作用。</p>
<p><img src="https://i.loli.net/2020/09/06/3qWYVXC4QIx1vh8.png" alt="img"></p>
<p><strong>实验结果：</strong>在三种损失函数上的对比测试结果显示，我们团队提出的分类方法（HUM_cls）在最困难的数据集IJB-C（具有大量模糊、噪声图像）上效果最佳；在LFW、CFP-FP、YTF这些较成熟的数据集上我们提出的两种方法同其他方法区别不大；在较困难的MegFace(R1)数据集上我们团队的分类方法效果最佳。</p>
<p><img src="https://i.loli.net/2020/09/06/9e3k4ImOhET5Wgo.jpg" alt="img"></p>
<p>下图展示了在三种数据集上学习出来的方差分布情况，展示了位于不同方差位置的图像的样子。</p>
<p><img src="https://i.loli.net/2020/09/06/81X3Pk4o9IHZTxE.jpg" alt="img"></p>
<p>进一步，我们团队使用了ResNet-64作为backbone（与PFE的SOTA模型backbone深度一致），来将本文方法同SOTA方法在最困难的数据集IJB-C上进行性能对比，结果显示在每一个指标上我们团队方法均实现了领先。为了测试本文方法对噪声信息干扰的鲁棒性，团队对图片人工施加了高斯噪声（从0到40%），可以发现，当噪声越明显的时候，本文引入的不确定估计方法的优越性也约高。</p>
<p><img src="https://i.loli.net/2020/09/06/4VLqFkPgIvaYSm2.jpg" alt="img"></p>
<h4 id="section"></h4>
<h3 id="参考-1">🚀参考</h3>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/95774787" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/95774787</a></p>
</blockquote>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
  </entry>
  <entry>
    <title>2020-09-05-知识点杂</title>
    <url>/2020/09/05/2020-09-05-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%9D%82/</url>
    <content><![CDATA[<h3 id="对数似然">对数似然</h3>
<p>最大化对数似然，因此值越大越好。例如，对数似然值 -3 比 -7 好。</p>
<p>对数为负值是完全可能的，如下图log函数</p>
<p><img src="E:\myBlog\source\_posts\1200px-Logarithm.svg.png" alt="对数- 维基百科，自由的百科全书" style="zoom: 33%;"></p>
<h3 id="高斯分布中考虑对数似然而不是似然">高斯分布中考虑对数似然而不是似然</h3>
<p>通过最大似然函数来确定高斯分布中未知参数的值，实际上，<strong>最大化似然函数的对数更方便</strong>。因为对数是其论证的单调递增函数，函数的对数的最大化等价于函数本身的最大化。logaithm不仅简化了后续的数学分析，而且还有助于数学计算，<strong>因为大量小概率的乘积很容易使计算机的数值精度下降，但是log就可以通过计算总和来解决</strong>。</p>
<ol type="1">
<li>当要计算随机变量的joint likelihood时很有用，他们之间独立，并且分布相同。</li>
</ol>
<p><img src="E:\myBlog\source_posts\image-20200905213103449.png" alt="image-20200905213103449"></p>
<p>联合概率是所有点的概率的乘积：</p>
<p><img src="E:\myBlog\source_posts\image-20200905213136550.png" alt="image-20200905213136550"></p>
<p><strong>如果是log，则只需要求和即可</strong></p>
<ol start="2" type="1">
<li>由于是<strong>高斯分布</strong>，使用log避免了计算指数</li>
</ol>
<p><img src="E:\myBlog\source_posts\image-20200905213239871.png" alt="image-20200905213239871"></p>
<p>可以写成：</p>
<p><img src="E:\myBlog\source_posts\image-20200905213249229.png" alt="image-20200905213249229"></p>
<ol start="3" type="1">
<li>ln x是单调递增的函数，因此log-likelihood和likelihood有相同的关系</li>
</ol>
<p><img src="E:\myBlog\source_posts\image-20200905213303446.png" alt="image-20200905213303446"></p>
<p><strong>负对数似然</strong>是一种用于解决分类问题的 损失函数 ，它是似然函数得一种自然对数形式，可用于测量两种概率分布之间的相似性，其取负号是为了让最大似然值和最小损失相对应，是最大似然估计及相关领域的常见函数形式。</p>
<p>机器学习中，习惯用优化 算法 求最小值，因此会用到负对数似然，这是分类问题中的常见的损失函数，且能拓展到 多分类 问题。</p>
<h3 id="负对数似然和似然估计">负对数似然和似然估计</h3>
<p><strong>负对数似然</strong>是一种用于解决分类问题的 损失函数 ，它是似然函数的一种自然对数形式，可用于测量两种概率分布之间的相似性，其取负号是为了让最大似然值和最小损失相对应，是最大似然估计及相关领域的常见函数形式。</p>
<p>机器学习中，习惯用优化 算法 求最小值，因此会用到负对数似然，这是分类问题中的常见的损失函数，且能拓展到 多分类 问题。</p>
<h3 id="最大似然估计">最大似然估计</h3>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/32803109" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/32803109</a></p>
</blockquote>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
  </entry>
  <entry>
    <title>2020-09-05-讨论总结</title>
    <url>/2020/09/05/2020-09-05-%E8%AE%A8%E8%AE%BA%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>研究生阶段想要重点去研究透彻某个知识点，还是要去系统学习。不要只是依赖博客</p>
<p>博客缺点</p>
<ol type="1">
<li>一般不成体系，比较片面</li>
<li>不管是翻译外国博客还是自己的总结，由于博主本身的能力，导致在写的时候，都会出现一定的误差，可信度不抵论文和书籍</li>
<li>讲的不深入</li>
</ol>
<p>和师兄讨论了卡尔曼滤波的内容，师兄针对我的问题也给了很好的建议，让我有方向去继续。发现一直以来我对卡尔曼滤波理解的太浅显，不深刻，理解只是停留结合例子理解卡尔曼滤波那五个公式，知道计算过程，但是没有去深入理解来源以及公式的意义，变量的含义等等，没有真正转化为自己的东西 因为卡尔曼滤波是RKN的核心基础，所以必须要深入理解，这样才能更好地运用卡尔曼滤波，也更好地理解模型。 因为融合到transformer中，也要讲清楚为什么融合之后效果好，或者为什么不好，只有将本质讲清楚，去理论分析的时候才有信服力。避免只是简单的拼接。</p>
<p>为什么这么做，这么做的好处。公式间的逻辑关系， 买了本卡尔曼滤波的书，意义和含义，背景和理论公式一步一步推导</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <tags>
        <tag>研究方法</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-09-04-transformer直观理解</title>
    <url>/2020/09/04/2020-09-04-transformer%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<h3 id="直观attention-模型">直观“Attention 模型”</h3>
<p>本文试着从直观的角度解析“Attention模型”，应用场景：原文--译文，具体选择 中文--英文，即在<strong>将中文翻译为英文</strong>这一场景中，直观解析“Attention模型”。</p>
<h4 id="概括">概括</h4>
<p>一句中文A翻译为一句英文B主要是完成以下“<strong>两项任务</strong>”：</p>
<ol type="1">
<li><p>理解中文A的意思为X；</p></li>
<li><p>将意思X用英文表达出来，即英文B；</p></li>
</ol>
<p>在用计算机完成以上任务前，需要以下三点“<strong>准备工作</strong>”：</p>
<ol type="i">
<li><p>需要将中文的字和英文的单词转换为计算机可以理解（计算）的数（即一个字/单词对应转换为一个向量，称为字向量/单词向量），然后计算机才有可能完成以上两项任务，实现翻译； <code>单词-&gt;单词向量</code></p></li>
<li><p>另外针对一句中文翻译为一句英文，每个字在句子中的位置也对意思的表达会产生很大的影响，所以每个字在句子中的位置也要定义一个向量来表达（即一个位置对应转换为一个向量，称为位置向量）； <code>位置向量</code></p></li>
<li><p>将字向量/单词向量加上位置向量（定义两种向量的维度相同，如都是512维，便于此处元素相加），能更好更全面的代表这句话，为更好的翻译做好准备；<code>单词向量+位置向量</code></p></li>
</ol>
<p>“Attention模型”实现以上内容，具体情况如下图所示：</p>
<p><img src="https://i.loli.net/2020/09/05/bEpK5wcj9rkAGCU.jpg" alt="img"></p>
<p>以下针对“准备工作”、任务1和任务2展开讨论；</p>
<h4 id="准备工作">准备工作</h4>
<p>包括字向量/单词向量、位置向量；此处也称为<strong>词嵌入，位置编码</strong>；</p>
<ol type="a">
<li>字向量/单词向量分别是<code>随机产生产生的一组512维向量</code>，如字向量，假设选用了3000个常用汉字，每个字对应一个512维的随机向量，则整个字向量就是一个3000 X 512 的二维矩阵，每一行代表一个字；</li>
</ol>
<p><strong>之所以用随机且选择较大维度（如512维），是为了让生成的各个向量间尽可能的独立，即没有相关性</strong>，就像“你、我、他、拿、和、中”指代的具体意思在最初定义时是可以随机互换的，之间也无关系，他们之间的相关性/关系是在该语系语境中根据语义、语法、文化等因素形成的，即上述任务1需要完成的。</p>
<p>（词嵌入，每个词之间没有关系）</p>
<p><img src="https://i.loli.net/2020/09/05/9tSTwmsdnfuW7Ol.jpg" alt="img"></p>
<ol start="2" type="a">
<li>位置向量是代表一个字在句子中的位置信息，也定义为一个512维的向量，但并不是随机产生的，而是根据位置确切计算得来，即<strong>一个位置对应转化为一个512维向量；</strong></li>
</ol>
<p><img src="https://i.loli.net/2020/09/05/FAR6vuDZgBoJwTX.jpg" alt="img"></p>
<ol start="3" type="a">
<li>假设翻译时定义一句话最大长度是10个字，则该句话对应的字向量是一个10 X 512的二维矩阵（每一行代表一个字），位置向量也是一个10 X 512的二维矩阵（每一行代表对应字的位置信息）；<strong>两个矩阵相加得新的二维矩阵能更好更全面的表达这句话；</strong></li>
</ol>
<h4 id="任务1编码">任务1：编码</h4>
<p><strong>理解</strong>一句中文A的意思为X；此处也称为“编码”</p>
<ol type="i">
<li><p>翻译时中文中的“你”、“我”大多时候对应着英文的“you”、“me”，如果都是这样的简单一一对应关系，那翻译是很简单的；而实际情况是<strong>绝大多数都是一对多的关系，即同一个中文字在不同的语境中对应的英文是不一样的单词</strong>，如“和”字在不同语境中翻译为英文可能是“and”、“sum”、“peace”等。</p></li>
<li><p>一个字从多个可能的意思中选择一个是根据语境来确定的，即根据这个字与句子中所有字的相关关系来确定；<strong>一句话需要计算该句话中每个字与该句子中所有字的相关关系来确定这句话中每个字在该语境中的意思，即确认中文语境</strong>；</p></li>
<li><p>在计算相关性之前，对每一个<strong>字对应的向量进行相应的线性变换</strong>以便于更好的计算相关性确认最终意思；计算完相关性（确认中文语境）并以此更新向量矩阵后（即self-attention，确认每个字在当前这句话的语境下的“确切意思”），再<strong>进行一次线性变换</strong>，对这个“确切意思”进行再次拟合校准；</p></li>
</ol>
<p>具体情况，如下图所示；</p>
<p><img src="https://i.loli.net/2020/09/05/ZT4OvczK3tyCdGX.jpg" alt="img"></p>
<p>Notes：i~iii是一个处理单元，<strong>输入“向量矩阵”和输出“新向量矩阵X”的维度是一样的</strong>；完成任务1是以上处理单元循环N次（<strong>强化上述效果</strong>），设定义N=3（论文中N=8）；即由3个处理单元依次链接完成任务1，如下图所示：</p>
<p><img src="https://i.loli.net/2020/09/05/ZS4YMITXOWyr8kf.jpg" alt="img"></p>
<h4 id="任务2解码">任务2：解码</h4>
<p>将意思X用英文表达出来，即英文B；此处也称为“解码”</p>
<p>和任务1类似，<strong>差异</strong>在于：</p>
<p>I. 任务1仅考虑中文语境即可，任务2<strong>既考虑中文语境（vanilla-attention），也考虑英文语境（self-attention）；</strong></p>
<ol start="2" type="i">
<li>和任务1类似，经过N个处理单元后获得的向量矩阵，经过“最后一次线性变换”转换为对应英文语系中各个单词的值，然后由softmax转换为是各个英文单词的概率，完成翻译；</li>
</ol>
<p>图示如下：</p>
<p><img src="https://i.loli.net/2020/09/05/yKDA2Fs3Xc4HkIo.jpg" alt="img"></p>
<p>整体简化图示如下：</p>
<p><img src="https://i.loli.net/2020/09/05/6epU1uboH2AGP7k.jpg" alt="img"></p>
<h3 id="attention注意力">Attention注意力</h3>
<p><img src="https://i.loli.net/2020/09/05/R2XINUW16u4anTs.jpg" alt="img"></p>
<p>上图是attention模型的总体结构，包含了模型所有节点及流程（因为有循环结构，流程不是特别清楚，下文会详细解释）；模型总体分为两个部分：编码部分和解码部分，分别是上图的左边和右边图示；以下选取翻译情景，以<strong>模型训练</strong>为例解释整个过程；</p>
<p><strong>训练样本：原文译文(一一对应)</strong></p>
<h4 id="编码部分inputs">编码部分（inputs）</h4>
<h5 id="input-embedding">Input embedding:</h5>
<p>1.1 将原文的所有单词汇总统计频率，删除低频词汇（比如出现次数小于20次的统一</p>
<p>定义为’<unk>’）；</unk></p>
<p>此时总共选出了假设10000个单词，则用数字编号为0~9999，一一对应，定义该对应表为word2num；</p>
<p>然后用<code>xaviers方法</code>生成随机矩阵Matrix ：<strong>10000行N列</strong>（10000行是确定的，对应10000个单词，N列自定义）；这样就可以将10000个不同的单词通过word2num映射成10000个不同的数字（int），然后将10000个不同的数字通过Matrix映射成10000个不同的N维向量（如何映射？比如数字0，3，经过 Matrix映射分别变为向量Matrix[0],Matrix[3]，维度为N维）；</p>
<p>这样，<strong>任何一个单词，都可以被映射成为唯一的一个N维向量</strong>；</p>
<p><img src="https://i.loli.net/2020/09/05/86ByVmtDIGfd2bx.png" alt="img"></p>
<p>*<strong>Note：此处N自定义为512*</strong></p>
<p>1.2 翻译的时候是<strong>一个句子一个句子的翻译</strong>，所以需要定义一个句子的标准长度，比如10个单词；如果一句话不足10个单词则用0填充（<strong>对应的word即word2num表中的<pad></pad></strong>），如果多了，删掉；</p>
<p>这样一句话就是标准的10个单词；比如句子 “中国人有中国梦。”，这句话共有八个字（最后一个是结束符），<strong>经过word2num变为一列X：<a href="注：100代表的word是结束符">1,7,3,2,1,7,6,100,0,0</a>,X经过Matrix映射为10行N列的矩阵matX</strong>= [Matrix[1], Matrix[7], Matrix[3], Matrix[2] , Matrix[1] , Matrix[7] , Matrix[6], Matrix[100] , Matrix[0] , Matrix[0]]; embedding 到此基本结束，即完成了将一句话变为 一个矩阵，矩阵的每一行代表一个特定的单词；此处还可以scale一下，即<code>matX*N**(1/2)</code>; （<code>**代表次方，即matX中的每一个元素都乘以N的1/2次方，此时N=512，以此来缩放</code>）</p>
<p><img src="https://i.loli.net/2020/09/05/xOJBLyNruSIX9s2.png" alt="img"></p>
<h5 id="positional-encoding">Positional encoding:</h5>
<p>2.1 单词在句子中的不同位置体现了不同信息，所以需要对位置进行编码，体现不同的信息情况，此处是对绝对位置进行编码，即位置数字0，1，2，3，…N等，进行运算编码，具体编码如下：</p>
<p>2.1.1 对于句子中的每一个字，其位置pos∈<a href="每句话10个字">0,1,2,…,9</a>,每个字是N（512）维向量，维度 i （i∈[ 0,1,2,3,4,..N]）带入<strong>函数计算</strong>，</p>
<p><img src="https://i.loli.net/2020/09/05/dR4rAa9DkZJKNQC.png" alt="img"></p>
<blockquote>
<p>用sin和cos是因为在后面运算过程中会近似出现sin(a)sin(b)+cos(a)cos(b)的形式，根据三角函数公式上式恰好等于cos(a-b)，当a和b差小时（即两个字离得近）值大，反之小。这在一定程度上可以表达两个字的距离。</p>
</blockquote>
<p>2.1.2 经过如上函数运行一次后，获得了一个<strong>10行N列的矩阵matP</strong>；每一行代表一个绝对位置信息，此时matP的shape和matX的shape相同；</p>
<p><img src="https://i.loli.net/2020/09/05/xFKDaYu1pSNZ7lo.png" alt="img"></p>
<p>2.1.3 <strong>对于矩阵matP的每一行，第0，2，4，6,...等偶数列上的值用sin()函数激 活，第1，3，5，。。。等奇数列的值用cos()函数激活，以此更新matP</strong>；即 matP[:,0::2]=sin(matP[:,0::2]), matP[:,1::2]=cos(matP[:,1::2])；</p>
<p><img src="https://i.loli.net/2020/09/05/w1FJXfzq5IRrPCS.png" alt="img"></p>
<p>2.2 至此positional encoding结束，最后通常也会scale一次，即对更新后的matP进行<code>matP*N**(1/2)</code>运算，得到再次更新的matP，此时的matP的shape还是和matX相同；<strong>然后将matP和matX相加即matEnc=matP+matX，矩阵matEnc其shape=[10，512]；</strong></p>
<h5 id="multi-head-attention循环单元">Multi-head attention循环单元</h5>
<p>3.1 然后matEnc进入模型编码部分的循环，即Figure1中左边红色框内部分，每个循环 单元又分为4个小部分：multi-head attention, add&amp;norm, feedForward, add&amp;norm；</p>
<p>3.2 Multi-head attention</p>
<p><img src="https://i.loli.net/2020/09/05/np9H73tSVYogJG4.jpg" alt="img"></p>
<p>3.2.1 Multi-head attention 由三个输入，分别为V，K，Q，此处<strong>V=K=Q=matEnc</strong>（在解码部分multi-head attention中的VKQ三者不是这种关系）;</p>
<p>3.2.2 首先分别对V，K，Q三者分别进行线性变换，即将三者分别输入到三个单层神经网络层，激活函数选择relu，输出新的V，K，Q（三者shape都和原来shape相同，即<strong>经过线性变换时输出维度和输入维度相同</strong>）；</p>
<p>3.2.3 然后将Q在最后一维上进行切分为num_heads(假设为8)段，然后对切分完的矩阵在axis=0维上进行concat链接起来(纵向连接)；对V和K都进行和Q一样的操作；操作后的矩阵记为Q_,K_,V_；</p>
<p><img src="https://i.loli.net/2020/09/05/PqJYGOb4fvTmsFw.png" alt="img"></p>
<p><img src="https://i.loli.net/2020/09/05/2npJkGobFc4RXwu.png" alt="img"></p>
<p>3.2.4 <strong>Q_矩阵相乘 K_的转置（对最后2维）</strong>，生成结果记为outputs，然后对outputs 进行scale一次更新为outputs；<strong>此次矩阵相乘是计算词与词的相关性，切成多个num_heads进行计算是为了实现对词与词之间深层次相关性进行计算；</strong></p>
<p><img src="https://i.loli.net/2020/09/05/imn5tKIUxzyfwLW.png" alt="img"></p>
<p><code>shape（outputs） = （8,10,10）</code></p>
<p>3.2.5 对outputs进行softmax运算，更新outputs，即outputs=softmax(outputs);</p>
<p>3.2.6 最新的outputs（即K和Q的相关性） 矩阵相乘 V_， 其值更新为outputs；</p>
<p><img src="https://i.loli.net/2020/09/05/oZalMTkQeRVqsUy.png" alt="img"></p>
<p><code>shape（outputs）= (8,10,64)</code></p>
<p>3.2.7 最后将outputs在axis=0维上切分为num_heads段，然后在axis=2维上合并， <strong>恢复原来Q的维度</strong>；</p>
<p><img src="https://i.loli.net/2020/09/05/JrFbIdWauXxA4nK.png" alt="img"></p>
<p>3.3 Add&amp;norm</p>
<p>3.3.1 类似ResNet，将<strong>最初的输入与其对应的输出叠加一次</strong>，即outputs=outputs+Q， 使网络有效叠加，<strong>避免梯度消失</strong>；</p>
<p><img src="https://i.loli.net/2020/09/05/falSI79c3xD2Ey8.png" alt="img"></p>
<p>3.3.2 标准化矫正一次，在outputs对最后一维计算均值和方差，用outputs减去均值除以方差+spsilon得值更新为outputs，然后变量gamma*outputs+变量beta；（Norm操作）</p>
<p>3.4 feed Forward （就是dense layer 全连接层）</p>
<p>3.4.1 对outputs进行第一次卷积操作，结果更新为outputs（卷积核为1*1，每一次卷积操作的计算发生在一个词对应的向量元素上，卷积核数目即最后一维向量长度，也就是一个词对应的向量维数）；</p>
<p>3.4.2 对最新outputs进行第二次卷积操作，卷积核仍然为1*1，卷积核数目为N；</p>
<p><img src="https://i.loli.net/2020/09/05/esShU1Nx32AYt8Z.png" alt="img"></p>
<p>3.5 Add&amp;norm : 和3.3相同，经过以上操作后，此时最新的output和matEnc的shape相同；</p>
<p>3.6 <strong>令matEnc=outputs, 完成一次循环，然后返回到3.2开始第二次循环</strong>；共循环Nx（自定义；每一次循环其结构相同，但对应的参数是不同的，即是独立训练的）；完成Nx次后，模型的编码部分完成，仍然令matEnc=outputs，准备进入解码部分；</p>
<p>解码部分：</p>
<p>​ <strong>此时的outputs指的是上一时间点解码器的输出</strong></p>
<ol type="1">
<li><p>Outputs：<strong>shifted right右移一位</strong>？？？？，是为了解码区最初初始化时第一次输入，并将其统一定义为特定值（在word2num中提前定义）；</p></li>
<li><p>Outputs embedding: 同编码部分；更新outputs；</p></li>
<li><p>Positional embedding：同编码部分；更新outputs； （前三步是准备工作）</p></li>
<li><p>进入解码区循环体； （以下是解码器的顺序操作）</p></li>
</ol>
<p>4.1 Masked multi-head attention: 和编码部分的multi-head attention类似，但是多了一 次<strong>masked</strong>，因为在解码部分，解码的时候时从左到右依次解码的，当解出第一个字的时候，第一个字只能与第一个字计算相关性，当解出第二个字的时候，只能计算出第二个字与第一个字和第二个字的相关性，...；所以需要进行一次mask；</p>
<p><img src="https://i.loli.net/2020/09/05/54eVnEgmh7CdqKH.jpg" alt="img"></p>
<p>4.2 Add&amp;norm：同编码部分，更新outputs；</p>
<p>4.3 Multi-head attention：同编码部分，但是Q和K，V不再相同，Q=outputs，K=V=matEnc；(outputs是上层的输出，k,v是来自编码器的输出)</p>
<p>4.4 Add&amp;norm:同编码部分，更新outputs；</p>
<p>4.5 Feed-Forward：同编码部分，更新outputs；</p>
<p>4.6 Add&amp;norm: 同编码部分，更新outputs；</p>
<p>4.7 最新outputs和最开始进入该循环时候的outputs的shape相同；回到4.1，开始第 二次循环。。。；直到完成Nx次循环（自定义；<strong>每一次循环layer结构相同，但对应的参数是不同的，即独立训练的</strong>）；</p>
<ol start="5" type="1">
<li><p>Linear: 将最新的outputs，输入到单层神经网络中，输出层维度为“译文”有效单词总数；更新outputs；</p></li>
<li><p>Softmax: 对outputs进行softmax运算，确定模型译文和原译文比较计算loss，进行网络优化（参数更新）；</p></li>
</ol>
<h4 id="注">注</h4>
<p>1.解码器的<code>outputs embedding</code> ：在训练的时候就是对应原文的译文，其中第一字统一定义为0,作为输入；在预测时第一次输入也是全是0,然后每循环一次，预测一个字直到出现终止符。</p>
<p>2.对于matEnc=matP+matX，这里为什么要用add,而不是contact ?</p>
<p>matX是一个10行512列的矩阵，每一行代表一个字；</p>
<p>matP是一个10行512列的矩阵，每一行代表一个位置；</p>
<p>对于不一样的句子，matX是不一样的，matP是完全一样的；</p>
<p>则对于不一样的句子，add后是不一样的，contact后至少一半是一样的，从直观上，add似乎更好；</p>
<p>对于一个字，其出现的位置不同，可能表达的意思完全不一样，比如“和”，如果其在句首或者句中出现更可能是“and”的意思，如果在句末出现，更可能是“sum”的意思，而这两个意思几乎完全不一样，即他们的向量完全不一样似乎更合理，而非contact的至少一半一样；</p>
<p>matP矩阵的特点从上到下对应各元素是递增的，matX是随机产生的（比如均值为0的随机数），即大约在0附近波动的数，与matP做add运算后，相当于均值被依次提高，以此代表融入每个字位置信息；因为每次训练的时候均值被提高的量是一定的，所以可以期望模型训练后能“意识”到这一点；</p>
<p>add产生“信息混淆”，比如两个字在两个不同的位置上分别add后，结果相近，从直观上这可能会造成问题；这个问题可以通过加大向量维度来降低其出现概率，比如选择512维是很长的维度了，出现这种概率的问题还是很小的；</p>
<p>如果用contact实际就是在每个字向量后面追加一个位置信息以示区别，做这种区别无需太多维，也许一两维即可；</p>
<p>深度学习算法的可解释性差，分析大多属于理论上的“纸上谈兵”，最可靠的方式，仍是分别以add和contact两种方式建模，大量测试后的结果更为可靠。</p>
<ol start="3" type="1">
<li><p>待探究</p>
<p>你文章中的逻辑是，对原始Q/K/V做不同线性变换（三个权重矩阵）得到新的Q/K/V→对新的Q/K/V在最后一个维度做切分得到多头（8组Q/K/V）→各组Q/K/V计算attetion值→8组Q/K/V的attetion值concat得到最终的attention值。</p>
<p>而原论文的逻辑是，对原始的Q/K/V做不同的线性变换（8（组）×3个权重矩阵）得到新的8组Q/K/V值→各组Q/K/V计算attention值→8组Q/K/V的attention值concat→concat结果经过一个线性变换（为了还原到最初的维度）得到最终的attention值。</p>
<p>论文提到multi-head attention是为了从不同表征子空间提取信息。个人理解实现这种差异化的提取，是通过多组权重矩阵来实现的，而不是通过embedding值不同分段获取。</p></li>
<li><p>在<strong>预测阶段</strong>，每次预测后底部decoder的输入是可变的，首先是[<bos>]，然后是[<bos>, word1 ]，再输入[<bos>, word1, word2 ]……，那么decoder内部如何保证它送入linear层的输出是(1, N)的向量呢？</bos></bos></bos></p>
<p><strong>答</strong>：[<bos>]时，经过解码区的循环部分后 是一个[1, 512]的矩阵， 经过linear层是准备预测1个字的；</bos></p>
<p>[<bos>, word1 ]时，经过解码区的循环部分 是一个[2, 512]的矩阵；经过linear层是准备预测2个字的；以此类推。</bos></p>
<p>也就是说，输入bos，输出word1；然后将bos word1输入，再输出word1 word2；再输入bos word1 word2......每次都把输出的最后一个字加到下一轮输入。</p></li>
<li><p>假设target是<bos>我爱中国<eos>，这算6个字，训练时decoder是不是也输出6个vocab-size长度的向量，那么第一个vocab-size长度的向量预测的是<bos>还是"我"呢？</bos></eos></bos></p>
<p><strong>答</strong>：预测的第一个是“我”,<bos>作为一个起始引导使用。</bos></p></li>
<li><p>第一个问题是训练和预测时解码端如何运行，我理解训练时使用mask一次性对所有时间步并行进行解码，预测时则需要先预测出上一步的词，再输入预测下一步，所以不能并行。如果我上面说的没错的话，第一个问题是为什么训练时mask没有掩盖自身，也就是对角线不mask，这样的话不就泄露了要预测那个词吗？第二个问题是预测时该如何进行，因为训练时，输入多少个时间步的词就会输出多少个时间步的预测值，但是在预测解码阶段，假设为t，要预测t + 1该如何操作？难道是先将t + 1随便加一个pad上去然后看预测值softmax吗？</p>
<p><strong>答</strong>：在训练时，用mask是一次性的解码，因为训练时所有label是已知的，用mask实现同时并行运算；预测时label是未知的，需要一个一个词预测，当预测第一个词时只能知道第一个词和第一个词的相关性，然后再运行模型一遍，预测出第一个词和第二词，依次循环直到出现终止符，这个过程不是并行的。</p>
<p>个人理解： 在训练时，把一整句话都作为解码器的输入，这样可以实现并行运算，因为每一个label都是已知的。而在预测时，需要一步一步来</p></li>
</ol>
<h3 id="参考">🚀参考</h3>
<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/62397974" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/62397974</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/44731789" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/44731789</a></p>
</blockquote>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>transformer</category>
      </categories>
      <tags>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-31-一周论文分享（第1期）</title>
    <url>/2020/08/31/2020-08-31-%E4%B8%80%E5%91%A8%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%EF%BC%88%E7%AC%AC1%E6%9C%9F%EF%BC%89/</url>
    <content><![CDATA[<h3 id="reformerthe-eficient-transformer">reformer：the eficient transformer</h3>
<h4 id="论文概况">论文概况</h4>
<ul>
<li>来源：ICLR 2020</li>
<li>arXiv: 1901.02860</li>
<li>作者：Nikita Kitaev ，Anselm Levskaya</li>
<li>论文地址：<a href="https://openreview.net/forum?id=rkgNKkHtvB" target="_blank" rel="noopener" class="uri">https://openreview.net/forum?id=rkgNKkHtvB</a></li>
<li>Code url：<a href="https://github.com/google/trax/tree/master/trax/models/reformer" target="_blank" rel="noopener" class="uri">https://github.com/google/trax/tree/master/trax/models/reformer</a></li>
<li>论文组会报告于<code>2020.08.30</code></li>
</ul>
<h4 id="背景">背景</h4>
<p>Transformer架构被广泛用于自然语言处理中，并在许多任务上产生了最新的结果</p>
<h5 id="问题">问题</h5>
<ol type="1">
<li>大型的 Transformer 可以在许多任务上实现 sota，但是面临着参数过多的问题，导致所占内存过大，造成资源紧张.</li>
</ol>
<p>在最大的配置中，参数数量已经超过了 5亿/层，层数多达 64。</p>
<ol start="2" type="1">
<li><p>具有 <em>N</em> 层的模型要消耗 <em>N</em> 倍于单层模型的内存，因为每一层中的激活都需要存储以进行反向传播。</p></li>
<li><p>由于点乘注意力本身的局限性，导致不能处理长序列数据，否则会导致效率不高</p></li>
</ol>
<p>也就是说transformer的上下文窗口有限制范围。最多也就几千个单词。</p>
<blockquote>
<p>Transformer 的强大来源于注意力机制 ，通过这一机制，Transformer 将上下文窗口内所有可能的单词对纳入考虑，以理解它们之间的联系。因此，如果文本包含 10 万个单词，Transformer 将需要评估 100 亿单词对（10 万 x 10 万），这显然不切实际。</p>
<p>另一个问题是如何保存每个模型层的输出 。对于使用大型上下文窗口的应用来说，存储多个模型层输出的内存需求会迅速变得过大。这意味着，实际使用大量层的 Transformer 模型只能用于生成几小段落的文本或一小段的音乐。</p>
</blockquote>
<h5 id="解决方案">解决方案</h5>
<ol type="1">
<li><p>使用可逆残差（reversible residual layers）代替标准残差（standard residuals），这使得存储在训练过程中仅激活一次，而不是 n 次（此处 n 指层数），更有效地使用可用内存</p></li>
<li><p>将点乘注意力（dot-product attention）替换为一个使用局部敏感哈希（locality-sensitive hashing）的点乘注意力，将复杂度从 O(L2 ) 变为 O(L log L)，此处 L 指序列的长度，来降低长序列的处理复杂度</p></li>
</ol>
<p><strong>Reformer与使用完全Transformer所获得的结果相匹配，但运行速度要快得多，尤其是在文本任务上，并且内存效率要高几个数量级。</strong></p>
<h4 id="注意力问题">注意力问题</h4>
<h5 id="原始注意力">原始注意力</h5>
<p>公式如下：<span class="math inline">\(Attention (Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}\right) V\)</span></p>
<p>self-attention操作的核心 ——<span class="math inline">\(QK^T\)</span> 表示key和query之间的相似度得分</p>
<p>计算带有所有k的q的点积，并用√dk进行缩放，然后应用softmax函数来获得v的权重。用来消除hidden size这个参数对注意力分布的影响。对于每个query，我们在所有keys上计算一个softmax，以确保矩阵的每一行和为1—— 确保新的隐藏状态的大小不依赖于序列长度。</p>
<p>最后，我们用我们的注意力矩阵乘以我们的values矩阵，为每个token生成一个新的隐藏表示。</p>
<hr>
<blockquote>
<h5 id="例子">例子</h5>
<p>Key:(batch, length,d_model)</p>
<p>Query:(batch, length,d_model)</p>
<p>-&gt; <span class="math inline">\(QK^T\)</span>　:(batch, length,length)</p>
<p>-&gt; 复杂度： O(<span class="math inline">\(L^2\)</span> )</p>
<p>-&gt;原始的transformer结构难以处理过长的序列长度</p>
</blockquote>
<p><img src="https://i.loli.net/2020/09/03/9mdzrXcGKZ5FPi3.png" alt="image-20200903163000933"></p>
<p><img src="https://i.loli.net/2020/09/03/6QvMn1qxGXzwKmC.png" alt="image-20200903161441529"></p>
<p>其实，在softmax中，对于每个查询 <em>q</em>，我们只需要注意最接近 <em>q</em> 的键 <em>k</em>。<strong>并不一定需要那些注意力权重很小的token。</strong></p>
<p>例如，如果序列长度是 64K，对于每个 <em>q</em>，我们可以只考虑 32 或 64 个最近的键的一个小子集。因为这些是和<em>q</em>最需要注意的</p>
<h5 id="局部敏感哈希lsh">局部敏感哈希(LSH)</h5>
<p><img src="https://i.loli.net/2020/09/03/zQI9n2ubZYDV7SL.png" alt="image-20200903163152560"></p>
<p>局部敏感哈希使用<code>球形投影点的随机旋转</code>，通过argmax在有符号轴投影上<code>建立桶（bucket）</code>。 在此高度简化的2D描绘中，对于三个不同的角度hash，两个点x和y不太可能共享相同的哈希桶（上方），除非它们的球面投影彼此靠近（下方）。</p>
<p>该图演示了一个用<code>4个桶进行3轮哈希的设置</code>。下面的图中的向量映射到了同一个bucket，因为它们的输入很接近，而上一张图中的向量映射到第一个和最后一个bucket。</p>
<p>LSH是一组将高维向量映射到一组离散值(桶/集群)的方法。是解决在高维空间中快速找到最近邻居（最相似）的问题。</p>
<p><code>基本思想</code>：选择 <em>hash</em> 函数，对于两个点 p 和 q，如果 q 接近 p，那么很有可能我们有 hash(q) == hash(p)</p>
<h5 id="lsh注意力">LSH注意力</h5>
<p><img src="https://i.loli.net/2020/09/03/KgnJ7iB2kImcshX.png" alt="image-20200903163641310"></p>
<p>完全不同的方法来处理序列长度问题，丢弃了<code>query投影</code>（Q=K）（实验结果发现，学习不同的keys和queries的投影并不是严格必要的），<code>并将注意力权重替换为key的函数（hash函数）</code>，以此降低复杂度</p>
<p>步骤如下：</p>
<p>1.使用LSH为每个token计算一个桶</p>
<p>2.根据相同的桶进行归类排序</p>
<p>3.分块并将标准的点乘注意力应用到桶中的token的块上，从而大大降低计算负载</p>
<h4 id="内存问题">内存问题</h4>
<p>单层能够执行长序列的单模型。但是，当使用梯度下降训练多层模型时，由于需要保存每一层的激活（函数），以用于执行逆推。一个传统的 Transformer 模型具有十几个或更多的层，通过缓存这些层的值，内存将会很快用完。</p>
<p>可逆层：在反向传播时，按需重新计算每个层的输入，而不是将其保存在内存中。其中来自网络最后一层的激活用于还原来自任何中间层的激活。</p>
<p>原始的残差网络：<span class="math inline">\(Y=F(x)\)</span></p>
<p>可逆层的残差网络： 注意我们如何从它的输出(Y ₁, Y ₂)计算物体的输入(X ₁, X ₂)。</p>
<p><span class="math inline">\(\begin{array}{ll}y_{1}=x_{1}+F\left(x_{2}\right) &amp; y_{2}=x_{2}+G\left(y_{1}\right) \\ x_{2}=y_{2}-G\left(y_{1}\right) &amp; x_{1}=y_{1}-F\left(x_{2}\right) \\ Y_{1}=X_{1}+\text { Attention }\left(X_{2}\right) &amp; Y_{2}=X_{2}+\text { FeedForward }\left(Y_{1}\right)\end{array}\)</span></p>
<p>示意图如下</p>
<p><img src="https://i.loli.net/2020/09/03/WX3lcQrmB16pI2Y.png" alt="image-20200903164816966"></p>
<p><img src="https://i.loli.net/2020/09/03/FgHKa4QNrsjlzMh.png" alt="image-20200903164907447"></p>
<h4 id="实验">实验</h4>
<p>作者分别对图像生成任务 <em>imagenet64</em>(长度为 12K)和文本任务 <em>enwik8</em>(长度为 64K)进行了实验，评价了可逆 Transformer 和 LSH 哈希对内存、精度和速度的影响。</p>
<p>🎉可逆 Transformer 匹配基准：他们的实验结果表明，可逆的 Transformer 可以节省内存不牺牲精度：</p>
<p><img src="https://i.loli.net/2020/09/03/LwSPM5qFuBfQhaZ.png" alt="null"></p>
<p>在 enwik8 和 imagenet64 训练中，可逆性对性能的影响</p>
<p>🎉LSH 注意力匹配基准：注意 LSH 注意力是一个近似的全注意力，其准确性随着散列值的增加而提高。当哈希值为 8 时，LSH 的注意力几乎等于完全注意力：</p>
<p><img src="https://i.loli.net/2020/09/03/t4zNAXOf6iEZ7cH.jpg" alt="null"></p>
<p>LSH 注意力作为散列循环对 imagenet64 的影响</p>
<p>🎉他们也证明了传统注意力的速度随着序列长度的增加而变慢，而 LSH 注意力速度保持稳定，它运行在序列长度~ 100k 在 8GB 的 GPU 上的正常速度：</p>
<p><img src="https://i.loli.net/2020/09/03/aGRcA42EiNSBz8v.jpg" alt="null"></p>
<p>注意力评估的速度作为全注意力和 LSH 注意力的输入长度的函数</p>
<blockquote>
<p>与 Transformer 模型相比，最终的 Reformer 模型具有更高的存储效率和更快的存储速度。</p>
</blockquote>
<h4 id="参考">🚀参考</h4>
<blockquote>
<p><a href="https://www.6aiq.com/article/1583729200869" target="_blank" rel="noopener" class="uri">https://www.6aiq.com/article/1583729200869</a></p>
<p><a href="https://thinkwee.top/2020/02/07/reformer/" target="_blank" rel="noopener" class="uri">https://thinkwee.top/2020/02/07/reformer/</a></p>
<p><a href="https://aijishu.com/a/1060000000100293" target="_blank" rel="noopener" class="uri">https://aijishu.com/a/1060000000100293</a></p>
</blockquote>
<h3 id="transformer-xl-attentive-language-models-beyond-a-fixed-length-context">Transformer-XL : Attentive Language Models Beyond a Fixed-Length Context</h3>
<h4 id="论文概况-1">论文概况</h4>
<ul>
<li>来源：ACL 2019</li>
<li>arXiv: 1901.02860</li>
<li>作者：ZihangDai , ZhilinYang , YimingYang</li>
<li>论文地址： <a href="https://arxiv.org/abs/1901.02860" target="_blank" rel="noopener" class="uri">https://arxiv.org/abs/1901.02860</a></li>
<li>Code url：<a href="https://github.com/kimiyoung/transformer-xl" target="_blank" rel="noopener" class="uri">https://github.com/kimiyoung/transformer-xl</a></li>
<li>论文组会报告于<code>2020.08.15</code></li>
</ul>
<h4 id="背景-1">背景</h4>
<h5 id="问题-1">问题</h5>
<p>Transformer存在局限性：</p>
<p>1.在语言建模时的设置受到固定长度（segment）的限制。对长距离依赖的建模能力仍然不足</p>
<p>2.因为transformer将文本等分为相同的片段，导致了上下文碎片</p>
<h5 id="解决方案-1">解决方案</h5>
<p>使学习不再仅仅依赖于定长，且不破坏时间的相关性。</p>
<ol type="1">
<li>提出<strong>片段级递归机制(segment-level recurrence mechanism)</strong>，引入一个<strong>记忆(memory)</strong>模块（类似于cache或cell） 之前计算过了不需要重复计算，直接为后面片段使用。</li>
</ol>
<ul>
<li>使得<code>长距离依赖的建模</code>成为可能；</li>
<li>使得片段之间产生交互，解决上下文碎片化问题</li>
</ul>
<p>2.提出<strong>相对位置编码机制</strong>，代替绝对位置编码。 Transformer的绝对位置编码指的是一个片段中，为1 为2 。如果是多个片段同时考虑的话，那么这种1，2就会重复，所以使用了相对位置编码的方法。这样可以在多个片段（segment）中使用相对编码。具体内容见论文</p>
<p>注：两者是一起使用的，共同解决transformer存在的局限性</p>
<h4 id="模型-transformer-xl">模型 transformer-XL</h4>
<h5 id="原始transformer">原始transformer</h5>
<p><img src="https://i.loli.net/2020/09/04/YU3mC2hIOA9ncrj.gif" alt="v2-732805e00feb35e41f1d00f8df516950_b"></p>
<h5 id="片段注意力机制">片段注意力机制</h5>
<p>为了解决长距离依赖，文章引入一个memory状态。</p>
<p>在训练过程中，每个片段的表示为最后的隐层状态，表示片段的序号，表示片段的长度，表示隐层维度。</p>
<p>在计算片段的表示时，用memory缓存片段层的隐层状态，用来更新，这样就给下一个片段同了上文，长距离依赖也通过memory保存了下来。并且，最大可能的依赖长度线性增长，达到**N*L**</p>
<p><img src="https://i.loli.net/2020/09/04/IjUWo7DahsNPAkv.gif" alt="v2-a8210cd2f9bfb9307ba81d694dc4e4b4_b"></p>
<h5 id="评估阶段">评估阶段</h5>
<h6 id="原始transformer-1">原始transformer</h6>
<p><img src="https://i.loli.net/2020/09/04/epOcXjYTy835dJv.gif" alt="v2-13a38126e684b838e5ed207fd5cae944_b"></p>
<h6 id="transformer-xl">Transformer-XL</h6>
<p><img src="https://i.loli.net/2020/09/04/qdYL5RsQEOFS8nG.gif" alt="v2-502e1e1fec12b326ace579e059b3b3df_b"></p>
<h4 id="实验-1">实验</h4>
<p>实验部分是对基于Transformer-XL的语言模型进行评估，分为字符级和词级。评价指标分别是bpc(每字符位数)和PPL(困惑度)，越小越好。enwiki8和text8用的是bpc。Transformer-XL在多个语言模型基准测试中实现了最先进的结果。 Transformer-XL第一个在char级语言模型基准enwiki8上突破1.0。</p>
<p><strong>去除实验：</strong></p>
<p><img src="https://i.loli.net/2020/09/04/ZV1lpewdtanoWi9.png" alt="image-20200904153950861"></p>
<p>重点是本文设计的相对位置编码<strong>优于</strong>其他工作，memory的设计也有很大的提升。</p>
<p>最后，Transformer-XL在评估阶段的速度也明显快于 vanilla Transformer，特别是对于较长的上下文。例如，对于 800 个字符的上下文长度，Transformer-XL 比Vanilla Transformer 快 363 倍；而对于 3800 字符的上下文，Transformer-XL 快了 1874 倍。</p>
<h4 id="创新点">创新点</h4>
<ul>
<li>提出了片段级递归机制和相对位置编码机制</li>
<li>依赖关系比原始Transformer长450％，并且在评估过程中，其速度比原始Transformer快1800倍以上</li>
</ul>
<h4 id="参考-1">🚀参考</h4>
<blockquote>
<p><a href="https://www.cnblogs.com/shona/p/12041055.html" target="_blank" rel="noopener" class="uri">https://www.cnblogs.com/shona/p/12041055.html</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/83062195" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/83062195</a></p>
<p><a href="https://www.cnblogs.com/mj-selina/p/12373636.html" target="_blank" rel="noopener" class="uri">https://www.cnblogs.com/mj-selina/p/12373636.html</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/70745925" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/70745925</a></p>
</blockquote>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>论文分享</category>
      </categories>
      <tags>
        <tag>论文</tag>
        <tag>论文分享</tag>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-31-git进阶</title>
    <url>/2020/08/31/2020-08-31-git%E8%BF%9B%E9%98%B6/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>之前总结过git的一些基本命令，后来使用了更多git，写博客用于记录。不断更新 ，在实践中总结git知识点。</p>
<p>回顾下之前的git基本操作</p>
<ul>
<li>将现有的项目添加提交并上传到远程仓库</li>
</ul>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">git add . #添加当前文件夹下的所有文件</span><br><span class="line"></span><br><span class="line">git commit -m "first commit " # 引号内是本次的提交说明 </span><br><span class="line"></span><br><span class="line">git push -u origin master # 提交本地分支到远程分支</span><br><span class="line">		(若出现failed to push som refs to， 则执行git pull origin master，</span><br><span class="line">		将远程服务器github上的master拉下来，再重新push)</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li>clone代码</li>
</ul>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">git clone   https://github.com/raymond-zhao/cat-mall.git   ../Github/cat-mall </span><br><span class="line">#将cat-mall代码克隆到  ../Github/cat-mall 中</span><br></pre></td></tr></tbody></table></figure>
<h3 id="git-status-和-git-diff">git status 和 git diff</h3>
<p>在对文件进行修改之后，可以用 <code>git status</code> 查看结果，可以让我们时刻掌握仓库当前的状态</p>
<p><img src="https://i.loli.net/2020/08/31/fTmxaAeZG1iSCLd.png" alt="image-20200831180231338" style="zoom:67%;"></p>
<p>可以看到在<code>modified</code>部分，可以看到有四个文件被修改了，<strong>但是还没有进行提交（<code>commit</code>）修改</strong></p>
<p>而下半部分的<code>untracked files</code>表示的是<strong>之前从未提交到仓库分支</strong>的文件（一个markd文件，一个照片）</p>
<p>上述只是看到被修改的文件，但如果能看看具体修改了什么内容就好了，<code>git diff</code> 可以实现这个功能</p>
<p><img src="https://i.loli.net/2020/08/31/nVd3hGKLJy6f7zH.png" alt="image-20200831194816455"></p>
<p>可以看到修改的详细细节（红色为修改前的内容，绿色为修改后的内容）。向下箭头可以下拉文本，<code>q</code>退出查看 （quit）</p>
<p>这样就可以放心的添加（add）到仓库的暂存区，并提交（commit）到仓库分支</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m 20/8/31/commit1</span><br></pre></td></tr></tbody></table></figure>
<h4 id="小结">小结</h4>
<ul>
<li>要随时掌握工作区的状态，使用<code>git status</code>命令。</li>
<li>如果<code>git status</code>告诉你有文件被修改过，用<code>git diff</code>可以查看修改内容。</li>
</ul>
<h3 id="版本回退">版本回退</h3>
<p>每当文件修改到一定程度的时候，就可以“保存一个快照”，这个快照在Git中被称为<code>commit</code>。一旦你把文件改乱了，或者误删了文件，还可以从最近的一个<code>commit</code>恢复，然后继续工作，而不是把几个月的工作成果全部丢失。</p>
<p>在Git中，我们用<code>git log</code>命令查看：</p>
<p><img src="https://i.loli.net/2020/08/31/4lC7ufP6ZmbUvWT.png" alt="image-20200831233324006" style="zoom:80%;"></p>
<p><code>git log</code>命令显示从最近到最远的提交日志，每一次<code>commit</code>很详细</p>
<p>可以加上<code>--pretty=oneline</code>参数，来简化显示。推荐使用</p>
<p><img src="https://i.loli.net/2020/08/31/xNXAn7Pt8rT2mcE.png" alt="image-20200831233340202" style="zoom:80%;"></p>
<p>其中前面编号类似<code>012214236e...</code>的是<code>commit id</code>（版本号），是一个<code>SHA1</code>计算出来的一个非常大的数字，用十六进制表示</p>
<p>每个人的编号不一样，因为Git是分布式的版本控制系统，多人在同一个版本库里工作，如果大家都用1，2，3……作为版本号，那肯定就冲突了。</p>
<blockquote>
<p><a href="https://1024tools.com/hash" target="_blank" rel="noopener">Hash在线计算、md5计算、sha1计算、sha256计算、sha512计算</a></p>
</blockquote>
<h4 id="回退到历史版本">回退到历史版本</h4>
<p>这样我们就可以进行回退操作</p>
<p>首先，Git必须知道当前版本是哪个版本。</p>
<p>在Git中，用<code>HEAD</code>表示当前版本，也就是最新的提交<code>012214236e...</code>，上一个版本就是<code>HEAD^</code>，上上一个版本就是<code>HEAD^^</code>，当然往上100个版本写100个<code>^</code>比较容易数不过来，所以写成<code>HEAD~100</code>。</p>
<p>我们可以使用<code>git reset</code>命令：</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">git reset --hard HEAD^ <span class="comment">#回退到上一版本</span></span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2020/08/31/k37ptdoMJxGcufR.png" alt="image-20200831233416378"></p>
<p>结果显示出现在是<code>ca41b0a</code>，也就是上一次<code>commit</code>的版本。我们成功回退版本！</p>
<p>当我们再查看日志的时候，发现已经没有<code>20/8/31/commit1</code>版本了</p>
<p><img src="https://i.loli.net/2020/08/31/xWIlbtTwazUJNdO.png" alt="image-20200831233446124"></p>
<hr>
<h4 id="还原到最新版本">还原到最新版本</h4>
<p>如果想要再还原到<code>20/8/31/commit1</code>版本呢？</p>
<p>也是可以的，只要<strong><code>上面的命令行窗口还没有被关掉</code></strong>，就可以顺着往上找，找到那个<code>20/8/31/commit1</code>版本的<code>commit id</code>是<code>012214236e...</code>，于是就可以指定回到未来的某个版本：</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">git reset --hard 0221423</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2020/08/31/9pK7UsnRrv1loSD.png" alt="image-20200831233507305"></p>
<p>版本号没必要写全，前几位就可以了，Git会自动去找。当然也不能只写前一两位，因为Git可能会找到多个版本号，就无法确定是哪一个了。</p>
<p>这样就实现了还原到最后<code>commit</code>版本</p>
<p>Git的版本回退速度非常快，因为Git在内部有个指向当前版本的<code>HEAD</code>指针，当你回退版本的时候，Git仅仅是把HEAD从指向历史版本，再将工作区的文件更新即可</p>
<p>如果回退到了某个版本，关掉了命令行窗口，后悔想恢复到新版本但是找不到新版本的<code>commit id</code>怎么办？</p>
<p>在Git中，总是有后悔药可以吃的。Git提供了一个命令<code>git reflog</code>用来记录你的每一次命令：</p>
<p><img src="https://i.loli.net/2020/09/01/Ly4MDnv6WAEwQlV.png" alt="image-20200901000008019"></p>
<p>知道<code>commit_id</code>，还原版本就十分滴完美！</p>
<blockquote>
<p><strong>注！！！</strong></p>
<p>如果从历史版本回到最后的版本，也只能还原到最后<code>commit</code>后的版本。</p>
<p>我才开始<code>commit</code>了版本A，之后又写了一部分内容 B(未<code>commit</code>)。还原到了A-1版本，之后又想还原到A+B版本，操作完之后发现还原后的没有B部分，也就是我只能还原到A。</p>
<p>原因就是我在最后一次<code>commit</code>就是A，而写完B之后，没有<code>commit</code> ，于是无法还原。 （多多<code>commit</code>，</p>
<p>，还原需谨慎。我是真的折腾）<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f62d.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f62d.png?v8">😭</span></p>
</blockquote>
<h4 id="小结-1">小结</h4>
<ul>
<li><code>HEAD</code>指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令<code>git reset --hard commit_id</code>。 （commit_id也写成HEAD^）</li>
<li>穿梭前，用<code>git log</code>可以查看提交历史，以便确定要回退到哪个版本。</li>
<li>要重返未来，用<code>git reflog</code>查看命令历史，以便确定要回到未来的哪个版本。</li>
</ul>
<h4 id="参考">参考</h4>
<blockquote>
<p><a href="http://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html" target="_blank" rel="noopener">常用git命令清单-阮一峰</a></p>
<p><a href="http://www.ruanyifeng.com/blog/2012/08/how_to_read_diff.html" target="_blank" rel="noopener">读懂diff-阮一峰</a></p>
<p><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="noopener">git教程-廖雪峰</a></p>
<p><a href="http://www.runoob.com/git/git-install-setup.html" target="_blank" rel="noopener">git教程-菜鸟教程</a></p>
<p><a href="https://git-scm.com/book/zh/v2" target="_blank" rel="noopener">gitbook</a></p>
<p><a href="http://gitbook.liuhui998.com/index." target="_blank" rel="noopener">Git Community Book</a></p>
<p><a href="https://juejin.im/post/6844903586023866375" target="_blank" rel="noopener">从只会git add .的菜鸟到掌握git基本功能</a></p>
</blockquote>
<h3 id="工作区和暂存区">工作区和暂存区</h3>
<h4 id="工作区working-directory">工作区（Working Directory）</h4>
<p>就是在电脑里能看到的目录，比如我的<code>mynlog</code>文件夹就是一个工作区：</p>
<p><img src="https://i.loli.net/2020/09/01/lp9hvTzLtVuMPG5.png" alt="image-20200901000937480" style="zoom:80%;"></p>
<h4 id="版本库repository">版本库（Repository）</h4>
<p>也就是本地仓库</p>
<p>工作区有一个隐藏目录<code>.git</code>，这个不算工作区，而是Git的版本库。（选择<code>隐藏文件可见</code>就可以看到）</p>
<p>Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫<code>index</code>）的暂存区，还有Git为我们自动创建的第一个分支<code>master</code>，以及指向<code>master</code>的一个指针叫<code>HEAD</code>。</p>
<p><img src="https://i.loli.net/2020/09/01/wBe5iWuajDJKxdV.png" alt="image-20200901001300425" style="zoom:80%;"></p>
<p><img src="https://i.loli.net/2020/09/01/KywEFn2dtMJeBkq.png" alt="image-20200901001406385" style="zoom:80%;"></p>
<p>前面讲了我们把文件往Git版本库里添加的时候，是分两步执行的：</p>
<p>第一步是用<code>git add</code>把文件添加进去，实际上就是把文件修改添加到暂存区(<code>index</code>)；</p>
<p>第二步是用<code>git commit</code>提交更改，实际上就是把暂存区的所有内容提交到当前分支(<code>master</code>)。</p>
<p>因为我们创建Git版本库时，Git自动为我们创建了唯一一个<code>master</code>分支，所以，现在，<code>git commit</code>就是往<code>master</code>分支上提交更改。</p>
<p>你可以简单理解为，<strong>需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。</strong> 也就是可以多次<code>git add .</code> ,之后再一次性<code>git commit</code></p>
<p>我对文件进行修改之后，<code>git status</code> 显示如下：</p>
<p><img src="https://i.loli.net/2020/09/01/qZ4JcAzCrBOQng5.png" alt="image-20200901003431025"></p>
<p>这是对文件进行了修改，但是未添加（add）到暂存区和提交（commit）到仓库分支。 并且出现了之前从未提交的文件（四张png图片）</p>
<p>然后<code>git add .</code>,再查看目前的状态 <code>git status</code></p>
<p><img src="https://i.loli.net/2020/09/01/leMQO9F83N5DxUq.png" alt="image-20200901003844459"></p>
<p>出现了绿色的<code>new file</code>字样和<code>modified</code>，代表已添加到缓存区。</p>
<p>现在，暂存区的状态就变成这样了（原文是添加的readme和LICENSE文件）：</p>
<p><img src="https://i.loli.net/2020/09/01/MHQiJkB674jcAE5.png" alt="image-20200901003951252"></p>
<p>所以，<code>git add</code>命令实际上就是把要提交的所有修改放到暂存区（index），然后，执行<code>git commit</code>就可以一次性把暂存区的所有修改提交到分支。</p>
<p><img src="https://i.loli.net/2020/09/01/1uzidT9knarwNMU.png" alt="image-20200901004202394"></p>
<p>这时候再 <code>git status</code>，则是干净的</p>
<p>现在版本库变成了这样，暂存区就没有任何内容了：</p>
<p><img src="https://i.loli.net/2020/09/01/kCXlv3FiurZNbIO.jpg" alt="git-stage-after-commit"></p>
<h4 id="小结-2">小结</h4>
<p>了解工作区和暂存区的概念，并通过例子加强<code>git status</code> 、<code>git add</code>、<code>git commit</code>的理解</p>
<p>如果不用<code>git add</code>到暂存区，那就不会加入到<code>commit</code>中。也就是说<code>commit</code>只会提交暂存区里的内容</p>
<h3 id="撤销修改">撤销修改</h3>
<h4 id="在工作区撤销修改">在工作区撤销修改</h4>
<p>在工作区写的内容想要撤销，当然可以手动删除。同时还有另外的一种方法</p>
<p><code>git status</code> 查看一下状态</p>
<p><img src="https://i.loli.net/2020/09/01/qT7BN95PkQeSumd.jpg" alt="img"></p>
<p>根据git提示，可以知道如下信息：</p>
<ol type="1">
<li><code>changes not staged for commit</code>：表示没有更改添加到暂存区，也就是对于当前的修改还没有进行<code>add</code>操作</li>
</ol>
<p><img src="https://i.loli.net/2020/09/01/NfZ2vXuB4etLHxF.jpg" alt="img"></p>
<ol start="2" type="1">
<li><p>可以看到修改的部分是<code>2020-08-31-git 进阶.md</code>文件，不能显示中文，所以用编码表示</p></li>
<li><p>同时<code>next</code>文件也做了修改。这个每次都有提示，猜想应该是因为next是我<code>clone</code>下来的文件，所以存在<code>.git</code>文件，将<code>.git</code>文件删除就ok了</p></li>
<li><p>提示显示，<code>git checkout -- file</code>可以丢弃工作区（work directory）的修改</p></li>
</ol>
<h5 id="git-checkout----file">git checkout -- file</h5>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">git checkout -- <span class="built_in">source</span>/_posts/2020-08-31-git进阶.md （注意--不要遗漏，同时后面有一个空格）</span><br><span class="line"><span class="comment"># git checkout -- .  这种写法也是可以的，表示全部撤销</span></span><br></pre></td></tr></tbody></table></figure>
<p>命令<code>git checkout -- filename</code>意思就是，把<code>filename</code>文件在工作区的修改全部撤销，这里有两种情况：</p>
<ul>
<li>一种是文件自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态；</li>
<li>一种是文件已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。</li>
</ul>
<p>总之，就是让这个文件回到最近一次<code>git commit</code>或<code>git add</code>时的状态。</p>
<p><code>git checkout</code>其实是<strong>用版本库里的版本替换工作区的版本</strong>，无论工作区是修改还是删除，都可以“一键还原”。</p>
<h5 id="注">注</h5>
<ul>
<li>文件必须写当前git bash 下的完整路径，可以参考<code>git status</code>下的modified部分路径名称，如上的<code>source/_posts/</code></li>
<li>文件名必须写中文（就是正常的文件名），不能按照modified部分的编码后的名称</li>
</ul>
<p><img src="https://i.loli.net/2020/09/01/2l6Nxsh14bdpAY8.jpg" alt="img"></p>
<p>这是错误过程，可以看到最后一次没有提示，表示成功撤销修改</p>
<p>打开git进阶文件可以看到内容已经撤销</p>
<h4 id="添加到暂存区后的撤销">添加到暂存区后的撤销</h4>
<p>如果在工作区已经修改，并且添加到暂存区了，在<code>commit</code>之前，发现了这个问题。用<code>git status</code>查看一下，修改只是添加到了暂存区，还没有提交：</p>
<p><img src="https://i.loli.net/2020/09/01/CIASBwaTMEY3Gh1.png" alt="添加到暂存区前"></p>
<p><img src="https://i.loli.net/2020/09/01/T8jefu37XvFnZMJ.png" alt="添加到暂存区后"></p>
<ul>
<li>在添加到暂存区后，可以看到在<code>changes to be committed</code> 部分，添加的部分已经变成绿色，等待被<code>commit</code>提交</li>
<li>根据git提示，用命令<code>git reset HEAD &lt;file&gt;</code>可以把暂存区的修改撤销掉（<code>unstage</code>），重新放回工作区：</li>
</ul>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">git reset HEAD .</span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<p><code>git reset</code>命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用<code>HEAD</code>时，表示最新的版本。</p>
</blockquote>
<p>撤销到工作区的内容可以根据上述内容撤销其修改</p>
<h4 id="提交到版本库后的撤销">提交到版本库后的撤销</h4>
<p>前提是<strong>还没有把自己的本地版本库推送到远程</strong>。</p>
<p>可以利用上述的<code>版本回退</code>功能</p>
<h4 id="小结-3">小结</h4>
<ul>
<li>场景1：当你改乱了<code>工作区</code>某个文件的内容，想直接丢弃工作区的修改时，用命令<code>git checkout -- file</code>。</li>
<li>场景2：当你不但改乱了工作区某个文件的内容，还<code>添加到了暂存区</code>时，想丢弃修改，分两步，第一步用命令<code>git reset HEAD &lt;file&gt;</code>，就回到了场景1，第二步按场景1操作，用命令<code>git checkout -- file</code>。</li>
<li>场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考<code>版本回退</code>，不过前提是没有推送到远程库。</li>
</ul>
<h3 id="远程仓库">远程仓库</h3>
<h4 id="section"></h4>
<p>已经在本地创建了一个Git仓库后，又想在GitHub创建一个Git仓库，并且让这两个仓库进行远程同步，这样，GitHub上的仓库既可以作为备份，又可以让其他人通过该仓库来协作。</p>
<p>首先，登陆GitHub，然后，在右上角找到“Create a new repo”按钮，创建一个新的仓库</p>
<p>在Repository name填入<code>shijian</code>，其他保持默认设置，点击“Create repository”按钮，就成功地创建了一个新的Git仓库。出现以下界面：</p>
<p><img src="https://i.loli.net/2020/09/01/vMnFmb9aQU6xuXp.png" alt="image-20200901142716798"></p>
<p>复制仓库的SSH链接</p>
<p>根据提示，可以返回到需要上传的文件夹目录下，右键选择<code>git bash</code></p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">git init  <span class="comment">#创建.git隐藏文件，用于本地仓库</span></span><br><span class="line"></span><br><span class="line">git remote add origin git@github.com:OopsAaron/shijian.git <span class="comment">#关联本地仓库和github远程仓库</span></span><br></pre></td></tr></tbody></table></figure>
<p>添加后，<strong>远程库的名字就是<code>origin</code></strong>，这是Git默认的叫法，也可以改成别的，但是<code>origin</code>这个名字一看就知道是远程库。</p>
<p>接下来就是git的基本三样操作，添加提交并推送</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">git add . <span class="comment">#添加当前文件夹下的所有文件</span></span><br><span class="line"></span><br><span class="line">git commit -m <span class="string">"first commit "</span> <span class="comment"># 引号内是本次的提交说明 </span></span><br><span class="line"></span><br><span class="line">git push -u origin master <span class="comment"># 提交本地分支到远程分支</span></span><br><span class="line">		(若出现failed to push som refs to， 则执行git pull origin master，</span><br><span class="line">		将远程服务器github上的master拉下来，再重新push)</span><br></pre></td></tr></tbody></table></figure>
<p>把本地库的内容推送到远程，用<code>git push</code>命令，实际上是把当前分支<code>master</code>推送到远程。这时候在github界面就可以看到推送的文件</p>
<blockquote>
<p>第一次push的时候可以添加参数 <code>-u</code> ，之后可以不添加</p>
<p>由于远程库是空的，我们第一次推送<code>master</code>分支时，加上了<code>-u</code>参数，Git不但会把本地的<code>master</code>分支内容推送的远程新的<code>master</code>分支，还会把本地的<code>master</code>分支和远程的<code>master</code>分支关联起来，在以后的推送或者拉取时就可以简化命令。</p>
</blockquote>
<h4 id="section-1"></h4>
<h3 id="分支">分支</h3>
<p>分支暂时用不到，就没有学习</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-30-阅读论文</title>
    <url>/2020/08/30/2020-08-30-%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87/</url>
    <content><![CDATA[<p>一篇论文至少要看三遍。 第一遍，仔细阅读论文中的标题、摘要和关键词。 第二遍，阅读文中的导言、结论以及图表，快速扫描一下论文剩下的内容。 这一步主要是要把握论文中的关键信息，不光是导言和结论，还包括文章中任何小结论的总 结，文中涉及的补充信息都跳过。 第三遍，阅读论文的整个部分，但是要跳过任何可能陌生看不懂的数学公式，技术术语。</p>
<p>不过，如果你需要对这个专业领域有一个「深入」的理解，那就必须要搞懂那些公式术语 了。</p>
<blockquote>
<p>参考</p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzA5ODEzMjIyMA==&amp;mid=2247501483&amp;idx=1&amp;sn=9b21f8e62fa2b4b33045900a1e721d30&amp;chksm=9094cf38a7e3462ed5901bd8b0b8ebf99a892b31d75aa6eaf8b3c8cc7698b1d708fd0891ab3e&amp;mpshare=1&amp;scene=1&amp;srcid=08304BRBOlTyXb4qDBM5SGTj&amp;sharer_sharetime=1598771438122&amp;sharer_shareid=2c9f868695c34cf5ff5f7a42eab3d2ed&amp;key=9b9af4fa8e2c96d71311b901f9c755ada338c70880cf596dfe4bc2b5ca69cfb094a0a310cf713fb50591ef0933e5f438e73110d797ab7406eeefa5dd5f4c460076a3e94537447c235df683c3eb24a048c7472ad2cdef063ec759505ebb6902987eb9a08ca55be656525ace69f39c8cdbedf7f2b71fa3d2c7c2c4b0dd2e660589&amp;ascene=1&amp;uin=ODEyNzQwMTM5&amp;devicetype=Windows+10+x64&amp;version=62090529&amp;lang=zh_CN&amp;exportkey=A4y9BBn%2B1GAGlkX0mhK71n0%3D&amp;pass_ticket=tS9Bcx3H%2FQ34yaxv%2F0nHTttU4aZeBoKDlw2k4Zwl5JMpqZkqPjEwcrpqIlAybtka" target="_blank" rel="noopener">沈向阳：读论文的三个层次</a></p>
<p><a href="https://www.youtube.com/watch?v=Du7qLsToW-o&amp;t=443s" target="_blank" rel="noopener">youtube视频，沈向阳读论文</a></p>
<p><a href="https://mp.weixin.qq.com/s?subscene=19&amp;__biz=MzIzNjc1NzUzMw==&amp;mid=2247546863&amp;idx=2&amp;sn=275577791d4cee894bd874eedc846f88&amp;chksm=e8d0809ddfa7098b90f2d601d59c1ea11162180387dd9677a96c03e666c1b1e05f8e719d989e&amp;scene=7&amp;ascene=1&amp;devicetype=Windows+10+x64&amp;version=62090529&amp;nettype=cmnet&amp;abtest_cookie=AAACAA%3D%3D&amp;lang=zh_CN&amp;exportkey=Ax%2BhWVV2Xr753%2BtDF%2BAIKRw%3D&amp;pass_ticket=sT%2F05g2Sqp72CoAfTsiZ8TDrxTKg0f%2FTh968brMSrSyOqE%2F1GuTq0PTOveYYBqof&amp;wx_header=0&amp;key=573aef4c1f9b4b5fc4e631a99eb0547e4182bf3ee5dd048cf4487f739b93c9b004f67e751713dea6880a5a922c03ceb30730558ff6be83d973abec53f6fb592491c98a1e205921d9c380c59d6f30c92ea2b1836956318f54b99e962b4d620a7ca074f2e317b259e495570360cc981c43758194fb5e38587a176b8af431cca351&amp;uin=ODEyNzQwMTM5" target="_blank" rel="noopener">吴恩达教你如何读论文：绘制进度表格，论文至少看三遍，还要问自己问题</a></p>
</blockquote>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
  </entry>
  <entry>
    <title>2020-08-29-temp</title>
    <url>/2020/08/29/2020-08-29-temp/</url>
    <content><![CDATA[<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
  </entry>
  <entry>
    <title>2020-08-27-edge还原到旧版本问题</title>
    <url>/2020/08/27/2020-08-27-edge%E8%BF%98%E5%8E%9F%E5%88%B0%E6%97%A7%E7%89%88%E6%9C%AC%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>win10自动更新edge，但是新版的edge用的是Chromium内核，新功能添加不少，也全部支持chrome的插件，但是对pdf的支持不友好，和chrome一个德行<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f611.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f611.png?v8">😑</span>。导致我在旧版本edge阅读论文时做的笔记在新版edge体验感极差，于是想着回退到旧版本 （edge不就是用来阅读论文的 ）<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8">😆</span></p>
<h3 id="版本回退">版本回退</h3>
<p>百度后发现将新版本的edge删除，就可以自己回退到旧版本的edge</p>
<p>geek<code>强制删除</code>新版edge之后，系统回退到旧版edge了。但是同时发现原来的一些设置消失了，系统不太稳定，可能是强制删除了一些系统配置文件。不太清楚具体原因，待解决</p>
<p>导致如下两个功能消失</p>
<ul>
<li>在开始栏中不显示安装的软件</li>
<li>在文件夹右键不能使用<code>发送到</code>功能</li>
</ul>
<p>目前发现这两个不能使用的功能。可能还存在其它故障。平时经常通过<code>开始栏</code>打开软件，不显示之后有点麻烦</p>
<h3 id="解决">解决</h3>
<p>用<code>listary</code>软件快速搜索软件名称，（双击ctrl键打开搜索框），然后添加到Rolan中，如图所示</p>
<p><img src="https://i.loli.net/2020/09/04/Kbk3ERwsMJ9AhlP.png" alt="image-20200904145340602" style="zoom:80%;"></p>
<h3 id="小结">小结</h3>
<ul>
<li>下次还是少用geek强制删除吧，乖乖在<code>程序与功能</code>中卸载删除吧，有可能涉及系统配置文件的就不要轻易删除</li>
<li>等待新版edge友好支持论文阅读</li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <tags>
        <tag>故障排除</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-25-chrome插件</title>
    <url>/2020/08/25/2020-08-25-chrome%E6%8F%92%E4%BB%B6/</url>
    <content><![CDATA[<h3 id="下载提速"><strong>下载提速</strong></h3>
<ul>
<li><h4 id="使用场景"><strong>使用场景</strong></h4></li>
</ul>
<p>Chrome的下载速度，有时候确实是慢得可以跟某网盘相媲美了，甚至赶不上某些国产浏览器。</p>
<p>这是因为，Google为了兼容所有的电脑性能和带宽，在Chrome中采取的是保守<strong>单线程下载机制</strong>，这就导致很多时候下载速度非常慢了。</p>
<p><img src="https://i.loli.net/2020/08/25/5ZMgPIUfc2YndtE.png" alt="img"></p>
<p>不过，很多人都不知道的是，Chrome其实也是自带多线程下载功能的。所谓多线程下载，就是可以同时对资源建立多个连接，提升下载速度。</p>
<p>只是这个功能是默认关闭的，需要用户手动去开启。</p>
<ul>
<li><h4 id="使用方法"><strong>使用方法</strong></h4></li>
</ul>
<p>在浏览器地址栏输入以下网址并回车：</p>
<p><strong>chrome://flags/#enable-parallel-downloading</strong></p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/D1XlU0QfU3GnNfPmPtO4D3rncDTK3kFcCxQMtjnyMUqI5hTIZydfXEDTnp06YjKEBIbdlnvUoFj3ht3ibXUatiaw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img"></p>
<p>在Parallel downloading的后面选项里，把「default」改为「Enabled」，并按照提示重启浏览器。</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/D1XlU0QfU3GnNfPmPtO4D3rncDTK3kFcYca3x5SEBJpOky2icdUADwP04jUYiaib6WvUQZ9XlSNHdeiach2RMydRGg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img"></p>
<p>这样就可以开启多线程下载了，经过实际测试，下载速度至少提高了三倍左右（也有可能下载速度飙升一段时间又跌回去）。</p>
<h3 id="link-to-text-fragment">Link to Text Fragment</h3>
<p>实际上就是带锚点功能的网页分享工具。</p>
<p>所谓锚文本，简单来说就像是关键词的定位，将关键字指向指向另一个页面的链接就是锚文本。这个工具则可以让你将网页上选中的文本片段生成为一个锚文本。</p>
<p><strong>当你点击这个锚文本时，就会直接跳转到该网页对应标记的锚点上了。</strong></p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/D1XlU0QfU3FtLAG0sobAP0xrYk6LJk6m3AU0icjVgSjiavYp3msxibjM7D9U6PXFbzm4wUeZ6OkaFibhPXLFeIBLOQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img"></p>
<h4 id="使用方法-1"><strong>使用方法</strong></h4>
<h5 id="生成锚文本"><strong>生成锚文本</strong></h5>
<p>鼠标划词选中文本，在右键菜单中选择【Copy Link to Text Fragment】，然后可以看到该文本被黄色标记。</p>
<p><img src="https://i.loli.net/2020/08/25/ns29PiDENtvJp3R.gif" alt="img"></p>
<h5 id="打开锚文本"><strong>打开锚文本</strong></h5>
<p>此时，锚文本已经自动生成并复制到你的剪贴板上，你可以将它发送给需要分享的好友，或者在浏览器中打开，另存为书签。</p>
<p>可以看到，在浏览器内打开这个锚文本，网页会自动定位到我们做了锚点的文本部分，再也不需要我们自行阅读查找，非常方便。</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_gif/D1XlU0QfU3FtLAG0sobAP0xrYk6LJk6m5F5vhCQoN8IeaxDibdMzqk2jFVjhDDhGMJdY3ZHpibCicN5yWbsRoN9Bg/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt="img"></p>
<p>需要注意的是，这个锚文本也<strong>仅限在安装了Link to Text Fragment插件的浏览器上打开</strong>，若没有安装则不会跳转对应位置。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>chrome</category>
      </categories>
      <tags>
        <tag>chrome</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-23-google搜索的高效使用</title>
    <url>/2020/08/23/2020-08-23-google%E6%90%9C%E7%B4%A2%E7%9A%84%E9%AB%98%E6%95%88%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h3 id="section">“”</h3>
<p>以整个短语作为搜索关键词，而不是拆开成每个词。</p>
<p>表示完全匹配，结果中必须出现与搜索文本完全相同的内容。</p>
<h3 id="a--b">A -B</h3>
<p>搜索包含A但不包含B的结果（请注意A后面的<strong>空格不能省略</strong>）</p>
<p><img src="https://i.loli.net/2020/08/23/pjDWIreKGtJU7Oa.png" alt="image-20200823173525379" style="zoom: 67%;"></p>
<p>当加上 <code>-poweredge</code> 时，就可以屏蔽掉机架式服务器关键字中所有含有poweredge的内容</p>
<p><img src="https://i.loli.net/2020/08/23/k2vbVtdCMBYzJfQ.png" alt="image-20200823173614387" style="zoom:67%;"></p>
<h3 id="filetype">filetype</h3>
<p>搜索对应类型的文件。例如：<code>时间简史 filetype:pdf</code>，即为搜索包含关键字时间简史的pdf文件。（请注意<strong>使用英文的冒号</strong>） （一般不加filetype也可以）</p>
<p><img src="https://i.loli.net/2020/08/23/UBJHv4YmfiGRhuy.png" alt="image-20200823174000514" style="zoom:67%;"></p>
<h3 id="site">site</h3>
<p>在某个网站内搜索，比如：site:<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com">http://pan.baidu.com</a> 特别好用，用来搜百度云里的资源。再如：</p>
<p>在我们实验室网站查找<code>招生</code>关键字，则 <code>招生 site:http://www.ubinec.org/</code>，十分便捷。</p>
<p>（直接招生 site:ubinec.org/ 也可以 ，中间不要加空格 ）</p>
<p><img src="https://i.loli.net/2020/08/24/aypbHTDAnF79CIi.png" alt="image-20200824160653772" style="zoom:67%;"></p>
<h3 id="section-1">*</h3>
<p>很多时候想搜一个东西但是不确定具体名字，可以用星号代替忘了的字，可以代替多个字</p>
<h3 id="define">define</h3>
<p><strong>当字典或快速查找意思</strong>，如[define:right]，还能看到单词在书籍中出现频率的年代变化，词源等；</p>
<p><img src="https://i.loli.net/2020/08/24/skUBwAFtVMm6OWJ.png" alt="image-20200824162755266" style="zoom:67%;"></p>
<h3 id="section-2">~</h3>
<p>同时搜索近义词。如搜“higher education” 和 “university”</p>
<h3 id="or-或逻辑">OR (或)逻辑</h3>
<p>通过<em>OR</em> 搜索, 可以得到和两个关键词分别相关的结果, 而不仅仅是和两个关键词都同时相关的结果.</p>
<p><img src="E:\myBlog\source\_posts\image-20200824193744947.png" alt="image-20200824193744947" style="zoom:67%;"></p>
<p><img src="E:\myBlog\source\_posts\image-20200824193731306.png" alt="image-20200824193731306" style="zoom:67%;"></p>
<h3 id="限定年份">限定年份</h3>
<ol type="1">
<li>在google工具选项中可以选择时间</li>
</ol>
<p><img src="E:\myBlog\source\_posts\image-20200824194504266.png" alt="image-20200824194504266" style="zoom:67%;"></p>
<ol start="2" type="1">
<li><code>世界杯 2010..2014</code></li>
</ol>
<h3 id="参考">参考</h3>
<p><img src="https://i.loli.net/2020/08/24/uqRyUOdYnGJbxHN.jpg" alt="preview"></p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
  </entry>
  <entry>
    <title>2020-08-19-期望、方差、协方差及相关系数的基本运算</title>
    <url>/2020/08/19/2020-08-19-%E6%9C%9F%E6%9C%9B%E3%80%81%E6%96%B9%E5%B7%AE%E3%80%81%E5%8D%8F%E6%96%B9%E5%B7%AE%E5%8F%8A%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%BF%90%E7%AE%97/</url>
    <content><![CDATA[<p>链接</p>
<p>https://blog.csdn.net/touristman5/article/details/56281887</p>
<p>https://developer.aliyun.com/article/65262</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
  </entry>
  <entry>
    <title>2020-08-19-解读卡尔曼滤波[第二部分]</title>
    <url>/2020/08/19/2020-08-19-%E8%A7%A3%E8%AF%BB%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86/</url>
    <content><![CDATA[<p>在开始之前，我想解释几个基本术语，如方差（variance）、标准差（standard deviation）、估计值（estimate）、准确度（accuracy）、精度（precision）、平均值（mean）和期望值（expected value）。</p>
<p>我想本教程的许多读者都熟悉基本统计学知识。但是，在本教程的开头，我承诺提供理解卡尔曼滤波器操作所需的必要背景知识。如果您熟悉这个主题，可以跳过它。</p>
<ul>
<li><strong>平均值与期望值</strong></li>
</ul>
<p>虽然<strong>平均值(mean)</strong>与<strong>期望值（expected value）</strong>是密切相关的术语。但是，它们是不同的。</p>
<p>例如，假设有五种不同的硬币——两个5美分的硬币和三个10美分的硬币，我们可以通过平均硬币的价值来轻松计算硬币的平均值。</p>
<p><img src="https://i.loli.net/2020/08/19/JxTbfDa2QOrz4oj.png" alt="image-20200819144207768"></p>
<p>上述结果不能被定义为期望值，因为系统状态（硬币值）没有被隐藏（想要表达的是确定的，此处没有任何不确定性），我们已经使用了所有的population（所有5枚硬币）来计算平均值。</p>
<p><strong>译者补充：因为很多同学经常混淆平均值与期望值的概念，因此，我在此特别解释一下。在解释两个概念之前，先说一下“大数法则”。</strong></p>
<ul>
<li>先说一下大数法则：</li>
</ul>
<p><img src="https://i.loli.net/2020/08/19/cHPovqVb2RFOS3r.jpg" alt="img"></p>
<ul>
<li>思考一下为什么会用到期望值？</li>
</ul>
<p><img src="https://i.loli.net/2020/08/19/F6K9M4aPrJxgnOS.jpg" alt="img"></p>
<p><img src="https://i.loli.net/2020/08/19/1QKexZgmNF6STPt.jpg" alt="img"></p>
<p>期望值也就是每个数*对应的概率值，再求和</p>
<p><strong>译者补充完毕。</strong></p>
<p>现在假设同一个人的五个不同的体重测量值：79.8kg，80kg，80.1kg，79.8kg和80.2kg。</p>
<p>由于秤的随机测量误差，称重测量值不同。 我们不知道准确的重量值是多少，因为它是一个<strong>隐藏变量Hidden Variable</strong>。 但是，我们可以通过平均尺度测量来估计重量。 （准确测量值不可知）</p>
<p><img src="https://i.loli.net/2020/08/19/PjARubvWoLmEV5U.png" alt="image-20200819145014158"></p>
<p>估计的结果是体重的期望值。</p>
<p>平均数经常使用希腊字母：<strong>μ</strong></p>
<p>期望值使用字母：<strong>E</strong></p>
<ul>
<li><strong>方差与标准差</strong></li>
</ul>
<p>方差用来度量随机变量与其期望值（即随机变量的期望值）之间的离散程度。</p>
<p>标准差是方差的平方根。标准差： <img src="https://www.zhihu.com/equation?tex=%5Csigma" alt="[公式]"> ，方差： <img src="https://www.zhihu.com/equation?tex=%5Csigma%5E%7B2%7D" alt="[公式]"></p>
<p>例如，我们想比较两个高中篮球队的身高。下表提供了两支球队的球员身高及其平均值。</p>
<p><img src="https://pic4.zhimg.com/80/v2-d6b2fea25722ffe4774167c3ca530177_1440w.png" alt="img"></p>
<p>如我们所见，两队的平均身高是一样的。现在让我们检查一下高度变化height variance。</p>
<p>由于方差用来度量随机变量与其期望值（即随机变量的期望值）之间的离散程度，我们想知道数据集偏离其平均值的情况。我们可以通过从每个变量中减去平均值来计算每个变量与平均值之间的距离。</p>
<p>我们将用x表示高度，用希腊字母μ表示高度的平均值。每个变量与平均值的距离为：</p>
<p><img src="https://pic1.zhimg.com/80/v2-8aeb370b55ec20c81cd6fb0ea1581a60_1440w.jpg" alt="img"></p>
<p>下表给出了每个变量与平均值之间的距离。</p>
<p><img src="https://picb.zhimg.com/80/v2-47a3cbd7c92a22bc2c1b532557d90609_1440w.png" alt="img"></p>
<p>下表给出了每个变量与平均值的平方距离。</p>
<p>有些值是负数。为了消除负值影响，让我们将高度与平均值的距离平方：</p>
<p><img src="https://picb.zhimg.com/80/v2-2bcc387a3d7e0da6267b04936c845c17_1440w.jpg" alt="img"></p>
<p><img src="https://pic4.zhimg.com/80/v2-759cb19ebbc545066259cfefb22237fb_1440w.png" alt="img"></p>
<p>为了计算数据集的离散程度，我们需要从中找出所有平方距离的平均值：</p>
<p><img src="https://pic2.zhimg.com/80/v2-0d382cddfdce473dfc744a382782c5ac_1440w.jpg" alt="img"></p>
<p>A队的方差是：</p>
<p><img src="https://pic3.zhimg.com/80/v2-9cc05c08921aab36b395d5b42134c911_1440w.png" alt="img"></p>
<p>B队的方差是：</p>
<p><img src="https://pic2.zhimg.com/80/v2-2b935f764b16ebf4b3420fd0f25574a5_1440w.png" alt="img"></p>
<p>我们可以看出，虽然两队的平均值相同，但A队的身高分布值高于B队的身高分布值，这意味着A队在控球员、中锋和后卫等不同位置有不同的球员，而B队球员则技能相差无几。</p>
<p>方差的单位是平方的；查看标准差更方便。正如我已经提到的，标准差是方差的平方根。</p>
<p><img src="https://pic1.zhimg.com/80/v2-4e5b9f3338566969fe0523fa06731489_1440w.jpg" alt="img"></p>
<p>A队运动员身高的标准差为0.12米。</p>
<p>B队运动员身高的标准差为0.036米。</p>
<p>进一步的，现在，假设我们要计算所有高中篮球运动员的平均值和方差。这是一项非常艰巨的任务，我们需要收集所有高中运动员的数据。</p>
<p>但是，我们可以通过选择一个大的数据集并对这个数据集进行计算来估计参与者的平均值和方差。（样本估计全局）</p>
<p>随机选取的100名选手的数据集足以进行准确的估计。</p>
<p>然而，当我们<strong>估计方差</strong>时，方差计算公式略有不同。我们不用N因子归一化，而是用N - 1因子归一化:</p>
<p><img src="https://pic1.zhimg.com/80/v2-9045e0012dc9592019009cca6c64f97f_1440w.jpg" alt="img"></p>
<p>你可以在以下资源中看到这个方程的数学证明：<a href="https://link.zhihu.com/?target=http%3A//www.visiondummy.com/2014/03/divide-variance-n-1/">http://www.visiondummy.com/2014/03/divide-variance-n-1/</a></p>
<hr>
<ul>
<li><strong>正态分布</strong></li>
</ul>
<p>事实证明，许多自然现象服从正态分布。继续以篮球运动员身高为例，如果随机选取运动员，构建大数据集，绘制身高VS.身高（heights vs. heights）的频率曲线图，得到“钟形”曲线，如下图所示:</p>
<p><img src="https://pic4.zhimg.com/80/v2-ca75549d80903118ac9a6ac08b58debc_1440w.jpg" alt="img"></p>
<p>正如你所看到的，这条曲线关于平均值（平均值是1.9米）对称。平均值附近值的频率高于远处值的频率。</p>
<p>高度的标准差等于0.2米。68.26%的值在平均值的一个标准差内。如下图所示，68.26%的值介于1.7米和2.1米之间（绿色区域占曲线下总面积的68.26%）。</p>
<p><img src="https://pic2.zhimg.com/80/v2-0f51f3a38d61049e8dc5dd18e363c114_1440w.jpg" alt="img"></p>
<p>95.44%的值在距离平均值的两个标准差内。</p>
<p>99.74%的值在距离平均值的三个标准差内。</p>
<p>正态分布，也称为高斯分布（它以数学家Carl Friedrich Gauss的名字命名），由以下方程描述：</p>
<p><img src="https://pic4.zhimg.com/80/v2-e4aee9ac01b76d9d688929e3d07ae69e_1440w.jpg" alt="img"></p>
<p>通常，测量误差是正态分布的，因此<code>卡尔曼滤波器设计基于测量误差是正态分布的假设。</code></p>
<hr>
<ul>
<li><strong>估计、准确度与精度</strong></li>
</ul>
<p><strong>— 估计（Estimate）：</strong>评估系统的隐藏状态。飞机的真实位置对观察者来说是隐藏的。我们可以用雷达等传感器来估计飞机的位置。采用多传感器和先进的估计跟踪算法（如卡尔曼滤波），可以显著提高估计精度。每一个测量或计算参数都是一个估计值。</p>
<p><strong>— 准确度（Accuracy）：</strong>表明测量值与真实值的接近程度。</p>
<p><strong>— 精度（Precision）：</strong>描述同一参数的许多 度量值中有多少可变性。准确度和精度是估算的基础。</p>
<p>下图说明了准确度和精度。</p>
<p><img src="https://pic3.zhimg.com/80/v2-7a1dfe3f5186ade70b8937099fb180a8_1440w.jpg" alt="img"></p>
<p><strong>高精度系统的测量方差较低</strong>（即不确定度/离散程度/变化程度较低），而低精度系统的测量方差较大（即不确定度/离散程度/变化程度较高）。方差是由随机测量误差产生的。</p>
<p>低精度系统被称为偏差系统，因为它们的测量具有内置的系统误差（偏差）。</p>
<p>通过<strong>平均或平滑测量</strong>可以显著降低方差的影响。例如，如果我们使用一个具有随机测量误差的温度计来测量温度，我们可以进行多次测量并对测量的值进行平均。由于误差是随机的，所以有些测量值会高于真实值，而另一些测量值会低于真实值。我们做的测量越多，估计就越接近。</p>
<p>另一方面，如果温度计有偏差，估计将包括一个恒定的系统误差。</p>
<p>本教程中的所有示例都假定系统是无偏差的。</p>
<p><img src="E:\myBlog\source_posts\image-20200819194609812.png" alt="image-20200819194609812"></p>
<p>极小化性能指标： 最优解</p>
<p><img src="E:\myBlog\source_posts\image-20200819195511498.png" alt="image-20200819195511498"></p>
<p>J就是选择能够令方差 <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7B%28%7BX_%7Bi%7D%7D%28%5Ctheta_%7Bhat%7D%29-%5Cmu%29%5E2%7D" alt="[公式]"> 最小的的参数。 X^就是最优解</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>研究方向</category>
      </categories>
      <tags>
        <tag>卡尔曼滤波</tag>
        <tag>RKN</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-18-解决hexo发布文章报错</title>
    <url>/2020/08/18/2020-08-18-%E8%A7%A3%E5%86%B3hexo%E5%8F%91%E5%B8%83%E6%96%87%E7%AB%A0%E6%8A%A5%E9%94%99/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>在进行<code>hexo s -g</code> 发布文章时，出现如下错误</p>
<p><img src="https://i.loli.net/2020/08/18/p17vthyDgEBlukC.png" alt="image-20200818023730784"></p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>故障排除</category>
      </categories>
      <tags>
        <tag>故障排除</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-18-解决图片caption出现多次</title>
    <url>/2020/08/18/2020-08-18-%E8%A7%A3%E5%86%B3%E5%9B%BE%E7%89%87caption%E5%87%BA%E7%8E%B0%E5%A4%9A%E6%AC%A1/</url>
    <content><![CDATA[<p>大部分参考自<a href="https://wylu.github.io/posts/7bd83fc5/" target="_blank" rel="noopener">Hexo NexT 图片caption出现多次</a></p>
<p>在使用 Hexo + NexT 搭建个人博客的过程中一直有个问题没有解决，直到今天才找到了解决方法。问题就是在展示同一张图片中，caption出现了两次，如图：</p>
<p><a href="https://cdn.jsdelivr.net/gh/wylu/cdn/post/Tool/Hexo/Hexo-NexT-图片caption出现多次/multiple-captions.png" target="_blank" rel="noopener"><img src="https://cdn.jsdelivr.net/gh/wylu/cdn/post/Tool/Hexo/Hexo-NexT-图片caption出现多次/multiple-captions.png" alt="multiple-captions"></a></p>
<h3 id="问题分析">问题分析</h3>
<p>图片正下方的 image-caption 是 NexT 给 fancybox 加上的；而图片左下方的 figcaption 是因为使用了 hexo-renderer-pandoc Markdown 渲染器导致的，hexo-renderer-pandoc 将 Markdown 文件渲染成 HTML 时，会对图片进行渲染，然后生成一个 figcaption 的标签。</p>
<p>很多人可能不会有这样的问题，因为 Hexo 默认的 Markdown 渲染器是 hexo-renderer-marked，hexo-renderer-marked 渲染图片时不会生成 figcaption。</p>
<p>如果你使用的是 hexo-renderer-marked 渲染器，就不会有这样的问题，但是相信很多人都是因为需要使用 mathjax，所以都将默认的 Hexo 默认的 Markdown 渲染器换成了 hexo-renderer-pandoc，hexo-renderer-pandoc 功能强大（依赖与 pandoc 自身强大的功能），它对数学公式的渲染简直可以说是吊打 hexo-renderer-marked，这也是我一直使用它的原因。</p>
<p>所以为了在使用 hexo-renderer-pandoc 的同时，把图片 caption 出现了两次的问题解决，我提过 issue，查阅了许多资料，终于找到了解决的方法。</p>
<h3 id="解决方法">解决方法</h3>
<p>编辑站点配置文件 <code>_config.yml</code>，添加如下内容：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">pandoc:</span><br><span class="line">  extensions:</span><br><span class="line">    - '-implicit_figures'</span><br></pre></td></tr></tbody></table></figure>
<p>执行下列命令重新生成站点，展示效果如下：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">$ hexo clean &amp;&amp; hexo g &amp;&amp; hexo s -o</span><br></pre></td></tr></tbody></table></figure>
<p><a href="https://cdn.jsdelivr.net/gh/wylu/cdn/post/Tool/Hexo/Hexo-NexT-图片caption出现多次/single-caption.png" target="_blank" rel="noopener"><img src="https://cdn.jsdelivr.net/gh/wylu/cdn/post/Tool/Hexo/Hexo-NexT-图片caption出现多次/single-caption.png" alt="single-caption"></a></p>
<h3 id="隐藏-fancybox-的-caption">隐藏 fancybox 的 caption</h3>
<p>以 NexT v7.7.0 为例，通过查看 hexo-theme-next/source/js/utils.js 源码，发现 NexT 在使用 fancybox 时，如果图片 title 或 alt 属性不为空时，就会 fancybox 添加一个子标签展示图片的 title 或 alt 属性值。</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">var imageTitle = $image.attr('title') || $image.attr('alt');</span><br><span class="line">if (imageTitle) {</span><br><span class="line">  $imageWrapLink.append(`&lt;p class="image-caption"&gt;${imageTitle}&lt;/p&gt;`);</span><br><span class="line">  // Make sure img title tag will show correctly in fancybox</span><br><span class="line">  $imageWrapLink.attr('title', imageTitle).attr('data-caption', imageTitle);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>如果想通过配置支持选择是否展示 caption，可以参考下方的方法（在 NexT v7.7.0 已测试过），其实不管 NexT 的版本如何，解决方法的思路基本是一致的。</p>
<p>首先修改主题配置文件 <code>_config.yml</code>，找到 fancybox 的配置，将 fancybox 的配置改成如下所示内容：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># FancyBox is a tool that offers a nice and elegant way to add zooming functionality for images.</span><br><span class="line"># For more information: https://fancyapps.com/fancybox</span><br><span class="line">fancybox: </span><br><span class="line">  enable: true</span><br><span class="line">  caption: false</span><br></pre></td></tr></tbody></table></figure>
<p>其中，enable 控制是否启用 fancybox，而 caption 控制是否展示 caption (当然只有在 enable 为 true 时，caption 配置才有效)，如果你不启用 fancybox 自然也不会有 caption。</p>
<p>然后，编辑 hexo-theme-next/source/js/utils.js 文件，将上面的代码修改成如下内容：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">var imageTitle = $image.attr('title') || $image.attr('alt');</span><br><span class="line">if (imageTitle) {</span><br><span class="line">  if (CONFIG.fancybox.caption) {</span><br><span class="line">    $imageWrapLink.append(`&lt;p class="image-caption"&gt;${imageTitle}&lt;/p&gt;`);</span><br><span class="line">  }</span><br><span class="line">  // Make sure img title tag will show correctly in fancybox</span><br><span class="line">  $imageWrapLink.attr('title', imageTitle).attr('data-caption', imageTitle);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>接着，编辑 hexo-theme-next/source/js/next-boot.js 文件，将 <code>CONFIG.fancybox &amp;&amp; NexT.utils.wrapImageWithFancyBox();</code> 替换成如下内容：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Register JS handlers by condition option.</span><br><span class="line"> * Need to add config option in Front-End at 'layout/_partials/head.swig' file.</span><br><span class="line"> */</span><br><span class="line">CONFIG.fancybox.enable &amp;&amp; NexT.utils.wrapImageWithFancyBox();</span><br></pre></td></tr></tbody></table></figure>
<p>相信你可以发现，我们这里将 <code>CONFIG.fancybox</code> 替换成 <code>CONFIG.fancybox.enable</code>，正是因为我们自定义的配置是通过 fancybox 下的 enable 的值来确定是否启用的。另外从源码上方的注释可以看到，CONFIG 下的配置项需要在前端文件 'layout/_partials/head.swig' （实际上该文件在'layout/_partials/head/head.swig'）中加上。</p>
<p>所以最后，我们需要在 <code>layout/_partials/head/head.swig</code> 中修改一下上面我们所使用 <code>CONFIG.fancybox.caption</code> 配置。参照其它配置，这里需要将 <code>fancybox:</code>，修改成如下内容：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">fancybox: {{ theme.fancybox | json }}</span><br></pre></td></tr></tbody></table></figure>
<p>重新生成，效果如下：</p>
<p><a href="https://cdn.jsdelivr.net/gh/wylu/cdn/post/Tool/Hexo/Hexo-NexT-图片caption出现多次/no-caption.png" target="_blank" rel="noopener"><img src="https://cdn.jsdelivr.net/gh/wylu/cdn/post/Tool/Hexo/Hexo-NexT-%E5%9B%BE%E7%89%87caption%E5%87%BA%E7%8E%B0%E5%A4%9A%E6%AC%A1/no-caption.png" alt="no-caption"></a></p>
<blockquote>
<h3 id="references">References</h3>
<p>https://github.com/wzpan/hexo-renderer-pandoc/issues/34</p>
<p>https://github.com/theme-next/hexo-theme-next/issues/857</p>
</blockquote>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>故障排除</category>
      </categories>
      <tags>
        <tag>故障排除</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-14-解读卡尔曼滤波[第一部分]</title>
    <url>/2020/08/14/2020-08-14-%E8%A7%A3%E8%AF%BB%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%5B%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%5D/</url>
    <content><![CDATA[<h3 id="关于卡尔曼滤波">关于卡尔曼滤波</h3>
<p>大多数现代系统都搭载上数量众多的传感器，它们通过传感器返回的一系列测量数据来估算一些有用的信息。例如，我们生活上的GPS接收器就是提供位置和速度的装置，它估算的位置和速度就是我们需要的有用数据，而不同时刻的卫星数据就是一系列的测量数据。</p>
<p><strong>对于一个跟踪和控制系统来说，其中最大的问题就是在存在不确定性的前提下提供一个准确的有用信息。</strong>回到刚刚的例子，GPS接收器测量的卫星数据充满不确定性，这些不确定性往往取决于外部环境的变化，其中包括热噪声，大气层影响，卫星位置的轻微改变，GPS的内部时钟准确性等等。</p>
<p>而卡尔曼滤波就是众多常用且重要的估算算法。因为卡尔曼滤波器在进行预估时是默认假设输入数据是不准确的。与此同时，卡尔曼滤波是根据上一次系统的预估值来预估下一次系统的状态。</p>
<p>这种类型的滤波器是卡尔曼首次公开发表的，因此被命名为卡尔曼滤波器。在1960年，卡尔曼发布了一篇描述离散数据线性滤波问题的递归解的问题的论文。</p>
<p>现在，卡尔曼滤波器常常用于雷达跟踪系统，位置和导航系统，控制系统，计算机图形等等领域。</p>
<h3 id="一个预测例子">一个预测例子</h3>
<p>在介绍卡尔曼滤波之前，让我们先来了解一下预测算法。</p>
<p>我们用一个雷达跟踪系统作为例子。</p>
<p><img src="https://www.kalmanfilter.net/img/Overview/tracking_radar.png" alt="Tracking Radar"></p>
<p>雷达跟踪系统向目标方向发射一个笔尖型射束用于追踪目标。假设发射周期为5S，因此，雷达系统会在每5秒的时间后通过向目标方向发射专用的跟踪射束来定位目标。</p>
<p>在发射射束之后，雷达系统会估算当前目标的位置和速度。与此同时，雷达系统也会预测下一个发射束应该发送到哪一个位置。</p>
<p>通过牛顿运动方程，我们能很容易计算出目标在下一个发射周期的位置。</p>
<p><img src="https://i.loli.net/2020/08/19/AIj2cnWB7HYlMzQ.png" alt="image-20200819142535510"></p>
<p>将上诉公式映射到<strong>三维空间</strong>，我们可以将牛顿运动方程作为系统的方程：</p>
<p><img src="https://i.loli.net/2020/08/19/ZnDtdf9ENB7xkga.png" alt="image-20200819142610853"></p>
<p>这些目标参数 [x,y,z,vx,vy,vz,ax,ay,az][x,y,z,vx,vy,vz,ax,ay,az] 被称为 <strong>系统状态</strong>. 通过当前系统状态代入到系统方程中，我们可以得到目标的下一个系统状态。</p>
<p>上面的方程被称为 <strong>动态模型</strong> (或者<strong>空间状态模型</strong>). 动态模型是一种描述输入和输出关系的方法。</p>
<p>回到我们的例子,我们知道当我们有了当前系统状态和掌握系统的动态模型之后，我们就能很容易地预测出目标的下一个状态。</p>
<p>然而并不是这样的。首先,雷达系统的测量数值不是完全可靠，它包含随机误差(或者这类型的不确定性)。这些随机错误的大小取决于很多因素，例如雷达自身的准确性，发射光束的宽度，返回信号强弱等等。这些测量误差被称为<strong>测量噪声</strong>。</p>
<p>此外, 因为有很多外部因素会做成干扰，目标运动并不是完全按着运动方程。例如：风向，空气流动，驾驶策略等等。这个动态模型误差被称为 <strong>处理噪声</strong>。</p>
<p>因为测量噪声和处理噪声的存在，这个根据上诉系统方程估算出来的目标位置会真实的目标位置相差很大。假若这样，雷达系统会向错误的方向发射跟踪射束并且丢失目标。</p>
<p>为了提高雷达跟踪系统的表现，这就需要<strong>能够将处理噪声和测量噪声考虑进来的预测算法</strong>。</p>
<p>对于此类算法，应用得最广泛无疑是<strong>卡尔曼滤波</strong>. (处理模型中的噪声)</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>研究方向</category>
      </categories>
      <tags>
        <tag>卡尔曼滤波</tag>
        <tag>RKN</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-12-更换hexo渲染器支持Latex</title>
    <url>/2020/08/12/2020-08-12-%E6%9B%B4%E6%8D%A2hexo%E6%B8%B2%E6%9F%93%E5%99%A8%E6%94%AF%E6%8C%81Latex/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<blockquote>
<p><code>LATEX</code> 是一种基于 <code>TEX</code> 的排版系统，利用这种格式，可以迅速生成复杂表格和数学公式等，对于我们写博客帮助十分大。</p>
</blockquote>
<h3 id="初级">初级</h3>
<h4 id="版本">版本</h4>
<p>我使用的是hexo + Next ，版本号如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">Hexo: <span class="number">4.2</span><span class="number">.1</span>  <span class="comment">#在 ~\package.json中查看</span></span><br><span class="line">NexT: <span class="number">7.8</span><span class="number">.0</span>  <span class="comment"># 在~\themes\next\package.json中查看</span></span><br></pre></td></tr></tbody></table></figure>
<h4 id="mathjax-插件">MathJax 插件</h4>
<p>渲染数学公式需要MathJax插件，有些 Hexo 主题自带 MathJax 插件，例如 <a href="http://theme-next.iissnan.com/" target="_blank" rel="noopener">NexT</a>只需启用该插件即可</p>
<p>如果没有的话，可以手动安装：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">npm install hexo-math --save</span><br></pre></td></tr></tbody></table></figure>
<h4 id="启用">启用</h4>
<p>NexT 主题的 MathJax 插件默认是禁用的，打开主题配置文件，将<code>mathjax</code>的<code>enable</code> 的值改为 <code>true</code> 即可启用 <code>MathJax</code></p>
<p>注意 <code>per_page</code> 上面的注释，注释表明了，MathJax 只渲染在文件前端注明 <code>mathjax: true</code> 字段的文章，</p>
<p>所以为了以后在每一个新建的文件都默认带有<code>mathjax: true</code> ，可以在<code>~\scaffolds\post.md</code>中修改文章头部，添加<code>mathjax: true</code> 即可</p>
<h4 id="效果">效果</h4>
<p>行内公式：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">这是一个行内公式：$sin^2\theta + cos^2\theta = 1$</span><br></pre></td></tr></tbody></table></figure>
<p>效果：</p>
<p>这是一个行内公式：<span class="math inline">\(sin^2\theta + cos^2\theta = 1\)</span></p>
<p>整行公式：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">$$sin^2\theta + cos^2\theta = 1$$</span><br></pre></td></tr></tbody></table></figure>
<p>效果：</p>
<p><span class="math display">\[sin^2\theta + cos^2\theta = 1\]</span></p>
<h4 id="获取latex公式mathpix-snipping-tool">获取Latex公式：Mathpix Snipping Tool</h4>
<p>如果要写Latex公式的话，需要掌握很多Latex语法，操作起来比较麻烦，学习成本也高。再加上平时我都是直接copy所读论文中的公式，于是我使用了<code>Mathpix Snipping Tool</code> 软件。</p>
<p><code>Mathpix Snipping Tool</code> ： 通过对所要获取的公式进行截图，可以得到公式的Latex表达形式，复制到博客中即可。操作简单高效。使用方法不再赘述，网上资源很多。</p>
<h3 id="高级">高级</h3>
<h4 id="危渲染复杂latex数学公式出现问题">危：渲染复杂LaTeX数学公式出现问题</h4>
<p>发现一个问题就是编辑好的LaTex公式可以在 Markdown 编辑器（Typora）中显示出来，但部署之后，公式出现无法被渲染</p>
<p>之后通过Google之后，发现问题的一些源头</p>
<blockquote>
<p>将<code>MathJax</code>改为true后发现，<strong>只能渲染部分简单的公式</strong>，对于稍微复杂一点的，特别是有下划线 ' _ ' 符号的公式，几乎都无法被渲染。</p>
<p>hexo默认使用marked.js去解析我们写的markdown，比如一些符号，_代表斜体，会被处理为*标签，比如x_i在开始被渲染的时候，处理为xi，比如__init__会被处理成<strong>init。</strong>*</p>
<p>Hexo 对 Markdown 文件的处理实际上分为两个步骤：</p>
<ol type="1">
<li>Hexo 中的 Markdown 引擎把 Markdown 变为 html 文件</li>
<li>MathJax 负责解释 html 的数学公式</li>
</ol>
</blockquote>
<p>所以现有的hexo渲染器是无法解决当前的问题，所以就要更换渲染器</p>
<h4 id="下载pandoc">下载pandoc</h4>
<p>打开powershell，输入以下命令行</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">pip install Pandoc</span><br></pre></td></tr></tbody></table></figure>
<h4 id="安装-hexo-renderer-pandoc">安装 hexo-renderer-pandoc</h4>
<p>在blog文件夹下打开git bash</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save #卸载旧版本</span><br><span class="line"><span class="meta">#</span><span class="bash">因为之前为了支持emoji，我已经将hexo-renderer-marked换成了hexo-renderer-markdown-it，所以我卸载后者</span></span><br><span class="line">npm install hexo-renderer-pandoc --save #安装新版本</span><br></pre></td></tr></tbody></table></figure>
<h4 id="更新部署">更新部署</h4>
<p>可以看到对于复杂的公式也是支持的~</p>
<p><img src="https://i.loli.net/2020/08/13/cXzadkQeCvAIwfB.png" alt="image-20200813003737055"></p>
<h3 id="注意事项">注意事项</h3>
<p>如果你使用这款 Pandoc renderer，那么书写 Markdown 时候需要遵循 <a href="https://pandoc.org/MANUAL.html#pandocs-markdown" target="_blank" rel="noopener">Pandoc 对 Markdown 的规定</a>。</p>
<p>有一些比较明显的需要注意的事项：正常的文字后面如果跟的是<a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#lists" target="_blank" rel="noopener"><code>list</code></a>, <a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#tables" target="_blank" rel="noopener"><code>table</code></a>或者<a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#blockquotes" target="_blank" rel="noopener"><code>quotation</code></a>，文字后面需要空一行，如果不空行，这些环境将不能被 Pandoc renderer 正常渲染。</p>
<h3 id="参考">参考</h3>
<blockquote>
<p>Hexo渲染Latex出现的问题： https://zhuanlan.zhihu.com/p/35988761</p>
</blockquote>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>Latex</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-12-hexo添加emoji表情</title>
    <url>/2020/08/12/2020-08-12-hexo%E6%B7%BB%E5%8A%A0emoji%E8%A1%A8%E6%83%85/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>markdown支持在文本中使用emoji，在Typora中可以很方便地使用表情。例如输入 <code>:star:</code> ,可以显示出:star:表情，即表情的<code>aliases</code> 编码格式。但是在部署到网站的时候，<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8">⭐</span>却渲染不出来，我寻找了很久的解决方案，终于解决 <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8">😆</span></p>
<h3 id="更换hexo渲染器">更换hexo渲染器</h3>
<p>我的hexo版本是version 4.2.1, 可以在在根目录下 packge.json 文件里面看到使用hexo初始化的结果。</p>
<p>将markdown 变成html的转换器叫做<code>markdown渲染器</code>.在Hexo中默认的markdown渲染器 使用的是<a href="https://github.com/hexojs/hexo-renderer-marked" target="_blank" rel="noopener">hexo-renderer-marked</a>,是Hexo版本，这个渲染器不支持插件扩展。另外一个 markdown 渲染器 <a href="https://github.com/celsomiranda/hexo-renderer-markdown-it" target="_blank" rel="noopener">hexo-renderer-markdown-it</a>，这个支持插件配置，可以使用 <a href="https://github.com/markdown-it/markdown-it-emoji" target="_blank" rel="noopener">markwon-it-emoji</a>插件来支持emoji。</p>
<p>解决方案：将原来的 <code>marked</code> 渲染器换成 <code>markdown-it</code>渲染器。</p>
<h4 id="安装新的渲染器">安装新的渲染器</h4>
<p>首先进入博客目录,卸载hexo默认的<code>marked</code>渲染器，安装<code>markdown-it</code>渲染器，运行的命令如：</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">cd Documents/blog</span><br><span class="line">npm un hexo-renderer-marked --save  #卸载旧的渲染器</span><br><span class="line">npm i hexo-renderer-markdown-it --save #暗转新的渲染器</span><br></pre></td></tr></tbody></table></figure>
<p>之后安装<code>markdown-it-emoji</code>插件：</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">npm install markdown-it-emoji --save</span><br></pre></td></tr></tbody></table></figure>
<h4 id="编辑站点配置文件">编辑站点配置文件</h4>
<p>这里的站点配置文件是指位于博客根目录下的 <code>_config.yml</code>，编辑它，然后在末尾添加如下内容：</p>
<figure class="highlight yml"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># Markdown-it config</span></span><br><span class="line"><span class="comment">## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki</span></span><br><span class="line"><span class="attr">markdown:</span></span><br><span class="line">  <span class="attr">render:</span></span><br><span class="line">    <span class="attr">html:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">xhtmlOut:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">breaks:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">linkify:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">typographer:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">quotes:</span> <span class="string">'“”‘’'</span></span><br><span class="line">  <span class="attr">plugins:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-abbr</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-footnote</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-ins</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-sub</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-sup</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-emoji</span>  <span class="comment"># add emoji</span></span><br><span class="line">  <span class="attr">anchors:</span></span><br><span class="line">    <span class="attr">level:</span> <span class="number">2</span></span><br><span class="line">    <span class="attr">collisionSuffix:</span> <span class="string">'v'</span></span><br><span class="line">    <span class="attr">permalink:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">permalinkClass:</span> <span class="string">header-anchor</span></span><br><span class="line">    <span class="attr">permalinkSymbol:</span> <span class="string">¶</span></span><br></pre></td></tr></tbody></table></figure>
<p>上面的是<code>hexo-renderer-markdown-it</code>的所有选项的配置，详细的每一项配置说明，需要到<a href="https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki/Advanced-Configuration" target="_blank" rel="noopener">Advanced Configuration</a>中查看。</p>
<p>这个时候就可以用表情的<code>aliases</code> 编码格式啦</p>
<p>如果觉得表情渲染的不好看，那么可以安装<a href="https://github.com/twitter/twemoji" target="_blank" rel="noopener">twemoji</a>，对表情进行优化。但是我对现在的渲染感到满意，就没有继续安装。</p>
<h4 id="查找emoji">查找emoji</h4>
<p>表情的<code>aliases</code> 编码可以参考<a href="https://www.webfx.com/tools/emoji-cheat-sheet/" target="_blank" rel="noopener">emoji-cheat-sheet</a>，表情很全，可以找到每个表情的表示，运用到自己的文章里</p>
<h3 id="unicode编码方案">Unicode编码方案</h3>
<p>如果不更换hexo渲染器，那么可以使用表情的<code>Unicode</code>表达方式。不过不推荐此方式，感觉过于麻烦</p>
<p>语法： <code>&amp;#xCODE ;</code></p>
<p>其中<code>CODE</code>是每个表情的编码方式，可以通过 <a href="https://link.zhihu.com/?target=https%3A//apps.timwhitlock.info/emoji/tables/unicode%23block-4-enclosed-characters">Emoji Unicode Tables</a>查询得到</p>
<p><strong>例子：</strong> 查到了 表情对应的 <strong>Unicode</strong> 编码为 <code>U+1F34E</code>，则与此表情对应的 <code>CODE</code> 为 <code>1F34E</code> (舍弃前面的 <strong>U+</strong>)。输入markdown文档内即可</p>
<h3 id="后续">后续</h3>
<p>因为要读论文，然而在论文中会出现很多的数学公式，这时候需要运用Latex，原始的hexo渲染器<a href="https://github.com/hexojs/hexo-renderer-marked" target="_blank" rel="noopener">hexo-renderer-marked</a>对渲染不了公式，在为了能够添加emoji而更换的新渲染器 <a href="https://github.com/celsomiranda/hexo-renderer-markdown-it" target="_blank" rel="noopener">hexo-renderer-markdown-it</a>还是无法渲染Latex公式<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f610.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f610.png?v8">😐</span></p>
<p>于是我又准备更换hexo渲染器，来让新的渲染器支持数学公式，于是我就更换了 <a href="https://github.com/wzpan/hexo-renderer-pandoc" target="_blank" rel="noopener">hexo-renderer-pandoc</a>，支持Mathjax语法，十分靠谱，然而问题来了，那就是不支持emoji了 <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f610.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f610.png?v8">😐</span></p>
<p>在我准备在两者中舍弃一个，或者用emoji的Unicode编码来代替渲染器的时候，我发现了一个插件，就尝试在现有的渲染器基础上添加了一个hexo插件 <a href="https://github.com/crimx/hexo-filter-github-emojis" target="_blank" rel="noopener">hexo-filter-github-emojis</a> ，发现此插件可以有效支持emoji表情，于是两全其美啦<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8">😆</span></p>
<hr>
<p>下面是插件的使用说明</p>
<h4 id="安装插件">安装插件</h4>
<p>使用以下命令安装 <a href="https://github.com/crimx/hexo-filter-github-emojis" target="_blank" rel="noopener">hexo-filter-github-emojis</a> 插件：</p>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">npm install hexo-filter-github-emojis --save</span><br></pre></td></tr></tbody></table></figure>
<h4 id="启用插件">启用插件</h4>
<p>向站点配置文件 <code>hexo_root\_config.yml</code> 中添加如下设置：</p>
<figure class="highlight yml"><table><tbody><tr><td class="code"><pre><span class="line"><span class="attr">githubEmojis:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">className:</span> <span class="string">github-emoji</span></span><br><span class="line">  <span class="attr">unicode:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">styles:</span></span><br><span class="line">    <span class="attr">display:</span> <span class="string">inline</span></span><br><span class="line">    <span class="attr">vertical-align:</span> <span class="string">middle</span> <span class="comment"># Freemind适用</span></span><br><span class="line">  <span class="attr">localEmojis:</span></span><br></pre></td></tr></tbody></table></figure>
<p>具体的每个配置项含义参见 <a href="https://github.com/crimx/hexo-filter-github-emojis" target="_blank" rel="noopener">说明文档</a>。</p>
<h4 id="使用方法">使用方法</h4>
<p>和上述使用方法一样，很方便！ <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f308.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f308.png?v8">🌈</span></p>
<h3 id="参考">参考</h3>
<blockquote>
<p>hexo中添加表情： https://www.cnblogs.com/fsong/p/5929773.html</p>
<p>hexo 使用emoji： https://spacefan.github.io/2018/06/30/hexo-emoji/</p>
</blockquote>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>故障排除</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-12-新页面添加友链</title>
    <url>/2020/08/12/2020-08-12-%E6%96%B0%E9%A1%B5%E9%9D%A2%E6%B7%BB%E5%8A%A0%E5%8F%8B%E9%93%BE/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>NexT 主题自带的友情链接的位置是在侧栏的 Social Link 中，位置不太明显，而且容量比较小，不美观。因此可以自定义一个特定的页面，单独显示友情链接</p>
<h3 id="新建links.swig-文件">新建<code>links.swig</code> 文件</h3>
<p>首先，在 <code>~/themes/next/layout/</code> 目录下新建一个 <code>links.swig</code> 文件，并写入以下内容：</p>
<!-- 所在目录：~/themes/next/layout/ -->
<figure class="highlight html"><table><tbody><tr><td class="code"><pre><span class="line">{% block content %}</span><br><span class="line">  {######################}</span><br><span class="line">  {###  LINKS BLOCK   ###}</span><br><span class="line">  {######################}</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"links"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="css">        <span class="selector-class">.links-content</span>{</span></span><br><span class="line"><span class="css">            <span class="selector-tag">margin-top</span><span class="selector-pseudo">:1rem</span>;</span></span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line"><span class="css">        <span class="selector-class">.link-navigation</span><span class="selector-pseudo">::after</span> {</span></span><br><span class="line">            content: " ";</span><br><span class="line">            display: block;</span><br><span class="line">            clear: both;</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line"><span class="css">        <span class="selector-class">.card</span> {</span></span><br><span class="line">            width: 240px;</span><br><span class="line">            font-size: 1rem;</span><br><span class="line">            padding: 10px 20px;</span><br><span class="line">            border-radius: 4px;</span><br><span class="line"><span class="css">            <span class="selector-tag">transition-duration</span>: 0<span class="selector-class">.15s</span>;</span></span><br><span class="line">            margin-bottom: 1rem;</span><br><span class="line"><span class="css">            <span class="selector-tag">display</span><span class="selector-pseudo">:flex</span>;</span></span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="keyword">@media</span> (<span class="attribute">max-width:</span> <span class="number">767px</span>) {</span></span><br><span class="line"><span class="css">			<span class="selector-class">.card</span><span class="selector-pseudo">:nth-child(odd)</span> {</span></span><br><span class="line">                float: left;</span><br><span class="line">            }</span><br><span class="line"><span class="css">            <span class="selector-class">.card</span><span class="selector-pseudo">:nth-child(even)</span> {</span></span><br><span class="line">                float: left !important;</span><br><span class="line">            }</span><br><span class="line">		}</span><br><span class="line">		</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span><span class="selector-pseudo">:nth-child(odd)</span> {</span></span><br><span class="line">            float: left;</span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span><span class="selector-pseudo">:nth-child(even)</span> {</span></span><br><span class="line">            float: right;</span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span><span class="selector-pseudo">:hover</span> {</span></span><br><span class="line"><span class="css">            <span class="selector-tag">transform</span>: <span class="selector-tag">scale</span>(1<span class="selector-class">.1</span>);</span></span><br><span class="line"><span class="css">            <span class="selector-tag">box-shadow</span>: 0 2<span class="selector-tag">px</span> 6<span class="selector-tag">px</span> 0 <span class="selector-tag">rgba</span>(0, 0, 0, 0<span class="selector-class">.12</span>), 0 0 6<span class="selector-tag">px</span> 0 <span class="selector-tag">rgba</span>(0, 0, 0, 0<span class="selector-class">.04</span>);</span></span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span> <span class="selector-tag">a</span> {</span></span><br><span class="line"><span class="css">            <span class="selector-tag">border</span><span class="selector-pseudo">:none</span>; </span></span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span> <span class="selector-class">.ava</span> {</span></span><br><span class="line">            width: 3rem!important;</span><br><span class="line">            height: 3rem!important;</span><br><span class="line"><span class="css">            <span class="selector-tag">margin</span><span class="selector-pseudo">:0</span>!<span class="selector-tag">important</span>;</span></span><br><span class="line">            margin-right: 1em!important;</span><br><span class="line"><span class="css">            <span class="selector-tag">border-radius</span><span class="selector-pseudo">:4px</span>;</span></span><br><span class="line">            </span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span> <span class="selector-class">.card-header</span> {</span></span><br><span class="line">            font-style: italic;</span><br><span class="line">            overflow: hidden;</span><br><span class="line">            width: 100%;</span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span> <span class="selector-class">.card-header</span> <span class="selector-tag">a</span> {</span></span><br><span class="line">            font-style: normal;</span><br><span class="line"><span class="css">            <span class="selector-tag">color</span>: <span class="selector-id">#2bbc8a</span>;</span></span><br><span class="line">            font-weight: bold;</span><br><span class="line">            text-decoration: none;</span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span> <span class="selector-class">.card-header</span> <span class="selector-tag">a</span><span class="selector-pseudo">:hover</span> {</span></span><br><span class="line"><span class="css">            <span class="selector-tag">color</span>: <span class="selector-id">#a166ab</span>;</span></span><br><span class="line">            text-decoration: none;</span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span> <span class="selector-class">.card-header</span> <span class="selector-class">.info</span> {</span></span><br><span class="line"><span class="css">            <span class="selector-tag">font-style</span><span class="selector-pseudo">:normal</span>;</span></span><br><span class="line"><span class="css">            <span class="selector-tag">color</span>:<span class="selector-id">#a3a3a3</span>;</span></span><br><span class="line"><span class="css">            <span class="selector-tag">font-size</span><span class="selector-pseudo">:14px</span>;</span></span><br><span class="line">            min-width: 0;</span><br><span class="line">            overflow: hidden;</span><br><span class="line">            white-space: nowrap;</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line"><span class="css">        <span class="selector-tag">span</span><span class="selector-class">.focus-links</span> {</span></span><br><span class="line">            font-style: normal;</span><br><span class="line">            margin-left: 10px;</span><br><span class="line">            position: unset;</span><br><span class="line">            left: 0;</span><br><span class="line">            padding: 0 7px 0 5px;</span><br><span class="line">            font-size: 11px;</span><br><span class="line"><span class="css">            <span class="selector-tag">border-color</span>: <span class="selector-id">#42c02e</span>;</span></span><br><span class="line">            border-radius: 40px;</span><br><span class="line">            line-height: 24px;</span><br><span class="line">            height: 22px;</span><br><span class="line"><span class="css">            <span class="selector-tag">color</span>: <span class="selector-id">#fff</span> !<span class="selector-tag">important</span>;</span></span><br><span class="line"><span class="css">            <span class="selector-tag">background-color</span>: <span class="selector-id">#42c02e</span>;</span></span><br><span class="line">            display: inline-block;</span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-tag">span</span><span class="selector-class">.focus-links</span><span class="selector-pseudo">:hover</span>{</span></span><br><span class="line"><span class="css">            <span class="selector-tag">background-color</span>: <span class="selector-id">#318024</span>;</span></span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line"><span class="css">        <span class="selector-class">.friends-btn</span>{</span></span><br><span class="line">            text-align: center;</span><br><span class="line"><span class="css">            <span class="selector-tag">color</span>: <span class="selector-id">#555</span>!<span class="selector-tag">important</span>;</span></span><br><span class="line"><span class="css">            <span class="selector-tag">background-color</span>: <span class="selector-id">#fff</span>;</span></span><br><span class="line">            border-radius: 3px;</span><br><span class="line">            font-size: 15px;</span><br><span class="line"><span class="css">            <span class="selector-tag">box-shadow</span>: <span class="selector-tag">inset</span> 0 0 10<span class="selector-tag">px</span> 0 <span class="selector-tag">rgba</span>(0,0,0,<span class="selector-class">.35</span>);</span></span><br><span class="line">            border: none!important;</span><br><span class="line">            transition-property: unset;</span><br><span class="line">            padding: 0 15px;</span><br><span class="line">            margin: inherit;</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line"><span class="css">        <span class="selector-class">.friends-btn</span><span class="selector-pseudo">:hover</span>{</span></span><br><span class="line">            color: rgb(255, 255, 255) !important;</span><br><span class="line">            border-radius: 3px;</span><br><span class="line">            font-size: 15px;</span><br><span class="line"><span class="css">            <span class="selector-tag">box-shadow</span>: <span class="selector-tag">inset</span> 0<span class="selector-tag">px</span> 0<span class="selector-tag">px</span> 10<span class="selector-tag">px</span> 0<span class="selector-tag">px</span> <span class="selector-tag">rgba</span>(0, 0, 0, 0<span class="selector-class">.35</span>);</span></span><br><span class="line"><span class="css">            <span class="selector-tag">background-image</span>: <span class="selector-tag">linear-gradient</span>(90<span class="selector-tag">deg</span>, <span class="selector-id">#a166ab</span> 0%, <span class="selector-id">#ef4e7b</span> 25%, <span class="selector-id">#f37055</span> 50%, <span class="selector-id">#ef4e7b</span> 75%, <span class="selector-id">#a166ab</span> 100%);</span></span><br><span class="line">            margin: inherit;</span><br><span class="line">        }</span><br><span class="line">    <span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"links-content"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"link-navigation"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">            {% for link in theme.mylinks %}</span><br><span class="line">            </span><br><span class="line">                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"card"</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">img</span> <span class="attr">class</span>=<span class="string">"ava"</span> <span class="attr">src</span>=<span class="string">"{{ link.avatar }}"</span>/&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"card-header"</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">div</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"{{ link.site }}"</span> <span class="attr">target</span>=<span class="string">"_blank"</span>&gt;</span> {{ link.nickname }}<span class="tag">&lt;/<span class="name">a</span>&gt;</span> <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"{{ link.site }}"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"focus-links"</span>&gt;</span>关注<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"info"</span>&gt;</span>{{ link.info }}<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">            </span><br><span class="line">            {% endfor %}</span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        {{ page.content }}</span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">     {##########################}</span><br><span class="line">  {###   END LINKS BLOCK  ###}</span><br><span class="line">  {##########################}</span><br><span class="line">{% endblock %}</span><br></pre></td></tr></tbody></table></figure>
<p>可以根据喜好自己更改样式</p>
<h3 id="修改page.swig文件">修改<code>page.swig</code>文件</h3>
<p>将代码行前<code>+</code>的代码添加到文件中</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">{% extends '_layout.swig' %}</span><br><span class="line">{% import '_macro/sidebar.swig' as sidebar_template with context %}</span><br><span class="line"></span><br><span class="line">  {% block title %}</span><br><span class="line">    {%- set page_title_suffix = ' | ' + title %}</span><br><span class="line"></span><br><span class="line">{%- if page.type === 'categories' and not page.title %}</span><br><span class="line">  {{- __('title.category') + page_title_suffix }}</span><br><span class="line">{%- elif page.type === 'tags' and not page.title %}</span><br><span class="line">  {{- __('title.tag') + page_title_suffix }}</span><br><span class="line"></span><br><span class="line">+ {%- elif page.type === 'links' and not page.title %}</span><br><span class="line">+	{{- __('title.links') + page_title_suffix }}</span><br><span class="line">{%- elif page.type === 'schedule' and not page.title %}</span><br><span class="line">  {{- __('title.schedule') + page_title_suffix }}</span><br><span class="line">{%- else %}</span><br><span class="line">  {{- page.title + page_title_suffix }}</span><br><span class="line">{%- endif %}</span><br><span class="line">{% endblock %}</span><br><span class="line"></span><br><span class="line">{% block content %}</span><br><span class="line"></span><br><span class="line">  &lt;div class="posts-expand"&gt;</span><br><span class="line">    {##################}</span><br><span class="line">    {### PAGE BLOCK ###}</span><br><span class="line">    {##################}</span><br><span class="line">    &lt;div class="post-block" lang="{{ page.lang or page.language or config.language }}"&gt;</span><br><span class="line">      {% include '_partials/page/page-header.swig' %}</span><br><span class="line">      {#################}</span><br><span class="line">      {### PAGE BODY ###}</span><br><span class="line">      {#################}</span><br><span class="line">      &lt;div class="post-body{%- if page.direction and page.direction.toLowerCase() === 'rtl' %} rtl{%- endif %}"&gt;</span><br><span class="line">        {%- if page.type === 'tags' %}</span><br><span class="line">          &lt;div class="tag-cloud"&gt;</span><br><span class="line">            &lt;div class="tag-cloud-title"&gt;</span><br><span class="line">              {{ _p('counter.tag_cloud', site.tags.length) }}</span><br><span class="line">            &lt;/div&gt;</span><br><span class="line">            &lt;div class="tag-cloud-tags"&gt;</span><br><span class="line">              {{ tagcloud({min_font: theme.tagcloud.min, max_font: theme.tagcloud.max, amount: theme.tagcloud.amount, color: true, start_color: theme.tagcloud.start, end_color: theme.tagcloud.end}) }}</span><br><span class="line">            &lt;/div&gt;</span><br><span class="line">          &lt;/div&gt;</span><br><span class="line">        {% elif page.type === 'categories' %}</span><br><span class="line">          &lt;div class="category-all-page"&gt;</span><br><span class="line">            &lt;div class="category-all-title"&gt;</span><br><span class="line">              {{ _p('counter.categories', site.categories.length) }}</span><br><span class="line">            &lt;/div&gt;</span><br><span class="line">            &lt;div class="category-all"&gt;</span><br><span class="line">              {{ list_categories() }}</span><br><span class="line">            &lt;/div&gt;</span><br><span class="line">          &lt;/div&gt;</span><br><span class="line">+       {% elif page.type === 'links' %}</span><br><span class="line">+         {% include 'links.swig' %}</span><br><span class="line">        {% elif page.type === 'schedule' %}</span><br><span class="line">          &lt;div class="event-list"&gt;</span><br><span class="line">          &lt;/div&gt;</span><br><span class="line">          {% include '_scripts/pages/schedule.swig' %}</span><br><span class="line">        {% else %}</span><br><span class="line">          {{ page.content }}</span><br><span class="line">        {%- endif %}</span><br><span class="line">      &lt;/div&gt;</span><br><span class="line">      {#####################}</span><br><span class="line">      {### END PAGE BODY ###}</span><br><span class="line">      {#####################}</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">    {% include '_partials/page/breadcrumb.swig' %}</span><br><span class="line">    {######################}</span><br><span class="line">    {### END PAGE BLOCK ###}</span><br><span class="line">    {######################}</span><br><span class="line">  &lt;/div&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">{% endblock %}</span><br><span class="line"></span><br><span class="line">{% block sidebar %}</span><br><span class="line">  {{ sidebar_template.render(true) }}</span><br><span class="line">{% endblock %}</span><br></pre></td></tr></tbody></table></figure>
<h3 id="新建page界面">新建page界面</h3>
<p>新建名为links的page，具体可以参考我的另外一篇博客<a href="%5Bhttps://lisijian.cn/2020/08/08/2020-08-08-hexo%E6%96%B0%E5%BB%BApage/%5D(https://lisijian.cn/2020/08/08/2020-08-08-hexo新建page/)">2020-08-08-hexo新建page</a></p>
<p>注意： 在<code>links</code> 文件夹，打开其中的 <code>index.md</code> 文件，在标题头中写入 <code>type = "links"</code> 这个属性头，如下：</p>
<figure class="highlight yml"><table><tbody><tr><td class="code"><pre><span class="line"><span class="attr">title:</span> <span class="string">友情链接</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2020</span><span class="number">-08</span><span class="number">-10</span> <span class="number">13</span><span class="string">:08:43</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">"links"</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="修改主题配置文件">修改主题配置文件</h3>
<p>在主题配置文件 <code>~/themes/next/_config.yml</code> 文件中按照以下格式添加友链：</p>
<figure class="highlight yml"><table><tbody><tr><td class="code"><pre><span class="line"><span class="attr">mylinks:</span></span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">nickname:</span> <span class="comment"># 昵称</span></span><br><span class="line">    <span class="attr">avatar:</span> <span class="comment"># 头像地址</span></span><br><span class="line">    <span class="attr">site:</span> <span class="comment">#友链地址</span></span><br><span class="line">    <span class="attr">info:</span> <span class="comment">#相关说明</span></span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">nickname:</span> <span class="comment"># 昵称</span></span><br><span class="line">    <span class="attr">avatar:</span> <span class="comment"># 头像地址</span></span><br><span class="line">    <span class="attr">site:</span> <span class="comment">#友链地址</span></span><br><span class="line">    <span class="attr">info:</span> <span class="comment">#相关说明</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="参考">参考</h3>
<blockquote>
<p>Hexo-NexT 主题个性优化 https://guanqr.com/tech/website/hexo-theme-next-customization/</p>
</blockquote>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>next</category>
      </categories>
      <tags>
        <tag>next</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-11-杂记</title>
    <url>/2020/08/11/2020-08-11-%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <div class="hbe-input-container">
  <input type="password" id="hbePass" placeholder="" />
    <label for="hbePass">输入密码，查看文章</label>
    <div class="bottom-line"></div>
  </div>
  <script id="hbeData" type="hbeData" data-hmacdigest="60538e9416c404b4b7457c2693fcb1c80ad4730351f64da5488d3b397a8b1058">b2636caa15154e7869096a6b870b46d4f9822c1e031b2d83b47c9c2cc6713956b74f0bf410c1d2c65843fb3c558f4afedd38e18d2f3ac178a01e97d68d8064885dd59d51fff996e09068e1a036158bcc6c3fe8b8fdf67083ddc8c4f595e9d6e8ed0a8ec2db6d74cc502e5071431c9be605cc093e4db8411eff873f63eb41f80ea803e12db33955033004441a9abd8820ddf306abfb79a99592a22f53964c9315ed223ed01005a3f81225eedda0e6e499388623037cd44645f87eb63ca01343c645b39e915e16281248b499092c688da74afe2935123576adad39ed6dba05d7da2faa5e1bf2762b8ba5c54cf70c808451d47fa9be8345594ce669e784c20c90bbc5c559c541d8ef9a27ce02db76b9e381dcc6ac1ff513a06b2d5872f5c716fb7f5d86363d3f475d28a81858b32df00fa15d6cfac6299ea1b3febc4eacd17147a307e9b90c94860f56389366d4f9609a68e8c876ec767a4eb7205bd25a773709320eab3787e03723c41cc1a2bfda9a969ac88dc8d205dd9c159f06be3b075d7d751912735a72d3e757b4e02b7f9092da5bec29216c989caf2b9a2c191bdccbf5228d86a6ec4926c5078cb62aae6458f16dea8617eb6cbd27d4d4cf04ab010045425128a33e092a052e984ce0763f91d3c070e5e784a45d0b56709659b7d7b73bb297498456207f4850aece54a967984fd2e196ab8cac1446e757d1def14d4b63afa3adbe86c8f9053b8d1610505c9c5f23c7d11ff4bbc0f9a77fbfa17b1d997f882ea3ab2946d5e144749e671eb7f4acdd07ea06b5c562ad14efcee487b016efd0df4ec1f00ccbfb74dd3f8d84b35d319b2fe560563b22eac16e69ad27434c71f6a1e4eb7b83ab19be1b76d2e0378d0330f98d4093e7f2cd2d2c29414ecbd578bd8221210b0b9eebedaf19904bebd5f7ba83f4144f60ec20b599aaec7bb43597536716d88e2a057f9bcb84e12a944031cc</script>
</div>
<script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>杂记</category>
      </categories>
      <tags>
        <tag>杂记</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-09-常用chrome快捷键</title>
    <url>/2020/08/09/2020-08-09-%E5%B8%B8%E7%94%A8chrome%E5%BF%AB%E6%8D%B7%E9%94%AE/</url>
    <content><![CDATA[<p>chrome是我日常使用的浏览器，平时也会使用快捷键来提高效率。chrome的快捷键真的很好使，可以</p>
<p>摆脱很多不必要的鼠标点击，键盘直接搞定。总结一下我常用的快捷键。</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">描述</th>
<th style="text-align: center;">快捷键</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">打开新窗口</td>
<td style="text-align: center;">Ctrl + n</td>
</tr>
<tr class="even">
<td style="text-align: center;">在隐身模式下打开新窗口</td>
<td style="text-align: center;">Ctrl + Shift + n</td>
</tr>
<tr class="odd">
<td style="text-align: center;">-----</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">打开新的标签页，并跳转到该标签页</td>
<td style="text-align: center;">Ctrl + t</td>
</tr>
<tr class="odd">
<td style="text-align: center;">恢复已关闭的标签页</td>
<td style="text-align: center;">Ctrl + Shift + t</td>
</tr>
<tr class="even">
<td style="text-align: center;">跳转到下一个标签页</td>
<td style="text-align: center;">Ctrl + Tab</td>
</tr>
<tr class="odd">
<td style="text-align: center;">跳转到上一个标签页</td>
<td style="text-align: center;">Ctrl + Shift + Tab</td>
</tr>
<tr class="even">
<td style="text-align: center;">关闭当前标签页</td>
<td style="text-align: center;">Ctrl + w</td>
</tr>
<tr class="odd">
<td style="text-align: center;">------</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">打开当前标签页浏览记录中的上一个页面</td>
<td style="text-align: center;">alt ＋左箭头</td>
</tr>
<tr class="odd">
<td style="text-align: center;">打开当前标签页浏览记录中的下一个页面</td>
<td style="text-align: center;">alt ＋右箭头</td>
</tr>
<tr class="even">
<td style="text-align: center;">------</td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">保存当前标签页为书签</td>
<td style="text-align: center;">Ctrl + d</td>
</tr>
<tr class="even">
<td style="text-align: center;">将所有打开的标签页以书签的形式保存在新文件夹中</td>
<td style="text-align: center;">Ctrl + Shift + d</td>
</tr>
<tr class="odd">
<td style="text-align: center;">------</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">跳转到与查找栏中搜索字词相匹配的下一条内容</td>
<td style="text-align: center;">Ctrl + g</td>
</tr>
<tr class="odd">
<td style="text-align: center;">跳转到与查找栏中搜索字词相匹配的上一条内容</td>
<td style="text-align: center;">Ctrl + Shift + g</td>
</tr>
<tr class="even">
<td style="text-align: center;">浏览下一个可点击项</td>
<td style="text-align: center;">Tab</td>
</tr>
<tr class="odd">
<td style="text-align: center;">浏览上一个可点击项</td>
<td style="text-align: center;">Shift + Tab</td>
</tr>
<tr class="even">
<td style="text-align: center;">选中浏览器地址栏</td>
<td style="text-align: center;">ctrl+L</td>
</tr>
</tbody>
</table>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>chrome</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-08-hexo新建page</title>
    <url>/2020/08/08/2020-08-08-hexo%E6%96%B0%E5%BB%BApage/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>在博客中需要一些个性化设置，添加一些page等 ，记录下我的操作</p>
<h3 id="添加page-界面">添加page 界面</h3>
<p>我想要添加一个“一句话感想”的page，于是可以这样操作</p>
<p>step 1.hexo新建新的page界面</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">hexo new page onesentence  <span class="comment"># onesentence 是新建page的名称 （最好是英文名）</span></span><br></pre></td></tr></tbody></table></figure>
<p>这时候在博客的source文件夹里会有一个onesentence的文件夹，并且里面生成了一个index.md文件，用于写一句话感想的内容</p>
<p>step 2.在主题的配置文件 _config.yml 文件中的 menu 中进行匹配，如下图，添加一个onesentence项，<code>/onesentence</code>表示挂接到上述的新建文件夹里，</p>
<p>在这里也可以设置图标，在fontawesome网站里找，我找了一个保龄球<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f3b3.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3b3.png?v8">🎳</span>的图标，和page主题没啥联系，就是看着顺眼 <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8">😆</span></p>
<p>此时<code>hexo s -g</code> 就可以看到已经有了这个界面，不过是英文的文件名，所以此时还要设置一下此文件名的中文名映射</p>
<p><img src="https://i.loli.net/2020/08/08/jiUOEvuzWnT7Kmp.png" alt="image-20200808192748174"></p>
<p>step 3. 打开**themes*，我用的是zh-CN，打开此文件，在menu下添加<code>onesentence: 一句话</code>，即可完成中文映射，</p>
<p>此时 hexo s -g ,就可以在本地服务器的侧边栏部分看到新添加的“一句话”page</p>
<p><img src="https://i.loli.net/2020/08/08/cCymB2KXMh1OPN5.png" alt="image-20200808193652117"></p>
<p><img src="https://i.loli.net/2020/08/08/ZrQkcR8IPspHMdi.png" alt="image-20200808194045722" style="zoom: 67%;"></p>
<p>step 4. 编辑“一句话”页面下的md文件，部署就能看到内容</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>next</category>
      </categories>
      <tags>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-08-next缺少custom.styl的问题</title>
    <url>/2020/08/08/2020-08-08-%E7%BC%BA%E5%B0%91custom-styl%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>在 next7.x 版本中没有custom.styl文件。如果我们想要在博客中添加自己的css样式，可以在此文件中添加，下面介绍一下</p>
<h3 id="操作">操作</h3>
<p>step1 ：添加custom.styl文件</p>
<p>文件路径：<code>~\themes\next\source\css</code> ,添加<code>_custom</code>文件夹。然后在<code>_custom</code>中创建<code>custom.styl</code>文件。我们自己的样式就可以在此文件中添加</p>
<p>step2： 添加引用</p>
<p>在<code>~\themes\next\source\css</code>中的<code>main.styl</code>文件末尾加入引用即可</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">//My Layer</span><br><span class="line">@import "_custom/custom.styl";</span><br></pre></td></tr></tbody></table></figure>
<p>step3： 添加样式</p>
<p>用vscode打开<code>custom.styl</code>，博客背景以及前页的不透明度等等，就可以更换样式了。</p>
<p>对于网页的组件，F12打开调试界面，就可以知道每个组件的名称等信息，便于更改样式</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>next</category>
      </categories>
      <tags>
        <tag>故障排除</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-08-vim常见操作</title>
    <url>/2020/08/08/2020-08-08-vim%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h3 id="常规操作">常规操作</h3>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">vim a.txt  <span class="comment"># 创建a.txt文件并进入编辑状态 。 如果a.txt 已经存在，则直接进入编辑状态</span></span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> 按下i键，下端显示 –INSERT–。可以进行插入，输入文本 </span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> 输入了之后 按Esc键退出编辑状态</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> 键入 :wq! 强制保存文件并退出  <span class="comment"># !是强制执行，注：有些文件设置了只读，一般不是修改文件的，但是如果你是`							文件的owner或者root的话，通过wq!还是能保存文件退出。:wq不可以</span></span><br><span class="line"></span><br><span class="line">   :w 在编辑的过程中保存文件,相当于word中的ctrl+s    </span><br><span class="line"></span><br><span class="line">   :wq 保存文件并退出 <span class="comment">#一般使用这个命令退出</span></span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<p>注：以<strong><code>:</code></strong>和<strong><code>/</code></strong>开头的命令都有历史纪录，可以首先键入:或/然后按<strong>上下箭头</strong>来选择某个历史命令</p>
</blockquote>
<h3 id="vim模式">Vim模式</h3>
<p>(都是在英文输入环境下操作)</p>
<ul>
<li><strong>Normal</strong> 模式：进入Vim后的一般模式。</li>
<li><strong>Insert</strong> 模式：按下<code>i</code>键后进入插入模式，可以修改文档。</li>
<li><strong>Visual</strong> 模式：按下<code>v</code>键后进入选择模式，可以选择文档内容。</li>
</ul>
<h3 id="vim打开和切换文件">Vim打开和切换文件</h3>
<ul>
<li><code>:ls</code>显示打开的文件，可以使用<code>:bn</code>在文件间切换( n也可以换成<code>:ls</code>里给出的文件序号 )。</li>
<li>在终端<code>vim -o file1 file2 ...</code>可以打开多个文件(横向分隔屏幕)。</li>
<li>终端<code>vim -O file1 file2 ...</code>可以打开多个文件(纵向分隔屏幕)。 <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8">⭐</span></li>
<li><code>Ctrl</code>+<code>w</code>+<code>方向键</code>在窗口间切换光标</li>
</ul>
<h3 id="vim退出">Vim退出</h3>
<ul>
<li><p><code>:q</code>：退出。</p></li>
<li><p><code>:q!</code>：强制退出，放弃所有修改。</p></li>
<li><p><code>:wq</code>：保存修改并退出。<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8">⭐</span></p></li>
</ul>
<h3 id="常用快捷键">常用快捷键</h3>
<ul>
<li><p><code>gg</code>到文档首行，<code>G</code>（shift+g）到文档结尾。</p></li>
<li><p><code>pageUp</code>下一页，<code>pageDown</code>上一页。</p></li>
<li><p><code>ctrl + d</code> 向下翻半页(down)， <code>ctrl + u</code> 向上翻半页(up) <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8">⭐</span></p></li>
<li><p><code>H</code>将光标移动到屏幕首行，<code>M</code>将光标移动到屏幕中间行，<code>L</code>将光标移动到屏幕最后一行。</p></li>
<li><p><code>q:</code>显示<strong>命令行历史记录</strong>（显示开头为:的历史命令行）窗口，可以选择命令行执行。若是<code>q/</code>,则会显示开头为/的历史命令行</p></li>
<li><p><code>u</code> 撤销 (undo) <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8">⭐</span></p></li>
<li><p><code>w</code> 下一个单词 word</p></li>
<li><p><code>b</code> 前一个单词 behind</p></li>
<li><p><code>e</code> 本单词末尾 end</p></li>
<li><p><code>:set nu</code> 显示行号 (number ) 　</p></li>
<li><p><code>:set nonu</code> 隐藏行号 ( number)</p></li>
<li><p><code>:98</code>跳转到第98行。</p></li>
<li><p><code>:5,10d</code> //回车后，第5~10行被删除</p></li>
<li><p><code>:5,$d</code> //回车后，第5~最后一行被删除</p></li>
<li><p><code>:5,10y</code> //回车后，第5~10行被复制</p></li>
</ul>
<h3 id="复制粘贴">复制粘贴</h3>
<ul>
<li>在<strong>Visual</strong>模式下选择文档内容后按<code>y</code>键，复制被选择内容。主要用于<strong>多行文字</strong>（复制完之后vim自动退出Visual模式）</li>
<li>在<strong>Visual</strong>模式下选择文档内容后按<code>d</code>删除</li>
<li>按<code>p</code>键粘贴，注意粘贴从<strong>紧跟光标后的那个字符</strong>之后才开始。（不需要进入Visual模式）</li>
<li><code>yy</code>复制当前行，<code>dd</code>删除(剪贴)当前行。 用于<strong>一行文字</strong></li>
<li><code>:5,10y</code> //回车后，第5~10行被复制</li>
</ul>
<p>如果在vim外的其它文件里复制内容到vim里，则无法使用<code>p</code>进行粘贴，此时右键粘贴即可（无需进入inset模式）</p>
<h3 id="查找">查找</h3>
<ul>
<li>在<strong>Normal</strong>模式下，按<code>/</code>进入查找模式，输入<code>/word</code>后回车，高亮显示所有文档<code>word</code>，按<code>n</code>跳到下一个<code>word</code>,按<code>N</code>跳到上一个。（默认大小写敏感）</li>
<li>若输入<code>/word\c</code>代表大小写不敏感查找，<code>\C</code>代表大小写敏感。</li>
<li>在<strong>Normal</strong>模式下按<code>q</code>+<code>/</code>显示<strong>查找历史记录</strong>窗口。</li>
<li>如果一个词很长，键入麻烦，可以将光标移动到该词上，按<code>*</code>键即可以该单词进行搜索，相当于/搜索。</li>
</ul>
<p><img src="https://i.loli.net/2020/08/11/GZszjJB9uIUMFTq.png" alt="img"></p>
<h3 id="参考">参考</h3>
<blockquote>
<p>vim的常用操作 https://www.cnblogs.com/doseoer/p/6241443.html</p>
</blockquote>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-07-transformerXL解读</title>
    <url>/2020/08/07/2020-08-07-transformerXL%E8%A7%A3%E8%AF%BB/</url>
    <content><![CDATA[<p>Transformer最大的问题：在语言建模时的设置受到固定长度上下文的限制。</p>
<p>本文提出的Transformer-XL，使学习不再仅仅依赖于定长，且不破坏时间的相关性。</p>
<p>Transformer-XL包含segment-level 循环机制和positional编码框架。不仅可以捕捉长时依赖，还可以解决上下文断片问题 fragmentation problem。可以学到比RNNs长80%的依赖，比vanilla Transformers长450%。在长短序列上都取得了更好的结果。与vanilla Transformer相比，Transformer-XL的另一个优势是它可以被用于单词级和字符级的语言建模。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
  </entry>
  <entry>
    <title>2020-08-06-pytorch函数之nn.Linear</title>
    <url>/2020/08/06/2020-08-06-pytorch%E5%87%BD%E6%95%B0%E4%B9%8BLinear/</url>
    <content><![CDATA[<h1 id="section"></h1>
<p>class torch.nn.Linear（in_features，out_features，bias = True ）</p>
<p>对传入数据应用线性变换：y = A x+ b</p>
<p>参数：</p>
<p>in_features - 每个输入样本的大小</p>
<p>out_features - 每个输出样本的大小</p>
<p>bias - 如果设置为False，则图层不会学习附加偏差。默认值：True</p>
<p>代码：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">m = nn.Linear(20, 30)</span><br><span class="line"></span><br><span class="line">input = autograd.Variable(torch.randn(128, 20))</span><br><span class="line"></span><br><span class="line">output = m(input)</span><br><span class="line"></span><br><span class="line">print(output.size())</span><br></pre></td></tr></tbody></table></figure>
<p>输出：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">torch.Size([128, 30])</span><br></pre></td></tr></tbody></table></figure>
<p>分析:</p>
<p>output.size()=矩阵size(128,20)*矩阵size（20,30）=(128,30)</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-05-BPE算法</title>
    <url>/2020/08/05/2020-08-05-%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h3 id="总说"><strong>总说</strong></h3>
<p>BPE，（byte pair encoder）字节对编码，也可以叫做digram coding双字母组合编码，<code>主要目的是为了数据压缩</code>，算法描述为<code>字符串里频率最常见的一对字符被一个没有在这个字符中出现的字符代替的层层迭代过程</code>。具体在下面描述。</p>
<h3 id="算法">算法</h3>
<ol type="1">
<li>准备足够大的训练语料</li>
<li>确定期望的<strong>subword词表大小</strong></li>
<li>将单词拆分为字符序列并在<strong>末尾添加后缀“ &lt;/ w&gt;”</strong>，统计单词频率。 本阶段的subword的粒度是字符。 例如，“ low”的频率为5，那么我们将其改写为“ l o w &lt;/ w&gt;”：5</li>
<li>统计每一个连续字节对的出现频率，选择最高频者合并成新的subword</li>
<li>重复第4步直到达到第2步设定的subword词表大小或下一个最高频的字节对出现频率为1</li>
</ol>
<p>停止符""的意义在于表示subword是词后缀。举例来说："st"字词不加""可以出现在词首如"st ar"，加了""表明改字词位于词尾，如"wide st"，二者意义截然不同。</p>
<p>每次合并后词表可能出现3种变化：</p>
<ul>
<li>+1，表明加入合并后的新字词，同时原来的2个子词还保留（2个字词不是完全同时连续出现）</li>
<li>+0，表明加入合并后的新字词，同时原来的2个子词中一个保留，一个被消解（一个字词完全随着另一个字词的出现而紧跟着出现）</li>
<li>-1，表明加入合并后的新字词，同时原来的2个子词都被消解（2个字词同时连续出现）</li>
</ul>
<p>实际上，随着合并的次数增加，词表大小通常先增加后减小。</p>
<h4 id="例子1"><strong>例子1</strong></h4>
<p>输入：</p>
<figure class="highlight"><table><tbody><tr><td class="code"><pre><span class="line">{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w e s t &lt;/w&gt;': 6, 'w i d e s t &lt;/w&gt;': 3}</span><br></pre></td></tr></tbody></table></figure>
<p>Iter 1, 最高频连续字节对"e"和"s"出现了6+3=9次，合并成"es"。输出：</p>
<figure class="highlight"><table><tbody><tr><td class="code"><pre><span class="line">{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w es t &lt;/w&gt;': 6, 'w i d es t &lt;/w&gt;': 3}</span><br></pre></td></tr></tbody></table></figure>
<p>Iter 2, 最高频连续字节对"es"和"t"出现了6+3=9次, 合并成"est"。输出：</p>
<figure class="highlight"><table><tbody><tr><td class="code"><pre><span class="line">{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w est &lt;/w&gt;': 6, 'w i d est &lt;/w&gt;': 3}</span><br></pre></td></tr></tbody></table></figure>
<p>Iter 3, 以此类推，最高频连续字节对为"est"和"" 输出：</p>
<figure class="highlight"><table><tbody><tr><td class="code"><pre><span class="line">{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w est&lt;/w&gt;': 6, 'w i d est&lt;/w&gt;': 3}</span><br></pre></td></tr></tbody></table></figure>
<p>……</p>
<p>Iter n, 继续迭代<strong>直到达到预设的subword词表大小或下一个最高频的字节对出现频率为1</strong>。</p>
<h3 id="bpe实现">BPE实现</h3>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re, collections</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_stats</span><span class="params">(vocab)</span>:</span></span><br><span class="line">    pairs = collections.defaultdict(int)</span><br><span class="line">    <span class="keyword">for</span> word, freq <span class="keyword">in</span> vocab.items():</span><br><span class="line">        symbols = word.split()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(symbols)<span class="number">-1</span>):</span><br><span class="line">            pairs[symbols[i],symbols[i+<span class="number">1</span>]] += freq</span><br><span class="line">    <span class="keyword">return</span> pairs</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_vocab</span><span class="params">(pair, v_in)</span>:</span></span><br><span class="line">    v_out = {}</span><br><span class="line">    bigram = re.escape(<span class="string">' '</span>.join(pair))</span><br><span class="line">    p = re.compile(<span class="string">r'(?&lt;!\S)'</span> + bigram + <span class="string">r'(?!\S)'</span>)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> v_in:</span><br><span class="line">        w_out = p.sub(<span class="string">''</span>.join(pair), word)</span><br><span class="line">        v_out[w_out] = v_in[word]</span><br><span class="line">    <span class="keyword">return</span> v_out</span><br><span class="line"></span><br><span class="line">vocab = {<span class="string">'l o w &lt;/w&gt;'</span>: <span class="number">5</span>, <span class="string">'l o w e r &lt;/w&gt;'</span>: <span class="number">2</span>, <span class="string">'n e w e s t &lt;/w&gt;'</span>: <span class="number">6</span>, <span class="string">'w i d e s t &lt;/w&gt;'</span>: <span class="number">3</span>}</span><br><span class="line">num_merges = <span class="number">1000</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(num_merges):</span><br><span class="line">    pairs = get_stats(vocab)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> pairs:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    best = max(pairs, key=pairs.get)</span><br><span class="line">    vocab = merge_vocab(best, vocab)</span><br><span class="line">    print(best)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print output</span></span><br><span class="line"><span class="comment"># ('e', 's')</span></span><br><span class="line"><span class="comment"># ('es', 't')</span></span><br><span class="line"><span class="comment"># ('est', '&lt;/w&gt;')</span></span><br><span class="line"><span class="comment"># ('l', 'o')</span></span><br><span class="line"><span class="comment"># ('lo', 'w')</span></span><br><span class="line"><span class="comment"># ('n', 'e')</span></span><br><span class="line"><span class="comment"># ('ne', 'w')</span></span><br><span class="line"><span class="comment"># ('new', 'est&lt;/w&gt;')</span></span><br><span class="line"><span class="comment"># ('low', '&lt;/w&gt;')</span></span><br><span class="line"><span class="comment"># ('w', 'i')</span></span><br><span class="line"><span class="comment"># ('wi', 'd')</span></span><br><span class="line"><span class="comment"># ('wid', 'est&lt;/w&gt;')</span></span><br><span class="line"><span class="comment"># ('low', 'e')</span></span><br><span class="line"><span class="comment"># ('lowe', 'r')</span></span><br><span class="line"><span class="comment"># ('lower', '&lt;/w&gt;')</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="编码和解码">编码和解码</h3>
<ul>
<li><h4 id="编码">编码</h4></li>
</ul>
<p>在之前的算法中，我们已经得到了<strong>subword词表</strong>，<strong>对该词表按照子词长度由大到小排序</strong>。编码时，<strong>对于每个单词，遍历排好序的子词词表寻找是否有token是当前单词的子字符串，如果有，则该token是表示单词的tokens之一</strong>。</p>
<p>我们从最长的token迭代到最短的token，尝试将每个单词中的子字符串替换为token。 最终，我们将迭代所有tokens，并将所有子字符串替换为tokens。 如果仍然有子字符串没被替换但所有token都已迭代完毕，则将剩余的子词替换为特殊token，如<unk>。</unk></p>
<h4 id="例子2">例子2</h4>
<p>用得到subword词表去表示含有多个单词的句子</p>
<figure class="highlight"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 给定单词序列</span></span><br><span class="line">[“the&lt;/w&gt;”, “highest&lt;/w&gt;”, “mountain&lt;/w&gt;”]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设已有排好序的subword词表</span></span><br><span class="line">[“errrr&lt;/w&gt;”, “tain&lt;/w&gt;”, “moun”, “est&lt;/w&gt;”, “high”, “the&lt;/w&gt;”, “a&lt;/w&gt;”]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 迭代结果</span></span><br><span class="line">"the&lt;/w&gt;" -&gt; ["the&lt;/w&gt;"]</span><br><span class="line">"highest&lt;/w&gt;" -&gt; ["high", "est&lt;/w&gt;"]</span><br><span class="line">"mountain&lt;/w&gt;" -&gt; ["moun", "tain&lt;/w&gt;"]</span><br></pre></td></tr></tbody></table></figure>
<p>编码的计算量很大。 在实践中，我们可以pre-tokenize所有单词，并在词典中保存单词tokenize的结果。 如果我们看到字典中不存在的未知单词。 我们应用上述编码方法对单词进行tokenize，然后将新单词的tokenization添加到字典中备用。</p>
<ul>
<li><h4 id="解码">解码</h4></li>
</ul>
<p><strong>将所有的tokens拼在一起</strong>。</p>
<figure class="highlight"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># 编码序列</span></span><br><span class="line">[“the&lt;/w&gt;”, “high”, “est&lt;/w&gt;”, “moun”, “tain&lt;/w&gt;”]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解码序列</span></span><br><span class="line">“the&lt;/w&gt; highest&lt;/w&gt; mountain&lt;/w&gt;”</span><br></pre></td></tr></tbody></table></figure>
<h4 id="例子3">例子3</h4>
<p>比如我们想编码：</p>
<p>aaabdaaabac</p>
<p>我们会发现这里的aa出现的词数最高（我们这里只看两个字符的频率），那么用这里没有的字符Z来替代aa：</p>
<p>ZabdZabac</p>
<p>Z=aa</p>
<p>此时，又发现ab出现的频率最高，那么同样的，Y来代替ab：</p>
<p>ZYdZYac</p>
<p>Y=ab</p>
<p>Z=aa</p>
<p>同样的，ZY出现的频率大，我们用X来替代ZY：</p>
<p>XdXac</p>
<p>X=ZY</p>
<p>Y=ab</p>
<p>Z=aa</p>
<p>最后，连续两个字符的频率都为1了，也就结束了。就是这么简单。</p>
<p>解码的时候，就按照相反的顺序更新替换即可。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-04-博客优化以及问题解决</title>
    <url>/2020/08/04/2020-08-04-%E5%8D%9A%E5%AE%A2%E4%BC%98%E5%8C%96%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h3 id="修改git-bash的默认打开工作路径">修改Git Bash的默认打开工作路径</h3>
<p>我每次想在我的博客文件夹里进入git bash，必须要打开文件夹才能进入，操作繁琐，于是在桌面建立git bash 快捷方式，并将git bash 的默认打开路径更改为我的博客文件夹下，这样点击图标，即能进入本地git仓库</p>
<p>1.找到git bash，右键属性，可以看到目标栏及起始位置栏。</p>
<p><img src="https://i.loli.net/2020/08/04/tPL1uzsVApn5FvC.png" alt="img" style="zoom: 80%;"></p>
<p>将目标栏中的 --cd-to-home 去掉；将起始位置中填写为本地git仓库的路径，即可完成操作。如下图所示，博客文件夹位置在<code>E:\myBlog</code></p>
<p><img src="https://i.loli.net/2020/08/04/Vw7Kg3U2OIZQ6R9.png" alt="image-20200804181206322" style="zoom: 50%;"></p>
<p>注： 若在文件夹里进入 git bash，则然后按下<code>shift+F10</code> （激活右键菜单栏），再按<code>s</code>跳转到git bash，最后按下<code>enter</code>即可</p>
<h3 id="博客打开网站和更新不完全">博客打开网站和更新不完全</h3>
<p>在这几天在本地文件夹更新完配置文件对博客进行个性化设置时，使用<code>localhost:4000</code>访问本地blog可以正常显示更改后的样式，但是在登录网站域名就会出现不一致的现象，有时会响应速度慢，延时高，甚至连接超时。</p>
<p>在整个过程中一直没发现问题，因为本地localhost和网站不一致就不能理解。后来才发现，我的hexo命令写错了。本应该是hexo clean ，我错写为hexo clear，导致不能轻触缓存，所以在网站中不能及时更新显示。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">hexo clean <span class="comment"># 清除缓存，网页正常情况下可以忽略此命令</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="博客无法连接">博客无法连接</h3>
<p>本地服务器可以正常显示，但是博客连接不上</p>
<p>如何可以ping 通，则代表不是域名方面的问题，应该就是服务器的问题，可能是部署在github上，所以会有点慢，后续准备买一个阿里云的服务器。</p>
<p>解决：</p>
<p>1.博客正在加载， 等一段时间刷新</p>
<p>2.如果还是不行，则清理chrome的cookie缓存再刷新即可， 可以解决问题，但是操作麻烦。</p>
<p><img src="https://i.loli.net/2020/08/10/Iwpk2yb5OAjuoKf.png" alt="image-20200810152929992"></p>
<p>3.清除特定网站下的缓存：</p>
<p>打开开发者工具（F12），选择 Network——Disable cache 。需要清除某网站缓存时 F12 打开开发者工具就会自动清除这个网站的缓存，而不必清除所有网站的缓存了。</p>
<p>4.如果在文章标题中使用了当天的日期，可能无法及时得到页面更新。因为Github使用了格林尼治标准时间，也就是UTC。中国是东八时区，UTC+8，对于hexo来说是一个未来的时间，所以新的Posts不会被渲染。</p>
<p>在hexo配置文件<code>_config.yml</code>中设置<code>timezone: Asia/Shanghai</code> (有效解决问题) <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8">⭐</span></p>
<p>参考</p>
<blockquote>
<p>博客无法更新post文章 https://www.jianshu.com/p/b73c28e77760</p>
</blockquote>
<h3 id="clone的时候无法clone-next的内容">clone的时候无法clone next的内容</h3>
<h4 id="问题">问题</h4>
<p>在使用git将myblog文件夹的博客内容push到github上之后，发现对于<code>./theme/next</code>中的内容无法上传</p>
<h4 id="原因">原因</h4>
<p>next当时是clone别人的仓库，在我的myblog文件夹里本身就有一个<code>.git</code>的隐藏文件，然而我在博客文件夹里又引用了next的git仓库，所以导致上述问题</p>
<blockquote>
<p>任意文件夹中，用 <code>git init</code> 命令初始化仓库，即可在此文件夹下创建 <code>.git</code> 文件夹（<code>.</code>打头为隐藏文件夹，所以平时可能看不到）。这个文件夹之外的部分叫做工作区（Working Directory），<code>.git</code> 文件夹我们称做 Git仓库 (Git Repository)。</p>
</blockquote>
<h4 id="解决">解决</h4>
<p>1.将themes/next这个文件里的.git文件删除，这样next文件就相当于是一个普通文件，可以上传到myblog仓库里。但是当next有大更新的时候不会提示</p>
<p>2.保留next 的.git，将next下的<code>_config.yml</code>和其它修改的文件单独复制出来（主要是<code>_config.yml</code>），备份一下到./source/文件夹下，将这些文件作为普通文件上传。这样next的.git不用删除，同时next文件夹下的内容不会上传。</p>
<h3 id="添加自启动项">添加自启动项</h3>
<p>添加开机自启动项，在文件管理器的路径栏输入</p>
<p><code>%USERPROFILE%\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Startup</code></p>
<p>然后将要添加的软件快捷方式复制到里面即可,如下：</p>
<p><strong><img src="https://i.loli.net/2020/08/31/dqOpCylYLNQ8EoV.png" alt="image-20200831170347078"></strong></p>
<h3 id="anaconda-prompt找不到">anaconda prompt找不到</h3>
<h4 id="操作">操作</h4>
<p>在开始栏里面找不到anaconda prompt的内容，自己在anaconda3文件夹里也没看到anaconda prompt的启动项。在powershell里使用conda，功能并不完整（如无法实现基本的<code>conda activate</code>）， 于是考虑将其添加到开始栏里，这样以后操作方便一些</p>
<p>step 1 :打开cmd, 进入到anaconda3的安装目录，下方是我的目录，于是操作如下：</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> C:\Users\Administrator\anaconda3</span><br></pre></td></tr></tbody></table></figure>
<p><img src="E:\myBlog\source_posts\image-20200902003632825.png" alt="image-20200902003632825"></p>
<p>step 2 : 进入到Anaconda的安装目录后，输入：</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">python .\Lib\_nsis.py mkmenus</span><br></pre></td></tr></tbody></table></figure>
<p>通过看文件夹目录树可以发现<code>anaconda prompt</code> 应该存在于<code>.\Lib\_nsis.py</code>文件里，用python运行 ，添加到开始栏里</p>
<p>step 3 打开左下角的开始栏，可以发现出现了<code>anaconda prompt</code></p>
<blockquote>
<h4 id="参考">参考</h4>
<p><a href="https://www.py.cn/tools/anaconda/16426.html" target="_blank" rel="noopener">anaconda prompt找不到怎么解决？</a></p>
</blockquote>
<h4 id="参考-1">参考</h4>
<blockquote>
<p><a href="https://www.py.cn/tools/anaconda/16426.html" target="_blank" rel="noopener">anaconda prompt找不到怎么解决？</a></p>
</blockquote>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>博客</category>
      </categories>
      <tags>
        <tag>故障排除</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-08-01-hexo+next个性化设置</title>
    <url>/2020/08/01/2020-08-10-hexo-next%E4%B8%AA%E6%80%A7%E5%8C%96%E8%AE%BE%E7%BD%AE/</url>
    <content><![CDATA[<p>一些基本的个性化设置可以参考其它博客，本文只记录在我完成</p>
<h3 id="修改文章底部的那个带号的标签">修改文章底部的那个带#号的标签</h3>
<p>在原本next自带的标签格式如下所示：</p>
<p><img src="https://i.loli.net/2020/08/10/GLtxuMpYd7WXmaV.png" alt="image-20200810180543537"></p>
<p>前面的<code>#</code>不太好看，在这里可以添加<code>font awesome</code>的<code>icon</code>，个性化标签显示</p>
<p>修改模板 <code>/themes/next/layout/_macro/post.swig</code>，搜索 <code>rel="tag"</code>，将<code>rel="tag"&gt;</code>换成<code>rel="tag"&lt;i class="fa fa-tag"&gt;&lt;/i&gt;</code> ，其中"fa fa-tag"可以根据<code>font awesome</code>里自己选择喜欢的<code>icon</code></p>
<p>因为在代码中不需要<code>tag_indicate</code>，所以可以将部分代码删去，如图中红框部分</p>
<p><img src="https://i.loli.net/2020/08/10/2zhlEdQjqyTcPRo.png" alt="image-20200810181951506"></p>
<p>个性化后如下所示：</p>
<p><img src="https://i.loli.net/2020/08/10/tuvBmHFRZ8JMk3S.png" alt="image-20200810180207065"></p>
<h3 id="hexo-文章加密">hexo 文章加密</h3>
<blockquote>
<p><a href="https://vic.kim/2019/05/27/Hexo文章加密/" target="_blank" rel="noopener">https://vic.kim/2019/05/27/Hexo%E6%96%87%E7%AB%A0%E5%8A%A0%E5%AF%86/</a></p>
</blockquote>
<h3 id="在每篇文章末尾添加本文结束标记">在每篇文章末尾添加“本文结束”标记</h3>
<p>修改模板 <code>/themes/next/layout/_macro/post.swig</code>，在<code></code>代码行中添加<code>&lt;div style="text-align:center;color: #ccc;font-size:14px;"&gt;-------------本文结束&lt;i class="fa fa-paw"&gt;&lt;/i&gt;感谢您的阅读-------------&lt;/div&gt;</code>即可完成设置，如下所示，红框内是添加内容</p>
<p><img src="https://i.loli.net/2020/08/10/TQEoIcbKLGaC5dr.png" alt="image-20200810182801218"></p>
<p>个性化如下所示：</p>
<p><img src="https://i.loli.net/2020/08/10/dCvbzpGBhs6excl.png" alt="image-20200810183022935"></p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
  </entry>
  <entry>
    <title>2020-08-01-teacher-foring以及解决</title>
    <url>/2020/08/01/2020-08-01-teacher-foring%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3/</url>
    <content><![CDATA[<p>https://zhuanlan.zhihu.com/p/93030328 链接</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
  </entry>
  <entry>
    <title>2020-07-30-pytorch使用手册</title>
    <url>/2020/07/30/2020-07-30-pytorch%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/</url>
    <content><![CDATA[<p>python中对于对象的拷贝分为浅拷贝(copy)和深拷贝(deepcopy)两种方式。其中浅拷贝由“=”完成。而深拷贝由copy模块中deepcopy()函数担任。</p>
<p>浅拷贝和深拷贝的区别是：浅拷贝只是将原对象在内存中引用地址拷贝过来了。让新的对象指向这个地址。而深拷贝是将这个对象的所有内容遍历拷贝过来了，相当于跟原来没关系了，所以如果你这时候修改原来对象的值跟他没关系了，不会随之更改。</p>
<h3 id="浅拷贝的使用">1.浅拷贝"="的使用</h3>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#1.使用=复制不可变对象的值，以及复制以后修改其值后的变化。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val1 = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val2 = val1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">"val1 is :{0},val2 is :{1}"</span>.format(val1,val2))<span class="comment">#val1 is :1000,val2 is :1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(id(val1),id(val2))  <span class="comment">#34052192 34052192</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#这时候修改val1的值，尽管val2指向val1.但因为val1是不可变类型，修改其值，会重新给新值分配内存，然后指向他。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val1 += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(val1,id(val1),val2,id(val2)) <span class="comment">#1001 10131616 1000 10131568  值不一样，内存地址也不一样了</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#1.使用=复制可变对象的值，以及复制以后修改其值后的变化。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls1 =[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls2 = ls1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(id(ls1),id(ls2)) <span class="comment">#43702792 43702792 直接使用=复制变量，内存地址一样，值也一样。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(ls1,ls2) <span class="comment">#[1, 2, 3, 4] [1, 2, 3, 4]直接使用=复制变量，内存地址一样，值也一样。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#这时候修改可变对的值,因为其值可变，所以只需要在原内存地址上修改即可。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls1.append(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(id(ls1),id(ls2)) <span class="comment">#可变对象修改其值，内存引用不变</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(ls1,ls2) <span class="comment">#[1, 2, 3, 4, 5] [1, 2, 3, 4, 5] 因为两个变量的内存指向一样，所以值也一样。</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="深拷贝copy.deepcopy函数">2.深拷贝：copy.deepcopy()函数</h3>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#1.使用copy.deepcopy()拷贝不可变对象的值，以及复制以后修改其值后的变化。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val1 = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val2 = copy.deepcopy(val1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">"val1 is :{0},val2 is :{1}"</span>.format(val1,val2))<span class="comment">#val1 is :1000,val2 is :1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(id(val1),id(val2))  <span class="comment">#33717408 33717408 对于不可变对象，深度拷贝内存地址没有修改。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val1 += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(val1,id(val1),val2,id(val2)) <span class="comment">#1001 33717904 1000 33717408</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#1.使用copy.deepcopy()复制可变对象的值，以及复制以后修改其值后的变化。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls1 =[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls2 = copy.deepcopy(ls1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(id(ls1),id(ls2)) <span class="comment">#34628472 34628712 注意对于可变对象深度拷贝后内存地址都修改了。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(ls1,ls2) <span class="comment">#[1, 2, 3, 4] [1, 2, 3, 4]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls1.append(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(id(ls1),id(ls2)) <span class="comment">#34628472 34628712</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(ls1,ls2) <span class="comment">#[1, 2, 3, 4, 5] [1, 2, 3, 4] #注意这个时候ls2的值没有随着ls1修改。</span></span><br></pre></td></tr></tbody></table></figure>
<p>总结：其实对于浅拷贝和深拷贝来说，如果拷贝对象都是不可变对象的话，那么两者效果是一样的。如果是可变对象的话，“=”拷贝的方式，只是拷贝了内存中的地址引用，两个对象的地址引用一样，所以两个对象的值会随着一方的修改而修改。而对于deepcopy()来说，如果是可变对象的话，那么拷贝内容后新对象的内存地址也会重新分配，跟原来的内存地址不一样了。所以两者任意修改变量的内容不会对另一方造成影响。</p>
<h3 id="注意一个特殊的copy跟深浅拷贝都有区别慎用">3.注意一个特殊的copy(),跟深浅拷贝都有区别，慎用。</h3>
<ol type="1">
<li>copy.copy对于可变类型，会进行浅拷贝</li>
<li>copy.copy对于不可变类型，不会拷贝，仅仅是指向</li>
</ol>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="number">1.</span>使用copy()拷贝不可变对象</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val1 = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val2 = copy.copy(val1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(val1,val2)<span class="comment">##1000 1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(id(val1),id(val2))<span class="comment">#8551568 8551568</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">2.</span>使用copy（）拷贝可变对象</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls1 =[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls2 = copy.copy(ls1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls1.append(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(ls1,ls2)  <span class="comment">#[1, 2, 3, 4, 5] [1, 2, 3, 4]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">看上去copy()函数效果和deepcopy()效果一样，可变对象拷贝后值也没有随着一个对象的修改而修改。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">然后真实情况真是这样嘛？请看下面的案例，同样是拷贝可变对象。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">origin = [<span class="number">1</span>, <span class="number">2</span>, [<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cop1 = copy.copy(origin)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cop2 = copy.deepcopy(origin)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">origin[<span class="number">2</span>][<span class="number">0</span>] = <span class="string">"hey!"</span>  <span class="comment">#修改数据源的值</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(cop1,cop2) <span class="comment">#[1, 2, ['hey!', 4]] [1, 2, [3, 4]]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">很显然这时copy（）函数拷贝的值随着原对象的值修改了，而deepcopy()的值没有随着原对象的值修改。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">主要是因为deepcopy会将复杂对象的每一层复制一个单独的个体出来对于copy（）函数要慎用，慎用。</span><br></pre></td></tr></tbody></table></figure>
<p>神经网络的典型处理如下所示：</p>
<ol type="1">
<li>定义可学习参数的网络结构（堆叠各层和层的设计）； 2. 数据集输入； 3. 对输入进行处理（由定义的网络层进行处理）,主要体现在网络的前向传播； 4. 计算loss ，由Loss层计算； 5. 反向传播求梯度； 6. 根据梯度改变参数值,最简单的实现方式（SGD）为: weight = weight - learning_rate * gradient</li>
</ol>
<p>下面是利用PyTorch定义深度网络层（Op）示例：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeatureL2Norm</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        super(FeatureL2Norm, self).__init__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, feature)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        epsilon = <span class="number">1e-6</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#        print(feature.size())</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#        print(torch.pow(torch.sum(torch.pow(feature,2),1)+epsilon,0.5).size())</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        norm = torch.pow(torch.sum(torch.pow(feature,<span class="number">2</span>),<span class="number">1</span>)+epsilon,<span class="number">0.5</span>).unsqueeze(<span class="number">1</span>).expand_as(feature)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.div(feature,norm)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeatureRegression</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, output_dim=<span class="number">6</span>, use_cuda=True)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        super(FeatureRegression, self).__init__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">225</span>, <span class="number">128</span>, kernel_size=<span class="number">7</span>, padding=<span class="number">0</span>),</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">64</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">0</span>),</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.linear = nn.Linear(<span class="number">64</span> * <span class="number">5</span> * <span class="number">5</span>, output_dim)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> use_cuda:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            self.conv.cuda()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            self.linear.cuda()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        x = self.conv(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        x = self.linear(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></tbody></table></figure>
<p>由上例代码可以看到，不论是在定义网络结构还是定义网络层的操作（Op），均需要定义forward函数，下面看一下<a href="https://pytorch.org/docs/stable/nn.html" target="_blank" rel="noopener">PyTorch官网</a>对PyTorch的forward方法的描述：</p>
<p><img src="https://img-blog.csdnimg.cn/20181114105426553.PNG" alt="img"></p>
<p>那么调用forward方法的具体流程是什么样的呢？<a href="https://blog.csdn.net/u012436149/article/details/70145598" target="_blank" rel="noopener">具体流程是这样的：</a></p>
<p>以一个Module为例： <strong>1. 调用module的call方法 2. module的call里面调用module的forward方法 3. forward里面如果碰到Module的子类，回到第1步，如果碰到的是Function的子类，继续往下 4. 调用Function的call方法 5. Function的call方法调用了Function的forward方法。 6. Function的forward返回值 7. module的forward返回值 8. 在module的call进行forward_hook操作，然后返回值。</strong></p>
<p>上述中“调用module的call方法”是指nn.Module 的__call__方法。定义__call__方法的类可以当作函数调用，具体参考Python的面向对象编程。也就是说，当把定义的网络模型model当作函数调用的时候就自动调用定义的网络模型的forward方法。nn.Module 的__call__方法部分源码如下所示：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, *input, **kwargs)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   result = self.forward(*input, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> hook <span class="keyword">in</span> self._forward_hooks.values():</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       <span class="comment">#将注册的hook拿出来用</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       hook_result = hook(self, input, result)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="keyword">return</span> result</span><br></pre></td></tr></tbody></table></figure>
<p>可以看到，当执行model(x)的时候，底层自动调用forward方法计算结果。具体示例如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        super(LeNet, self).__init__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	layer1 = nn.Sequential()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	layer1.add_module(<span class="string">'conv1'</span>, nn.Conv(<span class="number">1</span>, <span class="number">6</span>, <span class="number">3</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	layer1.add_moudle(<span class="string">'pool1'</span>, nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	self.layer1 = layer1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	layer2 = nn.Sequential()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	layer2.add_module(<span class="string">'conv2'</span>, nn.Conv(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	layer2.add_moudle(<span class="string">'pool2'</span>, nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	self.layer2 = layer2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	layer3 = nn.Sequential()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	layer3.add_module(<span class="string">'fc1'</span>, nn.Linear(<span class="number">400</span>, <span class="number">120</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	layer3.add_moudle(<span class="string">'fc2'</span>, nn.Linear(<span class="number">120</span>, <span class="number">84</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	layer3.add_moudle(<span class="string">'fc3'</span>, nn.Linear(<span class="number">84</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	self.layer3 = layer3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	x = self.layer1(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	x = self.layer2(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	x = self.layer3(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> x</span><br></pre></td></tr></tbody></table></figure>
<h3 id="model-lenet-y-modelx"><strong>model = LeNet() y = model(x)</strong></h3>
<p>如上则调用网络模型定义的forward方法。</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-07-30-待写博客</title>
    <url>/2020/07/30/2020-07-30-%E5%BE%85%E5%86%99%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<h3 id="pytorch-中forward的使用以及原理---pytorch使用">pytorch 中forward的使用以及原理 --pytorch使用</h3>
<p>https://blog.csdn.net/u011501388/article/details/84062483</p>
<h4 id="阅读代码时的问题-记录">阅读代码时的问题 记录</h4>
<h3 id="pytorch里面的torch.nn.parameter详解">PyTorch里面的torch.nn.Parameter()详解</h3>
<p>https://cloud.tencent.com/developer/article/1608348</p>
<p>chrome中github插件</p>
<p>https://www.bilibili.com/video/BV1Kt4y1X7fw/?spm_id_from=trigger_reload</p>
<h3 id="论文阅读的思维导图">论文阅读的思维导图</h3>
<p>conda 安装新版本python之后，会覆盖之前的版本</p>
<h1 id="linux-杀死暂停继续后台运行进程">LINUX 杀死、暂停、继续、后台运行进程</h1>
<p>ctrl + z</p>
<p>可以将一个正在前台执行的命令放到后台，并且暂停</p>
<p>若想恢复到前台，则</p>
<ol type="1">
<li>jobs #查看当前有多少在后台运行的命令 会有序号 job号</li>
<li>fg 〔<em>job</em>号〕 将后台中的命令调至前台继续运行 如： fg %1</li>
</ol>
<p>https://blog.csdn.net/QQ1910084514/article/details/80390671</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
  </entry>
  <entry>
    <title>2020-07-28-pytorch安装</title>
    <url>/2020/07/28/2020-07-28-pytorch%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<h3 id="anaconda安装配置">Anaconda安装配置</h3>
<p>由于墙的问题，用conda安装Pytorch过程中会连接失败，这是因为Anaconda.org的服务器在国外。在这里可以用清华TUNA镜像源，包含Anaconda仓库的镜像，将其加入conda的配置，配置如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#添加Anaconda的TUNA镜像</span></span><br><span class="line"></span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line"></span><br><span class="line"><span class="comment">#TUNA的help中镜像地址加有引号，需要去掉</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#设置搜索时显示通道地址</span></span><br><span class="line"></span><br><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></tbody></table></figure>
<p>执行完上述命令后，会生成~/.condarc文件，记录着对conda的配置，直接手动创建、编辑该文件是相同的效果。</p>
<p>https://www.jianshu.com/p/39819bcb889f</p>
<p>https://blog.csdn.net/weixin_39278265/article/details/84782550</p>
<p>镜像源内容理解一下？？？</p>
<p>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ 好用！</p>
<p>清华镜像源好像用不了了</p>
<p>为啥要使用镜像源？ 国内有啥比较靠谱的anaconda镜像源</p>
<p>https://www.py.cn/tools/anaconda/16426.html anaconda 问题</p>
<h3 id="anaconda-中的镜像源的基本操作">Anaconda 中的镜像源的基本操作</h3>
<h4 id="显示原来的镜像源">显示原来的镜像源</h4>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> conda config --show channels <span class="comment"># 在conda配置中只是显示channels项</span></span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - https://pypi.doubanio.com/simple/ <span class="comment">#自己添加配置的镜像源</span></span><br><span class="line">  - defaults   <span class="comment">#默认的channel</span></span><br></pre></td></tr></tbody></table></figure>
<h4 id="添加新镜像源">添加新镜像源</h4>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ <span class="comment">#后面的是镜像源地址，来自清华的镜像源</span></span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">channels: <span class="comment">#添加后的channels项</span></span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">  - https://pypi.doubanio.com/simple/</span><br><span class="line">  - defaults</span><br></pre></td></tr></tbody></table></figure>
<h4 id="删除旧镜像源">删除旧镜像源</h4>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> conda config --remove channels https://pypi.doubanio.com/simple/</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight cpp"><table><tbody><tr><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - https:<span class="comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span></span><br><span class="line">  - defaults</span><br></pre></td></tr></tbody></table></figure>
<p><img src="E:\myBlog\source_posts\image-20200901232602677.png" alt="image-20200901232602677"></p>
<h3 id="pytorch安装">Pytorch安装</h3>
<p>在这里的安装，我采用conda安装：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda install pytorch torchvision -c soumith</span><br></pre></td></tr></tbody></table></figure>
<h3 id="测试">测试</h3>
<p>进入python模式下，看能否导入torch成功：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">python</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br></pre></td></tr></tbody></table></figure>
<p>conda install pytorch=0.3.0</p>
<p>conda install torchvision==0.2.1</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-07-27-linux的session解析</title>
    <url>/2020/07/27/2020-07-27-linux%E7%9A%84session%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>我们使用ssh连接服务器时，ssh的窗口突然断开了连接，那么在服务器上跑的程序就也跟着断掉了，之前所有跑的数据也将丢失，这样将会浪费我们大量的时间。</p>
<h3 id="为什么ssh一旦断开我们的进程也将会被杀掉">为什么ssh一旦断开我们的进程也将会被杀掉？</h3>
<p>元凶：SIGHUP 信号</p>
<p>让我们来看看为什么关掉窗口/断开连接会使得正在运行的程序死掉。</p>
<p>在Linux/Unix中，有这样几个概念：</p>
<p>进程组（process group）：一个或多个进程的集合，每一个进程组有唯一一个进程组ID，即进程组长进程的ID。</p>
<p>会话期（session）：一个或多个进程组的集合，有唯一一个会话期首进程（session leader）。会话期ID为首进程的ID。</p>
<p>会话期可以有一个单独的控制终端（controlling terminal）。与控制终端连接的会话期首进程叫做控制进程（controlling process）。当前与终端交互的进程称为前台进程组。其余进程组称为后台进程组。</p>
<p>根据POSIX.1定义：</p>
<p>挂断信号（SIGHUP）默认的动作是终止程序。</p>
<p>当终端接口检测到网络连接断开，将挂断信号发送给控制进程（会话期首进程）。</p>
<p>如果会话期首进程终止，则该信号发送到该会话期前台进程组。</p>
<p>一个进程退出导致一个孤儿进程组中产生时，如果任意一个孤儿进程组进程处于STOP状态，发送SIGHUP和SIGCONT信号到该进程组中所有进程。</p>
<p>因此当网络断开或终端窗口关闭后，控制进程收到SIGHUP信号退出，会导致该会话期内其他进程退出。</p>
<p><strong>这里我认为我们的进程被杀掉也就是因为ssh与服务器之间的通信断掉了，这个通信断掉之后linux程序就默认将该连接下的所有进程都杀掉</strong></p>
<h3 id="session-是什么">session 是什么？</h3>
<p>我们常见的 Linux session 一般是指 shell session。Shell session 是终端中当前的状态，在终端中只能有一个 session。<code>当我们打开一个新的终端时，总会创建一个新的 shell session。</code></p>
<p>就进程间的关系来说，session 由一个或多个进程组组成。一般情况下，来自单个登录的所有进程都属于同一个 session。我们可以通过下图来理解进程、进程组和 session 之间的关系：</p>
<p><img src="https://img2018.cnblogs.com/blog/952033/202001/952033-20200103182042686-2100862807.png" alt="img"></p>
<p><code>会话是由会话中的第一个进程创建的，一般情况下是打开终端时创建的 shell 进程。</code>该进程也叫 session 的领头进程。Session 中领头进程的 PID 也就是 session 的 SID。我们可以通过下面的命令查看 SID：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">$ ps -o pid,ppid,pgid,sid,tty,comm</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://img2018.cnblogs.com/blog/952033/202001/952033-20200103182117962-99639442.png" alt="img"></p>
<p>Session 中的每个进程组被称为一个 job，有一个 job 会成为 session 的前台 job(foreground)，其它的 job 则是后台 job(background)。每个 session 连接一个控制终端(control terminal)，控制终端中的输入被发送给前台 job，从前台 job 产生的输出也被发送到控制终端上。同时由控制终端产生的信号，比如 ctrl + z 等都会传递给前台 job。</p>
<p>一般情况下 session 和终端是一对一的关系，当我们打开多个终端窗口时，实际上就创建了多个 session。</p>
<p><code>Session 的意义在于多个工作(job)在一个终端中运行，其中的一个为前台 job，它直接接收该终端的输入并把结果输出到该终端。其它的 job 则在后台运行。</code></p>
<h3 id="session-的诞生与消亡">session 的诞生与消亡</h3>
<p>通常，新的 session 由系统登录程序创建，session 中的领头进程是运行用户登录 shell 的进程。<code>新创建的每个进程都会属于一个进程组，当创建一个进程时，它和父进程在同一个进程组、session 中。</code></p>
<p>将进程放入不同 session 的惟一方法是使用 setsid 函数使其成为新 session 的领头进程。这还会将 session 领头进程放入一个新的进程组中。</p>
<p><code>当 session 中的所有进程都结束时 session 也就消亡了</code>。如下两种：</p>
<p>1.实际使用中比如网络断开了，session 肯定是要消亡的。</p>
<p>2.正常的消亡，比如让 session 的领头进程退出。</p>
<p>一般情况下 session 的领头进程是 shell 进程，如果它处于前台，我们可以使用 <code>exit 命令或者是 ctrl + d</code> 让它退出。或者我们可以直接通过 kill 命令杀死 session 的领头进程。这里面的原理是：当系统检测到挂断(hangup)条件时，内核中的驱动会将 SIGHUP 信号发送到整个 session。通常情况下，这会杀死 session 中的所有进程。</p>
<p>session 与终端的关系 如果 session 关联的是伪终端，这个伪终端本身就是随着 session 的建立而创建的，session 结束，那么这个伪终端也会被销毁。 如果 session 关联的是 tty1-6，tty 则不会被销毁。因为该终端设备是在系统初始化的时候创建的，并不是依赖该会话建立的，所以当 session 退出，tty 仍然存在。只是 init 系统在 session 结束后，会重启 getty 来监听这个 tty。</p>
<h3 id="nohup">nohup</h3>
<p><code>如果我们在 session 中执行了 nohup 等类似的命令，当 session 消亡时，相关的进程并不会随着 session 结束，原因是这些进程不再受 SIGHUP 信号的影响。</code>比如我们执行下面的命令：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">$ nohup sleep <span class="number">1000</span> &gt;/dev/null <span class="number">2</span>&gt;&amp;<span class="number">1</span> &amp;</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://img2018.cnblogs.com/blog/952033/202001/952033-20200103182343352-1366915632.png" alt="img"></p>
<p>此时 sleep 进程的 sid 和其它进程是相同的，还可以通过 pstree 命令看到进程间的父子关系：</p>
<p><img src="https://img2018.cnblogs.com/blog/952033/202001/952033-20200103182417115-817556079.png" alt="img"></p>
<p><code>如果我们退出当前 session 的领头进程(bash)，sleep 进程并不会退出，这样我们就可以放心的等待该进程运行结果了。</code> nohup 并不改变进程的 sid，同时也说明在这种情况中，虽然 session 的领头进程退出了，但是 session 依然没有被销毁(至少 sid 还在被引用)。重新建立连接，通过下面的命令查看 sleep 进程的信息，发现进程的 sid 依然是 7837：</p>
<p><img src="https://img2018.cnblogs.com/blog/952033/202001/952033-20200103182448160-376880623.png" alt="img"></p>
<p>但是<code>此时的 sleep 已经被系统的 1 号进程 systemd 收养了</code>：</p>
<p><img src="https://img2018.cnblogs.com/blog/952033/202001/952033-20200103182521953-1574746082.png" alt="img"></p>
<h3 id="参考">参考</h3>
<blockquote>
<p>https://www.cnblogs.com/sparkdev/p/12146305.html</p>
</blockquote>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-07-26-picgo上传失败原因</title>
    <url>/2020/07/26/2020-07-26-picgo%E4%B8%8A%E4%BC%A0%E5%A4%B1%E8%B4%A5%E5%8E%9F%E5%9B%A0/</url>
    <content><![CDATA[<h3 id="前言">前言</h3>
<p>在使用后PicGo上传图片至github时总是会显示上传失败，以下是我的解决方案经验，我的情况是可以上传图片，但是偶尔会失败</p>
<h3 id="case-1-检查服务及端口配置">case 1 检查服务及端口配置</h3>
<p>择相应的选项“设置server”，以下操作</p>
<p><img src="https://i.loli.net/2020/07/27/lf7Bw2jDUqgIxMk.png"></p>
<p>我们可以选择将开关先关闭，然后打开，确定后再重启软件，一般会成功。</p>
<p>或者修改端口号： 如修改为36688</p>
<p>记住，如果不行，那就直接关闭软件，然后等2分钟后，再打开picgo软件就可以上传成功了。</p>
<h3 id="case-2-查看日志">case 2 查看日志</h3>
<p>找到“设置日志文件”，然后打开日志文件，检查相应的日志，了解上传失败的原因。</p>
<p><img src="https://i.loli.net/2020/07/27/421CU9GzgKkauxt.png"></p>
<h3 id="参考">参考</h3>
<p>https://www.shopee6.com/web/web-tutorial/picgo-github-fail.html</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>杂</category>
      </categories>
      <tags>
        <tag>杂</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-07-26-tensorflow函数解析</title>
    <url>/2020/07/26/2020-07-26-tensorflow%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<p>tf.manul</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>tensorflow</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-07-26-numpy函数解析</title>
    <url>/2020/07/26/2020-07-26-numpy%E5%87%BD%E6%95%B0%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h3 id="newaxis用法">newaxis用法</h3>
<p>newaxis表示增加一个新的坐标轴</p>
<ul>
<li>x[:, np.newaxis] ，放在后面，会给列上增加维度</li>
<li>x[np.newaxis, :] ，放在前面，会给行上增加维度</li>
</ul>
<p><strong>用途：</strong> 通常用它将一维的数据转换成一个矩阵，与代码后面的权重矩阵进行相乘。</p>
<h4 id="第一个程序">第一个程序</h4>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">a = np.array([1,2,3])</span><br><span class="line">print (a.shape,'\n',a)</span><br></pre></td></tr></tbody></table></figure>
<p>结果为：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">(3,)</span><br><span class="line">[1 2 3]</span><br></pre></td></tr></tbody></table></figure>
<h4 id="第二个程序">第二个程序</h4>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = np.array([1,2,3])[:,np.newaxis]</span><br><span class="line">print (a.shape,'\n',a)</span><br></pre></td></tr></tbody></table></figure>
<p>结果为：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">(3, 1)</span><br><span class="line">[[1]</span><br><span class="line">[2]</span><br><span class="line">[3]]</span><br></pre></td></tr></tbody></table></figure>
<p>和第一个程序相比，a的shape为（3，）现在为（3，1）变为二维数组了，之前为[1,2,3]，现在变为</p>
<p>[[1] [2] [3]]</p>
<h4 id="第三个程序">第三个程序</h4>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">a = np.array([1,2,3])[np.newaxis,:]</span><br><span class="line">print (a.shape,'\n',a)</span><br></pre></td></tr></tbody></table></figure>
<p>输出结果为：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">(1, 3)</span><br><span class="line">[[1 2 3]]</span><br></pre></td></tr></tbody></table></figure>
<p>输出结果为：</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">(1, 3)</span><br><span class="line">[[1 2 3]]</span><br></pre></td></tr></tbody></table></figure>
<h4 id="总结">总结</h4>
<p>np.newaxis的作用就是在原来的数组上增加一个维度。[np.newaxis,:]这个地方np.newaxis放的位置有关，第二个程序放在[:,]的后面，相当于在原来的后面增加一个维度，所以变为(3,1)，而第三个则放在前面，则为(1,3)。<code>加到哪一维，那一维就为1</code></p>
<h3 id="concatenate用法">concatenate用法</h3>
<p>-用于进行数组拼接</p>
<p>函数定义：</p>
<p><code>numpy.concatenate</code>((a1, a2, ...), axis=0, out=None)</p>
<ul>
<li>axis=0: 合并行</li>
<li>axis=1: 合并列</li>
</ul>
<p>例子如下：</p>
<figure class="highlight csharp"><table><tbody><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; a=np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line"> &gt;&gt;&gt; b=np.array([[<span class="number">11</span>,<span class="number">21</span>,<span class="number">31</span>],[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]])</span><br><span class="line"> <span class="meta"># 合并行</span></span><br><span class="line"> &gt;&gt;&gt; np.concatenate((a,b,c),axis=<span class="number">0</span>)  <span class="meta"># 默认情况下，axis=0可以不写</span></span><br><span class="line"> array([[ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>],</span><br><span class="line">  [<span class="meta"> 4,  5,  6</span>],</span><br><span class="line">  [<span class="meta">11, 21, 31</span>],</span><br><span class="line">  [<span class="meta"> 7,  8,  9</span>]])</span><br><span class="line"> <span class="meta"># 合并列</span></span><br><span class="line"> &gt;&gt;&gt; np.concatenate((a,b),axis=<span class="number">1</span>) </span><br><span class="line">  array([[ <span class="number">1</span>,  <span class="number">2</span>,  <span class="number">3</span>, <span class="number">11</span>, <span class="number">21</span>, <span class="number">31</span>],</span><br><span class="line">  [<span class="meta"> 4,  5,  6,  7,  8,  9</span>]])</span><br></pre></td></tr></tbody></table></figure>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-07-26-python切片疑惑解析</title>
    <url>/2020/07/26/2020-07-26-python%E5%88%87%E7%89%87%E7%96%91%E6%83%91%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<p>Python中对于数组和列表进行切片操作是很频繁的，我主要简单总结一下常用集中索引化方式</p>
<h3 id="一维-nm--1-1">一维： [ : n]、[m : ] 、[-1]、[::-1]</h3>
<p><strong>[m : ]</strong> ：代表列表中的第m项到最后一项 （从0开始）</p>
<p><strong>[ : n]</strong> ：代表列表中的第0项到第n-1项 （含左不含右）</p>
<p><strong>[-1]：</strong>取最后一个元素</p>
<p><strong>[::-1]</strong>：取从后向前（相反）的元素 （倒序）</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">X = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>] )</span><br><span class="line">print(X.shape)</span><br><span class="line">print(<span class="string">'\n'</span>)</span><br><span class="line">print(X[<span class="number">3</span>:])</span><br><span class="line">print(X[:<span class="number">7</span>])</span><br><span class="line">print(X[::<span class="number">-1</span>][:<span class="number">3</span>]) <span class="comment"># 在进行了[::-1]之后得到倒序数组，再取[：3]</span></span><br></pre></td></tr></tbody></table></figure>
<p>结果如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">(<span class="number">8</span>,)</span><br><span class="line">[<span class="number">4</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span>]</span><br><span class="line">[<span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span>]</span><br><span class="line">[<span class="number">8</span>,<span class="number">7</span>,<span class="number">6</span>]</span><br></pre></td></tr></tbody></table></figure>
<h3 id="二维-x0-x1-x-mn">二维： X[:,0] 、X[:,1] 、 X[:, m:n]</h3>
<p>X[:,0]是numpy中数组的一种写法，表示对一个二维数组，取该二维数组第一维中的所有数据，第二维中取第0个数据，直观来说</p>
<p>X[:,0]：取第二维（所有行）的第0个数据,就是<code>第0列</code></p>
<p>X[:,1] ：取第二维（所有行）的第1个数据，就是<code>第1列</code></p>
<p>X[:, m:n]，即取所有数据的<code>第m到n-1列数据，含左不含右</code></p>
<p>示例如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">X = np.array([[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>],[<span class="number">9</span>,<span class="number">10</span>,<span class="number">11</span>],[<span class="number">12</span>,<span class="number">13</span>,<span class="number">14</span>],[<span class="number">15</span>,<span class="number">16</span>,<span class="number">17</span>],[<span class="number">18</span>,<span class="number">19</span>,<span class="number">20</span>]])</span><br><span class="line">print(X.shape)</span><br><span class="line">print(<span class="string">'\n'</span>)</span><br><span class="line"><span class="keyword">print</span> (X[:,<span class="number">1</span>:<span class="number">3</span>])</span><br></pre></td></tr></tbody></table></figure>
<p>结果如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">(<span class="number">7</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">[[ <span class="number">1</span>  <span class="number">2</span>]</span><br><span class="line"> [ <span class="number">4</span>  <span class="number">5</span>]</span><br><span class="line"> [ <span class="number">7</span>  <span class="number">8</span>]</span><br><span class="line"> [<span class="number">10</span> <span class="number">11</span>]</span><br><span class="line"> [<span class="number">13</span> <span class="number">14</span>]</span><br><span class="line"> [<span class="number">16</span> <span class="number">17</span>]</span><br><span class="line"> [<span class="number">19</span> <span class="number">20</span>]]</span><br></pre></td></tr></tbody></table></figure>
<h3 id="三维-x0x1xmn">三维 X[:,:,0]、X[:,:,1]、X[:,:,m:n]</h3>
<p>类比于二维，原理相同</p>
<p>X[:,:,0]：取第三维矩阵中第0列的所有数据</p>
<p>X[:,:,1]：取第三维矩阵中第1列的所有数据</p>
<p>X[:,:,m:n]：取第三维矩阵中第m列到第n-1列的所有数据</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">注：shape（<span class="number">9</span>,<span class="number">5</span>,<span class="number">2</span>）指的是最外层有<span class="number">9</span>个括号，每个括号里嵌套<span class="number">5</span>个括号，在<span class="number">5</span>个括号里又每个有<span class="number">2</span>个元素</span><br><span class="line"></span><br><span class="line">判断的时候先先出数组的shape，根据shape进行判断</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># !usr/bin/env python</span></span><br><span class="line"><span class="comment"># encoding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">simple_test</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    简单的小实验</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    data_list = [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">9</span>], [<span class="number">0</span>, <span class="number">4</span>, <span class="number">7</span>], [<span class="number">4</span>, <span class="number">6</span>, <span class="number">0</span>],[<span class="number">2</span>, <span class="number">9</span>, <span class="number">1</span>], [<span class="number">5</span>, <span class="number">8</span>, <span class="number">7</span>], [<span class="number">9</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">3</span>, <span class="number">7</span>, <span class="number">9</span>]]</span><br><span class="line">    <span class="comment"># data_list.toarray()</span></span><br><span class="line">    data_list = np.array(data_list)</span><br><span class="line">    print(<span class="string">'X[:,0]结果输出为：'</span>)</span><br><span class="line">    print( data_list[:, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    print(  <span class="string">'X[:,1]结果输出为：'</span>)</span><br><span class="line">    print( data_list[:, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'X[:,m:n]结果输出为：'</span>)</span><br><span class="line"></span><br><span class="line">    print( data_list[:, <span class="number">0</span>:<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    data_list = [[[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">7</span>, <span class="number">9</span>], [<span class="number">4</span>, <span class="number">0</span>]], [[<span class="number">1</span>, <span class="number">4</span>], [<span class="number">1</span>, <span class="number">5</span>], [<span class="number">3</span>, <span class="number">6</span>], [<span class="number">8</span>, <span class="number">9</span>], [<span class="number">5</span>, <span class="number">0</span>]],</span><br><span class="line">                 [[<span class="number">8</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">8</span>], [<span class="number">3</span>, <span class="number">5</span>], [<span class="number">7</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">6</span>]],</span><br><span class="line">                 [[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">5</span>], [<span class="number">7</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]], [[<span class="number">9</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">3</span>], [<span class="number">3</span>, <span class="number">5</span>], [<span class="number">7</span>, <span class="number">67</span>], [<span class="number">4</span>, <span class="number">4</span>]],</span><br><span class="line">                 [[<span class="number">8</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">9</span>], [<span class="number">3</span>, <span class="number">43</span>], [<span class="number">7</span>, <span class="number">3</span>], [<span class="number">43</span>, <span class="number">0</span>]],</span><br><span class="line">                 [[<span class="number">1</span>, <span class="number">22</span>], [<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">42</span>], [<span class="number">7</span>, <span class="number">29</span>], [<span class="number">4</span>, <span class="number">20</span>]], [[<span class="number">1</span>, <span class="number">5</span>], [<span class="number">1</span>, <span class="number">20</span>], [<span class="number">3</span>, <span class="number">24</span>], [<span class="number">17</span>, <span class="number">9</span>], [<span class="number">4</span>, <span class="number">10</span>]],</span><br><span class="line">                 [[<span class="number">11</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">110</span>], [<span class="number">3</span>, <span class="number">14</span>], [<span class="number">7</span>, <span class="number">4</span>], [<span class="number">4</span>, <span class="number">2</span>]]]</span><br><span class="line">    data_list = np.array(data_list)</span><br><span class="line">    print(data_list.shape)</span><br><span class="line">    print(<span class="string">'X[:,:,0]结果输出为：'</span>)</span><br><span class="line"></span><br><span class="line">    print( data_list[:, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'X[:,:,1]结果输出为：'</span>)</span><br><span class="line"></span><br><span class="line">    print(data_list[:, :, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'X[:,:,m:n]结果输出为：'</span>)</span><br><span class="line"></span><br><span class="line">    print( data_list[:, :, <span class="number">0</span>:<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    simple_test()</span><br></pre></td></tr></tbody></table></figure>
<p>部分结如下：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">X[:,:,<span class="number">0</span>]结果输出为：</span><br><span class="line">[[ <span class="number">1</span>  <span class="number">1</span>  <span class="number">3</span>  <span class="number">7</span>  <span class="number">4</span>]</span><br><span class="line"> [ <span class="number">1</span>  <span class="number">1</span>  <span class="number">3</span>  <span class="number">8</span>  <span class="number">5</span>]</span><br><span class="line"> [ <span class="number">8</span>  <span class="number">1</span>  <span class="number">3</span>  <span class="number">7</span>  <span class="number">4</span>]</span><br><span class="line"> [ <span class="number">1</span>  <span class="number">1</span>  <span class="number">3</span>  <span class="number">7</span>  <span class="number">7</span>]</span><br><span class="line"> [ <span class="number">9</span>  <span class="number">1</span>  <span class="number">3</span>  <span class="number">7</span>  <span class="number">4</span>]</span><br><span class="line"> [ <span class="number">8</span>  <span class="number">1</span>  <span class="number">3</span>  <span class="number">7</span> <span class="number">43</span>]</span><br><span class="line"> [ <span class="number">1</span>  <span class="number">1</span>  <span class="number">3</span>  <span class="number">7</span>  <span class="number">4</span>]</span><br><span class="line"> [ <span class="number">1</span>  <span class="number">1</span>  <span class="number">3</span> <span class="number">17</span>  <span class="number">4</span>]</span><br><span class="line"> [<span class="number">11</span>  <span class="number">1</span>  <span class="number">3</span>  <span class="number">7</span>  <span class="number">4</span>]]</span><br><span class="line">X[:,:,<span class="number">1</span>]结果输出为：</span><br><span class="line">[[  <span class="number">2</span>   <span class="number">0</span>   <span class="number">4</span>   <span class="number">9</span>   <span class="number">0</span>]</span><br><span class="line"> [  <span class="number">4</span>   <span class="number">5</span>   <span class="number">6</span>   <span class="number">9</span>   <span class="number">0</span>]</span><br><span class="line"> [  <span class="number">2</span>   <span class="number">8</span>   <span class="number">5</span>   <span class="number">3</span>   <span class="number">6</span>]</span><br><span class="line"> [  <span class="number">1</span>   <span class="number">2</span>   <span class="number">5</span>   <span class="number">6</span>   <span class="number">8</span>]</span><br><span class="line"> [  <span class="number">2</span>   <span class="number">3</span>   <span class="number">5</span>  <span class="number">67</span>   <span class="number">4</span>]</span><br><span class="line"> [  <span class="number">2</span>   <span class="number">9</span>  <span class="number">43</span>   <span class="number">3</span>   <span class="number">0</span>]</span><br><span class="line"> [ <span class="number">22</span>   <span class="number">2</span>  <span class="number">42</span>  <span class="number">29</span>  <span class="number">20</span>]</span><br><span class="line"> [  <span class="number">5</span>  <span class="number">20</span>  <span class="number">24</span>   <span class="number">9</span>  <span class="number">10</span>]</span><br><span class="line"> [  <span class="number">2</span> <span class="number">110</span>  <span class="number">14</span>   <span class="number">4</span>   <span class="number">2</span>]]</span><br></pre></td></tr></tbody></table></figure>
<h3 id="startendstep">[start：end：step]</h3>
<p>start:开始索引；end:结束索引；step:步长（步长为正时，从左到右索引，正序取值；步长为负时，从右到左索引，倒序取值）</p>
<p>[::2] 步长为2</p>
<p>[3:7:2] 第3个元素开始，第6个元素结束，步长为2</p>
<p>参考</p>
<p>https://blog.csdn.net/Together_CZ/article/details/79593952</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-07-25-transformer代码</title>
    <url>/2020/07/25/2020-07-25-transformer%E4%BB%A3%E7%A0%81/</url>
    <content><![CDATA[<h1 id="tensorflow-2.0-教程-transformer">TensorFlow 2.0 教程-Transformer</h1>
<p>这里我们将实现一个Transformer模型，将葡萄牙语翻译为英语。Transformer的核心思想是self-attention--通过关注序列不同位置的内容获取句子的表示。</p>
<p>Transformer的一些优点：</p>
<ul>
<li>不受限于数据的时间/空间关系</li>
<li>可以并行计算</li>
<li>远距离token的相互影响不需要通过很长的时间步或很深的卷积层</li>
<li>可以学习远程依赖</li>
</ul>
<p>Transformer的缺点：</p>
<ul>
<li>对于时间序列，输出需要根据整个历史，而不是当前状态和输入，可能造成效率较低</li>
<li>如果想要获取时间空间信息，需要额外的位置编码</li>
</ul>
<p>In [1]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">from __future__ import absolute_import, division, print_function, unicode_literals</span><br><span class="line"># 安装tfds pip install tfds-nightly==1.0.2.dev201904090105</span><br><span class="line">import tensorflow_datasets as tfds</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras.layers as layers</span><br><span class="line"></span><br><span class="line">import time</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">print(tf.__version__)</span><br><span class="line">2.0.0-alpha0</span><br></pre></td></tr></tbody></table></figure>
<h2 id="数据输入pipeline">1.数据输入pipeline</h2>
<p>我们将使用到Portugese-English翻译数据集。</p>
<p>该数据集包含大约50000个训练样例，1100个验证示例和2000个测试示例。</p>
<p>tfds.load :加载数据集.1.下载数据并将其另存为tfrecord文件. 2.加载tfrecord并创建tf.data.Dataset. metadata: 元数据 用于描述数据的数据，比如数码照片的EXIF信息，它就是一种用来描述数码图片的元数据</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,</span><br><span class="line">                              as_supervised=True)</span><br></pre></td></tr></tbody></table></figure>
<p>将数据转化为subwords格式</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">train_examples, val_examples = examples['train'], examples['validation']</span><br></pre></td></tr></tbody></table></figure>
<p>把单词用英语和葡萄牙语分别进行编码</p>
<p>2**13： 2的3次方大小的词汇表大小</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(</span><br><span class="line">(en.numpy() for pt, en in train_examples), target_vocab_size=2**13)</span><br><span class="line">tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(</span><br><span class="line">(pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)</span><br></pre></td></tr></tbody></table></figure>
<p>token转化测试</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">sample_str = 'hello world, tensorflow 2'</span><br><span class="line">tokenized_str = tokenizer_en.encode(sample_str)</span><br><span class="line">print(tokenized_str)</span><br><span class="line">original_str = tokenizer_en.decode(tokenized_str)</span><br><span class="line">print(original_str)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">[3222, 439, 150, 7345, 1378, 2824, 2370, 7881]</span><br><span class="line">hello world, tensorflow 2</span><br></pre></td></tr></tbody></table></figure>
<p>添加start、end的token表示</p>
<p>lang1：用于葡萄牙语翻译的开始</p>
<p>lang2：用于英语翻译完成的结束</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def encode(lang1, lang2):</span><br><span class="line">    lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(</span><br><span class="line">        lang1.numpy()) + [tokenizer_pt.vocab_size+1]</span><br><span class="line">    lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(</span><br><span class="line">        lang2.numpy()) + [tokenizer_en.vocab_size+1]</span><br><span class="line">    return lang1, lang2</span><br></pre></td></tr></tbody></table></figure>
<p>过滤长度超过40的数据</p>
<p>tf.logical_and ： 与运算</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">MAX_LENGTH=40</span><br><span class="line">def filter_long_sent(x, y, max_length=MAX_LENGTH):</span><br><span class="line">    return tf.logical_and(tf.size(x) &lt;= max_length,</span><br><span class="line">                         tf.size(y) &lt;= max_length)</span><br></pre></td></tr></tbody></table></figure>
<p>将python运算，转换为tensorflow运算节点。</p>
<p>这是一个可以把 TensorFlow 和 Python 原生代码无缝衔接起来的函数，有了它，你就可以在 TensorFlow 里面自由的实现你想要的功能，而不用考虑 TensorFlow 有没有实现它的 API</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def tf_encode(pt, en):</span><br><span class="line">    return tf.py_function(encode, [pt, en], [tf.int64, tf.int64])</span><br></pre></td></tr></tbody></table></figure>
<h3 id="构造数据集">构造数据集</h3>
<p>In [9]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">BUFFER_SIZE = 20000</span><br><span class="line">BATCH_SIZE = 64</span><br><span class="line"></span><br><span class="line"># 使用.map()运行相关图操作</span><br><span class="line">train_dataset = train_examples.map(tf_encode)</span><br><span class="line"># 过滤过长的数据</span><br><span class="line">train_dataset = train_dataset.filter(filter_long_sent) # 这个函数为什么不加（） ？？？</span><br><span class="line"># 使用缓存数据加速读入</span><br><span class="line">train_dataset = train_dataset.cache()</span><br><span class="line"># 打乱并获取批数据</span><br><span class="line">train_dataset = train_dataset.padded_batch(</span><br><span class="line">BATCH_SIZE, padded_shapes=([40], [40]))  # 填充为最大长度-90</span><br><span class="line"># 设置预取数据</span><br><span class="line">train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)</span><br><span class="line"></span><br><span class="line"># 验证集数据</span><br><span class="line">val_dataset = val_examples.map(tf_encode)</span><br><span class="line">val_dataset = val_dataset.filter(filter_long_sent).padded_batch(</span><br><span class="line">BATCH_SIZE, padded_shapes=([40], [40]))</span><br></pre></td></tr></tbody></table></figure>
<p>In [10]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">de_batch, en_batch = next(iter(train_dataset))</span><br><span class="line">de_batch, en_batch</span><br></pre></td></tr></tbody></table></figure>
<p>Out[10]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">(&lt;tf.Tensor: id=311363, shape=(64, 40), dtype=int64, numpy=</span><br><span class="line"> array([[8214,  116,   84, ...,    0,    0,    0],</span><br><span class="line">        [8214,    7,  261, ...,    0,    0,    0],</span><br><span class="line">        [8214,  155,   39, ...,    0,    0,    0],</span><br><span class="line">        ...,</span><br><span class="line">        [8214,  639,  590, ...,    0,    0,    0],</span><br><span class="line">        [8214,  204, 3441, ...,    0,    0,    0],</span><br><span class="line">        [8214,   27,   13, ...,    0,    0,    0]])&gt;,</span><br><span class="line"> &lt;tf.Tensor: id=311364, shape=(64, 40), dtype=int64, numpy=</span><br><span class="line"> array([[8087,   83,  145, ...,    0,    0,    0],</span><br><span class="line">        [8087, 4670, 1783, ...,    0,    0,    0],</span><br><span class="line">        [8087,  169,   56, ...,    0,    0,    0],</span><br><span class="line">        ...,</span><br><span class="line">        [8087,  174,   79, ...,    0,    0,    0],</span><br><span class="line">        [8087,   11,   16, ...,    0,    0,    0],</span><br><span class="line">        [8087,    4,   12, ...,    0,    0,    0]])&gt;)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="位置嵌入">2.位置嵌入</h2>
<p>将位置编码矢量添加得到词嵌入，相同位置的词嵌入将会更接近，但并不能直接编码相对位置</p>
<p>基于角度的位置编码方法如下：</p>
<p><img src="https://render.githubusercontent.com/render/math?math=%5CLarge%7BPE_%7B%28pos%2C%202i%29%7D%20%3D%20sin%28pos%20%2F%2010000%5E%7B2i%20%2F%20d_%7Bmodel%7D%7D%29%7D%20%24%24%24%24%5CLarge%7BPE_%7B%28pos%2C%202i%2B1%29%7D%20%3D%20cos%28pos%20%2F%2010000%5E%7B2i%20%2F%20d_%7Bmodel%7D%7D%29%7D&amp;mode=display" alt="\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} \Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} "></p>
<p>得到角度</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def get_angles(pos, i, d_model):</span><br><span class="line">    # 这里的i等价与上面公式中的2i和2i+1</span><br><span class="line">    angle_rates = 1 / np.power(10000, (2*(i // 2))/ np.float32(d_model))</span><br><span class="line">    return pos * angle_rates</span><br></pre></td></tr></tbody></table></figure>
<p>In [12]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def positional_encoding(position, d_model):</span><br><span class="line">	#numpy.arange(start, stop, step, dtype = None) np.arange(position) = [0,...,position-1]</span><br><span class="line">    angle_rads = get_angles(np.arange(position)[:, np.newaxis],   # shape(position,1)</span><br><span class="line">                           np.arange(d_model)[np.newaxis,:],  # shape(1,d_model)</span><br><span class="line">                           d_model)</span><br><span class="line">    # 第2i项使用sin</span><br><span class="line">    sines = np.sin(angle_rads[:, 0::2])  #从0开始，步长为2</span><br><span class="line">    # 第2i+1项使用cos</span><br><span class="line">    cones = np.cos(angle_rads[:, 1::2]) #从1开始，步长为2</span><br><span class="line">    pos_encoding = np.concatenate([sines, cones], axis=-1)</span><br><span class="line">    pos_encoding = pos_encoding[np.newaxis, ...]</span><br><span class="line">    </span><br><span class="line">    return tf.cast(pos_encoding, dtype=tf.float32)</span><br></pre></td></tr></tbody></table></figure>
<p>获得位置嵌入编码</p>
<p>position： 一句话中某个token的位置（0-50）， 如果一句话不够50个单词，那么就需要padding</p>
<p>depth ： 对每一个token进行编码 d_model：512维</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">pos_encoding = positional_encoding(50, 512)</span><br><span class="line">print(pos_encoding.shape)</span><br><span class="line"></span><br><span class="line">plt.pcolormesh(pos_encoding[0], cmap='RdBu')</span><br><span class="line">plt.xlabel('Depth')</span><br><span class="line">plt.xlim((0, 512))</span><br><span class="line">plt.ylabel('Position')</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.show() # 在这里左右边分别为原来2i 和 2i+1的特征</span><br><span class="line">(1, 50, 512)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="data:image/png;base64,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%0A" alt="img"></p>
<h2 id="掩码">3.掩码</h2>
<p>为了避免输入中padding的token对句子语义的影响，需要将<code>padding位mark掉，原来为0的padding项的mark输出为1</code></p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def create_padding_mark(seq):</span><br><span class="line">    # 获取为0的padding项</span><br><span class="line">    seq = tf.cast(tf.math.equal(seq, 0), tf.float32) #将seq的编码逐个与0比较，相等为1不等为0</span><br><span class="line">    </span><br><span class="line">    # 扩充维度以便用于attention矩阵</span><br><span class="line">    return seq[:, np.newaxis, np.newaxis, :] # (batch_size,1,1,seq_len)</span><br><span class="line"></span><br><span class="line"># mark 测试</span><br><span class="line">create_padding_mark([[1,2,0,0,3],[3,4,5,0,0]])</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">&lt;tf.Tensor: id=311819, shape=(2, 1, 1, 5), dtype=float32, numpy=</span><br><span class="line">array([[[[0., 0., 1., 1., 0.]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       [[[0., 0., 0., 1., 1.]]]], dtype=float32)&gt;</span><br></pre></td></tr></tbody></table></figure>
<p>look-ahead mask 用于对未预测的token进行掩码 这意味着要预测第三个单词，只会使用第一个和第二个单词。 要预测第四个单词，仅使用第一个，第二个和第三个单词，依此类推。 ？？？？？？</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def create_look_ahead_mark(size):</span><br><span class="line">    # 1 - 对角线和取下三角的全部对角线（-1-&gt;全部）</span><br><span class="line">    # 这样就可以构造出每个时刻未预测token的掩码</span><br><span class="line">    mark = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)</span><br><span class="line">    return mark  # (seq_len, seq_len)</span><br></pre></td></tr></tbody></table></figure>
<p>In [16]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># x = tf.random.uniform((1,3))</span><br><span class="line">temp = create_look_ahead_mark(3)</span><br><span class="line">print(temp)</span><br><span class="line">tf.Tensor(</span><br><span class="line">[[0. 1. 1.]</span><br><span class="line"> [0. 0. 1.]</span><br><span class="line"> [0. 0. 0.]], shape=(3, 3), dtype=float32)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="scaled-dot-product-attention">4.Scaled dot product attention</h2>
<p><img src="https://camo.githubusercontent.com/22371733ed7ffa9065a60e80d3b83b10d832072a/68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f696d616765732f7475746f7269616c732f7472616e73666f726d65722f7363616c65645f617474656e74696f6e2e706e67" alt="img">进行attention计算的时候有3个输入 Q (query), K (key), V (value)。计算公式如下：<img src="https://render.githubusercontent.com/render/math?math=%5CLarge%7BAttention%28Q%2C%20K%2C%20V%29%20%3D%20softmax_k%28%5Cfrac%7BQK%5ET%7D%7B%5Csqrt%7Bd_k%7D%7D%29%20V%7D&amp;mode=display" alt="\Large{Attention(Q, K, V) = softmax_k(\frac{QK^T}{\sqrt{d_k}}) V} "></p>
<p>点积注意力通过深度d_k的平方根进行缩放,因为较大的深度会使点积变大，由于使用softmax，会使梯度变小。 例如，考虑Q和K的均值为0且方差为1.它们的矩阵乘法的均值为0，方差为dk。我们使用dk的根用于缩放（而不是任何其他数字），因为Q和K的matmul应该具有0的均值和1的方差。</p>
<p>在这里我们将<code>被掩码的token乘以-1e9(表示负无穷)</code>,这样softmax之后就为0,不对其他token产生影响。</p>
<p>In [17]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def scaled_dot_product_attention(q, k, v, mask):</span><br><span class="line">    # query key 相乘获取匹配关系</span><br><span class="line">    matmul_qk = tf.matmul(q, k, transpose_b=True)  # transpose_b=True表示b项在运算前要进行转置运算</span><br><span class="line">    </span><br><span class="line">    # 使用dk进行缩放</span><br><span class="line">    dk = tf.cast(tf.shape(k)[-1], tf.float32)</span><br><span class="line">    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)</span><br><span class="line">    </span><br><span class="line">    # 掩码</span><br><span class="line">    if mask is not None:</span><br><span class="line">        scaled_attention_logits += (mask * -1e9)</span><br><span class="line">        </span><br><span class="line">    # 通过softmax获取attention权重</span><br><span class="line">    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)</span><br><span class="line">    </span><br><span class="line">    # attention 乘上value</span><br><span class="line">    output = tf.matmul(attention_weights, v) # （.., seq_len_v, depth）</span><br><span class="line">    </span><br><span class="line">    return output, attention_weights</span><br></pre></td></tr></tbody></table></figure>
<p>使用attention获取需要关注的语义</p>
<p>In [18]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def print_out(q, k, v):</span><br><span class="line">    temp_out, temp_att = scaled_dot_product_attention(</span><br><span class="line">    q, k, v, None)</span><br><span class="line">    print('attention weight:')</span><br><span class="line">    print(temp_att)</span><br><span class="line">    print('output:')</span><br><span class="line">    print(temp_out)</span><br></pre></td></tr></tbody></table></figure>
<p>attention测试</p>
<p>In [19]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 显示为numpy类型</span><br><span class="line">np.set_printoptions(suppress=True)</span><br><span class="line"></span><br><span class="line">temp_k = tf.constant([[10,0,0],</span><br><span class="line">                      [0,10,0],</span><br><span class="line">                      [0,0,10],</span><br><span class="line">                      [0,0,10]], dtype=tf.float32)  # (4, 3)</span><br><span class="line"></span><br><span class="line">temp_v = tf.constant([[   1,0],</span><br><span class="line">                      [  10,0],</span><br><span class="line">                      [ 100,5],</span><br><span class="line">                      [1000,6]], dtype=tf.float32)  # (4, 3)</span><br><span class="line"># 关注第2个key, 返回对应的value</span><br><span class="line">temp_q = tf.constant([[0,10,0]], dtype=tf.float32)</span><br><span class="line">print_out(temp_q, temp_k, temp_v)</span><br><span class="line">attention weight:</span><br><span class="line">tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)</span><br><span class="line">output:</span><br><span class="line">tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)</span><br></pre></td></tr></tbody></table></figure>
<p>In [20]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 关注重复的key(第3、4个), 返回对应的value（平均）</span><br><span class="line">temp_q = tf.constant([[0,0,10]], dtype=tf.float32)</span><br><span class="line">print_out(temp_q, temp_k, temp_v)</span><br><span class="line">attention weight:</span><br><span class="line">tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)</span><br><span class="line">output:</span><br><span class="line">tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)</span><br></pre></td></tr></tbody></table></figure>
<p>In [21]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 关注第1、2个key, 返回对应的value（平均）</span><br><span class="line">temp_q = tf.constant([[10,10,0]], dtype=tf.float32)</span><br><span class="line">print_out(temp_q, temp_k, temp_v)</span><br><span class="line">attention weight:</span><br><span class="line">tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)</span><br><span class="line">output:</span><br><span class="line">tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)</span><br></pre></td></tr></tbody></table></figure>
<p>In [22]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 依次放入每个query</span><br><span class="line">temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)</span><br><span class="line">print_out(temp_q, temp_k, temp_v)</span><br><span class="line">attention weight:</span><br><span class="line">tf.Tensor(</span><br><span class="line">[[0.  0.  0.5 0.5]</span><br><span class="line"> [0.  1.  0.  0. ]</span><br><span class="line"> [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)</span><br><span class="line">output:</span><br><span class="line">tf.Tensor(</span><br><span class="line">[[550.    5.5]</span><br><span class="line"> [ 10.    0. ]</span><br><span class="line"> [  5.5   0. ]], shape=(3, 2), dtype=float32)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="mutil-head-attention">5.Mutil-Head Attention</h2>
<p><img src="https://camo.githubusercontent.com/5464abc4535579fdb88afb7117617f6f23ff50af/68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f696d616765732f7475746f7269616c732f7472616e73666f726d65722f6d756c74695f686561645f617474656e74696f6e2e706e67" alt="img"></p>
<p>mutil-head attention包含3部分：</p>
<ul>
<li>线性层与分头</li>
<li>缩放点积注意力</li>
<li>头连接</li>
<li>末尾线性层</li>
</ul>
<p>每个多头注意块有三个输入; Q（查询），K（密钥），V（值）。 它们<code>通过第一层线性层并分成多个头</code>。</p>
<p>注意:点积注意力时需要使用mask， 多头输出需要使用tf.transpose调整各维度。</p>
<p>Q，K和V不是一个单独的注意头，而是分成多个头，因为<code>它允许模型共同参与来自不同表征空间的不同信息。 在拆分之后，每个头部具有降低的维度，总计算成本与具有全维度的单个头部注意力相同。</code></p>
<p>python 中<code>assert断言</code>是声明其布尔值必须为真的判定，如果发生异常就说明表达式为假。可以理解assert断言语句为<strong>raise-if-not</strong>，用来测试表示式，其返回值为假，则会抛出AssertError并且包含错误信息。如果它为真，就不做任何事</p>
<p>"//"不管两者出现任何数，都以整除结果为准，不对小数部分进行处理，直接抛弃，也就是整除法</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 构造mutil head attention层</span><br><span class="line">class MutilHeadAttention(tf.keras.layers.Layer):</span><br><span class="line">    def __init__(self, d_model, num_heads):</span><br><span class="line">        super(MutilHeadAttention, self).__init__()</span><br><span class="line">        self.num_heads = num_heads</span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        </span><br><span class="line">        # d_model 必须可以正确分为各个头</span><br><span class="line">        assert d_model % num_heads == 0</span><br><span class="line">        # 分头后的维度</span><br><span class="line">        self.depth = d_model // num_heads</span><br><span class="line">        </span><br><span class="line">        self.wq = tf.keras.layers.Dense(d_model)</span><br><span class="line">        self.wk = tf.keras.layers.Dense(d_model)</span><br><span class="line">        self.wv = tf.keras.layers.Dense(d_model)</span><br><span class="line">        </span><br><span class="line">        self.dense = tf.keras.layers.Dense(d_model)</span><br><span class="line">        </span><br><span class="line">    def split_heads(self, x, batch_size):</span><br><span class="line">        # 分头, 将头个数的维度 放到 seq_len 前面</span><br><span class="line">        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))</span><br><span class="line">        return tf.transpose(x, perm=[0, 2, 1, 3])</span><br><span class="line">    </span><br><span class="line">    def call(self, v, k, q, mask):</span><br><span class="line">        batch_size = tf.shape(q)[0]</span><br><span class="line">        </span><br><span class="line">        # 分头前的前向网络，获取q、k、v语义</span><br><span class="line">        q = self.wq(q)  # (batch_size, seq_len, d_model)</span><br><span class="line">        k = self.wk(k)</span><br><span class="line">        v = self.wv(v)</span><br><span class="line">        </span><br><span class="line">        # 分头</span><br><span class="line">        q = self.split_heads(q, batch_size) # (batch_size, num_heads, seq_len_q, depth)</span><br><span class="line">        k = self.split_heads(k, batch_size)</span><br><span class="line">        v = self.split_heads(v, batch_size)</span><br><span class="line">        # scaled_attention.shape == (batch_size, num_heads, seq_len_v, depth)</span><br><span class="line">        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)</span><br><span class="line">        </span><br><span class="line">        # 通过缩放点积注意力层</span><br><span class="line">        scaled_attention, attention_weights = scaled_dot_product_attention(</span><br><span class="line">        q, k, v, mask)</span><br><span class="line">        # 把多头维度后移</span><br><span class="line">        scaled_attention = tf.transpose(scaled_attention, [0, 2, 1, 3]) # (batch_size, seq_len_v, num_heads, depth)</span><br><span class="line"></span><br><span class="line">        # 合并多头</span><br><span class="line">        concat_attention = tf.reshape(scaled_attention, </span><br><span class="line">                                      (batch_size, -1, self.d_model))</span><br><span class="line">        </span><br><span class="line">        # 全连接重塑</span><br><span class="line">        output = self.dense(concat_attention)</span><br><span class="line">        return output, attention_weights</span><br></pre></td></tr></tbody></table></figure>
<p>测试多头attention</p>
<p>In [24]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">temp_mha = MutilHeadAttention(d_model=512, num_heads=8)</span><br><span class="line">y = tf.random.uniform((1, 60, 512))</span><br><span class="line">output, att = temp_mha(y, k=y, q=y, mask=None)</span><br><span class="line">print(output.shape, att.shape)</span><br><span class="line">(1, 60, 512) (1, 8, 60, 60)</span><br></pre></td></tr></tbody></table></figure>
<p>point wise前向网络</p>
<p>In [25]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">def point_wise_feed_forward_network(d_model, diff):</span><br><span class="line">    return tf.keras.Sequential([</span><br><span class="line">        tf.keras.layers.Dense(diff, activation='relu'),</span><br><span class="line">        tf.keras.layers.Dense(d_model)</span><br><span class="line">    ])</span><br></pre></td></tr></tbody></table></figure>
<p>In [26]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">sample_fnn = point_wise_feed_forward_network(512, 2048)</span><br><span class="line">sample_fnn(tf.random.uniform((64, 50, 512))).shape</span><br></pre></td></tr></tbody></table></figure>
<p>Out[26]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">TensorShape([64, 50, 512])</span><br></pre></td></tr></tbody></table></figure>
<h2 id="编码器和解码器">6.编码器和解码器</h2>
<p><img src="https://camo.githubusercontent.com/ce5d9e0b508ffa8c84c943258c677b7576f35757/68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f696d616765732f7475746f7269616c732f7472616e73666f726d65722f7472616e73666f726d65722e706e67" alt="img"></p>
<ul>
<li>通过N个编码器层，为序列中的每个字/令牌生成输出。</li>
<li>解码器连接编码器的输出和它自己的输入（自我注意）以预测下一个字。</li>
</ul>
<h3 id="编码层">编码层</h3>
<p>每个编码层包含以下子层</p>
<ul>
<li>Multi-head attention（带掩码）</li>
<li>Point wise feed forward networks</li>
</ul>
<p>每个子层中都有残差连接，并最后通过一个正则化层。残差连接有助于避免深度网络中的梯度消失问题。 每个子层输出是LayerNorm(x + Sublayer(x))，规范化是在d_model维的向量上。Transformer一共有n个编码层。</p>
<p>In [27]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class LayerNormalization(tf.keras.layers.Layer):</span><br><span class="line">    def __init__(self, epsilon=1e-6, **kwargs):</span><br><span class="line">        self.eps = epsilon</span><br><span class="line">        super(LayerNormalization, self).__init__(**kwargs)</span><br><span class="line">    def build(self, input_shape):</span><br><span class="line">        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],</span><br><span class="line">                                     initializer=tf.ones_initializer(), trainable=True)</span><br><span class="line">        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],</span><br><span class="line">                                    initializer=tf.zeros_initializer(), trainable=True)</span><br><span class="line">        super(LayerNormalization, self).build(input_shape)</span><br><span class="line">    def call(self, x):</span><br><span class="line">        mean = tf.keras.backend.mean(x, axis=-1, keepdims=True)</span><br><span class="line">        std = tf.keras.backend.std(x, axis=-1, keepdims=True)</span><br><span class="line">        return self.gamma * (x - mean) / (std + self.eps) + self.beta</span><br><span class="line">    def compute_output_shape(self, input_shape):</span><br><span class="line">        return input_shape</span><br></pre></td></tr></tbody></table></figure>
<p>In [28]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class EncoderLayer(tf.keras.layers.Layer):</span><br><span class="line">    def __init__(self, d_model, n_heads, ddf, dropout_rate=0.1):</span><br><span class="line">        super(EncoderLayer, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.mha = MutilHeadAttention(d_model, n_heads)</span><br><span class="line">        self.ffn = point_wise_feed_forward_network(d_model, ddf)</span><br><span class="line">        </span><br><span class="line">        self.layernorm1 = LayerNormalization(epsilon=1e-6)</span><br><span class="line">        self.layernorm2 = LayerNormalization(epsilon=1e-6)</span><br><span class="line">        </span><br><span class="line">        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)</span><br><span class="line">        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)</span><br><span class="line">        </span><br><span class="line">    def call(self, inputs, training, mask):</span><br><span class="line">        # 多头注意力网络</span><br><span class="line">        att_output, _ = self.mha(inputs, inputs, inputs, mask)</span><br><span class="line">        att_output = self.dropout1(att_output, training=training)</span><br><span class="line">        out1 = self.layernorm1(inputs + att_output)  # (batch_size, input_seq_len, d_model)</span><br><span class="line">        # 前向网络</span><br><span class="line">        ffn_output = self.ffn(out1)</span><br><span class="line">        ffn_output = self.dropout2(ffn_output, training=training)</span><br><span class="line">        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)</span><br><span class="line">        return out2</span><br></pre></td></tr></tbody></table></figure>
<p>encoder层测试</p>
<p>In [29]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">sample_encoder_layer = EncoderLayer(512, 8, 2048)</span><br><span class="line">sample_encoder_layer_output = sample_encoder_layer(</span><br><span class="line">tf.random.uniform((64, 43, 512)), False, None)</span><br><span class="line"></span><br><span class="line">sample_encoder_layer_output.shape</span><br></pre></td></tr></tbody></table></figure>
<p>Out[29]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">TensorShape([64, 43, 512])</span><br></pre></td></tr></tbody></table></figure>
<h3 id="解码层">解码层</h3>
<p>每个编码层包含以下子层：</p>
<ul>
<li>Masked muti-head attention（带padding掩码和look-ahead掩码）</li>
<li>Muti-head attention（带padding掩码）value和key来自encoder输出，query来自Masked muti-head attention层输出</li>
<li>Point wise feed forward network</li>
</ul>
<p>每个子层中都有残差连接，并最后通过一个正则化层。残差连接有助于避免深度网络中的梯度消失问题。</p>
<p>每个子层输出是LayerNorm(x + Sublayer(x))，规范化是在d_model维的向量上。Transformer一共有n个解码层。</p>
<p>当Q从解码器的第一个注意块接收输出，并且K接收编码器输出时，注意权重表示基于编码器输出给予解码器输入的重要性。 换句话说，解码器通过查看编码器输出并自我关注其自己的输出来预测下一个字。</p>
<p>ps：因为padding在后面所以look-ahead掩码同时掩padding</p>
<p>In [30]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class DecoderLayer(tf.keras.layers.Layer):</span><br><span class="line">    def __init__(self, d_model, num_heads, dff, drop_rate=0.1):</span><br><span class="line">        super(DecoderLayer, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.mha1 = MutilHeadAttention(d_model, num_heads)</span><br><span class="line">        self.mha2 = MutilHeadAttention(d_model, num_heads)</span><br><span class="line">        </span><br><span class="line">        self.ffn = point_wise_feed_forward_network(d_model, dff)</span><br><span class="line">        </span><br><span class="line">        self.layernorm1 = LayerNormalization(epsilon=1e-6)</span><br><span class="line">        self.layernorm2 = LayerNormalization(epsilon=1e-6)</span><br><span class="line">        self.layernorm3 = LayerNormalization(epsilon=1e-6)</span><br><span class="line">        </span><br><span class="line">        self.dropout1 = layers.Dropout(drop_rate)</span><br><span class="line">        self.dropout2 = layers.Dropout(drop_rate)</span><br><span class="line">        self.dropout3 = layers.Dropout(drop_rate)</span><br><span class="line">        </span><br><span class="line">    def call(self,inputs, encode_out, training, </span><br><span class="line">             look_ahead_mask, padding_mask):</span><br><span class="line">        # masked muti-head attention</span><br><span class="line">        att1, att_weight1 = self.mha1(inputs, inputs, inputs,look_ahead_mask)</span><br><span class="line">        att1 = self.dropout1(att1, training=training)</span><br><span class="line">        out1 = self.layernorm1(inputs + att1)</span><br><span class="line">        # muti-head attention</span><br><span class="line">        att2, att_weight2 = self.mha2(encode_out, encode_out, inputs, padding_mask)</span><br><span class="line">        att2 = self.dropout2(att2, training=training)</span><br><span class="line">        out2 = self.layernorm2(out1 + att2)</span><br><span class="line">        </span><br><span class="line">        ffn_out = self.ffn(out2)</span><br><span class="line">        ffn_out = self.dropout3(ffn_out, training=training)</span><br><span class="line">        out3 = self.layernorm3(out2 + ffn_out)</span><br><span class="line">        </span><br><span class="line">        return out3, att_weight1, att_weight2</span><br></pre></td></tr></tbody></table></figure>
<p>测试解码层</p>
<p>In [31]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">sample_decoder_layer = DecoderLayer(512, 8, 2048)</span><br><span class="line"></span><br><span class="line">sample_decoder_layer_output, _, _ = sample_decoder_layer(</span><br><span class="line">tf.random.uniform((64, 50, 512)), sample_encoder_layer_output,</span><br><span class="line">    False, None, None)</span><br><span class="line">sample_decoder_layer_output.shape</span><br></pre></td></tr></tbody></table></figure>
<p>Out[31]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">TensorShape([64, 50, 512])</span><br></pre></td></tr></tbody></table></figure>
<h3 id="编码器">编码器</h3>
<p>编码器包含：</p>
<ul>
<li>Input Embedding</li>
<li>Positional Embedding</li>
<li>N个编码层</li>
</ul>
<p>In [32]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Encoder(layers.Layer):</span><br><span class="line">    def __init__(self, n_layers, d_model, n_heads, ddf,</span><br><span class="line">                input_vocab_size, max_seq_len, drop_rate=0.1):</span><br><span class="line">        super(Encoder, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.n_layers = n_layers</span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        </span><br><span class="line">        self.embedding = layers.Embedding(input_vocab_size, d_model)</span><br><span class="line">        self.pos_embedding = positional_encoding(max_seq_len, d_model)</span><br><span class="line">        </span><br><span class="line">        self.encode_layer = [EncoderLayer(d_model, n_heads, ddf, drop_rate)</span><br><span class="line">                            for _ in range(n_layers)]</span><br><span class="line">        </span><br><span class="line">        self.dropout = layers.Dropout(drop_rate)</span><br><span class="line">    def call(self, inputs, training, mark):</span><br><span class="line">        </span><br><span class="line">        seq_len = inputs.shape[1]</span><br><span class="line">        word_emb = self.embedding(inputs)</span><br><span class="line">        word_emb *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))</span><br><span class="line">        emb = word_emb + self.pos_embedding[:,:seq_len,:]</span><br><span class="line">        x = self.dropout(emb, training=training)</span><br><span class="line">        for i in range(self.n_layers):</span><br><span class="line">            x = self.encode_layer[i](x, training, mark)</span><br><span class="line">        </span><br><span class="line">        return x</span><br></pre></td></tr></tbody></table></figure>
<p>编码器测试</p>
<p>In [33]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">sample_encoder = Encoder(2, 512, 8, 1024, 5000, 200)</span><br><span class="line">sample_encoder_output = sample_encoder(tf.random.uniform((64, 120)),</span><br><span class="line">                                      False, None)</span><br><span class="line">sample_encoder_output.shape</span><br></pre></td></tr></tbody></table></figure>
<p>Out[33]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">TensorShape([64, 120, 512])</span><br></pre></td></tr></tbody></table></figure>
<h3 id="解码器">解码器</h3>
<p>解码器包含以下部分：1、输出嵌入；2、位置编码；3、n个解码层</p>
<p>输出嵌入和位置编码叠加后输入解码器，解码器最后的输出送给一个全连接</p>
<p>In [34]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># import pdb</span><br><span class="line"># pdb.set_trace()</span><br><span class="line">class Decoder(layers.Layer):</span><br><span class="line">    def __init__(self, n_layers, d_model, n_heads, ddf,</span><br><span class="line">                target_vocab_size, max_seq_len, drop_rate=0.1):</span><br><span class="line">        super(Decoder, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.n_layers = n_layers</span><br><span class="line">        </span><br><span class="line">        self.embedding = layers.Embedding(target_vocab_size, d_model)</span><br><span class="line">        self.pos_embedding = positional_encoding(max_seq_len, d_model)</span><br><span class="line">        </span><br><span class="line">        self.decoder_layers= [DecoderLayer(d_model, n_heads, ddf, drop_rate)</span><br><span class="line">                             for _ in range(n_layers)]</span><br><span class="line">        </span><br><span class="line">        self.dropout = layers.Dropout(drop_rate)</span><br><span class="line">        </span><br><span class="line">    def call(self, inputs, encoder_out,training,</span><br><span class="line">             look_ahead_mark, padding_mark):</span><br><span class="line">    </span><br><span class="line">        seq_len = tf.shape(inputs)[1]</span><br><span class="line">        attention_weights = {}</span><br><span class="line">        h = self.embedding(inputs)</span><br><span class="line">        h *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))</span><br><span class="line">        h += self.pos_embedding[:,:seq_len,:]</span><br><span class="line">        </span><br><span class="line">        h = self.dropout(h, training=training)</span><br><span class="line">#         print('--------------------\n',h, h.shape)</span><br><span class="line">        # 叠加解码层</span><br><span class="line">        for i in range(self.n_layers):</span><br><span class="line">            h, att_w1, att_w2 = self.decoder_layers[i](h, encoder_out,</span><br><span class="line">                                                   training, look_ahead_mark,</span><br><span class="line">                                                   padding_mark)</span><br><span class="line">            attention_weights['decoder_layer{}_att_w1'.format(i+1)] = att_w1</span><br><span class="line">            attention_weights['decoder_layer{}_att_w2'.format(i+1)] = att_w2</span><br><span class="line">        </span><br><span class="line">        return h, attention_weights</span><br></pre></td></tr></tbody></table></figure>
<p>解码器测试</p>
<p>In [35]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">sample_decoder = Decoder(2, 512,8,1024,5000, 200)</span><br><span class="line">sample_decoder_output, attn = sample_decoder(tf.random.uniform((64, 100)),</span><br><span class="line">                                            sample_encoder_output, False,</span><br><span class="line">                                            None, None)</span><br><span class="line">sample_decoder_output.shape, attn['decoder_layer1_att_w1'].shape</span><br></pre></td></tr></tbody></table></figure>
<p>Out[35]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">(TensorShape([64, 100, 512]), TensorShape([64, 8, 100, 100]))</span><br></pre></td></tr></tbody></table></figure>
<h3 id="创建transformer">创建Transformer</h3>
<p>Transformer包含编码器、解码器和最后的线性层，解码层的输出经过线性层后得到Transformer的输出</p>
<p>In [36]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class Transformer(tf.keras.Model):</span><br><span class="line">    def __init__(self, n_layers, d_model, n_heads, diff,</span><br><span class="line">                input_vocab_size, target_vocab_size,</span><br><span class="line">                max_seq_len, drop_rate=0.1):</span><br><span class="line">        super(Transformer, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.encoder = Encoder(n_layers, d_model, n_heads,diff,</span><br><span class="line">                              input_vocab_size, max_seq_len, drop_rate)</span><br><span class="line">        </span><br><span class="line">        self.decoder = Decoder(n_layers, d_model, n_heads, diff,</span><br><span class="line">                              target_vocab_size, max_seq_len, drop_rate)</span><br><span class="line">        </span><br><span class="line">        self.final_layer = tf.keras.layers.Dense(target_vocab_size)</span><br><span class="line">    def call(self, inputs, targets, training, encode_padding_mask, </span><br><span class="line">            look_ahead_mask, decode_padding_mask):</span><br><span class="line">        </span><br><span class="line">        encode_out = self.encoder(inputs, training, encode_padding_mask)</span><br><span class="line">        print(encode_out.shape)</span><br><span class="line">        decode_out, att_weights = self.decoder(targets, encode_out, training, </span><br><span class="line">                                               look_ahead_mask, decode_padding_mask)</span><br><span class="line">        print(decode_out.shape)</span><br><span class="line">        final_out = self.final_layer(decode_out)</span><br><span class="line">        </span><br><span class="line">        return final_out, att_weights</span><br></pre></td></tr></tbody></table></figure>
<p>Transformer测试</p>
<p>In [37]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">sample_transformer = Transformer(</span><br><span class="line">n_layers=2, d_model=512, n_heads=8, diff=1024,</span><br><span class="line">input_vocab_size=8500, target_vocab_size=8000, max_seq_len=120</span><br><span class="line">)</span><br><span class="line">temp_input = tf.random.uniform((64, 62))</span><br><span class="line">temp_target = tf.random.uniform((64, 26))</span><br><span class="line">fn_out, _ = sample_transformer(temp_input, temp_target, training=False,</span><br><span class="line">                              encode_padding_mask=None,</span><br><span class="line">                               look_ahead_mask=None,</span><br><span class="line">                               decode_padding_mask=None,</span><br><span class="line">                              )</span><br><span class="line">fn_out.shape</span><br><span class="line">(64, 62, 512)</span><br><span class="line">(64, 26, 512)</span><br></pre></td></tr></tbody></table></figure>
<p>Out[37]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">TensorShape([64, 26, 8000])</span><br></pre></td></tr></tbody></table></figure>
<h2 id="实验设置">7.实验设置</h2>
<h3 id="设置超参">设置超参</h3>
<p>In [38]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">num_layers = 4</span><br><span class="line">d_model = 128</span><br><span class="line">dff = 512</span><br><span class="line">num_heads = 8</span><br><span class="line"></span><br><span class="line">input_vocab_size = tokenizer_pt.vocab_size + 2</span><br><span class="line">target_vocab_size = tokenizer_en.vocab_size + 2</span><br><span class="line">max_seq_len = 40</span><br><span class="line">dropout_rate = 0.1</span><br></pre></td></tr></tbody></table></figure>
<h3 id="优化器">优化器</h3>
<p>带自定义学习率调整的Adam优化器<img src="https://render.githubusercontent.com/render/math?math=%5CLarge%7Blrate%20%3D%20d_%7Bmodel%7D%5E%7B-0.5%7D%20%2A%20min%28step%7B%5C_%7Dnum%5E%7B-0.5%7D%2C%20step%7B%5C_%7Dnum%20%2A%20warmup%7B%5C_%7Dsteps%5E%7B-1.5%7D%29%7D&amp;mode=display" alt="\Large{lrate = d_{model}^{-0.5} * min(step{\_}num^{-0.5}, step{\_}num * warmup{\_}steps^{-1.5})}"></p>
<p>In [39]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):</span><br><span class="line">    def __init__(self, d_model, warmup_steps=4000):</span><br><span class="line">        super(CustomSchedule, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.d_model = tf.cast(d_model, tf.float32)</span><br><span class="line">        self.warmup_steps = warmup_steps</span><br><span class="line">    </span><br><span class="line">    def __call__(self, step):</span><br><span class="line">        arg1 = tf.math.rsqrt(step)</span><br><span class="line">        arg2 = step * (self.warmup_steps ** -1.5)</span><br><span class="line">        </span><br><span class="line">        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)</span><br></pre></td></tr></tbody></table></figure>
<p>In [40]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">learing_rate = CustomSchedule(d_model)</span><br><span class="line">optimizer = tf.keras.optimizers.Adam(learing_rate, beta_1=0.9, </span><br><span class="line">                                    beta_2=0.98, epsilon=1e-9)</span><br></pre></td></tr></tbody></table></figure>
<p>In [41]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 测试</span><br><span class="line">temp_learing_rate = CustomSchedule(d_model)</span><br><span class="line">plt.plot(temp_learing_rate(tf.range(40000, dtype=tf.float32)))</span><br><span class="line">plt.xlabel('learning rate')</span><br><span class="line">plt.ylabel('train step')</span><br></pre></td></tr></tbody></table></figure>
<p>Out[41]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">Text(0, 0.5, 'train step')</span><br></pre></td></tr></tbody></table></figure>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8XXW57/HPk6RJ2qZJ2yRt0zGdS8pMGARkHgoiVQEper14hMNVQTkOKOg5Dni5R/QoiIJeFAQ9YikgWrjMgsyUpgVKB1uS3dKmdNhJx6Rj0uf+sVba3ZBhN8nK3km+79crr6z9W2v91rN30jxd6/dbzzJ3R0REpKtlpDoAERHpnZRgREQkEkowIiISCSUYERGJhBKMiIhEQglGREQioQQjIiKRUIIREZFIKMGIiEgkslIdQCoVFRV5aWlpqsMQEelRFixYUOPuxe1t16cTTGlpKRUVFakOQ0SkRzGz95PZTpfIREQkEkowIiISCSUYERGJhBKMiIhEItIEY2YzzGy5mVWa2Y0trM8xswfD9fPMrDRh3U1h+3IzOz+h/V4z22hmi1s55jfMzM2sKIr3JCIiyYkswZhZJnAncAFQBlxhZmXNNrsK2Ozuk4DbgFvDfcuAWcB0YAZwV9gfwH1hW0vHHAOcB6zu0jcjIiKHLMozmBOASnePufseYDYws9k2M4H7w+WHgbPNzML22e6+291XApVhf7j7S8CmVo55G/AtQI/pFBFJsSgTzChgTcLr6rCtxW3cvQHYChQmue9BzGwmsNbd3+lc2OnL3Zkzfw11uxtSHYqISLt6xSC/mQ0AvgN8L4ltrzGzCjOriMfj0QfXhd5es4VvPbKIbz+8KNWhiIi0K8oEsxYYk/B6dNjW4jZmlgUUALVJ7ptoIjAeeMfMVoXbLzSzEc03dPe73b3c3cuLi9utdJBWVm/aAcCzSzekOBIRkfZFmWDmA5PNbLyZZRMM2s9tts1c4Mpw+VLgeXf3sH1WOMtsPDAZeLO1A7n7u+4+zN1L3b2U4JLase6+vmvfUmpVxesB2NO4j9W1O1IcjYhI2yJLMOGYynXA08AyYI67LzGzm83s4nCze4BCM6sEvg7cGO67BJgDLAWeAq5190YAM/sz8Dow1cyqzeyqqN5DuqmK12EWLD+1ZF1qgxERaYcFJwx9U3l5ufekYpcX/OJlhufnEN++m+ysDB798impDklE+iAzW+Du5e1t1ysG+fuCffuclTV1TCzO48IjSnhr9RbWbd2Z6rBERFqlBNNDfLB1J7v27mNC8UBmHB7MXXhqca8aYhKRXkYJpoeIhQP8E4vzmFicx9Thg3jsnQ9SHJWISOuUYHqIqngdABOKBwIw85iRLFy9hfdr61MZlohIq5RgeohYvJ5BuVkU5+UA8Imjg8IGf31LZzEikp6UYHqIqngdE4rzsHCe8sjB/TlpwlAefauavjwTUETSlxJMDxGL1zOxaOBBbZ86ZjSranfw1potKYpKRKR1SjA9QN3uBtZv28XEYXkHtV9wxAhysjJ4dGFbVXRERFJDCaYHWBnOIJvQ7AxmUG4/zi0bzmOLPmB3Q2MqQhMRaZUSTA8QqwlmkDU/gwG4rHwMW3bs5ZklKoApIulFCaYHqNpYR4bBuMIBH1r30UlFjB7Snwfm6SGeIpJelGB6gKqaekYPGUBOVuaH1mVkGFecMJbXY7XEwntlRETSgRJMD1C1sY6JxQNbXX9Z+WiyMozZ89e0uo2ISHdTgklz+/Y5q2rrmVD84fGXJsMG5XLOYcN5eEG1BvtFJG0owaS5piKXE9tIMACfOXEsm+r3qACmiKQNJZg01/QUywltXCIDOHVSEeOLBnLvq6t0Z7+IpAUlmDTXNHDf3hlMRobxL6eU8s6aLSxcvbk7QhMRaZMSTJqritcxKDeLorzsdre95NjR5Odmcc8rK7shMhGRtinBpLlYvP6gIpdtGZiTxRUnjuWpxetZs2lHN0QnItI6JZg0F4vXtzlFubnPn1xKhhn3vbYquqBERJIQaYIxsxlmttzMKs3sxhbW55jZg+H6eWZWmrDuprB9uZmdn9B+r5ltNLPFzfr6qZn908wWmdmjZjY4yvfWHfYXuWxn/CVRSUF/LjyihAfnr2HLjj0RRici0rbIEoyZZQJ3AhcAZcAVZlbWbLOrgM3uPgm4Dbg13LcMmAVMB2YAd4X9AdwXtjX3LHC4ux8JrABu6tI3lAIr9z8mOfkzGIAvnTGRut0NOosRkZSK8gzmBKDS3WPuvgeYDcxsts1M4P5w+WHgbAsGG2YCs919t7uvBCrD/nD3l4BNzQ/m7s+4e0P48g1gdFe/oe524DHJyZ/BABxWks85hw3n3ldWsn3X3ihCExFpV5QJZhSQWLukOmxrcZswOWwFCpPcty1fAJ5saYWZXWNmFWZWEY/HD6HL7heLt17ksj1fPXsS23Y18Mc33o8gMhGR9vW6QX4z+y7QAPyppfXufre7l7t7eXFxcfcGd4iq4vWMGdpykcv2HDl6MKdPKeZ3L69kx56G9ncQEeliUSaYtcCYhNejw7YWtzGzLKAAqE1y3w8xs88DFwGf9V5wO3tVvO5DDxk7FF85axKb6vfw3zqLEZEUiDLBzAcmm9l4M8smGLSf22ybucCV4fKlwPNhYpgLzApnmY0HJgNvtnUwM5sBfAu42N17/E0g+/Y5K2vqD2kGWXPlpUP56OQifv2PKrZpLEZEullkCSYcU7kOeBpYBsxx9yVmdrOZXRxudg9QaGaVwNeBG8N9lwBzgKXAU8C17t4IYGZ/Bl4HpppZtZldFfb1K2AQ8KyZvW1mv4nqvXWHtVt2srth3yEP8Df37RnT2LxjL799KdZFkYmIJCcrys7d/QngiWZt30tY3gVc1sq+twC3tNB+RSvbT+pUsGkmVtOxKcrNHT6qgIuOLOF3L6/kcx8Zx7BBuV0RnohIu3rdIH9vUbWxY1OUW/LN86ayt3Efv/x7Zaf7EhFJlhJMmorVJF/ksj2lRQO5/Pgx/PnN1awMz4xERKKmBJOmghpkyRW5TMb150wmJyuDW/7f0i7pT0SkPUowaaoqXtfuQ8YOxbBBuXz17Mk8t2wjLyzf2GX9ioi0RgkmDdXtbmDDtt2dmqLckn85ZTwTigbyo8eWsqdhX5f2LSLSnBJMGjrwFMuuO4MByM7K4D8+Xkaspp77XtNDyUQkWkowaSgWVlHuihlkzZ05dRhnTRvGL557j3Vbd3Z5/yIiTZRg0lBVJ4pcJuP7Hy+j0Z3/+OsSekFFHRFJU0owaSjWiSKXyRhXOJCvnTOF55Zt4MnF6yM5hoiIEkwaqorXdfkAf3NXnTqe6SPz+d7flrB1h+qUiUjXU4JJM01FLjtTRTkZWZkZ3HrJkWzesYf/88SySI8lIn2TEkyaaSpyOXFYtGcwENQpu/qj43mwYg0v/FP3xohI11KCSTP7H5Mc8RlMk6+dM4VpIwZxw8OLqK3b3S3HFJG+QQkmzUQ5Rbkluf0yue3yo9m2cy83/eVdzSoTkS6jBJNmYjV15HdRkctkHVaSzw3nT+WZpRt4qKK6244rIr2bEkyaqdpYz4QuLHKZrKtOHc9HJhTyw8eW7L9MJyLSGUowaSZWE/0U5ZZkZBg/v/wocvpl8uX/XsjOPY3dHoOI9C5KMGlk+669bNi2u0urKB+KkoL+3H750azYuJ1//+tijceISKcowaSRlV30mOTOOG1KMV85azKPLKxmTsWalMUhIj1fpAnGzGaY2XIzqzSzG1tYn2NmD4br55lZacK6m8L25WZ2fkL7vWa20cwWN+trqJk9a2bvhd+HRPneolC1v4py918iS3T92ZM5dVIR//G3JSxeuzWlsYhIzxVZgjGzTOBO4AKgDLjCzMqabXYVsNndJwG3AbeG+5YBs4DpwAzgrrA/gPvCtuZuBP7u7pOBv4eve5RYvJ4Mg7ERFblMVmaGcfusoykamM2//qGCjdt2pTQeEemZojyDOQGodPeYu+8BZgMzm20zE7g/XH4YONuC6VMzgdnuvtvdVwKVYX+4+0vAphaOl9jX/cAnuvLNdIdYvJ6xERa5PBRFeTn89spytuzYyzV/XMCuvRr0F5FDE2WCGQUkXsSvDtta3MbdG4CtQGGS+zY33N3XhcvrgeEtbWRm15hZhZlVxOPxZN5Htwkek5zay2OJpo8s4LbLj+LtNVu48ZFFGvQXkUPSKwf5PfhL2OJfQ3e/293L3b28uLi4myNrXWNY5DKVA/wtmXF4Cd88bwp/ffsDfvl8ZarDEZEeJMoEsxYYk/B6dNjW4jZmlgUUALVJ7tvcBjMrCfsqAXpU9cYPwiKX6XQG0+TaMyfxqWNH8fNnVzD7zdWpDkdEeogoE8x8YLKZjTezbIJB+7nNtpkLXBkuXwo8H559zAVmhbPMxgOTgTfbOV5iX1cCf+uC99BturvI5aEwM2695EhOn1LMdx59l2eXbkh1SCLSA0SWYMIxleuAp4FlwBx3X2JmN5vZxeFm9wCFZlYJfJ1w5pe7LwHmAEuBp4Br3b0RwMz+DLwOTDWzajO7Kuzrx8C5ZvYecE74usdoKnLZHWX6O6JfZgZ3ffZYjhhVwHUPLGT+qpbmWYiIHGB9eeC2vLzcKyoqUh0GAN999F0ee+cD3vn+ed1eh+xQ1Nbt5rLfvE5N3W4e+NeTOHxUQapDEpFuZmYL3L28ve165SB/TxSL1zNxWPcXuTxUhXk53P+FE8jLyeJ/3DOPZeu2pTokEUlTSjBpoipex4Si9Lw81tyYoQP48zUnkZuVyWd/N4/l67enOiQRSUNKMGlg+669bNyeuiKXHTGucCB/vuYksjKMz/7uDSo3KsmIyMGUYNLA/gH+NJyi3JbxRUGSAWPW3W+w9ANdLhORA5Rg0kCspqnIZc85g2kysTiPB//XSWRnZnD53a9TodllIhJSgkkDsXg9mRmW8iKXHTWxOI+HvnQyRXk5/I975vHiivQqwSMiqaEEkwaq4nWMGdI/LYpcdtSowf2Z878+wviiPK6+fz6PL/og1SGJSIopwaSBWLy+x42/tKR4UA6zrzmJo0YP5roH3uI3L1apQKZIH6YEk2KN+5xYTX2PmkHWloL+/fjvq0/koiNL+PGT/+Q7j77L3sZ9qQ5LRFIgK9UB9HUfbNnJnjQtctlRuf0yuWPWMYwrHMCdL1RRvXknd372WPJz+6U6NBHpRjqDSbF0eUxyV8vIMG44fxo/ueRIXq+q5ZK7XiMWvlcR6RuUYFKsKrwHprdcImvu08eP4Q9fOIGaut3M/NWrqsQs0ocowaRYLF5HQf9+FA7MTnUokTl5UhGPfeVUSosG8q9/qODnz65g3z4N/ov0dkowKRY8Jnlg2he57KzRQwbw0Bc/wqXHjeaOv7/HVffPZ3P9nlSHJSIRSirBmNmxZvZVM/uKmR0bdVB9SSxe32OKXHZWbr9MfnrpkfzoE4fzamUtF/ziZd6I1aY6LBGJSLsJxsy+B9wPFAJFwO/N7N+jDqwvaCpyOXFY7xx/aYmZ8bmTxvGXL59M/+xMrvjtG/z8meU0aCqzSK+TzBnMZ4Hj3f377v594CTgc9GG1Tc0FbnsK2cwiQ4fVcDjXzmVS44dzR3PV3L53W9QvXlHqsMSkS6UTIL5AMhNeJ0DrI0mnL6lqcjlpD50BpNoYE4W/3XZUfxi1tEsX7+dGbe/zIPzV+vuf5FeIpkEsxVYYmb3mdnvgcXAFjO7w8zuiDa83q1qY1jkcmjfTDBNZh49iiev/yiHj8rn24+8y+d/P591W3emOiwR6aRkEsyjwHeAF4B/AN8F/gYsCL9aZWYzzGy5mVWa2Y0trM8xswfD9fPMrDRh3U1h+3IzO7+9Ps3sbDNbaGZvm9krZjYpifeWUrGaOsYOHUB2libzjRk6gAeuPokfXjydN1du4rzbXmJOxRqdzYj0YO2WinH3+82sPzDW3Zcn27GZZQJ3AucC1cB8M5vr7ksTNrsK2Ozuk8xsFnArcLmZlQGzgOnASOA5M5sS7tNan78GZrr7MjP7MvDvwOeTjTcVqjbWM6Gob5+9JMrIMK48uZQzphZzw0OL+NbDi3jsnQ/40czDKdXnJNLjJDOL7OPA28BT4eujzWxuEn2fAFS6e8zd9wCzgZnNtplJMEMN4GHgbAtuCJkJzHb33e6+EqgM+2urTwfyw+UCgrGjtNW4z1lZ23uKXHalcYUDmX3NSdw8czpvr97Cebe/xC+ee4/dDY2pDk1EDkEy12Z+QPCHfQuAu78NTEhiv1HAmoTX1WFbi9u4ewPBeE9hG/u21efVwBNmVk0wy+3HScSYMk1FLntbDbKukpFh/M+PlPLcN07nvLLh3PbcCi64/WVeq6xJdWgikqRkEsxed9/arC0db1r4GnChu48Gfg/8vKWNzOwaM6sws4p4PHVPXqwMCz/2pirKURien8uvPnMs93/hBBrd+czv5nHdAws1pVmkB0gmwSwxs88AmWY22cx+CbyWxH5rgTEJr0fz4enN+7cxsyyCS1u1bezbYruZFQNHufu8sP1B4OSWgnL3u9293N3Li4uLk3gb0Wi6B2aiLpEl5fQpxTz9b6dx/dmTeW7ZBs762Yv89Ol/Ure7IdWhiUgrkkkwXyEYbN8NPEBwGev6JPabD0w2s/Fmlk0waN987GYucGW4fCnwvAfThuYCs8JZZuOBycCbbfS5GShImAhwLrAsiRhTpioscjm0Fxe57Gq5/TL52rlTeP4bZ3Dh4SO484UqzvyvfzBn/hoaVTxTJO0kk2A+5u7fdffjw69/By5ub6dwTOU64GmCP/Zz3H2Jmd1sZk373wMUmlkl8HXgxnDfJcAcYCnB5IJr3b2xtT7D9n8FHjGzdwjGYG5I9kNIhVgfKXIZhZGD+3P7rGN49MsnM2ZIf771yCIu+uUrPP/PDZrWLJJGrL1/kGa20N2Pba+tJyovL/eKioqUHPv4W57j9CnF/NdlR6Xk+L2Fu/PYonX87JnlvF+7g+PGDeGG86dy0oTCVIcm0muZ2QJ3L29vu1bvgzGzC4ALgVHN7tjPB3ThuxO279pLfPtuTVHuAmbGxUeN5ILDRzCnYg13/P09Zt39Bh+dXMQN50/lyNGDUx2iSJ/V1iWyD4AKYBcH7tpfQDDmcX4b+0k7DgzwawZZV+mXmcFnTxzHizecyXcunMa7a7dy8a9e5er75/PW6s2pDk+kT2r1DMbd3wHeMbMH3H0vgJkNAca4u/7FdkJVOEVZM8i6Xm6/TK45bSJXnDCWe19Zxb2vruSTd73GqZOKuO6sSZw4fqjGvUS6STKD/M+aWb6ZDQUWAr81s9sijqtXi8VV5DJqg3L7cf05k3n1xrO48YJp/HP9Nmbd/QaX/eZ1Xli+UZMBRLpBMgmmwN23AZ8C/uDuJwJnRxtW71YVV5HL7pKXk8UXT5/IK98+ix9ePJ21W3byL7+fz4V3vMLDC6pVfkYkQsn8hcsysxLg08DjEcfTJwSPSdbZS3fK7ZfJlSeX8uINZ/KTS46kcd8+vvnQO5zy4xe44+/vUVu3O9UhivQ6ySSYmwnuO6l09/lmNgF4L9qweq+mIpcTh2mAPxWyszL49PFjePrfTuMPXziB6SPz+fmzKzj5x89z4yOLWLFhe6pDFOk1kinX/xDwUMLrGHBJlEH1Zms3B0UudQaTWmbGaVOKOW1KMZUbt3PPK6v4y8JqZs9fw0cmFPLZk8ZyXtkIXcYU6YR2E4x0rarwMck6g0kfk4YN4j8/dQQ3nD+VP7+5mgfmrea6B96iKC+bT5eP4YoTxjJm6IBUhynS4yjBdLOqjWEVZZ3BpJ2hA7O59sxJfPH0ibz0Xpw/vbGa37xYxa9frOK0ycV89sSxnDVtGFmZOqsRSYYSTDeL1dQzeICKXKazzAzjzKnDOHPqMD7YspMH569h9vzVXPPHBRTlZfOJo0dxyXGjOawkv/3ORPqwdhOMmeUQjLmUJm7v7jdHF1bvVbWxjglFKnLZU4wc3J+vnTuFr5w1iReWx3l4wRruf30Vv3tlJWUl+Vxy3GhmHj2SorycVIcqknaSOYP5G0GJ/gUEJfulE2I19Zw+JXXPoZGOycrM4Nyy4ZxbNpxN9Xt47J0PeGRhNT96fCn/+cQyzphazCePGc1Z04bRPzsz1eGKpIVkEsxod58ReSR9wLawyKVqkPVsQwdmc+XJpVx5cikrNmznkYXV/PWttTy3bCMDsjM557DhXHRkCadPLSYnS8lG+q5kEsxrZnaEu78beTS9XFORS1VR7j2mDB/ETRccxrfOn8a8WC2PLVrHk4vXMfedDxiUm8V5ZSO46KgSTp1URD9NDpA+JpkEcyrweTNbSXCJzAB39yMjjawXiu0vcqkzmN4mM8M4eVIRJ08q4uaZ03m1sobHF63j6SXreWRhNYMH9OO8suGcVzaCUycXkdtPZzbS+yWTYC6IPIo+oipeFxa51D0VvVm/zAzOmDqMM6YO45ZPHs5LK2p4fNEHPPnueuZUVDMgO5PTpxRz3vThnDV1OAUD+qU6ZJFItPXAsfywyKVqZ3SRWLxeRS77mJyszP2TA/Y07OONWC3PLF3PM0s28OTi9WRlGCdOGMp5ZSM4p2w4owb3T3XIIl2m1Ucmm9nj7n5ReGnMCS6NNXF3n9AdAUapux+ZfN5tLzJ26AB+d+Xx3XZMSU/79jnvVG/hmaUbeGbJeqrC8bkpw/M4c+owTp9aTPm4ofrPiKSlTj8y2d0vCr+P70QQM4BfAJnA79z9x83W5wB/AI4DaoHL3X1VuO4m4CqgEfiquz/dVp8W3Fjyv4HLwn1+7e6Jj3pOqcZ9zqraHZwxdViqQ5E0kJFhHDN2CMeMHcK3Z0yjcmMd/1i+kReWb+TeV1fyf1+KkZeTxamTijhjajFnTB3GiILcVIctckiSupM/fJLlZGD/b7i7v9TOPpnAncC5QDUw38zmuvvShM2uAja7+yQzmwXcClxuZmXALGA6MBJ4zsymhPu01ufngTHANHffZ2Zp9Ze8qcilnmIpLZk0LI9Jw/K4+qMTqNvdwGuVNbywPM6Lyzfy1JL1ABxWks9pk4s4ZVIRx5cO1f02kvaSuZP/auB6YDTwNnAS8DpwVju7nkBQ4j8W9jMbmAkkJpiZwA/C5YeBX4VnIjOB2e6+G1hpZpVhf7TR55eAz7j7PgB339jee+tOTY9JnqAZZNKOvJwszps+gvOmj8DdWbGhjheWb+QfCWc32ZkZHDtuMKdMLOKUyUUcOapANdIk7SRzBnM9cDzwhrufaWbTgP+TxH6jgDUJr6uBE1vbxt0bzGwrUBi2v9Fs31Hhcmt9TiQ4+/kkECe4rJY2z62p0hRl6QAzY+qIQUwdMYgvnj6RHXsamL9qM69V1vBKZQ0/f24FP3t2BYNysjhxQiGnTCrklElFTCrOIyND5YgktZJJMLvcfZeZYWY57v5PM5saeWSHLocg1nIz+xRwL/DR5huZ2TXANQBjx47ttuCq4ipyKZ03IDuL06cU7y83tKl+D69X1fJqVQ2vVtbw3LINAAwZ0I/jS4dywvihnDi+kMNKBukMR7pdMgmm2swGA38FnjWzzcD7Sey3lmBMpMnosK2lbarNLAsoIBjsb2vf1tqrgb+Ey48Cv28pKHe/G7gbgllkSbyPLhGL16lEv3S5oQOz+diRJXzsyBIA1mzaweuxWuav3MSbqzbxzNIg4QzMzuS40qGcOD5IOkeOLlAZG4lcMk+0/GS4+AMze4EgCTyVRN/zgclmNp4gCcwCPtNsm7nAlQRjOpcCz7u7m9lc4AEz+znBIP9k4E2CqdKt9flX4ExgJXA6sCKJGLtNrKaeM1TkUiI2ZugAxgwdwKfLg/+Hbdi2izdXbtr/9dOnlwPBo6OPHjOY8nFDwtlsg1URWrpcmwkmnAm2xN2nAbj7i8l2HI6pXAc8TTCl+F53X2JmNwMV7j4XuAf4YziIv4kgYRBuN4dg8L4BuNbdG8OYPtRneMgfA38ys68BdcDVycYataYilxrgl+42PD+Xjx81ko8fNRKAzfV7mL8qSDbzV23i7pdiNOwLTuTHDh3AMWMHc2yYcA4ryVf9NOmUVm+03L+B2d+Ar7j76u4Jqft0142Wb6/ZwifufJW7P3cc500fEfnxRJK1a28ji9duZeHqzby1egsLV29mw7bgqRw5WRkcObogOMMZM5ijxgympCBXzzKSzt9omWAIsMTM3gTqmxrd/eJOxNen7H9Mss5gJM3k9sukvHQo5aVD97d9sGUnb63ewlurN7Nw9Wbue3UVdzfuA6AoL5vDRxVwRNPX6AJG5CvpSMuSSTD/EXkUvVysRkUupecYObg/Iwf33z9xYHdDI8vWbefd6i0sqt7Ku2u38vJ7NTSGl9aK8nI4YlQ+R4wezBGjCjhydAHD81V1QJJLMBe6+7cTG8zsViDp8Zi+rmpjPeNU5FJ6qJysTI4eM5ijxwze37ZzTyPL1m/j3eqtLKreyuK1W3lxxXuEOYfiQTkcVpLPYSWDKCvJ57CSfCYUDdRU6T4mmQRzLvDtZm0XtNAmrYjV1OkhY9Kr9M/O5NixQzh27JD9bTv2NLBs3bYw4Wxj2bpt3FtVw97GIOtkZ2UwZXgeh43ID5NPPmUl+XpcQS/WVrn+LwFfBiaY2aKEVYOAV6MOrLdo3OesqtnBmSpyKb3cgOwsjhs3lOPGHRjP2dOwj6p4HcvWbQu/tvP8Pzfy0ILq/duMLMjlsJJ8ppUMYsrwQUweNoiJwwbqPp1eoK0zmAeAJ4H/BG5MaN/u7psijaoXqd68gz2N+3QGI31SdlbG/rOVJu5OfPtuloYJpyn5/GNFfP+4ToZBaeFAJg/PC5LO8EFMGZ7HhKI8XWruQdoq178V2Apc0X3h9D6x8DkfqkEmEjAzhuXnMiw/96DHV+xuaGRlTT0rNtTx3obtrNiwnfc21PHs0g37x3YyM4zSwgEfSjrjiwaqunQaSqpcv3ScqiiLJCcnK5NpI/KZNiL/oPZdexuJxet5b2OQdFZsCC65PbVkPYm38Y0a3J8JxQOZUDSQCcV5TCzOY0LxQEbk56rwZ4oowURMRS5FOie3XyZlI/MpG9kEY95wAAATPUlEQVRy4onV1AXf43VUxet5eEE19Xsa92/Xv18m44sGBsmnOI+JxQODs57igeTl6E9glPTpRiwWr9PlMZEItJZ43J2N23dTFW9KPEESWlS9lSfeXbf/chsE9/CUFg5gbOEAxg0dSGnRAMYOHUBp4UAGD+inG0g7SQkmYlXxes6cqiKXIt3FzBien8vw/FxOnlh00LpdextZvWnH/rOd1bU7WFVbz+tVtfxl4cHF3gflZjGucADjCgcyLkw6YwsHMK5wAMMH6bJbMpRgIrR1515q6nYzcZjOYETSQW6/TKYMD6ZDN7drbyNrNu3g/TDprN60g1W1O1iyditPL16/vygoBHXaxg4Nks3oIQMYPaR/+BUsF/TX2Q8owUQq1jTAr+fAiKS93H6ZTA5npzXX0LiPD7bs4v1N9ayq3cHq2uD7mk07eCO2ibrdDQdtPygni1EJCScx+YwZMoD8/ll9IgEpwUSoaYqyZpCJ9GxZmRmMDcdqPjr54HXuztade6nevJPqzTvC703LO3gjVttuAho1uD8lg3MpKejPyMG5DBuUS2YvuASnBBOhqngdWRnGuEIVuRTprcyMwQOyGTwgqDTdXEcSUGaGMXxQDiWD+1NSkBsUIC3IpWRwf0YWBMmocGB22p8FKcFEKBavZ+zQAXpok0gflkwC2rargXVbd7Juyy4+aPZ98dqtPLN0A3sa9h20X3ZWBiUFuUECKjhwBjQinOAwvCCHooE5KZ2MoAQToaDIpS6PiUjrzIyC/v0o6N/vQzeZNnF3NtXvYd3WXXywZWfwPUxA67buZN7KTazftmt/qZ0mWRnGsEE5DC/I3Z94RoTLJ08sZFjEj1VQgomIilyKSFcxMwrzcijMy2nxLAiCvzk1dbtZv3UX67ftYsO2XQctr9iwnZffq9l/Oe4PXzhBCaanaipyqZssRaQ7ZGYcuP/nqDa2q9vdwPqtuygpiP6hcEowETlQg0xTlEUkfeTlZDGpm+7Ni3T02cxmmNlyM6s0sxtbWJ9jZg+G6+eZWWnCupvC9uVmdv4h9HmHmdVF9Z6SpSnKItLXRZZgzCwTuJPg6ZdlwBVmVtZss6uAze4+CbgNuDXctwyYBUwHZgB3mVlme32aWTkwhDRQFa9niIpcikgfFuUZzAlApbvH3H0PMBuY2WybmcD94fLDwNkWTOyeCcx2993uvhKoDPtrtc8w+fwU+FaE7ylpVXHNIBORvi3KBDMKWJPwujpsa3Ebd28geMBZYRv7ttXndcBcd1/XVlBmdo2ZVZhZRTweP6Q3dChi8XomavxFRPqwXnEHoJmNBC4Dftnetu5+t7uXu3t5cXE0VY6bilzqDEZE+rIoE8xaYEzC69FhW4vbmFkWUADUtrFva+3HAJOASjNbBQwws8queiOHSkUuRUSiTTDzgclmNt7MsgkG7ec222YucGW4fCnwvLt72D4rnGU2HpgMvNlan+7+/9x9hLuXunspsCOcOJASVeEMMpXpF5G+LLL7YNy9wcyuA54GMoF73X2Jmd0MVLj7XOAe4I/h2cYmgoRBuN0cYCnQAFzr7o0ALfUZ1XvoqFhY5HLsUBW5FJG+K9IbLd39CeCJZm3fS1jeRTB20tK+twC3JNNnC9uk9NQhFq9nbKGKXIpI36a/gBGoitcxoUiXx0Skb1OC6WINjft4v3YHE4dpgF9E+jYlmC5WvXlnUORSZzAi0scpwXSxWI2KXIqIgBJMl2sqcqky/SLS1ynBdLGqeB1DBvRjiIpcikgfpwTTxari9Tp7ERFBCabLxeJ1Gn8REUEJpktt3bGXmro9KnIpIoISTJeqCmeQ6RKZiIgSTJc68JhkXSITEVGC6UIqcikicoASTBeqitepyKWISEh/CbtQTFOURUT2U4LpIg2N+1hVW6/xFxGRkBJMF6nevJO9ja4ilyIiISWYLtJU5FJl+kVEAkowXaRqYzhFWWcwIiKAEkyXidXUMXRgtopcioiEIk0wZjbDzJabWaWZ3djC+hwzezBcP8/MShPW3RS2Lzez89vr08z+FLYvNrN7zaxflO+tuaqN9Uwo0uUxEZEmkSUYM8sE7gQuAMqAK8ysrNlmVwGb3X0ScBtwa7hvGTALmA7MAO4ys8x2+vwTMA04AugPXB3Ve2tJrEZFLkVEEkV5BnMCUOnuMXffA8wGZjbbZiZwf7j8MHC2mVnYPtvdd7v7SqAy7K/VPt39CQ8BbwKjI3xvB2kqcql7YEREDogywYwC1iS8rg7bWtzG3RuArUBhG/u222d4aexzwFOdfgdJqtr/mGQlGBGRJr1xkP8u4CV3f7mllWZ2jZlVmFlFPB7vkgMeeEyyLpGJiDSJMsGsBcYkvB4dtrW4jZllAQVAbRv7ttmnmX0fKAa+3lpQ7n63u5e7e3lxcfEhvqWWVYVFLseoyKWIyH5RJpj5wGQzG29m2QSD9nObbTMXuDJcvhR4PhxDmQvMCmeZjQcmE4yrtNqnmV0NnA9c4e77InxfHxKL1zFORS5FRA6SFVXH7t5gZtcBTwOZwL3uvsTMbgYq3H0ucA/wRzOrBDYRJAzC7eYAS4EG4Fp3bwRoqc/wkL8B3gdeD+YJ8Bd3vzmq95eoKl6v8RcRkWYiSzAQzOwCnmjW9r2E5V3AZa3sewtwSzJ9hu2RvpfWNDTu4/3aes4+bFgqDi8ikrZ0TaeT9he51BmMiMhBlGA6qSoeFrnUDDIRkYMowXRS0xRlFbkUETmYEkwnVcVV5FJEpCVKMJ0Ui6vIpYhIS5RgOqkqXqcBfhGRFijBdMLWHXuprd+jKsoiIi1QgumEpiKXOoMREfkwJZhOqNrYVEVZZzAiIs0pwXRCrKaefpkqciki0hIlmE6o2ljH2KEqciki0hL9ZeyEWI2KXIqItEYJpoOailxqgF9EpGVKMB20JixyqQF+EZGWKcF0UCyuKcoiIm1RgukgVVEWEWmbEkwHxeL1FA7MZvAAFbkUEWmJEkwHVcXrNP4iItIGJZgOCqooa/xFRKQ1kSYYM5thZsvNrNLMbmxhfY6ZPRiun2dmpQnrbgrbl5vZ+e31aWbjwz4qwz4ju3a1Zcceauv3MHGYzmBERFoTWYIxs0zgTuACoAy4wszKmm12FbDZ3ScBtwG3hvuWAbOA6cAM4C4zy2ynz1uB28K+Nod9R6JKT7EUEWlXlGcwJwCV7h5z9z3AbGBms21mAveHyw8DZ5uZhe2z3X23u68EKsP+Wuwz3OessA/CPj8R1RvbP0V5mBKMiEhrokwwo4A1Ca+rw7YWt3H3BmArUNjGvq21FwJbwj5aO1aXqYqHRS6H9I/qECIiPV6fG+Q3s2vMrMLMKuLxeIf6KC0cwCePGUWWilyKiLQqyr+Qa4ExCa9Hh20tbmNmWUABUNvGvq211wKDwz5aOxYA7n63u5e7e3lxcXEH3hbMOmEsP7n0qA7tKyLSV0SZYOYDk8PZXdkEg/Zzm20zF7gyXL4UeN7dPWyfFc4yGw9MBt5src9wnxfCPgj7/FuE701ERNqR1f4mHePuDWZ2HfA0kAnc6+5LzOxmoMLd5wL3AH80s0pgE0HCINxuDrAUaACudfdGgJb6DA/5bWC2mf1v4K2wbxERSREL/vPfN5WXl3tFRUWqwxAR6VHMbIG7l7e3nUapRUQkEkowIiISCSUYERGJhBKMiIhEQglGREQi0adnkZlZHHi/g7sXATVdGE5XUVyHRnEdGsV1aNI1LuhcbOPcvd071ft0gukMM6tIZpped1Nch0ZxHRrFdWjSNS7onth0iUxERCKhBCMiIpFQgum4u1MdQCsU16FRXIdGcR2adI0LuiE2jcGIiEgkdAYjIiKRUILpADObYWbLzazSzG7shuOtMrN3zextM6sI24aa2bNm9l74fUjYbmZ2RxjbIjM7NqGfK8Pt3zOzK1s7Xjux3GtmG81scUJbl8ViZseF77Uy3Nc6EdcPzGxt+Lm9bWYXJqy7KTzGcjM7P6G9xZ9t+IiIeWH7g+HjItqLaYyZvWBmS81siZldnw6fVxtxpfTzCvfLNbM3zeydMLYfttWfBY/0eDBsn2dmpR2NuYNx3WdmKxM+s6PD9u783c80s7fM7PF0+KwO4u76OoQvgscEVAETgGzgHaAs4mOuAoqatf0EuDFcvhG4NVy+EHgSMOAkYF7YPhSIhd+HhMtDOhDLacCxwOIoYiF47s9J4T5PAhd0Iq4fAN9sYduy8OeWA4wPf56Zbf1sgTnArHD5N8CXkoipBDg2XB4ErAiPndLPq424Uvp5hdsakBcu9wPmhe+vxf6ALwO/CZdnAQ92NOYOxnUfcGkL23fn7/7XgQeAx9v67Lvrs0r80hnMoTsBqHT3mLvvAWYDM1MQx0zg/nD5fuATCe1/8MAbBE/6LAHOB551903uvhl4FphxqAd195cInt3T5bGE6/Ld/Q0PfvP/kNBXR+JqzUxgtrvvdveVQCXBz7XFn234P8mzgIdbeI9txbTO3ReGy9uBZcAoUvx5tRFXa7rl8wrjcXevC1/2C7+8jf4SP8uHgbPD4x9SzJ2IqzXd8rM0s9HAx4Dfha/b+uy75bNKpARz6EYBaxJeV9P2P86u4MAzZrbAzK4J24a7+7pweT0wvJ34ooy7q2IZFS53ZYzXhZco7rXwUlQH4ioEtrh7Q0fjCi9HHEPwP9+0+byaxQVp8HmFl3zeBjYS/AGuaqO//TGE67eGx+/yfwfN43L3ps/slvAzu83McprHleTxO/qzvB34FrAvfN3WZ99tn1UTJZie4VR3Pxa4ALjWzE5LXBn+jyctpgOmUyzAr4GJwNHAOuBnqQjCzPKAR4B/c/dtietS+Xm1EFdafF7u3ujuRwOjCf4XPS0VcTTXPC4zOxy4iSC+4wkue327u+Ixs4uAje6+oLuOeaiUYA7dWmBMwuvRYVtk3H1t+H0j8CjBP7oN4Wk14feN7cQXZdxdFcvacLlLYnT3DeEfhX3Abwk+t47EVUtwiSOrWXu7zKwfwR/xP7n7X8LmlH9eLcWVDp9XInffArwAfKSN/vbHEK4vCI8f2b+DhLhmhJcb3d13A7+n459ZR36WpwAXm9kqgstXZwG/II0+q8gGpnvrF5BFMDA3ngMDX9MjPN5AYFDC8msEYyc/5eCB4p+Eyx/j4MHFN8P2ocBKgoHFIeHy0A7GVMrBg+ldFgsfHui8sBNxlSQsf43gOjPAdA4e1IwRDGi2+rMFHuLggdMvJxGPEVxLv71Ze0o/rzbiSunnFW5bDAwOl/sDLwMXtdYfcC0HD1zP6WjMHYyrJOEzvR34cYp+98/gwCB/Sj+rg+LqyB+Yvv5FMENkBcG14e9GfKwJ4Q/2HWBJ0/EIrp3+HXgPeC7hl9SAO8PY3gXKE/r6AsEAXiXwLx2M588El0/2ElyTvaorYwHKgcXhPr8ivBm4g3H9MTzuImAuB/8B/W54jOUkzNZp7Wcb/hzeDON9CMhJIqZTCS5/LQLeDr8uTPXn1UZcKf28wv2OBN4KY1gMfK+t/oDc8HVluH5CR2PuYFzPh5/ZYuC/OTDTrNt+98N9z+BAgknpZ5X4pTv5RUQkEhqDERGRSCjBiIhIJJRgREQkEkowIiISCSUYERGJhBKMSCvMrK79rTp9jIs7VKW2c8c8w8xO7s5jSt+U1f4mItIZZpbp7o0trXP3uQT3nHT1MbP8QD2q5s4A6ghu2hWJjM5gRJJgZjeY2fywqOEPE9r/GhYhXZJQiBQzqzOzn5nZO8BHLHimzw/NbGH4zI9p4XafN7Nfhcv3hc8Bec3MYmZ2adieYWZ3mdk/LXh+zBNN65rF+A8zu92CZwZdb2YfD5/78ZaZPWdmw8Pill8EvmbB80s+ambFZvZI+P7mm9kpUX6W0nfoDEakHWZ2HjCZoM6UAXPN7DQPHhHwBXffZGb9gflm9oi71xKU9Znn7t8I+wCocfdjzezLwDeBq1s4XAnBnfbTCM5sHgY+RVAGpwwYRlBe/95Wws129/LwmEOAk9zdzexq4Fvu/g0z+w1Q5+7/FW73AHCbu79iZmOBp4HDOvyBiYSUYETad1749Vb4Oo8g4bwEfNXMPhm2jwnba4FGgmKSiZqKXS4gSBot+asHxSaXmllTGf9TgYfC9vVm9kIbsT6YsDwaeDAsqJlNUPeqJecAZXbgAYr5ZpbnB55/ItIhSjAi7TPgP939/x7UaHYGwR/nj7j7DjP7B0G9J4BdLYy77A6/N9L6v73dCctJPTK3mfqE5V8CP3f3uWGsP2hlnwyCM51dHTieSKs0BiPSvqeBL4TPT8HMRpnZMIJy55vD5DKNoBJuFF4FLgnHYoYTDNIno4AD5dWvTGjfTvCo5CbPAF9pemHhc+VFOksJRqQd7v4MwTPPXzezdwnGRQYBTwFZZrYM+DHwRkQhPEJQIXopQcXehQRPI2zPD4CHzGwBUJPQ/hjwyaZBfuCrQHk4gWEpwSQAkU5TNWWRHqBpTMTMCglKrZ/i7utTHZdIWzQGI9IzPG5mgwkG63+k5CI9gc5gREQkEhqDERGRSCjBiIhIJJRgREQkEkowIiISCSUYERGJhBKMiIhE4v8DbrKdCVzqSvIAAAAASUVORK5CYII=%0A" alt="img"></p>
<h3 id="损失和指标">损失和指标</h3>
<p>由于目标序列是填充的，因此在计算损耗时应用填充掩码很重要。 padding的掩码为0，没padding的掩码为1</p>
<p>In [42]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,</span><br><span class="line">                                                           reduction='none')</span><br><span class="line"></span><br><span class="line">def loss_fun(y_ture, y_pred):</span><br><span class="line">    mask = tf.math.logical_not(tf.math.equal(y_ture, 0))  # 为0掩码标1</span><br><span class="line">    loss_ = loss_object(y_ture, y_pred)</span><br><span class="line">    </span><br><span class="line">    mask = tf.cast(mask, dtype=loss_.dtype)</span><br><span class="line">    loss_ *= mask</span><br><span class="line">    return tf.reduce_mean(loss_)</span><br></pre></td></tr></tbody></table></figure>
<p>In [43]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">train_loss = tf.keras.metrics.Mean(name='train_loss')</span><br><span class="line">train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')</span><br></pre></td></tr></tbody></table></figure>
<h2 id="训练和保持模型">8、训练和保持模型</h2>
<p>In [44]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">transformer = Transformer(num_layers, d_model, num_heads, dff,</span><br><span class="line">                          input_vocab_size, target_vocab_size,</span><br><span class="line">                          max_seq_len, dropout_rate)</span><br></pre></td></tr></tbody></table></figure>
<p>In [45]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line"># 构建掩码</span><br><span class="line">def create_mask(inputs,targets):</span><br><span class="line">    encode_padding_mask = create_padding_mark(inputs)</span><br><span class="line">    # 这个掩码用于掩输入解码层第二层的编码层输出</span><br><span class="line">    decode_padding_mask = create_padding_mark(inputs)</span><br><span class="line">    </span><br><span class="line">    # look_ahead 掩码， 掩掉未预测的词</span><br><span class="line">    look_ahead_mask = create_look_ahead_mark(tf.shape(targets)[1])</span><br><span class="line">    # 解码层第一层得到padding掩码</span><br><span class="line">    decode_targets_padding_mask = create_padding_mark(targets)</span><br><span class="line">    </span><br><span class="line">    # 合并解码层第一层掩码</span><br><span class="line">    combine_mask = tf.maximum(decode_targets_padding_mask, look_ahead_mask)</span><br><span class="line">    </span><br><span class="line">    return encode_padding_mask, combine_mask, decode_padding_mask</span><br></pre></td></tr></tbody></table></figure>
<p>创建checkpoint管理器</p>
<p>In [46]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">checkpoint_path = './checkpoint/train'</span><br><span class="line">ckpt = tf.train.Checkpoint(transformer=transformer,</span><br><span class="line">                          optimizer=optimizer)</span><br><span class="line"># ckpt管理器</span><br><span class="line">ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)</span><br><span class="line"></span><br><span class="line">if ckpt_manager.latest_checkpoint:</span><br><span class="line">    ckpt.restore(ckpt_manager.latest_checkpoint)</span><br><span class="line">    print('last checkpoit restore')</span><br></pre></td></tr></tbody></table></figure>
<p>target分为target_input和target real. target_input是传给解码器的输入，target_real是其左移一个位置的结果，每个target_input位置对应下一个预测的标签</p>
<p>如句子=“SOS A丛林中的狮子正在睡觉EOS”</p>
<p>target_input =“SOS丛林中的狮子正在睡觉”</p>
<p>target_real =“丛林中的狮子正在睡觉EOS”</p>
<p>transformer是个自动回归模型：它一次预测一个部分，并使用其到目前为止的输出，决定下一步做什么。</p>
<p>在训练期间使用teacher-forcing，即无论模型当前输出什么都强制将正确输出传给下一步。</p>
<p>而预测时则根据前一个的输出预测下一个词</p>
<p>为防止模型在预期输出处达到峰值，模型使用look-ahead mask</p>
<p>In [47]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">@tf.function</span><br><span class="line">def train_step(inputs, targets):</span><br><span class="line">    tar_inp = targets[:,:-1]</span><br><span class="line">    tar_real = targets[:,1:]</span><br><span class="line">    # 构造掩码</span><br><span class="line">    encode_padding_mask, combined_mask, decode_padding_mask = create_mask(inputs, tar_inp)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    with tf.GradientTape() as tape:</span><br><span class="line">        predictions, _ = transformer(inputs, tar_inp,</span><br><span class="line">                                    True,</span><br><span class="line">                                    encode_padding_mask,</span><br><span class="line">                                    combined_mask,</span><br><span class="line">                                    decode_padding_mask)</span><br><span class="line">        loss = loss_fun(tar_real, predictions)</span><br><span class="line">    # 求梯度</span><br><span class="line">    gradients = tape.gradient(loss, transformer.trainable_variables)</span><br><span class="line">    # 反向传播</span><br><span class="line">    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))</span><br><span class="line">    </span><br><span class="line">    # 记录loss和准确率</span><br><span class="line">    train_loss(loss)</span><br><span class="line">    train_accuracy(tar_real, predictions)</span><br></pre></td></tr></tbody></table></figure>
<p>葡萄牙语用作输入语言，英语是目标语言。</p>
<p>In [48]:</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">EPOCHS = 20</span><br><span class="line">for epoch in range(EPOCHS):</span><br><span class="line">    start = time.time()</span><br><span class="line">    </span><br><span class="line">    # 重置记录项</span><br><span class="line">    train_loss.reset_states()</span><br><span class="line">    train_accuracy.reset_states()</span><br><span class="line">    </span><br><span class="line">    # inputs 葡萄牙语， targets英语</span><br><span class="line">    </span><br><span class="line">    for batch, (inputs, targets) in enumerate(train_dataset):</span><br><span class="line">        # 训练</span><br><span class="line">        train_step(inputs, targets)</span><br><span class="line">        </span><br><span class="line">        if batch % 500 == 0:</span><br><span class="line">            print('epoch {}, batch {}, loss:{:.4f}, acc:{:.4f}'.format(</span><br><span class="line">            epoch+1, batch, train_loss.result(), train_accuracy.result()</span><br><span class="line">            ))</span><br><span class="line">            </span><br><span class="line">    if (epoch + 1) % 2 == 0:</span><br><span class="line">        ckpt_save_path = ckpt_manager.save()</span><br><span class="line">        print('epoch {}, save model at {}'.format(</span><br><span class="line">        epoch+1, ckpt_save_path</span><br><span class="line">        ))</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    print('epoch {}, loss:{:.4f}, acc:{:.4f}'.format(</span><br><span class="line">    epoch+1, train_loss.result(), train_accuracy.result()</span><br><span class="line">    ))</span><br><span class="line">    </span><br><span class="line">    print('time in 1 epoch:{} secs\n'.format(time.time()-start))</span><br><span class="line">(64, 40, 128)</span><br><span class="line">(64, 39, 128)</span><br><span class="line">(64, 40, 128)</span><br><span class="line">(64, 39, 128)</span><br><span class="line">epoch 1, batch 0, loss:4.0259, acc:0.0000</span><br><span class="line">epoch 1, batch 500, loss:3.4436, acc:0.0340</span><br><span class="line">(31, 40, 128)</span><br><span class="line">(31, 39, 128)</span><br><span class="line">epoch 1, loss:3.2112, acc:0.0481</span><br><span class="line">time in 1 epoch:467.3876633644104 secs</span><br><span class="line"></span><br><span class="line">epoch 2, batch 0, loss:2.4443, acc:0.0982</span><br><span class="line">epoch 2, batch 500, loss:2.3006, acc:0.1139</span><br><span class="line">epoch 2, save model at ./checkpoint/train/ckpt-1</span><br><span class="line">epoch 2, loss:2.2473, acc:0.1184</span><br><span class="line">time in 1 epoch:429.6356120109558 secs</span><br><span class="line"></span><br><span class="line">epoch 3, batch 0, loss:2.0709, acc:0.1306</span><br><span class="line">epoch 3, batch 500, loss:2.0279, acc:0.1412</span><br><span class="line">epoch 3, loss:1.9927, acc:0.1443</span><br><span class="line">time in 1 epoch:426.3838963508606 secs</span><br><span class="line"></span><br><span class="line">epoch 4, batch 0, loss:1.8720, acc:0.1571</span><br><span class="line">epoch 4, batch 500, loss:1.8020, acc:0.1678</span><br><span class="line">epoch 4, save model at ./checkpoint/train/ckpt-2</span><br><span class="line">epoch 4, loss:1.7664, acc:0.1714</span><br><span class="line">time in 1 epoch:387.37333059310913 secs</span><br><span class="line"></span><br><span class="line">epoch 5, batch 0, loss:1.6616, acc:0.1807</span><br><span class="line">epoch 5, batch 500, loss:1.5908, acc:0.1936</span><br><span class="line">epoch 5, loss:1.5610, acc:0.1961</span><br><span class="line">time in 1 epoch:389.60524225234985 secs</span><br><span class="line"></span><br><span class="line">epoch 6, batch 0, loss:1.4435, acc:0.2087</span><br><span class="line">epoch 6, batch 500, loss:1.4117, acc:0.2127</span><br><span class="line">epoch 6, save model at ./checkpoint/train/ckpt-3</span><br><span class="line">epoch 6, loss:1.3852, acc:0.2147</span><br><span class="line">time in 1 epoch:438.03212571144104 secs</span><br><span class="line"></span><br><span class="line">epoch 7, batch 0, loss:1.3070, acc:0.2183</span><br><span class="line">epoch 7, batch 500, loss:1.2383, acc:0.2320</span><br><span class="line">epoch 7, loss:1.2111, acc:0.2346</span><br><span class="line">time in 1 epoch:378.90994358062744 secs</span><br><span class="line"></span><br><span class="line">epoch 8, batch 0, loss:1.1545, acc:0.2332</span><br><span class="line">epoch 8, batch 500, loss:1.0854, acc:0.2508</span><br><span class="line">epoch 8, save model at ./checkpoint/train/ckpt-4</span><br><span class="line">epoch 8, loss:1.0658, acc:0.2525</span><br><span class="line">time in 1 epoch:377.7305886745453 secs</span><br><span class="line"></span><br><span class="line">epoch 9, batch 0, loss:1.0109, acc:0.2532</span><br><span class="line">epoch 9, batch 500, loss:0.9780, acc:0.2645</span><br><span class="line">epoch 9, loss:0.9624, acc:0.2656</span><br><span class="line">time in 1 epoch:378.3708670139313 secs</span><br><span class="line"></span><br><span class="line">epoch 10, batch 0, loss:0.9245, acc:0.2576</span><br><span class="line">epoch 10, batch 500, loss:0.8940, acc:0.2749</span><br><span class="line">epoch 10, save model at ./checkpoint/train/ckpt-5</span><br><span class="line">epoch 10, loss:0.8820, acc:0.2757</span><br><span class="line">time in 1 epoch:378.5437033176422 secs</span><br><span class="line"></span><br><span class="line">epoch 11, batch 0, loss:0.8609, acc:0.2728</span><br><span class="line">epoch 11, batch 500, loss:0.8305, acc:0.2833</span><br><span class="line">epoch 11, loss:0.8222, acc:0.2835</span><br><span class="line">time in 1 epoch:378.56798672676086 secs</span><br><span class="line"></span><br><span class="line">epoch 12, batch 0, loss:0.8031, acc:0.2821</span><br><span class="line">epoch 12, batch 500, loss:0.7770, acc:0.2905</span><br><span class="line">epoch 12, save model at ./checkpoint/train/ckpt-6</span><br><span class="line">epoch 12, loss:0.7700, acc:0.2906</span><br><span class="line">time in 1 epoch:378.8077425956726 secs</span><br><span class="line"></span><br><span class="line">epoch 13, batch 0, loss:0.7457, acc:0.2857</span><br><span class="line">epoch 13, batch 500, loss:0.7311, acc:0.2971</span><br><span class="line">epoch 13, loss:0.7257, acc:0.2969</span><br><span class="line">time in 1 epoch:378.34697437286377 secs</span><br><span class="line"></span><br><span class="line">epoch 14, batch 0, loss:0.7159, acc:0.2925</span><br><span class="line">epoch 14, batch 500, loss:0.6931, acc:0.3026</span><br><span class="line">epoch 14, save model at ./checkpoint/train/ckpt-7</span><br><span class="line">epoch 14, loss:0.6874, acc:0.3025</span><br><span class="line">time in 1 epoch:379.3904767036438 secs</span><br><span class="line"></span><br><span class="line">epoch 15, batch 0, loss:0.6885, acc:0.2905</span><br><span class="line">epoch 15, batch 500, loss:0.6594, acc:0.3072</span><br><span class="line">epoch 15, loss:0.6546, acc:0.3070</span><br><span class="line">time in 1 epoch:377.10075068473816 secs</span><br><span class="line"></span><br><span class="line">epoch 16, batch 0, loss:0.6465, acc:0.2961</span><br><span class="line">epoch 16, batch 500, loss:0.6306, acc:0.3117</span><br><span class="line">epoch 16, save model at ./checkpoint/train/ckpt-8</span><br><span class="line">epoch 16, loss:0.6257, acc:0.3115</span><br><span class="line">time in 1 epoch:379.0886535644531 secs</span><br><span class="line"></span><br><span class="line">epoch 17, batch 0, loss:0.6033, acc:0.3021</span><br><span class="line">epoch 17, batch 500, loss:0.6023, acc:0.3162</span><br><span class="line">epoch 17, loss:0.5984, acc:0.3159</span><br><span class="line">time in 1 epoch:377.6911520957947 secs</span><br><span class="line"></span><br><span class="line">epoch 18, batch 0, loss:0.5469, acc:0.3225</span><br><span class="line">epoch 18, batch 500, loss:0.5791, acc:0.3195</span><br><span class="line">epoch 18, save model at ./checkpoint/train/ckpt-9</span><br><span class="line">epoch 18, loss:0.5755, acc:0.3191</span><br><span class="line">time in 1 epoch:378.4746241569519 secs</span><br><span class="line"></span><br><span class="line">epoch 19, batch 0, loss:0.5287, acc:0.3209</span><br><span class="line">epoch 19, batch 500, loss:0.5575, acc:0.3229</span><br><span class="line">epoch 19, loss:0.5546, acc:0.3224</span><br><span class="line">time in 1 epoch:378.284138917923 secs</span><br><span class="line"></span><br><span class="line">epoch 20, batch 0, loss:0.5182, acc:0.3193</span><br><span class="line">epoch 20, batch 500, loss:0.5374, acc:0.3263</span><br><span class="line">epoch 20, save model at ./checkpoint/train/ckpt-10</span><br><span class="line">epoch 20, loss:0.5344, acc:0.3257</span><br><span class="line">time in 1 epoch:377.9467544555664 secs</span><br></pre></td></tr></tbody></table></figure>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>transformer</category>
      </categories>
      <tags>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-07-23-深度学习杂记</title>
    <url>/2020/07/23/2020-07-23-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h3 id="logits">logits</h3>
<p>在tensorflow代码中，经常会出现logits，logits表示的含义就是在模型的最后一层输出后，进入到Softmax函数之前得到的n维向量。是feature的抽象。</p>
<p>logits是未归一化的概率， 一般也就是 softmax层的输入。所以logits和lables的shape一样</p>
<p>而softmax是在一个n分类问题中，输入一个n维的logits向量，输出一个n维概率向量，其物理意义是logits代表的物体属于各类的概率。是对logits进行归一化。</p>
<p><img src="https://i.loli.net/2020/08/09/W6yEXJorYvaK4pf.png" alt="image-20200723160820328" style="zoom:50%;"></p>
<p>输入softmax的Logits中最大的一维会成为输出中同样最大的一维。例如：</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="number">4</span>分类问题的</span><br><span class="line">Logits = [<span class="number">1</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">0.2</span>]</span><br><span class="line">输入softmax后</span><br><span class="line">得到的 one_hot_pred = [<span class="number">0.017</span> <span class="number">0.958</span> <span class="number">0.017</span> <span class="number">0.008</span>]</span><br></pre></td></tr></tbody></table></figure>
<h3 id="beam-search">beam search</h3>
<p>在sequence2sequence模型中，beam search的方法只用在测试的情况，因为在训练过程中，每一个decoder的输出是有正确答案的，也就不需要beam search去加大输出的准确率。</p>
<p><strong>我们需要翻译中文“我是中国人”---&gt;英文“I am Chinese”</strong></p>
<p>假设我们的词表大小只有三个单词就是I am Chinese。那么如果我们的beam size为2的话，我们现在来解释,</p>
<p>如下图所示，我们在decoder的过程中，有了beam search方法后，在第一次的输出，我们选取概率最大的"I"和"am"两个单词，而不是只挑选一个概率最大的单词。</p>
<p><img src="https://i.loli.net/2020/07/24/32grlE4uLGpQPCq.png"></p>
<p>然后接下来我们要做的就是，把“I”单词作为下一个decoder的输入算一遍得到y2的输出概率分布，把“am”单词作为下一个decoder的输入算一遍也得到y2的输出概率分布。</p>
<p>比如将“I”单词作为下一个decoder的输入算一遍得到y2的输出概率分布如下：</p>
<p><img src="https://i.loli.net/2020/07/24/s6OErw5yT41uLPa.png" alt="image-20200724095714528"></p>
<p>比如将“am”单词作为下一个decoder的输入算一遍得到y2的输出概率分布如下：</p>
<p><img src="https://i.loli.net/2020/07/24/Ng1ZyrxehmpUIoC.png" alt="image-20200724095747262"></p>
<p>那么此时我们由于我们的beam size为2，也就是我们只能保留概率最大的两个序列，此时我们可以计算所有的序列概率：</p>
<p>“I I” = 0.4<em>0.3 "I am" = 0.4</em>0.6 "I sChinese" = 0.4*0.1</p>
<p>"am I" = 0.5<em>0.3 "am am" = 0.5</em>0.3 "am Chinese" = 0.5*0.4</p>
<p>我们很容易得出俩个最大概率的序列为 “I am”和“am Chinese”，然后后面会不断重复这个过程，直到遇到结束符为止。</p>
<p><strong>最终输出2个得分最高的序列。</strong></p>
<p><strong>这就是seq2seq中的beam search算法过程</strong></p>
<h3 id="tpu--tensorflow">TPU -tensorflow</h3>
<p>在神经网络学习过程中，需要进行矩阵运算，包括大量的加法和乘法，所以关键点是我们该如何快速执行大型矩阵运算，同时还需要更小的能耗。</p>
<h4 id="与cpu和gpu的对比">与CPU和GPU的对比</h4>
<p>CPU：CPU 非常灵活，硬件无法一直了解下一个计算是什么，直到它读取了软件的下一个指令。</p>
<p>​ 缺点:每一个 CPU 的算术逻辑单元（ALU，控制乘法器和加法器的组件）都只能一个接一个地执行它们，每一次都需要访问内存，限制了总体吞吐量，并需要大量的能耗。</p>
<p>GPU：在单个处理器中使用成千上万个 ALU。现代 GPU 通常在单个处理器中拥有 2500-5000 个 ALU，意味着你可以同时执行数千次乘法和加法运算。在<code>并行化</code>的应用中很好，比如神经网络的矩阵乘法。</p>
<p>​ 缺点：因为 GPU 在其 ALU 上执行更多的并行计算，它也会成比例地耗费更多的能量来访问内存，同时也因为复杂的线路而增加 GPU 的物理空间占用。</p>
<h4 id="tpu的工作特点">TPU的工作特点</h4>
<p>TPU 不能运行文本处理软件、控制火箭引擎或执行银行业务，但它们可以为神经网络处理大量的乘法和加法运算，同时 TPU 的速度非常快、能耗非常小且物理空间占用也更小。常用于<code>加速神经网络</code></p>
<p>TPU 可以在神经网络运算上达到高计算吞吐量，同时能耗和物理空间都很小。</p>
<h4 id="参考">参考</h4>
<blockquote>
<p>TPU 加速深度学习 https://www.ednchina.com/news/201809041331.html</p>
<p>PPT 解释了 TPU 的特性与定义 tpudemo.com</p>
</blockquote>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-07-22-如何有效读论文-思维导图</title>
    <url>/2020/07/22/2020-07-22-%E5%A6%82%E4%BD%95%E6%9C%89%E6%95%88%E8%AF%BB%E8%AE%BA%E6%96%87-%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/</url>
    <content><![CDATA[<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-07-22-每周论文分享</title>
    <url>/2020/07/22/2020-07-22-%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/</url>
    <content><![CDATA[<p><strong>对神经网络的不确定度估计</strong>涉及较多概率论的知识，而且从理论到应用的转化也涉及到使用近似量估计的问题，因此初次接触这部分知识该我带来了不小的挑战。经过几天的探究，还是走了不少弯路，虽说很多细节的理论推理还没有深究，但摸清了借助贝叶斯神经网络估计不确定度的原理和过程。你会发现，在原有神经网络上增加不确定度估计功能，<strong>从结构上的变化看似非常简单（只是损失函数，dropout层，输出等已有部分的修改），但背后有很严密的数理逻辑驱动着。</strong></p>
<h2 id="原理简述">原理简述</h2>
<p>不确定度虽分为两类，一类是模型不确定性，另一类是数据不确定性，两种不确定性所在的对象不同。<strong>利用模型预测结果的分布特点（注意是分布），可以成为测量不确定度的一种手段。</strong></p>
<p>模型预测由模型生成，在给定训练数据情况下，模型自身有后验分布（因此用不确定度衡量）。为了得到模型预测的分布特点，由贝叶斯定理，需要边缘化（marginalizing，旨在消除条件分布中某个变量的影响）模型的后验分布。</p>
<p>从理想层面，边缘化就是以积分形式穷尽所有模型的分布最后得到模型预测的分布，但现实层面由于深度网络的复杂性，有<strong>两方面不现实 - 模型表示的抽象性 &amp; 积分操作</strong>，为了落地，在应用时，理想的“积分操作”由离散的采样操作代替（因为我们最终不需要预测分布的完整描述，只需方差即可，而基于dropout的采样方式被证明可以求出方差）。</p>
<p>理想的模型分布是无法满足采样需求的，因此需引入近似模型分布的可采样的分布，新引入的分布<strong>由诸多参数决定着</strong>，要想近似原模型分布必须要进行参数调整，一种方法是最小化近似分布和原分布的KL散度指标，而这恰好是一个带有明确目标函数的优化任务。至此，<strong>对预测分布求解</strong>实现了从理论的边缘化操作到实际的优化操作（可通过反向传播）+采样的转换。</p>
<h2 id="不确定性估计">不确定性估计</h2>
<h3 id="不确定性分类">不确定性分类</h3>
<p>在贝叶斯模型中，有两类主要的不确定性：模型不确定性和数据不确定性。</p>
<ol type="1">
<li><p>模型不确定性</p>
<p>（又称认知不确定性，epistemic uncertainty）：</p>
<ul>
<li>主要代表模型参数的不确定性，<strong>这种不确定常常来自于我们对收集的用于训练数据的无知（Ignorance）</strong>，例如当数据集中缺乏某类数据时，模型中对应处理这种场景的参数的不确定性就变大了，结果就是，如果测试时给一个这类的数据，模型表现可能很差。</li>
<li>模型不确定性在现有诸多的深度神经网络中都没有被考虑，因为推理预测的后验分布过于困难，<strong>变分推理（Variational Inference）</strong>是一种流行的方法，其目的在于使用已有的数据样本，驱动简化版的分布去拟合真实的后验分布，而这个拟合指标通过变换<strong>某些无法求出的分布</strong>，从而变得可以计算。Gal等人发表的论文显示，在神经网络上的带dropout训练过程可被理解为以Bernoulli为假设分布的变分分布拟合过程。（当然，若要达到拟合效果，损失函数等结构都要调整，这篇文章也正是基于此。）</li>
<li>模型不确定性<strong>可以</strong>被消除：通过增大数据集。</li>
</ul></li>
<li><p>数据不确定性</p>
<p>（又称偶然不确定性，aleatoric uncertainty）：</p>
<ul>
<li>数据不确定性主要是<strong>观测噪音</strong>，如传感器噪音或者动作噪音。数据不确定相较模型不确定性在神经网络运用更多，通过分析输出的分布，可以评估该类不确定性。例如之前提到的Social LSTM模型，输出是二维位置高斯分布的五个参数(μ1,μ2,σ1,σ2,ρ)(μ1,μ2,σ1,σ2,ρ)，通过预测这五个参数就反映了数据不确定性。</li>
<li>数据不确定性<strong>不可以</strong>被消除。</li>
</ul></li>
<li><p>文章的一篇重要引文用了”formalize“来表示对于这两类不确定性的定义：模型不确定制定在<strong>参数的分布上</strong>，通过先验分布预设模型，在给予一些训练数据后观察这个分布的变化；数据不确定性制定在<strong>输出的分布上</strong>，通过分析不同输入对应输出的方差。根据笔者来看，文章最终在估计这两类不确定性时，只有数据不确定性按定义来的，模型不确定性的估计文章通过Gal. 等人的结论成功转移到了估计输出分布上。</p></li>
</ol>
<p>这里模型不确定性的重要性在此就不赘述了.</p>
<ul>
<li>其实,笔者之前就有一个疑惑:为什么在神经网络中模型不确定度不能按照传统模型那样去计算熵? 文献指出:主流的Deep Learning都采用最大似然估计或最大后验来训练,因此产生的往往是一个point estimation而不是uncertainty value. 具体来说, 直观来说Softmax层之后的概率向量可以用来解释模型的置信度. 但是实际上模型依然会对具有很大Softmax输出的预测表明较大的不确定性.</li>
<li>大部分不确定性估计算法都是基于Bayesian Neural Networks (可以理解为概率性的神经网络, 认为其参数服从一定的先验分布), 给定输入时就可以产生具有一定分布性质的输出用来计算模型不确定度. 但是计算非常复杂,只是理论上的保证.</li>
</ul>
<p>transformer</p>
<h3 id="regularization"><strong>3.4 Regularization</strong></h3>
<p>在训练过程中，使用了两种正则化手段：</p>
<p>第一种是 <strong>「Residual Dropout」</strong>。在每一层进行残差连接和归一化之前，先执行 dropout [6]。此外，编码器与解码器中嵌入编码与位置编码之和也应用了 dropout。对于基础模型，原文使用 <img src="https://www.zhihu.com/equation?tex=P_%7Bdrop%7D+%3D+0.1" alt="[公式]">.</p>
<p>第二种是 <strong>「Label Smoothing」</strong>。在训练过程中，使用了标签平滑策略 [7]，参数设置 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon_%7Bls%7D+%3D+0.1" alt="[公式]">。这种策略会增加模型的不确定性，影响困惑度（perplexity），但会提升准确率与 BLEU 得分。</p>
<p>在模型的不确定性程度较低时人工会介入对话，这一特性使得系统会在出现差错之前咨询人工的建议，所以会极大程度地降低给出不合理回复带来的风险。</p>
<p>不确定性估计模块还能让系统以更少的数据量达到更好的性能。</p>
<h2 id="论文-4a-general-framework-for-uncertainty-estimation-in-deep-learning"><strong>论文 4：A General Framework for Uncertainty Estimation in Deep Learning</strong></h2>
<ul>
<li>作者：Antonio Loquercio、Mattia Segu、Davide Scaramuzza</li>
<li>论文地址：https://arxiv.org/pdf/1907.06890v3.pdf</li>
</ul>
<p><strong>摘要：</strong>神经网络的预测通常是不可靠的，特别是当输入的样本不在训练集的分布中，或者因为噪声而损坏的情况下。深度学习算法应当具有自动预测这种失败的能力，然而现有的不确定性预测方法需要对网络和优化流程进行调整，尤其忽略了数据中先验知识的重要性。这些方法倾向于过度简化假设，从而低估了不确定性。为了解决这些问题，研究者提出了一种新的不确定性估计框架。基于贝叶斯信念网络和蒙特卡洛采样，研究者的框架不仅能够完善模型对不同来源的不确定性预测，还可以和之前的感知噪声等数据信息相结合。研究者从理论上说明这一模型相比现有模型可以更好地捕捉不确定性。相比之前的方法，在计算机视觉和控制任务上，研究者的方法最多可以超出 23% 的表现。</p>
<p><img src="https://bbs.cvmart.net/uploads/images/201910/21/11/ns0sx4ghnM.png?imageView2/2/w/1240/h/0" alt="file"> <em>▲图 1：模型的架构。给定变量 x 作为输入，以及噪声 v^(0)，和训练好的神经网络。研究者的方法需要计算输出的置信度。</em></p>
<p><strong>推荐：</strong>对于神经网络预测结果的不确定性研究是近来关注的一个热点。本文提出了一种新颖的方法，推荐读者参考。</p>
<p>神经网络是非线性的 。所以要变为线性，再使用卡尔曼更新</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>论文</category>
      </categories>
      <tags>
        <tag>论文</tag>
      </tags>
  </entry>
  <entry>
    <title>linux &amp; vim 常用操作-初级</title>
    <url>/2020/07/22/2020-07-22-%20linux&amp;vim%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>跑实验需要用服务器，远程服务器我用的是XShell + FileZilla进行连接和传输文件，然而在操控linux服务器中需要用到一些常见的linux命令，之前学过《鸟哥linux》，但是一直没有总结过，现在总结下。</p>
<h2 id="linux-常用命令">linux 常用命令</h2>
<h3 id="ls-命令">ls 命令</h3>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">ls  -a   <span class="comment"># 列出目录所有文件，包含以.开始的隐藏文件</span></span><br><span class="line"></span><br><span class="line">ls ~  <span class="comment">#进入主目录</span></span><br><span class="line"></span><br><span class="line">ls E: <span class="comment"># 在win中进入E盘</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="cd-目录名">cd [目录名]</h3>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">cd ..   <span class="comment">#返回上一级目录</span></span><br><span class="line"></span><br><span class="line">cd . /temp  <span class="comment"># 当前目录下的temp文件夹</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="pwd-命令">pwd 命令</h3>
<p>查看当前工作目录路径</p>
<h3 id="mkdir-命令">mkdir 命令</h3>
<p>用于创建文件夹</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">mkdir temp  <span class="comment">#当前工作目录下创建名为 temp的文件夹</span></span><br><span class="line"></span><br><span class="line">mkdir -p /tmp/test/t1/t   <span class="comment"># 在 tmp 目录下创建路径为 test/t1/t 的目录，若不存在，则创建</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="rm-命令">rm 命令</h3>
<p>删除一个目录中的一个或多个文件或目录</p>
<p>如果没有使用 -r 选项，则 rm 不会删除目录。如果使用 rm 来删除文件，通常仍可以将该文件恢复原状。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">rm  -i  *.log <span class="comment"># 删除全部.log文件， 删除前逐一询问</span></span><br><span class="line"></span><br><span class="line">rm a.txt <span class="comment"># 删除文件a.txt</span></span><br><span class="line"></span><br><span class="line">rm -rf test <span class="comment"># 删除test文件夹 </span></span><br><span class="line"></span><br><span class="line">​	 <span class="comment">#-r 就是向下递归，不管有多少级目录，一并删除</span></span><br><span class="line"></span><br><span class="line">​	<span class="comment">#-f 就是直接强行删除，不作任何提示的意思</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="vim-命令">vim 命令</h3>
<p>编辑文件</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">vim a.txt  <span class="comment"># 创建a.txt文件并进入编辑状态 。 如果a.txt 已经存在，则直接进入编辑状态</span></span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> 按下i键，下端显示 –INSERT–。可以进行插入，输入文本 </span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> 输入了之后 按Esc键退出编辑状态</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> 键入 :wq!保存退出  <span class="comment"># 注意是在英文输入状态下进行的操作</span></span><br><span class="line"></span><br><span class="line">    :w 在编辑的过程中保存文件,相当于word中的ctrl+s    </span><br><span class="line"></span><br><span class="line">   :wq 保存文件并退出</span><br></pre></td></tr></tbody></table></figure>
<h3 id="less-命令">less 命令</h3>
<p>有时实验结果较长，在终端前面的输出会无法显示，此命令可以在终端显示上屏无法查看的内容，可以<strong>分页显示</strong>。</p>
<p>用法： 在执行命令后面加上|less即可，它可以用<strong><code>PageUp</code></strong>和<strong><code>PageDown</code></strong>按键上下翻页，也可以用<strong><code>上下方向键</code></strong>一点点查看。退出按<strong><code>q</code></strong>。</p>
<p>一般显示的结果过长，都可在命令行后加上<strong>|less</strong>来分页显示</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">python main.py | less</span><br></pre></td></tr></tbody></table></figure>
<p>less也可直接查看文件</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">less test.txt</span><br></pre></td></tr></tbody></table></figure>
<h3 id="重定向">重定向</h3>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">python main.py &gt;test.txt  <span class="number">2</span>&gt;&amp;<span class="number">1</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">#表示将标准输出（STDOUT）重定向到test.txt文件</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2&gt;&amp;1 ：把标准输出和标准错误一起重定向到一个文件中。1是标准输出的文件描述符，2是标准错误的文件描述符</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="cat-命令">cat 命令</h3>
<p>可以直接查看a.txt 文件</p>
<h3 id="cp-命令">cp 命令</h3>
<p>复制文件/文件夹</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">cp [option] Source Directory</span><br></pre></td></tr></tbody></table></figure>
<p>1.如果要复制的源目录中还存在子目录，此时使用选项R递归地复制子目录。</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">cp -r test file/  <span class="comment">#将目录test复制到目录file中</span></span><br></pre></td></tr></tbody></table></figure>
<p>2..复制并重命名文件</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">cp /etc/samba/smb.conf  smb.backup  <span class="comment">#将/etc/samba/smb.conf备份到当前目录中，并将文件重命名 smb.backup</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="swp文件">.swp文件</h3>
<p>非正常关闭vi/vim编辑器时（如不小心按下<code>ctrl+Z</code>强制退出）会生成一个.swp文件。</p>
<h4 id="解决">解决</h4>
<ul>
<li>使用vim -r a.txt 来恢复文件</li>
<li>然后在提示中删除.swp文件即可，以后就不会有提示了</li>
</ul>
<h3 id="shell-bash-退出码">Shell Bash 退出码</h3>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">exit <span class="number">0</span> :也就是说调用环境就认为你的这个程序执行正确</span><br><span class="line">exit <span class="number">1</span> :一般是出错定义这个<span class="number">1</span>，也可以是其他数字，很多系统程序这个错误编号是有约定的含义的。 </span><br><span class="line">但不为<span class="number">0</span> 就表示程序运行出错。 </span><br><span class="line">exit <span class="number">127</span>: command <span class="keyword">not</span> found <span class="comment">#指令输入错误</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="ps--ef-grep-查找进程">ps -ef | grep 查找进程</h3>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">ps -ef | grep main.py  <span class="comment">#其中main.py是要查找的关键字</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">ps命令将某个进程显示出来</span><br><span class="line"></span><br><span class="line">grep命令是查找</span><br><span class="line"></span><br><span class="line">中间的|是管道命令 是指ps命令与grep同时执行</span><br><span class="line"></span><br><span class="line">字段含义如下：</span><br><span class="line">UID    PID    PPID    C   STIME   TTY    TIME     CMD</span><br><span class="line"></span><br><span class="line">zzw   <span class="number">14124</span>  <span class="number">13991</span>   <span class="number">0</span>   <span class="number">00</span>:<span class="number">38</span>   pts/<span class="number">0</span>   <span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>  grep --color=auto dae</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">UID   ：程序被该 UID 所拥有</span><br><span class="line"></span><br><span class="line">PID   ：就是这个程序的 ID </span><br><span class="line"></span><br><span class="line">PPID  ：则是其上级父程序的ID</span><br><span class="line"></span><br><span class="line">C     ：CPU使用的资源百分比</span><br><span class="line"></span><br><span class="line">STIME ：系统启动时间</span><br><span class="line"></span><br><span class="line">TTY   ：登入者的终端机位置</span><br><span class="line"></span><br><span class="line">TIME  ：使用掉的CPU时间。</span><br><span class="line"></span><br><span class="line">CMD  ：所下达的是什么指令</span><br></pre></td></tr></tbody></table></figure>
<p>这里是两个shell命令通过管道进行了结合，第一个ps能够列出当前系统所有活跃的进程，然后通过grep 关键字查找就能找到带有关键字的进程。<code>找到PID</code>（PID是输出的第二列那个数字）再杀掉。</p>
<h3 id="服务器常用操作">服务器常用操作</h3>
<p>具体操作参考《服务器心得》</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
  </entry>
  <entry>
    <title>Anaconda管理虚拟环境</title>
    <url>/2020/07/21/2020-07-21-Anaconda%E7%AE%A1%E7%90%86%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h2 id="前言">前言</h2>
<p>之前一直用的是pycharm上的虚拟环境管理，后来觉得不利于管理。于是开始使用anaconda。</p>
<p>anaconda可以跨平台使用，我安装window版的anaconda，使用它管理虚拟环境。</p>
<h2 id="下载并安装">下载并安装</h2>
<p>到<a href="https://www.anaconda.com/download/" target="_blank" rel="noopener">官网</a>根据自己情况下载好anaconda版本，安装完毕，可通过以下两种方式进入anaconda操作环境</p>
<ul>
<li>1.可以增加到path环境变量，打开cmd/powershell，即可操作</li>
<li>2.打开Anaconda Prompt即可操作（推荐）</li>
</ul>
<p>在命令行输入<code>conda --version</code> ，显示出版本号，即安装成功</p>
<h2 id="anaconda管理虚拟环境">anaconda管理虚拟环境</h2>
<p>anaconda自带的是base环境，命令行前的（base）说明当前的虚拟环境是base环境 ，我们创建并管理的虚拟环境会放在<code>C:\Users\Administrator\anaconda3\envs</code> 里，</p>
<h3 id="创建新的虚拟环境">1.创建新的虚拟环境</h3>
<p>为自己的项目配置一个单独的虚拟环境</p>
<p>创建一个名字叫做python36的虚拟环境， 同时指定python的版本，如果本机内没有安装这个版本的python，就会自动下载安装。 后面<code>python==3.6</code>一般可以不添加</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda create -n python36  python==<span class="number">3.6</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="激活虚拟环境">2. 激活虚拟环境</h3>
<p>激活进入python36的虚拟环境。如果activate后什么参数都不加，就会进入anaconda自带的base环境</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda activate python36</span><br></pre></td></tr></tbody></table></figure>
<h3 id="退出虚拟环境">3.退出虚拟环境</h3>
<p>在激活新环境的时候要先退出目前的环境至base环境，然后才能activate 新环境，不然代码会bug</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda deactivate</span><br></pre></td></tr></tbody></table></figure>
<h3 id="查看所有的虚拟环境">4.查看所有的虚拟环境</h3>
<p>如果忘记了虚拟环境名称，可以如下命令</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda env list</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2020/07/22/gnUbt2eR7TZvjfy.png" alt="image-20200722093423681"></p>
<p>可以看到目前的虚拟环境状况，共6个虚拟环境。其中<code>*</code>表示当前操作的虚拟环境。</p>
<h3 id="安装第三方包">5.安装第三方包</h3>
<p>现在pyhton36的虚拟环境除了python自带的一些官方包之外是没有其他包</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda install requests <span class="comment">#安装requests包</span></span><br><span class="line">conda install keras==<span class="number">2.2</span><span class="number">.0</span> <span class="comment">#安装指定版本的keras</span></span><br></pre></td></tr></tbody></table></figure>
<p>安装完成之后我们输入python进入解释器并import requests包, 好使的.</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">anaconda search -t conda tensorflow <span class="comment"># 帮助找tensorflow可安装的包。 找到合适的资源（win64的版本包）  ，按照指示操作即可</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="卸载第三方包">6.卸载第三方包</h3>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda remove requests</span><br></pre></td></tr></tbody></table></figure>
<h3 id="查看环境的包信息">7.查看环境的包信息</h3>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda list <span class="comment"># 查看当前环境的包信息</span></span><br><span class="line">conda list -n python36 <span class="comment">#查看指定环境的包信息</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="卸载环境">8.卸载环境</h3>
<p>卸载test虚拟环境</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda remove -n test --all</span><br></pre></td></tr></tbody></table></figure>
<h3 id="conda查看tensorflow和keras的版本">9.conda查看tensorflow和keras的版本</h3>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="number">1.</span>进入python解释器</span><br><span class="line"><span class="number">2.</span><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line"><span class="number">3.</span>tf.__version__ <span class="comment">#注意是两个下划线</span></span><br><span class="line"><span class="number">4.</span> exit（） <span class="comment">#退出python操作环境  或者 ctrl + Z</span></span><br><span class="line">(keras 同理）</span><br></pre></td></tr></tbody></table></figure>
<h3 id="环境包的克隆">10.环境包的克隆</h3>
<p>创建一个新的虚拟环境test， 将环境python36信息克隆到test中</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda create -n   test --clone  python36</span><br></pre></td></tr></tbody></table></figure>
<h3 id="导入导出环境">11.导入导出环境</h3>
<p>切换到了要导出的环境之后，使用命令将当前环境导出</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda env export &gt; environment.yml</span><br></pre></td></tr></tbody></table></figure>
<p>使用命令建立（导入）新的环境</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda env create -f environment.yml</span><br></pre></td></tr></tbody></table></figure>
<p>注： 不过由于不同的操作平台（例如从windows迁移到linux），迁移的时候会报错，找不到安装的包，因为不同平台的包的格式是不一样的，，每个版本号后面的一串字符就类似于手机的序列号，就是指示用于不同环境下的。目前我没有办法进行有效迁移</p>
<p><img src="https://i.loli.net/2020/07/22/MEFRgdAxiuzyhDZ.png" alt="image-20200722102049506"></p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">补充：anaconda所谓的创建虚拟环境其实就是安装了一个真实的python环境, </span><br><span class="line">只不过我们可以通过activate,conda等命令去随意的切换我们当前的python环境, </span><br><span class="line">用不同版本的解释器和不同的包环境去运行python脚本.</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">补充：conda、anaconda概念的差别</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> conda可以理解为一个工具，也是一个可执行命令，其核心功能是包管理与环境管理。</span><br><span class="line">包管理与pip的使用类似，环境管理则允许用户方便地安装不同版本的python并快速切换。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> Anaconda是一个打包的集合，里面预装好了conda、某个版本的python、众多packages、</span><br><span class="line">科学计算工具等，也称为Python的一种发行版。</span><br></pre></td></tr></tbody></table></figure>
<h2 id="参考">参考</h2>
<p>Anaconda详细安装及使用教程： https://blog.csdn.net/ITLearnHall/article/details/81708148</p>
<p>Anaconda虚拟环境跨平台迁移： https://blog.csdn.net/lixufeng1028/article/details/80669525</p>
<p>不同tensorflow、keras、python的版本对应： https://docs.floydhub.com/guides/environments/</p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
  </entry>
  <entry>
    <title>Transformer原理</title>
    <url>/2020/07/20/2020-07-20-%20Transformer%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p>本文转自国外一篇讲解transformer的优秀博客<a href="https://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener">《The Illustrated Transformer》</a>，阅读完之后对于transformer的理解深入了很多，正文如下：</p>
<p>In the <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank" rel="noopener">previous post, we looked at Attention</a> – a ubiquitous method in modern deep learning models. <code>Attention is a concept that helped improve the performance of neural machine translation applications</code>. In this post, we will look at <strong>The Transformer</strong> – a model that uses attention to boost the speed with which these models can be trained. The Transformers outperforms the Google Neural Machine Translation model in specific tasks. <code>The biggest benefit, however, comes from how The Transformer lends itself to parallelization.</code> It is in fact Google Cloud’s recommendation to use The Transformer as a reference model to use their <a href="https://cloud.google.com/tpu/" target="_blank" rel="noopener">Cloud TPU</a> offering. So let’s try to break the model apart and look at how it functions.</p>
<p>The Transformer was proposed in the paper <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention is All You Need</a>. A TensorFlow implementation of it is available as a part of the <a href="https://github.com/tensorflow/tensor2tensor" target="_blank" rel="noopener">Tensor2Tensor</a> package. Harvard’s NLP group created a <a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html" target="_blank" rel="noopener">guide annotating the paper with PyTorch implementation</a>. In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.</p>
<h2 id="a-high-level-look">A High-Level Look</h2>
<p>Let’s begin by looking at the model as a single black box. In a machine translation application, it would take a sentence in one language, and output its translation in another.</p>
<p><img src="https://i.loli.net/2020/07/24/MJXH3BE5vi4wFao.png" alt="img"></p>
<p>Popping open that Optimus Prime goodness, we see an encoding component, a decoding component, and connections between them.</p>
<p><img src="https://i.loli.net/2020/07/26/nvqhT56NEYVf9J7.png" alt="img"></p>
<p><code>The encoding component is a stack of encoders</code> (the paper stacks six of them on top of each other – there’s nothing magical about the number six, one can definitely experiment with other arrangements). <code>The decoding component is a stack of decoders of the same number.</code></p>
<p><img src="https://i.loli.net/2020/07/25/2zSYCOeodvq1mMV.png" alt="img"></p>
<p>The encoders are all identical in structure (yet they do not share weights). Each one is broken down into two sub-layers:</p>
<p><img src="https://i.loli.net/2020/07/25/5Aqnfeo9iPQs1Oh.png" alt="img"></p>
<p><code>The encoder’s inputs first flow through a self-attention layer –</code> a layer that helps the encoder look at other words in the input sentence as it encodes a specific word. We’ll look closer at self-attention later in the post.</p>
<p><code>The outputs of the self-attention layer are fed to a feed-forward neural network</code>. The exact same feed-forward network is independently applied to each position.</p>
<p><code>The decoder has both those layers, but between them is an attention layer that helps the decoder focus on relevant parts of the input sentence</code> (similar what attention does in <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank" rel="noopener">seq2seq models</a>).</p>
<p><img src="https://i.loli.net/2020/07/25/Kmc68dxUuqfQRk4.png" alt="img"></p>
<h2 id="bringing-the-tensors-into-the-picture">Bringing The Tensors Into The Picture</h2>
<p>Now that we’ve seen the major components of the model, let’s start to look at the various vectors/tensors and how they flow between these components to turn the input of a trained model into an output.</p>
<p>As is the case in NLP applications in general, <code>we begin by turning each input word into a vector using an</code> <a href="https://medium.com/deeper-learning/glossary-of-deep-learning-word-embedding-f90c3cec34ca" target="_blank" rel="noopener">embedding algorithm</a>.</p>
<p><img src="https://i.loli.net/2020/07/25/jkPRN5E2cDTfL4p.png" alt="img"> <code>Each word is embedded into a vector of size 512</code>. We'll represent those vectors with these simple boxes.</p>
<p>The embedding only happens in the bottom-most encoder. <code>The abstraction that is common to all the encoders is that they receive a list of vectors each of the size 512 – In the bottom encoder that would be the word embeddings, but in other encoders, it would be the output of the encoder that’s directly below.</code> The size of this list is hyperparameter we can set – basically it would be the length of the longest sentence in our training dataset.</p>
<p>After embedding the words in our input sequence, each of them flows through each of the two layers of the encoder.</p>
<p><img src="https://i.loli.net/2020/07/25/Aj4sHXynq1lOa2x.png" alt="img"></p>
<p>Here we begin to see <code>one key property of the Transformer, which is that the word in each position flows through its own path in the encoder</code>. <code>There are dependencies between these paths</code> in the self-attention layer. The feed-forward layer does not have those dependencies, however, and <code>thus the various paths can be executed in parallel while flowing through the feed-forward layer.</code></p>
<p>Next, we’ll switch up the example to a shorter sentence and we’ll look at what happens in each sub-layer of the encoder.</p>
<h2 id="now-were-encoding">Now We’re Encoding!</h2>
<p>As we’ve mentioned already, an encoder receives a list of vectors as input. It processes this list by passing these vectors into a ‘self-attention’ layer, then into a feed-forward neural network, then sends out the output upwards to the next encoder.</p>
<p><img src="https://i.loli.net/2020/07/25/e34cngFjsyxNvSq.png" alt="img"> The word at each position passes through a self-attention process. Then, they each pass through a feed-forward neural network -- the exact same network with each vector flowing through it separately.</p>
<h2 id="self-attention-at-a-high-level">Self-Attention at a High Level</h2>
<p>Don’t be fooled by me throwing around the word “self-attention” like it’s a concept everyone should be familiar with. I had personally never came across the concept until reading the Attention is All You Need paper. Let us distill how it works.</p>
<p>Say the following sentence is an input sentence we want to translate:</p>
<p>”<code>The animal didn't cross the street because it was too tired</code>”</p>
<p>What does “it” in this sentence refer to? Is it referring to the street or to the animal? It’s a simple question to a human, but not as simple to an algorithm.</p>
<p><code>When the model is processing the word “it”, self-attention allows it to associate “it” with “animal”.</code></p>
<p><code>As the model processes each word (each position in the input sequence), self attention allows it to look at other positions in the input sequence for clues that can help lead to a better encoding for this word.</code></p>
<p>If you’re familiar with RNNs, think of how maintaining a hidden state allows an RNN to incorporate its representation of previous words/vectors it has processed with the current one it’s processing. Self-attention is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing.</p>
<p><img src="https://i.loli.net/2020/07/25/VB6jDHY9PuLrShx.png" alt="img"> <code>As we are encoding the word "it" in encoder #5 (the top encoder in the stack), part of the attention mechanism was focusing on "The Animal", and baked a part of its representation into the encoding of "it".</code></p>
<p>Be sure to check out the <a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb" target="_blank" rel="noopener">Tensor2Tensor notebook</a> where you can load a Transformer model, and examine it using this interactive visualization.</p>
<h2 id="self-attention-in-detail">Self-Attention in Detail</h2>
<p>Let’s first look at <code>how to calculate self-attention using vectors</code>, then proceed to look at how it’s actually implemented – using matrices.</p>
<p>The <strong>first step</strong> in calculating self-attention is to <code>create three vectors from each of the encoder’s input vectors</code> (in this case, the embedding of each word). So <code>for each word, we create a Query vector, a Key vector, and a Value vector. These vectors are created by multiplying the embedding by three matrices that we trained during the training process.</code></p>
<p>Notice that these new vectors are smaller in dimension than the embedding vector. <code>Their dimensionality is 64</code>, while the embedding and encoder input/output vectors have dimensionality of 512. <code>They don’t HAVE to be smaller, this is an architecture choice to make the computation of multiheaded attention (mostly) constant.</code></p>
<p><img src="https://i.loli.net/2020/07/25/aCuE9FmWZyOn2Xs.png" alt="img"> Multiplying x1 by the WQ weight matrix produces q1, the "query" vector associated with that word. We end up creating a "query", a "key", and a "value" projection of each word in the input sentence.</p>
<p>What are the “query”, “key”, and “value” vectors?</p>
<p>They’re abstractions that are useful for calculating and thinking about attention. Once you proceed with reading how attention is calculated below, you’ll know pretty much all you need to know about the role each of these vectors plays.</p>
<p><code>The **second step** in calculating self-attention is to calculate a score</code>. Say we’re calculating the self-attention for the first word in this example, “Thinking”. We need to score each word of the input sentence against this word. <code>The score determines how much focus to place on other parts of the input sentence as we encode a word at a certain position.</code></p>
<p>The score is calculated by taking the dot product of the query vector with the key vector of the respective word we’re scoring. So if we’re processing the self-attention for the word in position #1, the first score would be the dot product of q1 and k1. The second score would be the dot product of q1 and k2.</p>
<p><img src="https://i.loli.net/2020/07/25/xgtf9K4cJkRpbV2.png" alt="img"></p>
<p><code>The **third and forth steps** are to divide the scores by 8</code> (the square root of the dimension of the <code>key vectors</code> used in the paper – 64. This leads to having more stable gradients. There could be other possible values here, but this is the default), <code>then pass the result through a softmax operation. Softmax normalizes the scores so they’re all positive and add up to 1.</code></p>
<ul>
<li></li>
</ul>
<p><img src="https://i.loli.net/2020/07/25/u7HQAF28ci3oPpq.png" alt="img"></p>
<p>This softmax score determines how much each word will be expressed at this position. <code>Clearly the word at this position will have the highest softmax score, but sometimes it’s useful to attend to another word that is relevant to the current word.</code></p>
<p><code>The **fifth step** is to multiply each value vector by the softmax score</code> (in preparation to sum them up). The intuition here is to keep intact the values of the word(s) we want to focus on, and drown-out irrelevant words (by multiplying them by tiny numbers like 0.001, for example).</p>
<p><code>The **sixth step** is to sum up the weighted value vectors.</code> This produces the output of the self-attention layer at this position (for the first word).</p>
<p><img src="https://i.loli.net/2020/07/25/SNa4Km1EvVpyXIr.png" alt="img"></p>
<p>That concludes the self-attention calculation. <code>The resulting vector is one we can send along to the feed-forward neural network</code>. In the actual implementation, however, <code>this calculation is done in matrix form for faster processing. So let’s look at that now that we’ve seen the intuition of the calculation on the word level.</code></p>
<h2 id="matrix-calculation-of-self-attention">Matrix Calculation of Self-Attention</h2>
<p><strong>The first step</strong> is to calculate the Query, Key, and Value matrices. We do that by packing our embeddings into a matrix X, and multiplying it by the weight matrices we’ve trained (WQ, WK, WV).</p>
<p><img src="https://i.loli.net/2020/07/25/jAwgJ62muho8nvI.png" alt="img"> Every row in the X matrix corresponds to a word in the input sentence. We again see the difference in size of the embedding vector (512, or 4 boxes in the figure), and the q/k/v vectors (64, or 3 boxes in the figure)</p>
<p><strong>Finally</strong>, since we’re dealing with matrices, we can condense steps two through six in one formula to calculate the outputs of the self-attention layer.</p>
<p><img src="https://i.loli.net/2020/07/25/PCcj7Rlpn9XHaMF.png" alt="img"> The self-attention calculation in matrix form</p>
<h2 id="the-beast-with-many-heads">The Beast With Many Heads</h2>
<p><code>The paper further refined the self-attention layer by adding a mechanism called “multi-headed” attention. This improves the performance of the attention layer in two ways:</code></p>
<ol type="1">
<li><code>It expands the model’s ability to focus on different positions</code>. Yes, <code>in the example above, z1 contains a little bit of every other encoding, but it could be dominated by the the actual word itself.</code> It would be useful if we’re translating a sentence like “The animal didn’t cross the street because it was too tired”, we would want to know which word “it” refers to.</li>
<li><code>It gives the attention layer multiple “representation subspaces</code>”. As we’ll see next, <code>with multi-headed attention we have not only one, but multiple sets of Query/Key/Value weight matrices</code> (the Transformer uses eight attention heads, so we end up with eight sets for each encoder/decoder). <code>Each of these sets is randomly initialized. Then, after training, each set is used to project the input embeddings (or vectors from lower encoders/decoders) into a different representation subspace.</code></li>
</ol>
<p><img src="https://i.loli.net/2020/07/25/7UB4w8oijMvCfyq.png" alt="img"> With multi-headed attention, <code>we maintain separate Q/K/V weight matrices for each head resulting in different Q/K/V matrices.</code> As we did before, we multiply X by the WQ/WK/WV matrices to produce Q/K/V matrices.</p>
<p>If we do the same self-attention calculation <code>we outlined above, just eight different times with different weight matrices, we end up with eight different Z matrices</code></p>
<p><img src="https://i.loli.net/2020/07/25/p9WTsRgd2ye7F8I.png" alt="img"></p>
<p><code>This leaves us with a bit of a challenge.</code> The feed-forward layer is not expecting eight matrices – <code>it’s expecting a single matrix (a vector for each word). So we need a way to condense these eight down into a single matrix.</code></p>
<p>How do we do that? <code>We concat the matrices then multiple them by an additional weights matrix WO.</code></p>
<p><img src="https://i.loli.net/2020/07/25/i7bU1pIfDqgZuAx.png" alt="img"></p>
<p>That’s pretty much all there is to multi-headed self-attention. It’s quite a handful of matrices, I realize. Let me try to put them all in one visual so we can look at them in one place</p>
<p><img src="https://i.loli.net/2020/07/25/YIVPms5cNDj2Mpq.png" alt="img"></p>
<p>Now that we have touched upon attention heads, let’s revisit our example from before to see <code>where the different attention heads are focusing as we encode the word “it” in our example sentence:</code></p>
<p><img src="https://i.loli.net/2020/07/25/nXZ4OMkluRFjwJH.png" alt="img"> As we encode the word "it", <code>one attention head is focusing most on "the animal", while another is focusing on "tired" -- in a sense, the model's representation of the word "it" bakes in some of the representation of both "animal" and "tired".</code></p>
<p>If we add all the attention heads to the picture, however, things can be harder to interpret:</p>
<p><img src="https://i.loli.net/2020/07/25/jk2hUsJGM6qxRwD.png" alt="img"></p>
<h2 id="representing-the-order-of-the-sequence-using-positional-encoding">Representing The Order of The Sequence Using <code>Positional Encoding</code></h2>
<p>One thing that’s missing from the model as we have described it so far is a way to account for the order of the words in the input sequence.</p>
<p>To address this, the transformer adds a vector to each input embedding. <code>These vectors follow a specific pattern that the model learns, which helps it determine the position of each word, or the distance between different words in the sequence.</code> The intuition here is that adding these values to the embeddings provides meaningful distances between the embedding vectors once they’re projected into Q/K/V vectors and during dot-product attention.</p>
<p><img src="https://i.loli.net/2020/07/25/ypGiMmaYjeIo5ct.png" alt="img"> To give the model a sense of the order of the words, we add positional encoding vectors -- the values of which follow a specific pattern.</p>
<p>If we assumed the <code>embedding has a dimensionality of 4,</code> the actual positional encodings would look like this:</p>
<p><img src="https://i.loli.net/2020/07/25/u3Kn2rIF68DWmtX.png" alt="img"> A real example of positional encoding with a toy embedding size of 4</p>
<p>What might this pattern look like?</p>
<p>In the following figure, <code>each row corresponds the a positional encoding of a vector.</code> So the <code>first row would be the vector we’d add to the embedding of the first word in an input sequence</code>. <code>Each row contains 512 values – each with a value between 1 and -1. We’ve color-coded them so the pattern is visible.</code></p>
<p><img src="https://i.loli.net/2020/07/25/XTrgBuPAKbU58lL.png" alt="img"> A real example of <code>positional encoding for 20 words (rows) with an embedding size of 512 (columns)</code>. You can see that it appears split in half down the center. <code>That's because the values of the left half are generated by one function (which uses sine), and the right half is generated by another function (which uses cosine).</code> They're then concatenated to form each of the positional encoding vectors.</p>
<p>The formula for positional encoding is described in the paper (section 3.5). You can see the code for generating positional encodings in <a href="https://github.com/tensorflow/tensor2tensor/blob/23bd23b9830059fbc349381b70d9429b5c40a139/tensor2tensor/layers/common_attention.py" target="_blank" rel="noopener"><code>get_timing_signal_1d()</code></a>. <code>This is not the only possible method for positional encoding. It, however, gives the advantage of being able to scale to unseen lengths of sequences</code> (e.g. if our trained model is asked to translate a sentence longer than any of those in our training set).</p>
<p><strong>July 2020 Update:</strong> The positional encoding shown above is from the Tranformer2Transformer implementation of the Transformer. The method shown in the paper is slightly different in that it doesn’t directly concatenate, but interweaves the two signals. The following figure shows what that looks like. <a href="https://github.com/jalammar/jalammar.github.io/blob/master/notebookes/transformer/transformer_positional_encoding_graph.ipynb" target="_blank" rel="noopener">Here’s the code to generate it</a>:</p>
<p><img src="https://i.loli.net/2020/07/25/9V4sImeBjPaXQpE.png" alt="img"></p>
<h2 id="the-residuals">The <code>Residuals</code></h2>
<p>One detail in the architecture of the encoder that we need to mention before moving on, is that each sub-layer (self-attention, ffnn) in each encoder has a residual connection around it, and is followed by a <a href="https://arxiv.org/abs/1607.06450" target="_blank" rel="noopener">layer-normalization</a> step.</p>
<p><img src="https://i.loli.net/2020/07/25/uteZNE9q7wxIo6Y.png" alt="img"></p>
<p>If we’re to visualize the vectors and the layer-norm operation associated with self attention, it would look like this:</p>
<p><img src="https://i.loli.net/2020/07/25/2GZuRSainMsYfHQ.png" alt="img"></p>
<p>This goes for the sub-layers of the decoder as well. If we’re to think of a Transformer of 2 stacked encoders and decoders, it would look something like this:</p>
<p><img src="https://i.loli.net/2020/07/25/9RHz2i8nZhyMPdt.png" alt="img"></p>
<h2 id="the-decoder-side">The Decoder Side</h2>
<p>Now that we’ve covered most of the concepts on the encoder side, we basically know how the components of decoders work as well. But let’s take a look at how they work together.</p>
<p>The encoder start by processing the input sequence. <code>The output of the top encoder is then transformed into a set of attention vectors K and V. These are to be used by each decoder in its “encoder-decoder attention” layer which helps the decoder focus on appropriate places in the input sequence:</code></p>
<p><img src="https://i.loli.net/2020/07/26/2MZ3SophkRgD9eJ.gif" alt="MQfaxEpcKV8AGDv"></p>
<p>After finishing the encoding phase, we begin the decoding phase. <code>Each step in the decoding phase outputs an element from the output sequence (the English translation sentence in this case).</code></p>
<p>The following steps repeat the process until a <code>special symbol</code> is reached indicating the transformer decoder has completed its output. <code>The output of each step is fed to the bottom decoder in the next time step, and the decoders bubble up their decoding results just like the encoders did</code>. And just like we did with the encoder inputs, <code>we embed and add positional encoding</code> to those decoder inputs to indicate the position of each word.</p>
<p><img src="https://jalammar.github.io/images/t/transformer_decoding_2.gif" alt="img"></p>
<p><img src="https://i.loli.net/2020/07/26/lwq4T3gIaEZHdu5.png" alt="image-20200726205210899"></p>
<p>The self attention layers in the decoder operate in a slightly different way than the one in the encoder:</p>
<p><code>In the decoder, the self-attention layer is only allowed to attend to earlier positions in the output sequence</code>. This is done by <code>masking future positions (</code>setting them to <code>-inf</code>) before the softmax step in the self-attention calculation.</p>
<p><code>The “Encoder-Decoder Attention” layer works just like multiheaded self-attention</code>, except it creates its Queries matrix from the layer below it, and takes the Keys and Values matrix from the output of the encoder stack.</p>
<h2 id="the-final-linear-and-softmax-layer">The Final Linear and Softmax Layer</h2>
<p><code>The decoder stack outputs a vector of floats</code>. How do we turn that into a word? That’s the job of the final Linear layer which is followed by a Softmax Layer.</p>
<p><code>The Linear layer is a simple fully connected neural network that projects the vector produced by the stack of decoders, into a much, much larger vector called a logits vector.</code></p>
<p><code>Let’s assume that our model knows 10,000 unique English words (our model’s “output vocabulary”) that it’s learned from its training dataset. This would make the logits vector 10,000 cells wide – each cell corresponding to the score of a unique word</code>. That is how we interpret the output of the model followed by the Linear layer.</p>
<p><code>The softmax layer then turns those scores into probabilities</code> (all positive, all add up to 1.0). <code>The cell with the highest probability is chosen</code>, and the <code>word associated with it is produced as the output for this time step.</code></p>
<p><img src="https://i.loli.net/2020/07/25/w62DtS8vVYpkQqg.png" alt="img"> This figure starts from the bottom with the vector produced as the output of the decoder stack. It is then turned into an output word.</p>
<h2 id="recap-of-training">Recap Of Training</h2>
<p>Now that we’ve covered the entire forward-pass process through a trained Transformer, it would be useful to glance at the intuition of training the model.</p>
<p><code>During training, an untrained model would go through the exact same forward pass. But since we are training it on a labeled training dataset, we can compare its output with the actual correct output.</code></p>
<p>To visualize this, let’s assume our output vocabulary only contains six words(“a”, “am”, “i”, “thanks”, “student”, and “<eos>” (short for ‘end of sentence’)).</eos></p>
<p><img src="https://i.loli.net/2020/07/25/BgKxbL57uJGiZ4E.png" alt="img"> <code>The output vocabulary of our model is created in the preprocessing phase before we even begin training.</code></p>
<p>Once we define our output vocabulary, we can use a vector of the same width to indicate each word in our vocabulary. This also known as <code>one-hot encoding</code>. So for example, we can indicate the word “am” using the following vector:</p>
<p><img src="https://i.loli.net/2020/07/25/ot8s4Gl6LNC3pdk.png" alt="img"> Example: one-hot encoding of our output vocabulary</p>
<p>Following this recap, let’s discuss the model’s loss function – the metric we are optimizing during the training phase to lead up to a trained and hopefully amazingly accurate model.</p>
<h2 id="the-loss-function">The <code>Loss Function</code></h2>
<p>Say we are training our model. Say it’s our first step in the training phase, and we’re training it on a simple example – translating “merci” into “thanks”.</p>
<p>What this means, is that we want the output to be a probability distribution indicating the word “thanks”. But since this model is not yet trained, that’s unlikely to happen just yet.</p>
<p><img src="https://i.loli.net/2020/07/25/qcKFVhUSmiNIkTJ.png" alt="img"> <code>Since the model's parameters (weights) are all initialized randomly, the (untrained) model produces a probability distribution with arbitrary values for each cell/word.</code> We can compare it with the actual output, then tweak all the model's weights using <code>backpropagation</code> to make the output closer to the desired output.</p>
<p>How do you compare two probability distributions? We simply subtract one from the other. For more details, look at <a href="https://colah.github.io/posts/2015-09-Visual-Information/" target="_blank" rel="noopener">cross-entropy</a> and <a href="https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained" target="_blank" rel="noopener">Kullback–Leibler divergence</a>.</p>
<p>But note that this is an oversimplified example. More realistically, we’ll use a sentence longer than one word. For example – input: “je suis étudiant” and expected output: “i am a student”. What this really means, is that we want our model to successively output probability distributions where:</p>
<ul>
<li><code>Each probability distribution is represented by a vector of width vocab_size</code> (6 in our toy example, but more realistically a number like 30,000 or 50,000)</li>
<li>The first probability distribution has the highest probability at the cell associated with the word “i”</li>
<li>The second probability distribution has the highest probability at the cell associated with the word “am”</li>
<li>And so on, until the fifth output distribution indicates ‘<code>&lt;end of sentence&gt;</code>’ symbol, which also has a cell associated with it from the 10,000 element vocabulary.</li>
</ul>
<p><img src="https://i.loli.net/2020/07/25/VKGpQ8MqYTnrROs.png" alt="img"> The targeted probability distributions we'll train our model against in the training example for one sample sentence.</p>
<p>After training the model for enough time on a large enough dataset, we would <code>hope the produced probability distributions would look like this:</code></p>
<p><img src="https://jalammar.github.io/images/t/output_trained_model_probability_distributions.png" alt="img"> Hopefully upon training, the model would output the right translation we expect. Of course it's no real indication if this phrase was part of the training dataset (see: <a href="https://www.youtube.com/watch?v=TIgfjmp-4BA" target="_blank" rel="noopener">cross validation</a>). Notice that every position gets a little bit of probability even if it's unlikely to be the output of that time step -- that's a very useful property of softmax which helps the training process.</p>
<p>Now, <code>because the model produces the outputs one at a time, we can assume that the model is selecting the word with the highest probability from that probability distribution and throwing away the rest.</code> That’s one way to do it (called <code>greedy decoding</code>). Another way to do it would be to hold on to, say, the top two words (say, ‘I’ and ‘a’ for example), then in the next step, run the model twice: once assuming the first output position was the word ‘I’, and another time assuming the first output position was the word ‘a’, and whichever version produced less error considering both positions #1 and #2 is kept. We repeat this for positions #2 and #3…etc. This method is called “<code>beam search</code>”, where in our example, beam_size was two (meaning that at all times, two partial hypotheses (unfinished translations) are kept in memory), and top_beams is also two (meaning we’ll return two translations). These are both hyperparameters that you can experiment with.</p>
<h2 id="go-forth-and-transform">Go Forth And Transform</h2>
<p>I hope you’ve found this a useful place to start to break the ice with the major concepts of the Transformer. If you want to go deeper, I’d suggest these next steps:</p>
<ul>
<li>Read the <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention Is All You Need</a> paper, the Transformer blog post (<a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html" target="_blank" rel="noopener">Transformer: A Novel Neural Network Architecture for Language Understanding</a>), and the <a href="https://ai.googleblog.com/2017/06/accelerating-deep-learning-research.html" target="_blank" rel="noopener">Tensor2Tensor announcement</a>.</li>
<li>Watch <a href="https://www.youtube.com/watch?v=rBCqOTEfxvg" target="_blank" rel="noopener">Łukasz Kaiser’s talk</a> walking through the model and its details</li>
<li>Play with the <a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb" target="_blank" rel="noopener">Jupyter Notebook provided as part of the Tensor2Tensor repo</a></li>
<li>Explore the <a href="https://github.com/tensorflow/tensor2tensor" target="_blank" rel="noopener">Tensor2Tensor repo</a>.</li>
</ul>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>DeepLearning</category>
      </categories>
      <tags>
        <tag>Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>2020-07-20-git使用指南</title>
    <url>/2020/07/20/2020-07-20-git%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/</url>
    <content><![CDATA[<h3 id="利用git上传本地项目到github">利用git上传本地项目到github</h3>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">利用git上传本地项目到github</span><br><span class="line"></span><br><span class="line">1.绑定用户</span><br><span class="line"></span><br><span class="line">2.设置ssh key 并为github账号配置ssh key</span><br><span class="line"></span><br><span class="line">3.上传本地项目到github</span><br></pre></td></tr></tbody></table></figure>
<h4 id="绑定用户">1.绑定用户</h4>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">$ git config --global user.name "OopsAaron" # 注册github时的name</span><br><span class="line">$ git config --global user.email "1574468139@qq.com" # 注册github时的email</span><br></pre></td></tr></tbody></table></figure>
<h4 id="生成密钥ssh-key">2.生成密钥SSH key</h4>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">"1574468139@qq.com"</span></span><br></pre></td></tr></tbody></table></figure>
<p>此时，在根目录的.ssh文件中会生成公钥和密钥文件</p>
<p>打开<a href="https://link.zhihu.com/?target=http%3A//github.com/">github</a>，在头像下面点击<code>settings</code>，再点击<code>SSH and GPG keys</code>，新建一个SSH，名字随便。</p>
<p>git bash中输入</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">cat ~/.ssh/id_rsa.pub <span class="comment"># 复制.ssh里的公钥文件到github中</span></span><br></pre></td></tr></tbody></table></figure>
<p>将输出的内容复制到框中，点击确定保存。即建立了ssh连接</p>
<p><img src="https://i.loli.net/2020/07/20/45pTnsvKBbYPDCQ.png" alt="image-20200720163835551"></p>
<p><img src="https://i.loli.net/2020/08/10/TBqj7pxGadESw1m.png" alt="image-20200810192758491"></p>
<p>github上新建一个仓库后，在本地进行初始化本地仓库以及上传文件</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">git init #初始化仓库</span><br><span class="line"></span><br><span class="line">#复制git clone中的ssh地址</span><br><span class="line"></span><br><span class="line">git remote add origin git@github.com:OopsAaron/myBlog.git #远程连接仓库 （后部分是ssh地址）</span><br><span class="line"></span><br><span class="line">		（若出现fatal: remote origin already exists. 则执行 git remote rm origin，</span><br><span class="line"> 		 再重新执行git remote add origin git@github.com:OopsAaron/myBlog.git）</span><br></pre></td></tr></tbody></table></figure>
<p>在本地写md文件以及修改，然后进行提交到github， 并更新到网站上。</p>
<h4 id="提交到github">3.提交到github</h4>
<blockquote>
<p>提交到 github 中的myBlog文件夹中</p>
</blockquote>
<p>将现有的项目添加并上传 (在所在目录下右键git bash)</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">git add . #添加当前文件夹下的所有文件</span><br><span class="line"></span><br><span class="line">git commit -m "first commit " # 引号内是本次的提交说明 </span><br><span class="line"></span><br><span class="line">git push -u origin master # 提交本地分支到远程分支</span><br><span class="line">		(若出现failed to push som refs to， 则执行git pull origin master，</span><br><span class="line">		将远程服务器github上的master拉下来，再重新push)</span><br></pre></td></tr></tbody></table></figure>
<p>刷新github，即可看到上传的文件</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">git clone   https://github.com/raymond-zhao/cat-mall.git   ../Github/cat-mall </span><br><span class="line">#将cat-mall代码克隆到  ../Github/cat-mall 中</span><br></pre></td></tr></tbody></table></figure>
<h4 id="注">注</h4>
<p>在<code>git commit -m "first commit"</code>中，若名称<code>first commit</code>不加引号，则不能有空格</p>
<p>如下则会报错</p>
<p><img src="https://i.loli.net/2020/09/01/KJbWjRr6OsHzu4E.png" alt="image-20200901141302927"></p>
<p>不知道原因，我用<code>git status</code> 排查了一下，发现已经添加到暂存区了，所以应该是<code>commit</code>的原因</p>
<p><img src="https://i.loli.net/2020/09/01/smtWaV2eRCpbhJx.png" alt="image-20200901142150766"></p>
<p>可以看到，<code>changes to be committed</code> ，说明都在暂存区，等待提交<code>commit</code></p>
<p>将空格去掉，或者加上双引号即可成功</p>
<p><img src="https://i.loli.net/2020/09/01/1rntRV8cQGlaHfg.png" alt="image-20200901141341959"></p>
<p>之后就可以push到远程仓库中了</p>
<h4 id="参考">参考</h4>
<blockquote>
<p><a href="http://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html" target="_blank" rel="noopener">常用git命令清单-阮一峰</a> <a href="http://www.ruanyifeng.com/blog/2012/08/how_to_read_diff.html" target="_blank" rel="noopener">读懂diff-阮一峰</a> <a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="noopener">git教程-廖雪峰</a> <a href="http://www.runoob.com/git/git-install-setup.html" target="_blank" rel="noopener">git教程-菜鸟教程</a> <a href="https://git-scm.com/book/zh/v2" target="_blank" rel="noopener">gitbook</a> <a href="http://gitbook.liuhui998.com/index." target="_blank" rel="noopener">Git Community Book</a></p>
<h6 id="从只会git-add-.的菜鸟到掌握git基本功能"><a href="https://juejin.im/post/6844903586023866375" target="_blank" rel="noopener">从只会git add .的菜鸟到掌握git基本功能</a></h6>
</blockquote>
<h3 id="hexo更新到网站">hexo更新到网站</h3>
<p>提交到github中的<code>OopsAaron</code>文件中托管，并更新到网站</p>
<p>在本地编写完md文件，所在目录下右键git bash</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">hexo new new_article  # 新建md文件</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">e.g.</span><br><span class="line">#打开Typora（已添加到环境变量）</span><br><span class="line">hexo new 2020-07-20-tensorflow笔记</span><br><span class="line">#Typora自动跳出新建笔记界面， 这时笔记会自带已预设好的title、description等(因为用的是hexo new 命令)</span><br><span class="line"></span><br><span class="line">注： 1.预设的标签不能空着，不用的话去掉</span><br><span class="line"> 	2. 在每一个title冒号后面要空格，再添加信息 ，不然会报错，示例如下</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://i.loli.net/2020/07/21/AeMFUSKwfWGkjpr.png" alt="image-20200721232830843"></p>
<h4 id="一般命令">一般命令</h4>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">hexo clean # </span><br><span class="line"></span><br><span class="line">hexo g  # ==hexo generate 生成静态网页至public目录 </span><br><span class="line"></span><br><span class="line">hexo s # ==hexo server 可以在本地预览效果 http://localhost:4000/   ctrl+C 退出预览</span><br><span class="line"></span><br><span class="line">hexo d # ==hexo deploy 部署到github上，并可以看到发布的文章</span><br><span class="line"></span><br><span class="line">hexo help # 查看帮助</span><br><span class="line"></span><br><span class="line">hexo version # 查看版本</span><br></pre></td></tr></tbody></table></figure>
<h4 id="组合命令">组合命令</h4>
<figure class="highlight shell"><table><tbody><tr><td class="code"><pre><span class="line">hexo s -g  # 生成静态网页并本地预览</span><br><span class="line"></span><br><span class="line">hexo d -g  # 生成并上传</span><br><span class="line"></span><br><span class="line">hexo clean &amp;&amp; hexo d -g &amp;&amp; hexo s  #一步到位</span><br></pre></td></tr></tbody></table></figure>
<h3 id="hexo高级操作">hexo高级操作</h3>
<p>hexo的根目录结构如下所示</p>
<p><img src="https://i.loli.net/2020/07/22/5EWcOhQ8MBCem4s.png" alt="image-20200722181143933"></p>
<h4 id="config.yml">_config.yml</h4>
<p>网站配置信息，也就是本文所称的<strong>站点配置文件</strong>，可以在此配置大部分的参数。</p>
<h4 id="scaffolds">scaffolds</h4>
<p>模版文件夹。新建文章时，Hexo 会根据 scaffold 来建立文件。</p>
<p>Hexo的模板是指新建的markdown文件中默认填充的内容。例如，在使用<code>hexo new 文章名</code>时，默认生成的md文件会包含如下内容：</p>
<p><img src="https://i.loli.net/2020/07/22/H6JKBeIwhcTkN5z.png" alt="image-20200722182540918"></p>
<p>默认内容就在scaffold/post.md中保存</p>
<p>假如对每篇博客我都需要添加分类<code>categories</code>，每次都手动添加太麻烦，我希望每次默认生成都有<code>categories:</code>，那么就可以在scaffold/post.md中添加categories</p>
<p>保存后，每次新建一篇文章时都会包含post.md中的内容。</p>
<p>当然，你也可以在scaffolds文件夹下创建自己的博客模板，我创建一个名为<code>blog</code>的模板：</p>
<p><img src="https://i.loli.net/2020/07/22/oLMuDQOmg6xaBYU.png" alt="image-20200722182806115"></p>
<p>通过如下命令调用我创建的blog模板新建文章，在<code>_posts</code>中生成md文件，并且是以blog.md为模板的</p>
<figure class="highlight plain"><table><tbody><tr><td class="code"><pre><span class="line">hexo new blog 2020-07-22-测试blog</span><br></pre></td></tr></tbody></table></figure>
<h4 id="public">public</h4>
<p>该文件夹中的内容将被最终push到github仓库中。</p>
<h4 id="source">source</h4>
<p>资源文件夹是存放用户资源的地方。除<code>_posts</code> 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件（如刚刚生成的about文件夹）会被拷贝到 public 文件夹。</p>
<h4 id="为github仓库添加readme">为github仓库添加readme</h4>
<p>既然 source 文件夹中的内容将全部被推送到 public 文件夹，public 文件夹中的内容又将被最终push到github仓库中，那么如果我们想要为github仓库添加readme.md，只要在 source 文件夹中创建就好了：</p>
<p>部署到github，就有readme了，但我们发现，README.md已经被解析为README.html，显示的全是html代码，并不是我们想要的文档格式的内容</p>
<p>为了解决这个问题，我们回到source文件夹，将<code>README.md</code>重命名为<code>README.MDOWN</code>，再部署到github即可</p>
<p>source文件夹中，.md会被解析为html，并放到 public 文件夹被push到github，但.MDWN不会被解析。</p>
<h4 id="themes">themes</h4>
<p>主题文件夹，下载的主题都保存在此文件夹下。Hexo 会根据主题来生成静态页面。</p>
<h4 id="参考-1">参考</h4>
<blockquote>
<p>Hexo+Github博客搭建： https://zhuanlan.zhihu.com/p/35668237 git上传文件： https://blog.csdn.net/sinat_20177327/article/details/76062030 git版本管理工具详细教程： https://www.cnblogs.com/cuixiaoying/p/11821797.html</p>
</blockquote>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
</search>
