<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>思建的NLP之旅</title>
  
  <subtitle>沉淀自己</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-10-20T07:09:48.737Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>李思建</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>2020-10-20-transformer和GNN的关系理解</title>
    <link href="http://yoursite.com/2020/10/20/2020-10-20-transformer%E5%92%8CGNN%E7%9A%84%E5%85%B3%E7%B3%BB%E7%90%86%E8%A7%A3/"/>
    <id>http://yoursite.com/2020/10/20/2020-10-20-transformer%E5%92%8CGNN%E7%9A%84%E5%85%B3%E7%B3%BB%E7%90%86%E8%A7%A3/</id>
    <published>2020-10-20T07:04:37.000Z</published>
    <updated>2020-10-20T07:09:48.737Z</updated>
    
    <content type="html"><![CDATA[<h3 id="transformer和gnn的关系">transformer和GNN的关系</h3><blockquote><p>Transformer和GNN有什么关系？一开始可能并不明显。但是通过这篇文章，你会从GNN的角度看待Transformer的架构，对于原理有更清楚的认知。</p></blockquote><p>通过这篇博文，现为南洋理工大学助理研究员Chaitanya Joshi 将为读者介绍图神经网络和 Transformer 之间的内在联系。具体而言，作者首先介绍 NLP 和 GNN 中模型架构的基本原理，使用公式和图片来加以联系，然后讨论怎样能够推动这方面的进步。</p><p><strong>transformer是GNN的一种特例</strong></p><h4 id="nlp-中的表示学习">NLP 中的表示学习</h4><p>从一个很高的角度来看，所有的神经网络架构都是<strong>对输入数据构建表示</strong>(<em>representations</em>)——以向量或嵌入矩阵的形式。这种方法将有用的统计或语义信息进行编码。</p><p>这些隐表示(<em>latent</em> or <em>hidden</em> representations)可以被用来进行一些有用的任务，如图像分类或句子翻译。<strong>神经网络通过反馈（即损失函数）来构建更好的表示。</strong></p><p>对于 NLP 来说，传统上，RNN 对每个词都会建立一个表示——<strong>使用序列的方式</strong>。例如，每个时间步一个词。从直观上来说，我们可以想象，一个 RNN 层是一个传送带。词汇以自回归(<em>autoregressively</em>)的方式从左到右被处理。在结束的时候，我们可以得到每个词在句子中的隐藏特征，然后将这些特征输入到下一个 RNN 层中，或者用到任务中去。</p><p><img src="https://i.loli.net/2020/10/20/Do7nd4r83wpJIuQ.jpg" alt="img"></p><p>从机器翻译开始，Transformer 就逐渐开始取代 RNN。<strong>这一模型有着新的表示学习策略</strong>。它不再使用递归，而是使用注意力机制对每个词构建表示——即每个词语在句子中的重要程度。知道了这一点，词的特征更新则是所有词的线性变换之和——通过其重要性进行加权。</p><h4 id="解析transformer">解析Transformer</h4><p>通过将前一段翻译成数学符号以及向量的方式去创建对整个体系结构的认知。将长句 S 中的第 i 个单词的隐藏特征 h 从 ℓ 层更新至ℓ+1 层：</p><p><img src="https://i.loli.net/2020/10/20/ZPO4o7kHUsy9GT2.png" alt="img"></p><p>其中 j∈S 为句子中单词的集合，Q<sup>ℓ、K</sup>ℓ、V^ℓ为可学习的线性权重（分别表示注意力计算的 Query、Key 以及 Value）。针对句子中每个单词的并行执行注意力机制，从而在 one shot 中（在 RNNs 转换器上的另外一点，逐字地更新特征）获取它们的更新特征。</p><p>我们可通过以下途径更好地理解注意力机制：</p><p><img src="https://i.loli.net/2020/10/19/M7EcF9nmQRfLOBA.jpg" alt="img" style="zoom:67%;"></p><p>考虑到 h_j^l； ∀j∈S 句中 h_i^l 和其他词的特征，通过点积计算每对（i，j）的注意力权重，然后在所有 j 上计算出 softmax。最后通过所有 h_j^l 的权重进行相应的加权，得到更新后的单词特征 h_i^l+1。</p><h4 id="多头注意力机制">多头注意力机制</h4><p>让点积注意力机制发挥作用是被证明较为棘手：糟糕的随机初始化可能会破坏学习过程的稳定性，此情况可以通过并行执行多头注意力将结果连接起来，从而克服这个问题（<strong>而每个「head」都有单独的可学习权重</strong>）：</p><p><img src="https://i.loli.net/2020/10/20/8R6hMowJm1zYlPX.png" alt="img"></p><p>其中 Q<sup>k,ℓ、K</sup>k,ℓ、V^k,ℓ是第 K 个注意力 head 的可学习权重，O^ℓ 是向下的投影，用以匹配 h_i^l+1 和 h_i^l 跨层的维度。</p><p>通过观察上一层中隐藏特征的不同的变换过程以及方面，多头机制允许注意力机制从本质上“规避风险”。关于这点，我们将在后面详细讨论。</p><h4 id="尺度问题和前向传播子层">尺度问题和前向传播子层</h4><p>促使形成最终形态的Transformer结构的<strong>关键问题点</strong>是，注意机制之后的<strong>词的特征</strong>可能在不同的尺度或重要性上：1）这可能是由于某些词在将其他词的特征累加时具有非常集中或非常分散的注意力权重 w_ij；（2）在单个特征/向量输入级别，跨多个注意力头（每个可能会以不同的比例输出值）进行级联可以导致最终向量 h_i^ℓ+1的输入具有一个大范围的值。遵循传统的机器学习思路，在上述流程中增加一个归一化层似乎是一个合理的选择。</p><p><img src="https://i.loli.net/2020/10/20/LpmV5fOXb3NMQAR.png" alt="image-20201019200900240"></p><p><strong>Transformers使用LayerNorm克服了问题（2）</strong>，LayerNorm在特征层级上进行归一化并学习一种仿射变换。此外，通过求特征维度的平方根来缩放点积注意力有助于抵消问题（1）。</p><p>最后，作者提出了控制尺度问题的另一个“技巧”：<strong>具有特殊结构的考虑位置的双层MLP</strong>。在多头注意力之后，他们通过一个可学习的权重 h_i^ℓ+1 将投影到一个更高的维度，在该维度中， h_i^ℓ+1 经过ReLU非线性变换，然后投影回其原始维度，然后再进行另一个归一化操作：</p><p><img src="https://i.loli.net/2020/10/20/8mlU4tj9YgzvGKX.png" alt="image-20201019201217429"></p><p>说实话，我不确定超参数化前馈子层背后的确切理由是什么，似乎也没有人对此提出疑问！我认为LayerNorm和缩放的点积不能完全解决突出的问题，因此大型MLP是一种可以相互独立地重新缩放特征向量的手段。</p><p>Transformer层的最终形态如下所示：</p><p><img src="https://i.loli.net/2020/10/19/2YgkMdw7l5JyPGT.png" alt="img" style="zoom:50%;"></p><p>Transformer架构也非常适合非常深的网络，使NLP界能够在模型参数和扩展数据这两方面进行延伸。</p><p>每个多头注意力子层和前馈子层的输入和输出之间的残差连接是堆叠Transformer层的关键（但为了清楚起见，在上图中省略了）。</p><h4 id="gnns构建图的表示">GNNs构建图的表示</h4><p>图卷积网络是图神经网络的一个分类</p><p>图神经网络（GNNs）或图卷积网络（GCNs）在图数据中建立节点和边的表示（representations）。它们是通过<strong>邻域聚合</strong>（或消息传递）（<strong>neighbourhood aggregation</strong> or message passing）来实现的，<strong>在邻域聚合中，每个节点从其邻域收集特征，以更新其周围的局部图结构表示</strong>。通过堆叠多个GNN层使得该模型可以将每个节点的特征传播到整个图中，从其邻居传播到邻居的邻居，依此类推。</p><p><img src="https://i.loli.net/2020/10/20/WD2hXpu18kmSqKU.png" alt="image-20201019201748102"></p><p>以这个表情符号社交网络为例：由GNN产生的节点特征可用于预测性任务，例如识别最有影响力的成员或提出潜在的联系。</p><p>在他们最基本的形式中，GNNs通过以下方法来更新节点i在ℓ层的隐藏层特征h（例如，😆），也就是先将节点自身的特征 h_i^l 和每个邻居节点 j∈N(i) 特征 h_j^l 的聚合相累加，然后再整体做一个<strong>非线性变换</strong>，如下：</p><p><img src="https://i.loli.net/2020/10/20/Meg8lO7IcuADTd3.png" alt="image-20201019202233150"></p><p>其中U<sup>l,V</sup>l是GNN层的可学习的权重矩阵，而<img src="https://i.loli.net/2020/10/20/rtfhOwx4lTWRjXz.png" alt="image-20201019202245048">是一个非线性变换，例如ReLU。</p><p>在上述例子中，N (😆) ={ 😘, 😎, 😜, 🤩 }。</p><p>邻域节点 j∈N(i) 上的求和可以被其他输入大小不变的聚合函数代替，例如简单的均值/最大值函数或其他更强大的函数（如通过注意机制的加权和）。</p><p>这听起来熟悉吗？</p><p>也许这样一条流程可以帮助建立连接：</p><p><img src="https://i.loli.net/2020/10/20/Askv9i74DwX3zIP.png" alt="image-20201019202551797"></p><blockquote><p><strong>如果我们要执行多个并行的邻域聚合头，并且用注意力机制（即加权和）替换领域上的求和 ，我们将获得图注意力网络（GAT）。加上归一化和前馈MLP，瞧，我们就有了Graph Transformer！</strong></p></blockquote><h3 id="句子就是由词全连接而成的图">句子就是由词全连接而成的图</h3><p>Sentences are fully-connected word graphs</p><p>为了使连接更加清晰，可以将一个句子看作一个完全连接的图，其中每个单词都连接到其他每个单词。现在，我们可以<strong>使用GNN来为图（句子）中的每个节点（单词）构建特征</strong>，然后我们可以使用它来执行NLP任务。</p><p><img src="https://i.loli.net/2020/10/20/YbeLK31vHIjUNRp.png" alt="image-20201019203155390"></p><p>广义上来讲，这就是Transformers正在做的事情：Transformers是以多头注意力作为邻居聚合函数的GNNs（<strong>GNNs with multi-head attention</strong> as the neighbourhood aggregation function ）。<strong>标准GNNs从其局部邻域节点j∈N(i) 聚合特征，而NLP的<code>Transformers将整个句子视为局部邻域</code>，在每个层聚合来自每个单词j∈S的特征。</strong></p><p>重要的是，各种特定于问题的技巧（如位置编码、因果/掩码聚合、学习率表和大量的预训练）对于Transformers的成功至关重要，但在GNN界中却很少出现。同时，从GNN的角度看Transformers可以启发我们摆脱模型结构中的许多花哨的玩意。</p><h3 id="可以从transformers和gnn中学到什么">可以从Transformers和GNN中学到什么？</h3><p>现在我们已经在Transformers和GNN之间建立了联系，接着让我们来探讨一些新的问题...</p><h4 id="全连接图是nlp的最佳输入格式吗">全连接图是NLP的最佳输入格式吗？</h4><p>在统计NLP和ML之前，Noam Chomsky等语言学家致力于发展语言结构的最新理论，如语法树/图。Tree LSTMs已经尝试过这一点，但是也许Transformers/GNNs是可以让语言理论和统计NLP的领域结合得更加紧密的更好的架构？</p><p><img src="https://i.loli.net/2020/10/20/XuSVtxfpclmaCjs.png" alt="image-20201019203855101"></p><h4 id="如何学习到长期依赖">如何学习到长期依赖？</h4><p><strong>完全连通图使得学习词与词之间的非常长期的依赖关系变得非常困难，这是完全连通图的另一个问题。</strong>这仅仅是因为图中的边数与节点数成二次平方关系，即在n个单词的句子中，Transformer/GNN将在n^2对单词上进行计算。如果n很大，那将会是一个非常棘手的问题。</p><p>NLP界对长序列和依赖性问题的看法很有意思：例如，使注意力机制在输入大小方面稀疏或自适应，在每一层中添加递归或压缩，以及使用对局部性敏感的哈希法进行有效的注意，这些都是优化Transformers有希望的新想法。</p><p>有趣的是，还可以看到一些GNN界的想法被混入其中，例如，用于句子图稀疏化的二进制分区似乎是另一种令人兴奋的方法。</p><p><img src="https://i.loli.net/2020/10/20/7JndG8ZPg3zUWE1.png" alt="image-20201019210515688"></p><h4 id="transformers在学习神经网络的句法吗">Transformers在学习神经网络的句法吗？</h4><p>NLP界有几篇关于Transformers可能学到什么的有趣论文。其基本前提是，对句子中的所有词对使用注意力机制（目的是确定哪些词对最有趣），可以让Transformers学习特定任务句法之类的东西。</p><p>多头注意力中的不同头也可能“关注”不同的句法属性。</p><p>从图的角度来看，通过在完全图上使用GNN，我们能否从GNN在每一层执行邻域聚合的方法中恢复最重要的边线及其可能带来的影响？我还不太相信这种观点。</p><p><img src="https://i.loli.net/2020/10/20/cNW2ZmO7yExKo4s.png" alt="image-20201019211524983"></p><h4 id="为什么要用多头注意力为什么要用注意力机制">为什么要用多头注意力？为什么要用注意力机制？</h4><p>我更赞同多头机制的优化观点——拥有多个注意力可以改进学习，克服不好的随机初始化。例如，这些论文表明，Transformers头可以在训练后“修剪”或“删除”，并且不会产生重大的性能影响。</p><p>多头邻聚合机制在GNNs中也被证明是有效的，例如在GAT使用相同的多头注意力，MoNet使用多个高斯核来聚合特征。虽然多头技巧是为了稳定注意力机制而发明的，但它能否成为提炼出额外模型性能的标准？</p><p>相反，具有简单聚合函数（如sum或max）的GNNs不需要多个聚合头来维持稳定的训练。如果我们不需要计算句子中每个词对之间的成对兼容性，对Transformers来说不是很好吗？</p><p>Transformers能从抛弃注意力中获益吗？Yann Dauphin和合作者最近的工作提出了另一种ConvNet架构。Transformers也可能最终会做一些类似于ConvNets的事情。</p><p><img src="https://i.loli.net/2020/10/20/x8a9EmGXlARLJpw.png" alt="img"></p><h4 id="为什么transformers这么难训练">为什么Transformers这么难训练？</h4><p>阅读新的Transformer论文让我觉得，在确定最佳学习率表、预热策略和衰减设置时，训练这些模型需要一些类似于黑魔法的东西。这可能仅仅是因为模型太大，而且所研究的NLP任务非常具有挑战性。</p><p>但是最近的结果表明，这也可能是由于结构中归一化和残差连接的特定组合导致的。</p><p>在这一点上我很在意，但是也让我感到怀疑：我们真的需要代价昂贵的成对的多头注意力结构，超参数化的MLP子层以及复杂的学习计划吗？</p><p>我们真的需要具有大量碳足迹的（译者注：有人提出现在训练一个模型相当于5辆汽车一天的排碳量）大规模模型吗？</p><p>具有良好归纳偏差的架构难道不容易训练吗？</p><p>参考</p><blockquote><p><a href="https://graphdeeplearning.github.io/post/transformers-are-gnns/" target="_blank" rel="noopener" class="uri">https://graphdeeplearning.github.io/post/transformers-are-gnns/</a></p><p><a href="https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/104666156" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/104666156</a></p></blockquote><h3 id="总结如下">总结如下</h3><p>句子就是由词全连接而成的图</p><p>如果我们要执行多个并行的邻域聚合头，并且用注意力机制（即加权和）替换领域上的求和 ，我们将获得图注意力网络（GAT）。加上归一化和前馈MLP，瞧，我们就有了Graph Transformer！</p><p>Transformers是以多头注意力作为邻居聚合函数的GNNs（<strong>GNNs with multi-head attention</strong> as the neighbourhood aggregation function ）。<strong>标准GNNs从其局部邻域节点j∈N(i) 聚合特征，而NLP的<code>Transformers将整个句子视为局部邻域</code>，在每个层聚合来自每个单词j∈S的特征。</strong></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      transformer和GNN的关系理解,翻译自南洋理工大学助理研究员Chaitanya Joshi的博客
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-10-17-论文分享</title>
    <link href="http://yoursite.com/2020/10/17/2020-10-17-%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"/>
    <id>http://yoursite.com/2020/10/17/2020-10-17-%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/</id>
    <published>2020-10-17T13:36:45.000Z</published>
    <updated>2020-10-20T07:12:25.997Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言">前言</h3><p>本次阅读的论文是《Greedy Layerwise Learning Can Scale to ImageNet》，本周日论文分享组会中汇报</p><h3 id="论文">论文</h3><blockquote><p>《Greedy Layerwise Learning Can Scale to ImageNet》</p><p>ICML 2019</p><p>code url （pytorch） ：<a href="https://github.com/eugenium/layerCNN" target="_blank" rel="noopener" class="uri">https://github.com/eugenium/layerCNN</a></p></blockquote><p>两年前的code了 ，最近一次提交也是一年前，更新了readme说明部分。但是为什么在论文中没有说明呢？</p><p>看了代码，发现好像没有什么特别之处，就是这样一个逻辑</p><h4 id="背景">背景</h4><p>浅层监督的1隐藏层（ 1-hidden layer ）神经网络具有许多有利的属性，这些属性使它们比深层次的同类神经网络更易于解释，分析和优化，但缺乏表示能力。</p><p>深度神经网络（CNN）并不一定需要共同学习各个CNN层以获得高性能。</p><h4 id="问题">问题</h4><p>同时多层网络较为复杂，尚不清楚各层如何协同工作以实现高精度的预测。</p><p>就计算和内存资源而言，端到端的反向传播效率可能较低。</p><h4 id="解决">解决</h4><p>本文主要工作就是使用1隐藏层学习问题来逐层顺序构建深度网络，从而可以从浅层网络继承有利属性。</p><p>将上述这种greedy layerwise learning 拓展到了imagenet和CIFAR-10数据集等大型数据集上，应用场景是图像分类任务。</p><p>greedy approach 将更少地依赖于获得完整的梯度。不需要存储大多数中间激活，也不需要计算大多数中间梯度。 这样不需要很多的计算资源。本文就是解决将分层训练策略（ layer-wise training strategies）应用到大规模数据集的问题</p><h4 id="结果">结果</h4><p>使用一组简单的架构和培训构想，我们发现解决顺序出现的1隐藏层辅助问题会导致CNN超过ImageNet上的AlexNet性能。</p><h4 id="背景知识">背景知识</h4><h5 id="深层网络的贪婪逐层预训练方法greedy-layer-wise-train">深层网络的贪婪逐层预训练方法（greedy layer-wise train）</h5><p>每次只训练网络中的一层，即我们首先训练一个只含一个隐藏层的网络，仅当这层网络训练结束之后才开始训练一个有两个隐藏层的网络，以此类推。</p><p>在每一步中，我们把已经训练好的前k-1层固定，然后增加第k层（也就是将我们已经训练好的前k-1的输出作为输入）。每一层的训练可以是有监督的（例如，将每一步的分类误差作为目标函数），但更通常使用无监督方法（例如自动编码器）。</p><p>这些各层单独训练所得到的权重被用来初始化最终（或者说全部）的深度网络的权重，然后对整个网络进行“微调”（即把所有层放在一起来优化有标签训练集上的训练误差）。</p><p>考虑一个神经网络，如下图所示。它的输入是6维向量，输出是3维向量，代表输入样本属于三个类别的概率。</p><p><img src="https://i.loli.net/2020/10/18/OUnJaYGuvNDTzq1.png" alt="img"></p><p>最开始我们通过高斯分布随机初始化网络参数，然后逐层地优化网络参数。首先第一层。如下图，我们只保留输入层Input和第一个隐藏层Features I，其余层去掉。</p><p>之后，加入一个输出层，该<strong>输出层的输出向量维度和输入层一样</strong>，从而构成一个自编码器。我们训练这个自编码器，便可以得到第一层的网络参数，即绿线部分。</p><p><img src="https://i.loli.net/2020/10/18/SeutKCU7da1ImxF.png" alt="img"></p><p>然后是第二层的网络参数。如下图，我们只保留原始神经网络中的第一个隐藏层和第二个隐藏层，其余层去掉。</p><p>之后添加一个输出层，其输出向量维度和第一个隐藏层维度一样，从而构成一个自编码器，自编码器的输入是第一个隐藏层。</p><p>优化这个自编码器，我们就可以得到第二层网络参数，即红线部分。</p><p><img src="https://i.loli.net/2020/10/18/HVRc9A8xG5y2Mvj.png" alt="img"></p><p>优化这两个自编码器的过程就是逐层贪婪预训练。由于每个自编码器都只是优化了一层隐藏层，所以每个隐藏层的参数都只是局部最优的。</p><p>优化完这两个自编码器之后，我们把优化后的网络参数作为神经网络的初始值，之后微调（fine tune）整个网络，直到网络收敛。</p><h4 id="模型">模型</h4><h5 id="模型架构">模型架构</h5><p><img src="https://i.loli.net/2020/10/18/3wXjSyEbUKnsP7A.png" alt="image-20201018104055941"></p><p><img src="https://i.loli.net/2020/10/18/jR9JAHOolUP6Bmv.png" alt="image-20201018104658134"></p><p><img src="https://i.loli.net/2020/10/18/IXaq52BcrGbgyDk.png" alt="image-20201018104744620"></p><p>Xj+1 ：先对上一次训练的结果进行下采样 （ invertible downsampling 可逆下采样操作），然后进行CNN ， 再进行RELU函数</p><p>Ｚj+1 : 对Xj+1 进行辅助分类器操作得到，预测zj计算中间分类输出。</p><p><img src="https://i.loli.net/2020/10/18/ZlFPWJGkA5mHBtv.png" alt="image-20201018105215075"></p><p>根据1式，xj已经经过了一层卷积，又W是从0开始的，所以下标只有k-2</p><p><img src="https://i.loli.net/2020/10/18/dPVRxjHkbNmGvws.png" alt="image-20201018105539176"></p><h5 id="损失函数">损失函数</h5><p><img src="https://i.loli.net/2020/10/18/8vO62gaeNxE9Bnl.png" alt="image-20201018104427451"></p><h5 id="算法流程">算法流程</h5><p><img src="https://i.loli.net/2020/10/18/2PJMlYuLHEW4XQN.png" alt="image-20201018104104058"></p><hr><h3 id="小样本的预训练">小样本的预训练</h3><p><strong>预训练</strong>是（Pre-training）大家都熟悉且非常有效的获取先验知识的方法。具体就是在大型数据集上，学习一个强大的神经网络作为特征提取器，例如CV里面常见的在ImageNet上预训练的ResNet网络，或是NLP里面在Wikipedia上训练的BERT，都代表一种特征表达的先验知识。</p><p><strong>在预训练基础上，我们只需在样本数量少的目标任务中，微调部分（例如只训练最后一层fc分类器）或者全部网络的参数，便得到了一个可以解决小样本学习问题的模型。</strong></p><p>预训练相当于给了小样本学习一个好的起点，就像一个人在上课前预习了大量的知识点。不过想要更上一层楼，还需要<strong>有效的学习方法</strong>。<strong>元学习</strong>（meta learning）的目的就是找到这种方法。具体来说，我们可以从<strong>预训练集</strong>中，每次采样出来一个“沙盒”版小样本任务，例如选5个类，每个类选5张图片作为训练集（support set），再选15张作为测试集（query set），然后我们要求模型在support set训练的结果，能够在query set上面取得好的表现。其实这种学习策略在我们身边随处可见，例如准备考试的时候，我们会提前做一些模拟测试，了解题型，规划答题节奏等等，这就是一种元学习。在小样本学习的实际操作中，我们可以使用元学习训练一个模型的初始化参数（MAML），或是一个分类器参数的生成网络（LEO）等等。通过元学习得到的知识，就构成了一种学习方法的先验知识，在预训练的网络之上，进一步提升小样本学习的表现。</p><p><strong>预训练是小样本学习中一个核心的环节</strong>，无论是基于微调的，还是基于元学习的方法，都以预训练为开始。那么从常理来说，更强的预训练，应该会带来更好的小样本学习的表现，例如在现有文献中，使用更深层的神经网络架构<strong>WRN-28-10</strong>的微调结果，往往会比相对较浅的<strong>ResNet-10</strong>表现好很多。</p><blockquote><p>利用其它的网络进行预训练，然后再进行元学习+微调，或者直接微调操作</p></blockquote><p><strong>小样本学习的解决思路</strong>，可以用下面这张图来概括：我们先在一个大的数据集 D 上面预训练一个特征提取网络Ω ，之后我们既可以直接使用 Ω在每一个小样本任务中微调(红色方块的Fine-Tuning);</p><p>也可以进一步使用元学习(Meta-Learning)，将D 拆成一个个由support set S和query set Q 组成的沙盒任务（Si，Qi） ，训练高效的学习方法；元学习结束以后，我们就可以用这种高效的学习方法，在小样本学习的任务中进行微调(绿色方块的Fine-Tuning)。</p><p><img src="https://i.loli.net/2020/10/19/6QDIWERFnLOHpeo.jpg" alt="img">小样本学习的两种解决思路。</p><hr><h3 id="小样本的演变">小样本的演变</h3><p>小样本学习一般会简化为N-way K-shot问题，如图[1]。其中N代表类别数量，K代表每一类中(支持集)的样本量；</p><p><img src="https://i.loli.net/2020/10/19/deMzbQKUACDHYgj.jpg" alt="图[1] N-way K-shot"></p><p>解决分类问题，人们最先想到的是采用传统监督学习的方式，直接在训练集上进行训练，在测试集上进行测试，如图[2]，但神经网络需要优化的参数量是巨大的，<strong>在少样本条件下，几乎都会发生过拟合</strong>；</p><p><img src="https://i.loli.net/2020/10/19/H1aK73enx4MtJYL.jpg" alt="图[2] 传统监督学习"></p><p>为了解决上述问题，人们首先想到的是通过<strong>使用迁移学习+Fine-tune的方式</strong>，<strong>利用Base-classes中的大量数据进行网络训练，得到的Pre-trained模型迁移到Novel-classes进行Fine-tune</strong>，如图[3]。虽然是Pre-trained网络+Fine-tune微调可以避免部分情况的过拟合问题，但是当数据量很少的时候，<strong>仍然存在较大过拟合的风险</strong>。</p><p><img src="https://i.loli.net/2020/10/19/2zCAg5987iLqZxF.jpg" alt="图[3] Pre-trained网络+Fine-tune微调"></p><p>接下来讲的就是小样本学习中极具分量的<strong>Meta-learning</strong>方法，现阶段绝大部分的小样本学习都使用的是Meta-learning方法。Meta-learning，即learn to learn，翻译成中文是元学习。Meta-learning共分为Training和Testing两个阶段，Training阶段的思路如图[4]。简单描述下流程：</p><p>1：将训练集采样成Support set和Query set两部分；</p><p>2：基于Support set生成一个分类模型；</p><p>3：利用模型对Query set进行分类预测生成predict labels；</p><p>4：通过query labels和predict labels进行Loss(e.g., cross entropy loss )计算，从而对分类模型中的参数θ进行优化。</p><p><img src="https://i.loli.net/2020/10/19/JyE325Rwtp4lBNM.jpg" alt="图[4] Meta-learning Training阶段思路"></p><p>Testing阶段的思路如图[5]，利用Training阶段学来的分类模型在Novel class的Support set上进行进一步学习，学到的模型对Novel class的Query set进行预测。</p><p><img src="https://i.loli.net/2020/10/19/XS2uiqF3seQptVd.jpg" alt="图[5] Meta-learning Testing阶段思路"></p><p>介绍到这里，Meta-learning的整体流程的流程就介绍完了，如图[6];</p><p>现在反过来看，Meta-learning核心点之一是如何通过少量样本来学习这个分类模型，即图[6]中的keyu部分。</p><p><img src="https://i.loli.net/2020/10/19/cg7HEokwPnB5S3N.jpg" alt="图[6] Meta-learning整体流程以及key point"></p><h3 id="预训练与微调">预训练与微调</h3><p>假设我们想从图像中识别出不同种类的椅子，然后将购买链接推荐给用户。一种可能的方法是先找出100种常见的椅子，为每种椅子拍摄1,000张不同角度的图像，然后在收集到的图像数据集上训练一个分类模型。这个椅子数据集虽然可能比Fashion-MNIST数据集要庞大，但样本数仍然不及ImageNet数据集中样本数的十分之一。这可能会导致适用于ImageNet数据集的复杂模型在这个椅子数据集上过拟合。同时，因为数据量有限，最终训练得到的模型的精度也可能达不到实用的要求。</p><p>为了应对上述问题，一个显而易见的解决办法是收集更多的数据。然而，收集和标注数据会花费大量的时间和资金。例如，为了收集ImageNet数据集，研究人员花费了数百万美元的研究经费。虽然目前的数据采集成本已降低了不少，但其成本仍然不可忽略。</p><p>另外一种解决办法是应用迁移学习（transfer learning），将从源数据集学到的知识迁移到目标数据集上。例如，虽然ImageNet数据集的图像大多跟椅子无关，但在该数据集上训练的模型可以抽取较通用的图像特征，从而能够帮助识别边缘、纹理、形状和物体组成等。这些类似的特征对于识别椅子也可能同样有效。</p><p>本节我们介绍迁移学习中的一种常用技术：<strong>微调（fine tuning）</strong>。如图所示，微调由以下4步构成。</p><ol type="1"><li><p>在源数据集（如ImageNet数据集）上预训练一个神经网络模型，即源模型。</p></li><li><p>创建一个新的神经网络模型，即目标模型。它复制了源模型上除了输出层外的所有模型设计及其参数。我们假设这些模型参数包含了源数据集上学习到的知识，且这些知识同样适用于目标数据集。我们还假设源模型的输出层与源数据集的标签紧密相关，因此在目标模型中不予采用。</p></li><li><p>为目标模型添加一个输出大小为目标数据集类别个数的输出层，并随机初始化该层的模型参数。</p></li><li><p>在目标数据集（如椅子数据集）上训练目标模型。我们将从头训练输出层，而其余层的参数都是基于源模型的参数微调得到的。</p><p><img src="https://i.loli.net/2020/10/19/RGUqhE9bWox6iFj.png" alt="image-20201019213025514"></p></li></ol><p><strong>当目标数据集远小于源数据集时，微调有助于提升模型的泛化能力。</strong></p><h4 id="小结">小结</h4><ul><li>迁移学习将从源数据集学到的知识迁移到目标数据集上。微调是迁移学习的一种常用技术。</li><li>目标模型复制了源模型上除了输出层外的所有模型设计及其参数，并基于目标数据集微调这些参数。而目标模型的输出层需要从头训练。</li><li>一般来说，微调参数会使用较小的学习率，而从头训练输出层可以使用较大的学习率。</li></ul><p><span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8">⭐</span> 具体实例可以参考下面的链接</p><h4 id="参考">参考</h4><blockquote><p><a href="http://zh.gluon.ai/chapter_computer-vision/fine-tuning.html" target="_blank" rel="noopener" class="uri">http://zh.gluon.ai/chapter_computer-vision/fine-tuning.html</a></p><p><a href="https://zhuanlan.zhihu.com/p/35890660" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/35890660</a></p></blockquote><h3 id="benchmark-和-baseline">Benchmark 和 baseline</h3><blockquote><p>benchmark：N-COUNT A <strong>benchmark</strong> is something whose quality or quantity is known and which can therefore be used as a standard with which other things can be compared.</p></blockquote><p>通俗的讲，一个算法之所以被称为benchmark，是因为它的<strong>性能已经被广泛研究，人们对它性能的表现形式、测量方法都非常熟悉，因此可以作为标准方法来衡量其他方法的好坏</strong>。 这里需要区别state-of-the-art（SOTA），能够称为SOTA的算法表明其性能在当前属于最佳性能。如果一个新算法以SOTA作为benchmark，这当然是最好的了，但如果比不过SOTA，能比benchmark要好，且方法有一定创新，也是可以发表的。</p><blockquote><p>baseline：N-COUNT A <strong>baseline</strong> is a value or starting point on a scale with which other values can be compared.</p></blockquote><p>通俗的讲，一个算法被称为baseline，基本上表示<strong>比这个算法性能还差的基本上不能接受的</strong>，除非方法上有革命性的创新点，而且还有巨大的改进空间和超越benchmark的潜力，只是因为是发展初期而性能有限。所以baseline有一个自带的含义就是“<strong>性能起点</strong>”。这里还需要指出其另一个应用语境，就是<strong>在算法优化过程中，一般version1.0是作为baseline的，即这是你的算法能达到的一个基本性能，在算法继续优化和调参数的过程中，你的目标是比这个性能更好</strong>，因此需要在这个base line的基础上往上跳。</p><p>简而言之， benchmark一般是和同行中比较牛的算法比较，比牛算法还好，那你可以考虑发好一点的会议/期刊； baseline一般是自己算法优化和调参过程中自己和自己比较，目标是越来越好，当性能超过benchmark时，可以发表了，当性能甚至超过SOTA时，恭喜你，考虑投顶会顶刊啦。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录阅读的论文
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-10-13-小样本学习</title>
    <link href="http://yoursite.com/2020/10/13/2020-10-13-%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yoursite.com/2020/10/13/2020-10-13-%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/</id>
    <published>2020-10-13T07:44:01.000Z</published>
    <updated>2020-10-20T07:03:24.089Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言">前言</h3><p>最近了解了一下小样本学习的相关知识，这几天看了几篇论文介绍如下</p><h3 id="综述">综述</h3><p>Generalizing from a Few Examples : A Survey on Few-Shot Learning</p><h4 id="简介">简介</h4><p>问题</p><p>（a）例如典型的 MNIST 分类问题，一共有 10 个类，训练集一共有 6000 个样本，平均下来每个类大约 600 个样本，但是我们想一下我们人类不需要这么多样本，这表明当前的深度学习技术和我们人类智能差距还是很大的，要想弥补这一差距，<strong>小样本学习是一个很关键的问题。</strong></p><ol start="2" type="a"><li>如果想要构建新的数据集（以分类数据集为例），我们需要<strong>标记大量的数据</strong>，但是有的时候标记数据集需要某些领域的专家（例如医学图像的标记），这费时又费力，因此<strong>如果我们可以解决小样本学习问题，只需要每个类标记几张图片就可以高准确率的给剩余大量图片自动标记。</strong></li></ol><p><strong>以上两个原因使得小样本学习的研究成为热点。</strong></p><p><strong>小样本学习（Few-Shot Learning，以下简称 FSL ）</strong>用于解决当可用的数据量比较少时，如何提升神经网络的性能。</p><h4 id="定义">定义</h4><p>以下是FSL的一些符号术语</p><p><img src="https://i.loli.net/2020/10/15/Wy3Yzfv8OibZsgS.png" alt="image-20201015093502514"></p><p><img src="https://i.loli.net/2020/10/15/3Dy7SHqXgEIPwUB.png" alt="image-20201015164223838"></p><p>FSL是机器学习的一个子领域，所以先来介绍一下机器学习定义</p><p>机器学习：</p><p><img src="https://i.loli.net/2020/10/15/kNUTzD2WLYIgpZf.png" alt="image-20201015093951256"></p><p>给定一个任务T，任务的性能P，给定一些经验E，比如通过训练学习得到的标注数据，可以提升任务T的性能P</p><p>以下是简单例子</p><p><img src="https://i.loli.net/2020/10/15/4pRq6PcLUYgbKC5.png" alt="image-20201015094231448"></p><p>在传统机器学习中需要很多样本信息，但是在实际中是很困难的，所以FSL就是解决这类问题。在训练集Dtrain中提供的监督信息有限的情况下，包括（输入xi和对应的输出yi），来获得好的学习性能</p><p>FSL 小样本学习</p><p><img src="https://i.loli.net/2020/10/15/KT7aSbA6hg3iXVq.png" alt="image-20201015094815702"></p><p>和机器学习定义类似，只是E包含了有限的监督信息的样例（example）。也即，每个类class中包含了很少的有标签样例。</p><p><strong>小样本分类</strong>主要就是学习一个分类器h，能够预测每一个输入数据xi的标签yi，通常使用的是N-way-K-shot分类方法，N个类，每个类有K个例子。其中 Dtrain包括I=KN个例子</p><p><img src="E:\myBlog\source_posts\image-20201015095811521.png" alt="image-20201015095811521"></p><p>只要关注的是image classification .可以看到相比于机器学习，FSL在经验E部分多了一个prior knowledge，也就是如果只是一些少的监督信息的样例不足以去解决tesk T中的问题，如图像分类。所以还是<strong>需要结合一些先验知识。</strong></p><blockquote><p>处理目标T（target T）时，在E中的监督信息如果只有一个例子的话，那么就是one-shot learning。</p><p>处理目标T（target T）时，当E中没有任何监督信息例子的话，那么就是zero-shot learning。</p><p>Zero-shot Learing <strong>就是训练样本里没有这个类别的样本，但是如果我们可以学到一个好的映射，这个映射好到我们即使在训练的时候没看到这个类，但是我们在遇到的时候依然能通过这个映射得到这个新类的特征。</strong></p><p><strong>即：训练集</strong>中<strong>没有出现过</strong>的<strong>类别</strong>，能自动创造出相应的映射。</p></blockquote><p>主要问题</p><p>在机器学习中寻找最适合的假设时通常都是通过找到一组最优的参数来确定这个假设，并通过给定的训练集，最小化损失函数这一目标来指示最优参数的搜索，<strong>最小化损失函数</strong>如下所示：</p><p>　　　　<img src="https://i.loli.net/2020/10/15/kHsi7YgaSIVQeGr.png" alt="img"></p><p>　　在训练模型中，我们是通过训练集来拟合真实分布，我们训练出来的分布和真实分布往往不一样，这<strong>中间的差值称为期望风险（期望损失）</strong>，表达式如下：</p><p>　　　　<img src="https://i.loli.net/2020/10/15/sXLuTmn7SzlaFUV.png" alt="img"></p><p>　理论上说，<strong>让期望风险最下化才能逼近真实分布</strong>，但因为你并不知道真实分布，所有最小化期望风险是无法实现的</p><p>在机器学习中通常用经验风险来替换期望风险，经验风险就是在训练集上预测的结果和真实结果的差异，也是我们常说的<strong>损失函数</strong>，表达式如下：</p><p>　　　　<img src="https://i.loli.net/2020/10/15/UO37Pd9GIqjxBDL.png" alt="img"></p><p>　　我们给出下面一个符号描述：</p><p>　　　　<img src="https://i.loli.net/2020/10/15/OK6DQwaZ34Bbct2.png" alt="img"></p><p>h^是真实分布的假设</p><p>h∗是假设空间H中最接近h^的假设</p><p>而hI是通过最小化经验损失得到的假设。根据机器学习中的误差分解可得：</p><p>　　　　<img src="https://i.loli.net/2020/10/15/h9Loiz4wqbFX2Qj.png" alt="img"></p><p>　　等式右边第一项表示的是<strong>假设空间H中最优的假设和真实假设的误差</strong>，这一项其实<strong>由所选择的模型和参数的初始化分布决定的</strong>，这也就是为什么有的时候，模型选择的简单了，给再多的数据也训练不好，欠拟合。</p><p>第二项就是<strong>训练得到的假设和H中最优假设的误差</strong>，我们训练得到的假设也是从假设空间H中选择的，但有时候会陷入局部最优，或者提供的训练数据分布有偏差，导致无法到全局最优。</p><p>　　但理论上对于第二项，当样本数量II足够大时，有：</p><p>　　　　<img src="https://i.loli.net/2020/10/15/wnJhz4qAXgjUrQR.png" alt="img"></p><p><img src="https://i.loli.net/2020/10/15/diHcTjyW1hPGMNQ.png" alt="image-20201015102743694"></p><p>　<strong>传统的机器学习都是建立在大规模的训练数据上的，因此εest(H,I)是很小的，但是在FSL任务上，训练数据很小，因此εest(H,I)是很大的，</strong>此时采用传统的训练模式，如softmax+交叉熵，是极容易陷入过拟合的。</p><p><strong>所以需要更多的先验知识</strong></p><p>具体的图如下：</p><p><img src="https://i.loli.net/2020/10/15/mp3Bjruof89JskS.png" alt="image-20201015103318798"></p><p>解决方法-分类：</p><p><img src="https://i.loli.net/2020/10/15/XS5ZnfOL8mMHow2.png" alt="image-20201015103338811"></p><p>假设空间的确定就是模型函数的可行性范围</p><p><strong>Data</strong></p><p>　　Data就是通过先验知识来做<strong>数据增强</strong>， 数据量增大可以获得可靠的hI，自然能解决上述问题。</p><p>通常进行手动操作对FSL进行数据预处理。例如在图像上，比如图片的旋转剪切放缩等，句子中的同义词替换等，以及复杂的生成模型生成和真实数据相近的数据。数据增强的方式有很多种，大量的合适的增强一定程度上可以缓解FSL问题，但需要耗费大量的精力，以及很强的域知识，只是针对特定的数据集，很难应用到其它数据集中，因此<strong>不能很好的解决FSL问题</strong></p><p>分类</p><p><img src="https://i.loli.net/2020/10/15/umBnUeEhCTFfrbo.png" alt="image-20201015110602917"></p><p><img src="https://i.loli.net/2020/10/15/VgKI5RENmQXtipo.png" alt="image-20201015110557216"></p><p><strong>Model</strong></p><p>　　通过先验知识来<strong>限制模型复杂度，降低假设空间H的大小</strong>，使得当前的数据集可以满足</p><p>如果我们想使用机器学习模型来解决FSL问题，我们需要使用假设空间H很小的模型，这样样本复杂度也就小了，对于一些简单的任务，这样是可行的，但是对于复杂的任务，小的模型会导致εapp(H)很大，而现实中大多数任务都很复杂，它们的特征很多，且特征维度也很高。</p><p>因此我们<strong>只能一开始给一个假设空间H很大的模型，然后通过一些先验知识将这个空间中无效的hypothesis去掉，缩小假设空间H</strong>，但实际上和<strong>模型剪枝</strong>中的理念类似，你一开始给一个小的模型，这个模型空间离真实假设太远了，而你给一个大的模型空间，它离真实假设近的概率比较大，然后通过先验知识去掉哪些离真实假设远的假设。</p><p><img src="https://i.loli.net/2020/10/15/1R2cuKxSPkaFwUb.png" alt="image-20201015110729588"></p><p><strong>Algorithm</strong></p><p>　　通过先验知识来提供一个好的搜索策略，可以是一个好的搜索起始点，也可以是一个明确的搜索策略，来寻找最优点。</p><p>在机器学习中我们<strong>通常使用SGD以及它的变体，如ADAM，RMSProp等来更新参数，寻找最优的参数</strong>，对应到假设空间H中最优的假设h∗。这种方式在有大量的数据集的情况下可以用来慢慢迭代更新寻找最优参数，但是在FSL任务中，样本数量很少，这种方法就失效了。在这一节，我们不再限制假设空间。</p><p>根据使用不同的先验知识，可以将ALGORITHM分为下面3类：</p><p><img src="https://i.loli.net/2020/10/15/lr86fNGOuwLtPZn.png" alt="image-20201015110816197"></p><p>　　接下来的工作都是围绕这几个方向展开来求解FSL问题。</p><p><img src="https://i.loli.net/2020/10/15/a5x4EvrUSj3WAl1.png" alt="image-20201015103435972"></p><h3 id="应用">应用</h3><p><strong>Few-shot Learning Meta Learning 在监督学习领域的应用。</strong></p><p><strong>Meta Learning研究Task！</strong></p><p>Meta Learning，又称为 learning to learn，在 meta training 阶段将数据集分解为不同的 meta task，去学习类别变化的情况下模型的泛化能力，在 meta testing 阶段，面对全新的类别，不需要变动已有的模型，就可以完成分类。<strong>如果我们构建的深度学习系统能够学到先验知识，并且能够利用这些知识，我们就可以在新的问题上学的更快更好</strong>！那么，这个就是Meta Learning要做的事情了</p><p><strong>不是要学一个具体的模型，我们要学的是一个先验知识</strong>。<strong>如果我们已有的先验知识来帮助我们解决新的问题，那么我们对于新的问题就可以不需要那么多的样本，从而解决 few-shot 问题</strong>。</p><p>形式化来说，few-shot 的训练集中包含了很多的类别，每个类别中有多个样本。在训练阶段，会在训练集中<strong>随机抽取</strong> C 个类别，每个类别 K 个样本（总共 CK 个数据），构建一个 meta-task，作为模型的支撑集（support set）输入；再从这 C 个类中剩余的数据中抽取一批（batch）样本作为模型的预测对象（batch set）。即要求模型从 C*K 个数据中学会如何区分这 C 个类别，<strong>这样的任务被称为 C-way K-shot 问题。</strong></p><p>图 1 展示的是一个 2-way 5-shot 的示例，可以看到 meta training 阶段构建了一系列 meta-task 来让模型学习如何根据 support set 预测 batch set 中的样本的标签；meta testing 阶段的输入数据的形式与训练阶段一致（2-way 5-shot），但是会在全新的类别上构建 support set 和 batch。每一行都是一个task，包含了task的train set和test set。</p><p>我们可以把<strong>每一个task当做一个meta learning的训练样本</strong>。我们要通过多种task的训练，从而在Meta-test的时候也就是在新的task上取得好效果。</p><p><img src="https://i.loli.net/2020/10/15/n9C1hakXsYGuQAf.jpg" alt="img">▲ 图1：Few-shot Learning示例</p><h4 id="通常解决办法">通常解决办法</h4><h4 id="hypernetwork-生成参数">HyperNetwork 生成参数</h4><p><img src="https://i.loli.net/2020/10/15/oEJPShp9M2k5Nzi.png" alt="image-20201015163737823"></p><p>HyperNetwork 简单说就是<strong>用一个网络来生成另外一个网络的参数</strong>。</p><p>那么我们这里非常直接，我们的设想就是<strong>希望用一个hypernetwork输入训练集数据，然后给我输出我的对应模型也就是上图f的参数，我们希望输出的这个参数能够使得在测试图片上取得好的识别效果</strong>。</p><p>有了这样设计，这个hypernetwork其实就是一个meta network。大家可以看到，<strong>本来基本的做法是用训练集直接训练这个模型f，但是现在我们用这个hypernetwork不训练了，直接给你输出参数，这等价于hypernetwork学会了如何学习图像识别，这也是为什么meta learning也同时叫做learning to learn的原因。</strong></p><h4 id="训练">训练</h4><p><strong>训练过程</strong>中，每次训练<strong>（episode）</strong>（Dtrain | Dtest）都会采样得到不同 meta-task，所以总体来看，训练包含了不同的类别组合，这种机制使得模型学会不同 meta-task 中的共性部分，比如如何提取重要特征及比较样本相似等，忘掉 meta-task 中 task 相关部分。通过这种学习机制学到的模型，在面对新的未见过的 meta-task 时，也能较好地进行分类。</p><p>这里有个所谓的<strong>episodic training</strong>！一个<strong>episode就是包含了一个task，有训练集有测试集</strong>。我们<strong>使用训练集输入到hypernetwork，得到f的参数，然后使用测试集输入到f 得到预测的标签，最后用测试集的样本标签得到模型的loss，之后就用梯度下降进行训练。</strong>所以我们可以看到，整个模型是端到端的。通过大量的episodic training，也就是大量的task进行训练，我们就可以训练出一个模型出来。</p><p>在 meta training 阶段将数据集分解为不同的 meta task，<strong>去学习类别变化的情况下模型的泛化能力，</strong>在 meta testing 阶段，面对全新的类别，<strong>不需要变动已有的模型，就可以完成分类</strong>。</p><blockquote><p><a href="https://zhuanlan.zhihu.com/p/61215293" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/61215293</a></p></blockquote><h3 id="其它">其它</h3><h4 id="inductive-learning-与-transductive-learning">inductive learning 与 transductive learning</h4><p>在训练过程中，已知testing data（unlabelled data）是transductive learing</p><p>在训练过程中，并不知道testing data ，训练好模型后去解决未知的testing data 是inductive learing</p><p>通俗地来说inductive learning是特殊到一般的学习，测试数据只是用来测试这个通用模型的好坏；transductive learning是特殊到特殊的学习，目的就是解决target domain的问题。</p><p><img src="https://i.loli.net/2020/10/15/2HOTN5fb3Lvz7pD.png" alt="img"></p><p>现在有这个问题，已知ABC的类别，求问号的类别，</p><p>inductive learning就是只根据现有的ABC，用比如kNN距离算法来预测，在来一个新的数据的时候，还是只根据5个ABC来预测。</p><p>transductive learning直接以某种算法观察出数据的分布，这里呈现三个cluster，就根据cluster判定，不会建立一个预测的模型，如果一个新的数据加进来 就必须重新算一遍整个算法，新加的数据也会导致旧的已预测问号的结果改变</p><h4 id="representation-learning">representation learning</h4><p>在机器学习领域，表征学习（或<strong>特征学习</strong>）是一种将原始数据转换成为能够被机器学习有效开发的一种技术的集合。在特征学习算法出现之前，机器学习研究人员需要利用手动特征工程（manual feature learning）等技术从原始数据的领域知识（domain knowledge）建立特征，然后再部署相关的机器学习算法。</p><p>特征学习弥补了这一点，它使得机器不仅能学习到数据的特征，并能利用这些特征来完成一个具体的任务。</p><p>表征学习的目标不是通过学习原始数据预测某个观察结果，而是学习数据的底层结构（underlying structure），从而可以分析出原始数据的其它特性。</p><p>特征学习可以被分为两类：监督式特征学习（Supervised Representation Learning）和无监督式特征学习（Unsupervised Representation Learning）。</p><p>在监督特征学习中，被标记过的数据被当做特征用来学习。例如神经网络（Neural Networks），多层感知器（Multi-Layer Perception），监督字典学习（Supervised Dictionary Learning）。</p><p>在无监督特征学习中，未被标记过的数据被当做特征用来学习。例如无监督字典学习（Unsupervised Dictionary Learning），主成分分析（Principal Component Analysis），独立成分分析（Independent Component Analysis），自动编码（Auto-encoders），矩阵分解（Matrix Factorization） ，各种聚类分析（Clustering）及其变形。</p><blockquote><p><a href="https://www.jiqizhixin.com/graph/technologies/64d4c374-6061-46cc-8d29-d0a582934876" target="_blank" rel="noopener" class="uri">https://www.jiqizhixin.com/graph/technologies/64d4c374-6061-46cc-8d29-d0a582934876</a></p></blockquote><h3 id="论文-edge-labeling-graph-neural-network-for-few-shot-learning">论文-Edge-Labeling Graph Neural Network for Few-shot Learning</h3><p>CVPR 2019</p><p>code url： <a href="https://github.com/khy0809/fewshot-egnn" target="_blank" rel="noopener" class="uri">https://github.com/khy0809/fewshot-egnn</a></p><h5 id="abstract">Abstract</h5><p>在本文中，提出了一种新颖的边标记图神经网络（edge-labeling graph neural network ）（EGNN），该网络将边标记图上的深层神经网络应用于小样本学习。</p><p>以前在小样本学习中使用的图神经网络（GNN）方法是基于节点标记框架（ node-labeling framework）的，该框架对聚类内的相似度和聚类间不相似度进行隐式地建模（implicitly modeling）。 相反，提出的EGNN学会<strong>预测图上的边标签</strong>，而不是节点标签，从而通过直接利用聚类内的相似性和聚类间不相似性来<strong>迭代更新边标签</strong>，从而实现显式聚类的进化。 <strong>它也非常适合在各种类别上执行而无需重新训练，并且可以轻松扩展以执行直推推理（transductive inference）。</strong></p><p>EGNN的参数是通过带有边标记损失（edge-labeling loss）的episodic training来学习的，从而获得了针对未见的低数据问题的可普遍推广的模型。</p><p>在带有两个基准数据集的有监督和半监督的小样本图像分类任务上，提出的EGNN大大提高了现有GNN的性能。</p><p>对GNN的改进，提高了GNN的性能</p><p>预测图上的边标签，而不是节点标签，直接利用聚类内的相似性和聚类间不相似性来<strong>迭代更新边标签</strong>，从而实现显式聚类的进化。</p><h5 id="背景">背景</h5><p>GNN可以很好的处理数据之间丰富的关系结构，是迭代地通过消息传递（message passing）从邻居节点进行特征聚合。而小样本学习算法已显示要求充分利用support集和query集之间的关系，因此使用GNN可以自然地解决小样本学习问题。</p><p>GNN解决小样本学习问题的思路：</p><p>先建立一个从support到query的全连接的图，节点使用嵌入向量和独热编码label表示，通过邻居聚合迭代的更新节点feature，完成对query的分类。</p><h5 id="问题">问题</h5><p>然而以前在小样本学习中使用的图神经网络（GNN）方法是基于节点标记框架（ node-labeling framework）的，该框架对聚类内的相似度和聚类间不相似度进行隐式建模（implicitly modeling）。</p><h5 id="解决">解决</h5><p>提出的EGNN学会<strong>预测图上的边标签</strong>，而不是节点标签，从而通过直接利用聚类内的相似性和聚类间不相似性来<strong>迭代更新边标签</strong>，从而实现显式聚类的进化。</p><p><img src="https://i.loli.net/2020/10/15/ZewrSL3qdRy68iD.png" alt="image-20201015191818980"></p><h5 id="贡献">贡献</h5><p>EGNN首次使用边标注的方式构建，利用的是 episodic training framework</p><p>在小样本分类的有监督和半监督任务中，表现超过了所有的GNN。同时，证明显式聚类和分别利用类内相似、类间不同都是有效的。</p><h5 id="模型">模型</h5><p>术语介绍</p><p><img src="https://i.loli.net/2020/10/15/63wSKIRlfJGjEXB.png" alt="image-20201015193021049"></p><p>过程</p><p>每个episode中的支持集S都用作标记的训练集，在该训练集上训练模型以最小化其在查询集Q上的预测损失。此训练过程逐个episode反复进行，直到收敛为止。</p><p><img src="https://i.loli.net/2020/10/15/SaoD8MkpsU5uPnA.png" alt="image-20201015193456782"></p><p><img src="https://i.loli.net/2020/10/15/VIE751M3FlTBjKw.png" alt="image-20201015200148142"></p><p>给出tesk所有样本的特征表示，那么就可以构建一个全连接图，其中每个节点代表一个样本，每个边代表两个连接点之间的关系。</p><h5 id="伪代码">伪代码</h5><p><img src="https://i.loli.net/2020/10/15/vIdrJxt1TLEwNRU.jpg" alt="在这里插入图片描述"></p><p>我们可以看到，这个整体更新的方式像极了EM算法。 第一步是获取特征，<strong>这个embedding的网络在文章的图3。</strong></p><p>点特征先通过图(a)的卷积嵌入网络进行初始化， 边特征也被初始化如下面公式 第二步是初始化边</p><p><img src="https://i.loli.net/2020/10/15/LU549hpFxOYynQR.png" alt="image-20201015194613945"></p><p>如果两个点是同一个标签，那么就是1， 否则就是0</p><p><img src="https://i.loli.net/2020/10/15/xACgHdYarn32fpD.jpg" alt="在这里插入图片描述"></p><p>如果其是同一类，或者其不是同一类，或者其相邻节点不属于支持集</p><p>第三步是进入一个更新循环。</p><p>第四步是更新节点 <img src="https://i.loli.net/2020/10/15/eV9Zj1zlRCDBXTw.jpg" alt="在这里插入图片描述"></p><p>是把边的不同维数的特征（分别代表类内，和类间（相似性和不相似性））和节点特征相乘，然后2个结果做连接操作，作为参数传入神经网络，得到更新之后的节点特征，这个时候的节点特征就是包含了相应的边的语意信息了。信息更加饱满。</p><p>可以看到图中就是先进行算法，然后连接操作，然后进入一个多层感知机，最后得到更新之后的节点信息。 其中：eijd是做了归一化操作，f是点转移网络（transformation network）</p><p>第五步是更新边 <img src="https://i.loli.net/2020/10/15/kcoI5NE1KxQgACq.jpg" alt="在这里插入图片描述"></p><p>然后不断进行第四五步的循环L次，结束后计算出我们要测试的数据所属于的类的概率。</p><p>最终的边标签预测结果就是最后的边特征</p><p><img src="https://i.loli.net/2020/10/15/I36BJMaP2WlZy8g.png" alt="image-20201015200438652"></p><h5 id="损失函数">损失函数</h5><p><img src="https://i.loli.net/2020/10/15/sXD6vTOF1p7weiC.png" alt="image-20201015200559689"></p><p><img src="https://i.loli.net/2020/10/15/XwjzkxMNTQ1hGv9.png" alt="image-20201015200725295"></p><p>L代表第L层，M代表M个任务，这个是episodic training可以理解为多任务。</p><p>λ是学习率，L是二元交叉滴损失，Y是真实的标签，Yˆ是预测的标签。就是说损失函数是所有M个任务L层的所有损失的和。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      小样本学习
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-10-12-transformer图像处理论文</title>
    <link href="http://yoursite.com/2020/10/12/2020-10-12-transformer%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E8%AE%BA%E6%96%87/"/>
    <id>http://yoursite.com/2020/10/12/2020-10-12-transformer%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E8%AE%BA%E6%96%87/</id>
    <published>2020-10-12T14:17:41.000Z</published>
    <updated>2020-10-17T14:17:35.713Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言">前言</h3><h3 id="end-to-end-object-detection-with-transformers">End-to-End Object Detection with Transformers</h3><p>CVPR 2020</p><p>code url ： <a href="https://github.com/facebookresearch/detr" target="_blank" rel="noopener" class="uri">https://github.com/facebookresearch/detr</a></p><p>简易 code：</p><p><a href="https://colab.research.google.com/github/facebookresearch/detr/blob/colab/notebooks/detr_demo.ipynb" target="_blank" rel="noopener" class="uri">https://colab.research.google.com/github/facebookresearch/detr/blob/colab/notebooks/detr_demo.ipynb</a></p><h4 id="abstract">Abstract</h4><p>我们把目标检测看做是一种set prediction的问题，我们的方法也直接移除了一些人工设计的组件，例如NMS和anchor的生成。</p><p>我们的框架DETR，由两个部分构成，一是set-based的全局loss，使用bipartite matching (二分匹配)生成唯一的预测，二是transformer的encoder-decoder 结构。</p><p>只需提供固定大小学习到的目标查询集合，DETR推理出目标与全局图像上下文，直接并行地预测出结果。新的模型非常简单，不需要特定的库来支持。DETR在coco数据集上有着可以和faster-rcnn媲美的准确率与效率。而且它也能完成全景分割的任务。</p><h4 id="问题">问题</h4><p>目标检测的目标是预测一个bbox的集合和各个bbox的标签。目前的检测器不是直接预测一个目标的集合，而是使用替代的回归和分类去处理大量的propoasls、anchors或者window centers。</p><p>模型的效果会受到一系列问题的影响：后处理去消除大量重叠的预测、anchors的设计、怎么把target box与anchor关联起来。为了简化流程，我们提出一种直接set prediction的方式来消除这些替代的方法。</p><h4 id="解决">解决</h4><p>将目标检测看做是一种set prediction（序列预测）的问题，我们的方法也直接移除了一些人工设计的组件，例如NMS和anchor的生成。</p><p><img src="https://i.loli.net/2020/10/16/36UT8nHdBIKNQ4m.png" alt="DETR模型的大体结构"></p><p>DETR模型的大体结构</p><p>DETR可一次预测所有对象，并通过设置损失函数进行端到端训练，该函数执行预测对象与真实对象之间的<strong>二分匹配</strong>。</p><p>与大多数现有的检测方法不同，DETR不需要任何自定义层，因此可以在任何包含标准CNN和转换器类的框架中轻松重现。</p><h4 id="两大核心思想">两大核心思想</h4><p>1、transformer保证了attention，确保对一个实例的识别，是在整幅图的知识下进行的。</p><p>2、二分最大匹配，确保了一一对应的关系。</p><h4 id="局限性">局限性</h4><p>DETR在大型物体上表现出明显更好的性能，这可能是由于transformer的非局部计算所致。然而在小型物体上就表现出一般的性能</p><h4 id="模型">模型</h4><p><img src="https://i.loli.net/2020/10/16/cS3QMqNTJGykKZd.png" alt="image-20201016094016507"></p><p>DETR的整体结构Transformer类似：Backbone得到的特征铺平，加上Position信息之后送到一Encoder里，得到上下文信息。这100个candidates是被Decoder<strong>并行解码的</strong>（显存就很大，但实现的时候可写成不并行的），以得到最后的检测框。</p><p><img src="https://i.loli.net/2020/10/16/ZiGXu5nE3OF8syv.png" alt="image-20201013142352470"></p><h5 id="detr-encoder"><strong>DETR Encoder</strong></h5><p>网络一开始是使用Backbone（比如ResNet）提取一些feature，然后降维到d×HW。</p><p><img src="https://i.loli.net/2020/10/16/3C4qzOXKLsJco5H.png" alt="image-20201016094956398"></p><p>Feature降维之后与<strong>Spatial Positional Encoding相加</strong>，然后被送到Encoder里。</p><p>为了体现图像在x和y维度上的信息，作者的代码里<strong>分别计算了两个维度的Positional Encoding，然后Cat到一起。</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pos_x = torch.stack((pos_x[:, :, :, <span class="number">0</span>::<span class="number">2</span>].sin(), pos_x[:, :, :, <span class="number">1</span>::<span class="number">2</span>].cos()), dim=<span class="number">4</span>).flatten(<span class="number">3</span>)</span><br><span class="line">pos_y = torch.stack((pos_y[:, :, :, <span class="number">0</span>::<span class="number">2</span>].sin(), pos_y[:, :, :, <span class="number">1</span>::<span class="number">2</span>].cos()), dim=<span class="number">4</span>).flatten(<span class="number">3</span>)</span><br><span class="line">pos = torch.cat((pos_y, pos_x), dim=<span class="number">3</span>).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure><p>FFN、LN等操作也与Transformer类似。<strong>Encoder最后得到的结果是对N个物体编码后的特征。</strong></p><h5 id="detr-decoder"><strong>DETR Decoder</strong></h5><p>DETR Decoder的结构也与Transformer类似，<strong>区别在于Decoder并行解码N个object。</strong></p><p>每个Decoder有两个输入：一路是Object Query（或者是上一个Decoder的输出），另一路是Encoder的结果。</p><p>We add prediction FFNs and Hungarian loss after each decoder layer. All predictions FFNs share their parameters。</p><p>在每一个decode层都会添加FFN和Hungarian loss，并行计算出N个object ， FFN是共享参数的</p><p>object queries会输入到每一层中，我一开始不明白Object Query是怎样得到的。后来从代码看，<strong>Object Query是一组nn.Embedding的weight（就是一组学到的参数）。</strong></p><p><strong>最后一个Decoder后面接了两个FFN，分别预测检测框及其类别。</strong></p><p>仔细看论文和代码，才发现它的输出是定长的（N）：100个检测框和类别，这种操作可能跟COCO评测的时候取top 100的框有关。100比一个图像中普遍的目标数量都要多。</p><h4 id="损失函数---bipartite-matching">损失函数 - Bipartite Matching</h4><p>一个难点就是如何去评价预测目标和真实目标（class 、边框大小位置）</p><p><strong>由于输出物体的顺序不一定与ground truth的序列相同</strong>，作者使用二元匹配将GT框与预测框进行匹配。其匹配策略如下：</p><p>（y和y^都是N大小，用no object填充）</p><p><img src="https://i.loli.net/2020/10/16/7HnIS2eMsPoRqpO.jpg" alt="img"></p><p>但是Lmatch中yi和y^的最佳分配需要用到<strong>匈牙利算法</strong>（Hungarian algorithm），参考的是前人的做法</p><h5 id="匈牙利算法"><strong>匈牙利算法</strong></h5><p>寻找二分图的最大匹配</p><p>最后的损失函数：</p><p><img src="https://i.loli.net/2020/10/16/wsH8nTdmuaekDl5.jpg" alt="img"></p><p>所谓二分的最大匹配，即保证预测值与真值实现最大的匹配，保证预测的N的实例（包括∅）按照位置与真值对应起来。实现一一对应之后，便能够利用分类Loss以及boundingbox Loss进行优化。这种一一对应的关系，同时也另一个好处是，不会多个预测值对应到同一个真实值上，然后再通过NMS进行后处理。</p><hr><p><img src="https://i.loli.net/2020/10/16/VaPDHrkwgthvSTb.png" alt="image-20201013000531053"></p><p>个人觉得最直白的理解方式就是用positional embedding替代了原本的anchor。</p><p>第一步用CNN提feature，然后展开成一维之后加上位置信息进入encoder加工。之后decoder里的object queries，实际上是另一组可学习的positional embedding，其功能类似于anchor。之后每个query进过decoder后算一个bbox和class prob。</p><p>网络的结构是非常简单的，先是CNN提取特征，然后将CNN提取的特征送入到transformer中，而由于transformer是位置无关，所以为了保持位置信息，需要送入CNN特征的同时，送入位置的编码信息，确保整个链路中位置信息不丢失。在transformer中编码之后，送入到解码器，同时送入到解码器的还包括object queries（即文中说的N个查询对象），N个对象以及编码器的输入在解码器的综合作用下，获取N个输出，这N个输出在FFN的作用下，产生N个位置以及每个位置对应的类别。</p><p>至此，网络的便具备物体检测的能力。与原始的transformer不同的地方在于decoder每一层都输出结果，计算loss。这种思想还是相对简单并且work的，EV-FlowNet以及龙明盛迁移学习的某一个版本中均有类似的操作。如果仔细探究的话，我想一定会有一种更合计的叠加方式，而不是这种简单的加在一起，毕竟每一层理论上的物理意义都不同，这种叠加loss的方法，限制了decoder只有第一层完成了大部分任务，更多的层只是一个上采样和细化的过程。</p><p>概括而言，文章的两大核心思想为：</p><p>1、transformer保证了attention，确保对一个实例的识别，是在整幅图的知识下进行的。注意力机制本质是在跑message passing去对提取的特征进行一种滤波，这里面在很大程度上就是<strong>实现了其他分析中的去提取不同位置不同物体之间的相互关系这个功能，通过发掘这个约束提高了对物体识别的可靠性。</strong></p><p>2、二分最大匹配，确保了一一对应的关系。</p><p><img src="https://i.loli.net/2020/10/16/E7CjvLOxHBSMR25.jpg" alt="img"></p><h4 id="二分图最大匹配问题与匈牙利算法的核心思想">二分图最大匹配问题与匈牙利算法的核心思想</h4><p><a href="https://liam.page/2016/04/03/Hungarian-algorithm-in-the-maximum-matching-problem-of-bigraph/" target="_blank" rel="noopener" class="uri">https://liam.page/2016/04/03/Hungarian-algorithm-in-the-maximum-matching-problem-of-bigraph/</a></p><p>图上的object queries实际上是N个emebding，更具体得说应该是N个实例query的embedding(我理解是这样)，退一步不准确一点可以简单理解成位置。N是固定值但是emebding完之后N个quries都不太一样。所以差不多的意思就是告诉模型要100个实例，然后decoder根据encoder得到特征的位置和显著性decoder出100个抽象点代表instance，其中部分是前景instance，部分是背景instance，前景的就class+box loss，背景的就当背景。这就是训练过程。推理过程也就很简单了，前景的就直接用，背景的就丢掉。</p><p>Transformer encoder： 注意力机制本质是在跑message passing去对提取的特征进行一种滤波，这里面在很大程度上就是<strong>实现了其他分析中的去提取不同位置不同物体之间的相互关系这个功能，通过发掘这个约束提高了对物体识别的可靠性。</strong></p><hr><h3 id="an-image-is-worth-16x16-words-transformers-for-image-recognition-at-scale">AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE</h3><p>ICLR 2021 under review</p><p>code url (非官方) : <a href="https://github.com/lucidrains/vit-pytorch" target="_blank" rel="noopener" class="uri">https://github.com/lucidrains/vit-pytorch</a></p><h4 id="abstract-1">Abstract</h4><p>patch： 图像块</p><p>尽管Transformer体系结构已成为自然语言处理任务的实际标准，但其在计算机视觉中的应用仍然受到限制。 在视觉领域，注意力要么与卷积网络一起应用，要么用于替换卷积网络的某些组件，同时将其整体结构保持在适当的位置。 我们表明，这种对CNN的依赖不是必需的，并且当直接应用于图像块序列时，纯transformer可以很好地执行图像分类任务。 当对大量数据进行预训练并转移到多个识别基准（ImageNet，CIFAR-100，VTAB等）时，与最先进的卷积网络相比，Vision Transformer可获得出色的结果，而在训练中所需更少的计算资源。</p><h4 id="问题-1">问题</h4><p>在视觉领域中，transformer模型存在着对CNN的依赖，无法做到纯transformer模型。</p><h4 id="解决-1">解决</h4><p>当直接应用于图像块（patch）序列时，纯transformer可以很好地执行图像分类任务。 对transformer进行尽可能少的修改，这样有利于以后模型的拓展。为此，我们将图像拆分为小块，并提供这些小块的线性嵌入序列作为transformer的输入。图像块与NLP中的token（单词）的处理方式相同，应用在图像分类中。</p><h4 id="性能">性能</h4><p><img src="https://i.loli.net/2020/10/16/t9nKLb241IBUXxM.png" alt="image-20201016142258890"></p><p>在一些 mid-sized datasets 数据集（中型数据集）上表现一般，可能是transformer缺少CNN的归纳偏置特性。</p><p>然而在大型数据集中表现超过了CNN的归纳偏置。</p><h4 id="模型-1">模型</h4><h5 id="整体架构">整体架构</h5><p><img src="https://i.loli.net/2020/10/16/3UnGydo5C8aIOhm.png" alt="image-20201016143430430"></p><p><img src="https://i.loli.net/2020/10/16/o3VuAQ5IYZtmMej.png" alt="image-20201016143922712"></p><p>图像transformer遵循为NLP设计的体系结构。</p><p>标准的Transformer接收一维token嵌入的序列作为输入。 为了处理2D图像，我们将图像x∈R H×W×C reshape为一系列flatten的2D的patch，xp∈R N×（P 2·C）。</p><p>（H，W）是原始图像的分辨率，（P，P）是每个图像块的分辨率。 那么N = HW / P2是transformer的有效序列长度。</p><p>transformer在所有图层上使用恒定的宽度(d_model)，因此可训练的线性投影将每个向量图形块映射到模型尺寸D，我们将其输出称为图像块嵌入（patch embedding）。</p><h5 id="总体流程">总体流程</h5><p><img src="https://i.loli.net/2020/10/16/8KpGO94DXLlIZCS.png" alt="image-20201016145353457"></p><p>位置嵌入： 没有使用行和列的位置嵌入（DETR），和token的位置嵌入一样</p><p>为什么位置向量是随机生成的，并进行优化的呢？ 原transformer是计算得到的？？？</p><p><img src="https://i.loli.net/2020/10/16/XCLARSYyO3tewTg.png" alt="image-20201016150139040"></p><p><img src="https://i.loli.net/2020/10/16/pRZHo6XKFYltTfg.png" alt="image-20201016150253070"></p><p>class embeding: 可学习的标签嵌入</p><h5 id="预训练与微调">预训练与微调</h5><p>在实验阶段，在大型数据集上进行预训练，然后在较小的数据集上进行微调，作为tesk。</p><p>在微调时，去掉了pre-trained prediction head （Xclass），并将最后的num_classes改为数据集需要的类数目</p><p>2020.10.16 讨论 ：</p><ol type="1"><li><p>transformer和图神经网络/图卷积网络的联系 论文 + 代码</p></li><li><p>传统方法处理小样本学习 论文 + 代码</p></li><li><p>目标检测和小样本学习的联系 论文+ 代码</p></li><li><p>根据读的上述论文，多跑小样本实验，了解基本思路框架逻辑</p></li><li><p>根据已经读过的论文，改进的transformer应用到图像处理中（transformer可以处理目标检测，那么也可以解决小样本学习），验证</p></li><li><p>将图像处理中flatten变换为1*1卷积 ，验证</p></li><li><p>transformer做时间序列聚类 ，验证</p><p>.</p></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      此文是将transformer应用到目标检测，可以作为我研究方向的拓展
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-09-28-windows-terminal探索</title>
    <link href="http://yoursite.com/2020/09/28/2020-09-28-windows-terminal%E6%8E%A2%E7%B4%A2/"/>
    <id>http://yoursite.com/2020/09/28/2020-09-28-windows-terminal%E6%8E%A2%E7%B4%A2/</id>
    <published>2020-09-28T02:38:58.000Z</published>
    <updated>2020-09-30T12:57:58.465Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言">前言</h3><p>优化方法终于考完了，最近几天都是在复习。可以放松两天，折腾一下</p><h3 id="windows-terminal">windows terminal</h3><h4 id="安装windows-terminal">安装Windows Terminal</h4><p>在Windows上，可以安装<code>Windows Terminal</code>。有点类似于MacOS上的<code>iTerm</code>，可以说是Windows下最舒适的终端。</p><p>在<code>windows store</code>中安装即可，比较方便，如下图所示</p><p><img src="https://i.loli.net/2020/09/30/KLziDFhWNBg9qYR.png" alt="image-20200930205359665"></p><h3 id="安装ubuntu子系统">安装Ubuntu子系统</h3><p>此时，我们仅仅安装了一个命令行终端而已，还是需要在<code>Windows</code>上安装<code>Ubuntu</code>。</p><p>只需要两步</p><p>1.在系统中开启子系统功能</p><p>2.在<code>windows store</code>安装linux版本即可。我安装的是<code>ubuntu 18.04 LTS</code>版本的，和实验室服务器一个版本号，利于操作。</p><blockquote><p>关于LTS</p><p>1.LTS= 长期支持版本，你会在较长的时间内获得安全、维护和(有时有)功能的更新。</p><p>2.LTS 版本被认为是最稳定的版本，它经历了广泛的测试，并且大多包含了多年积累的改进。</p><p>3.对于ubuntu，没两年发布一个LST版本，比如ubuntu 16.04 ubuntu 18.04等等，代表的是发布的年份。</p><p>4.最新的 LTS 版本是 Ubuntu 20.04 ，它将被支持到 2025 年 4 月，支持5年的软件更新和修补。换句话说，Ubuntu 20.04 在那之前都会收到软件更新。非 LTS 版本只支持九个月。</p></blockquote><p>如下图，在控制面板，找到程序选项，点击 “启用或关闭Windows功能”。</p><p><img src="https://i.loli.net/2020/09/28/KQ3LocsNrBxiRf5.png" alt="image-20200928105917992"></p><p>从弹出的对话框里，划到最下边，然后给“适用于Linux的Windows子系统“，打勾，完事！</p><p><img src="https://i.loli.net/2020/09/28/HPVhtscoGj8iCRA.png" alt="image-20200928105907117"></p><p>在windows中访问ubuntu系统</p><p>可以认为在windows 文件资源管理器中开辟一个空间用来储存ubuntu系统，但是如何找到位置呢？</p><p>执行如下命令：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home  </span><br><span class="line">explorer.exe .  <span class="comment">#用文件资源管理器来打开当前home目录所在位置</span></span><br></pre></td></tr></tbody></table></figure><p>可以看到是在<code>网络</code>一栏中， 可以看到ubuntu的文件目录。但是返回到<code>网络</code>根目录，却显示是无文件夹。不知道为什么。</p><p>为了操作方便，我把这个长长的目录，右键映射到了Z盘上。如图，下次在访问Linux的时候，直接访问Z盘就可以了。</p><p><img src="https://i.loli.net/2020/09/28/XqMOBfSKRkwHC93.png" alt="image-20200928111036904"></p><p>这时，就可以看到在我的电脑里就有了Z盘</p><p><img src="https://i.loli.net/2020/09/28/V9MFRujrqgl46me.png" alt="image-20200928111104530"></p><blockquote><p><strong>映射网络驱动器</strong>目的就是为了让远程网络中的资源和本地共享，在本地可以对远程网络中的资源进行访问，并且可以创建文件。</p></blockquote><h3 id="工作区快捷键">工作区快捷键</h3><table><thead><tr class="header"><th style="text-align: left;">Win 快捷键</th><th style="text-align: left;">作用</th><th style="text-align: left;">备注</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;"><strong>Ctrl + Shift + P</strong>，F1</td><td style="text-align: left;">显示命令面板</td><td style="text-align: left;"></td></tr><tr class="even"><td style="text-align: left;"><strong>Ctrl + B</strong></td><td style="text-align: left;">显示/隐藏侧边栏</td><td style="text-align: left;">很实用</td></tr><tr class="odd"><td style="text-align: left;"><code>Ctrl + \</code></td><td style="text-align: left;"><strong>创建多个编辑器</strong></td><td style="text-align: left;">【重要】抄代码利器</td></tr><tr class="even"><td style="text-align: left;"><strong>Ctrl + 1、2</strong></td><td style="text-align: left;">聚焦到第 1、第 2 个编辑器</td><td style="text-align: left;">同上重要</td></tr><tr class="odd"><td style="text-align: left;"><strong>ctrl +/-</strong></td><td style="text-align: left;">将工作区放大/缩小（包括代码字体、左侧导航栏）</td><td style="text-align: left;">在投影仪场景经常用到</td></tr><tr class="even"><td style="text-align: left;">Ctrl + J</td><td style="text-align: left;">显示/隐藏控制台</td><td style="text-align: left;"></td></tr><tr class="odd"><td style="text-align: left;"><strong>Ctrl + Shift + N</strong></td><td style="text-align: left;">重新开一个软件的窗口</td><td style="text-align: left;">很常用</td></tr><tr class="even"><td style="text-align: left;">Ctrl + Shift + W</td><td style="text-align: left;">关闭软件的当前窗口</td><td style="text-align: left;"></td></tr><tr class="odd"><td style="text-align: left;">Ctrl + N</td><td style="text-align: left;">新建文件</td><td style="text-align: left;"></td></tr><tr class="even"><td style="text-align: left;">Ctrl + W</td><td style="text-align: left;">关闭当前文件</td><td style="text-align: left;"></td></tr></tbody></table><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      才考完优化方法，折腾一下微软神器windows terminal
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-09-19-一周论文分享（第2期）</title>
    <link href="http://yoursite.com/2020/09/19/2020-09-19-%E4%B8%80%E5%91%A8%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%EF%BC%88%E7%AC%AC2%E6%9C%9F%EF%BC%89/"/>
    <id>http://yoursite.com/2020/09/19/2020-09-19-%E4%B8%80%E5%91%A8%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%EF%BC%88%E7%AC%AC2%E6%9C%9F%EF%BC%89/</id>
    <published>2020-09-19T02:58:48.000Z</published>
    <updated>2020-10-17T13:37:14.066Z</updated>
    
    <content type="html"><![CDATA[<h4 id="联邦学习">联邦学习</h4><p>参考 <a href="https://zhuanlan.zhihu.com/p/79284686" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/79284686</a></p><p>背景</p><p>1.现实生活中，除了少数巨头公司能够满足，绝大多数企业都存在数据量少，数据质量差的问题，不足以支撑人工智能技术的实现；</p><p>2.同时国内外监管环境也在逐步加强数据保护，因此数据在安全合规的前提下自由流动，成了大势所趋，所以不能获取很多涉及用户隐私的信息。</p><p>3.数据的不充分交流，同时也导致即使在同一个公司内，数据也往往以孤岛形式出现。</p><p>基于以上不足以支撑实现、不允许粗暴交换、不愿意贡献价值三点，</p><p>现在大量存在的<strong>数据孤岛</strong>，以及隐私保护问题，联邦学习被提出。</p><p>概念</p><p>本质：联邦学习本质上是一种<strong>分布式</strong>机器学习技术，或机器学习<strong>框架</strong>。</p><p>目标：联邦学习的目标是在保证数据隐私安全及合法合规的基础上，实现共同建模，提升AI模型的效果。</p><p>前身：联邦学习最早在 2016 年由谷歌提出，原本用于解决安卓手机终端用户在本地更新模型的问题；</p><p><img src="E:\myBlog\source_posts\v2-657a9f63512351691e60af9d88a34605_720w.jpg" alt="img"></p><h2 id="横向联邦学习">3.1 横向联邦学习</h2><p><strong>适用场景：</strong></p><p>横向联邦学习的本质是<strong>样本的联合</strong>，适用于参与者间业态相同但触达客户不同，即特征重叠多，用户重叠少时的场景，比如不同地区的银行间，他们的业务相似（特征相似），但用户不同（样本不同）</p><p><strong>学习过程：</strong></p><p><img src="E:\myBlog\source_posts\v2-23616816b92a6d62be206b0aa28ba393_720w.jpg" alt="img"></p><p>step1：参与方各自从服务器A下载最新模型；</p><p>step2：每个参与方利用本地数据训练模型，加密梯度上传给服务器A，服务器A聚合各用户的梯度更新模型参数；</p><p>step3：服务器A返回更新后的模型给各参与方；</p><p>step4：各参与方更新各自模型。</p><p><strong>步骤解读：</strong>在传统的机器学习建模中，通常是把模型训练需要的数据集合到一个数据中心然后再训练模型，之后预测。在横向联邦学习中，可以看作是<strong>基于样本的分布式模型训练</strong>，分发全部数据到不同的机器，每台机器从服务器下载模型，然后利用本地数据训练模型，之后返回给服务器需要更新的参数；服务器聚合各机器上的返回的参数，更新模型，再把最新的模型反馈到每台机器。</p><p>在这个过程中，每台机器下都是<strong>相同且完整的模型</strong>，且机器之间不交流不依赖，在预测时每台机器也可以<strong>独立预测</strong>，可以把这个过程看作成基于样本的分布式模型训练。谷歌最初就是采用横向联邦的方式解决安卓手机终端用户在本地更新模型的问题的。</p><h2 id="简介"><strong>简介</strong></h2><p>NAS</p><p>深度学习可以自动学习出有用的特征，脱离了对特征工程的依赖，在图像、语音等任务上取得了超越其他算法的结果。这种成功很大程度上得益于新神经网络结构的出现，如ResNet、Inception、DenseNet等。但设计出高性能的神经网络需要大量的专业知识与反复试验，成本极高，限制了神经网络在很多问题上的应用。神经结构搜索（Neural Architecture Search，简称NAS）是一种自动设计神经网络的技术，可以通过算法根据样本集自动设计出高性能的网络结构，在某些任务上甚至可以媲美人类专家的水准，甚至发现某些人类之前未曾提出的网络结构，这可以有效的降低神经网络的使用和实现成本。</p><p>NAS的原理是给定一个称为搜索空间的候选神经网络结构集合，用某种策略从中搜索出最优网络结构。神经网络结构的优劣即性能用某些指标如精度、速度来度量，称为性能评估。这一过程如下图所示。</p><p><img src="E:\myBlog\source_posts\v2-261f4e89d5c60e5d336052e7fc6d116d_720w.png" alt="img"></p><p>在搜索过程的每次迭代中，从搜索空间产生“样本”即得到一个神经网络结构，称为“子网络”。在训练样本集上训练子网络，然后在验证集上评估其性能。逐步优化网络结构，直至找到最优的子网络。</p><p>搜索空间，搜索策略，性能评估策略是NAS算法的核心要素。搜索空间定义了可以搜索的神经网络结构的集合，即解的空间。搜索策略定义了如何在搜索空间中寻找最优网络结构。性能评估策略定义了如何评估搜索出的网络结构的性能。对这些要素的不同实现得到了各种不同的NAS算法，本节将选择有代表性的进行介绍。</p><h3 id="fisher-information">Fisher Information</h3><p>反映了我们对参数估计的准确度，它越大，对参数估计的准确度越高，即代表了越多的信息。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录每周值得分享的论文，周一发布、
《reformer-the eficient transformer》、
《Transformer-XL-Attentive Language Models Beyond a Fixed-Length Context》

    
    </summary>
    
    
      <category term="论文分享" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"/>
    
    
      <category term="论文" scheme="http://yoursite.com/tags/%E8%AE%BA%E6%96%87/"/>
    
      <category term="论文分享" scheme="http://yoursite.com/tags/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"/>
    
  </entry>
  
  <entry>
    <title>2020-09-14-修改pytorch版transformer代码</title>
    <link href="http://yoursite.com/2020/09/14/2020-09-14-%E4%BF%AE%E6%94%B9pytorch%E7%89%88transformer%E4%BB%A3%E7%A0%81/"/>
    <id>http://yoursite.com/2020/09/14/2020-09-14-%E4%BF%AE%E6%94%B9pytorch%E7%89%88transformer%E4%BB%A3%E7%A0%81/</id>
    <published>2020-09-14T08:26:17.000Z</published>
    <updated>2020-09-14T09:14:07.600Z</updated>
    
    <content type="html"><![CDATA[<p><del>源代码是<code>main3.py</code> ,在此基础上进行修改，修改后文件为<code>main3-2.py</code></del></p><p>740中<code>annotated-transformer</code>中<code>main.py</code>和哈佛的一样</p><p>复制到了本地<code>main.py</code> ,再复制到<code>annotated-transformer1</code>中的main.py</p><p><strong>所以改前的代码是<code>main.py</code> ，改后的代码是<code>main-1.py</code></strong></p><p>注：</p><p><strong><code>python main.py &gt;main.txt 2&gt;&amp;1</code>，在将结果重定向到main.txt中，会覆盖main.txt之前的内容</strong></p><p><strong>每次跑实验的预测都是不一样的，但是都是和输入差不多</strong></p><ol type="1"><li>将<code>attention</code>函数去掉，合并到<code>MultiHeadedAttention</code>中，服务器上测试<strong>可行</strong></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录修改过程
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-09-11-gpu实验加速</title>
    <link href="http://yoursite.com/2020/09/11/2020-09-11-gpu%E5%AE%9E%E9%AA%8C%E5%8A%A0%E9%80%9F/"/>
    <id>http://yoursite.com/2020/09/11/2020-09-11-gpu%E5%AE%9E%E9%AA%8C%E5%8A%A0%E9%80%9F/</id>
    <published>2020-09-11T00:48:00.000Z</published>
    <updated>2020-09-16T08:00:54.184Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言">前言</h3><p>将深度学习应用到实际问题中，一个非常大的问题在于训练深度学习模型需要的计算量太大。为了加速训练过程，本文将介绍如何如何在TensorFlow中使用单个GPU进行计算加速</p><h3 id="简介">简介</h3><h4 id="cuda">CUDA</h4><p><a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">CUDA</a>（Compute Unified Device Architecture,点击进入安装网站），是显卡厂商NVIDIA推出的运算平台。 CUDA™是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。安装GPU版tensorflow,必须有这个环境。</p><p>CUDA是NVIDIA推出的用于自家GPU的并行计算框架，也就是说CUDA只能在NVIDIA的GPU上运行，而且只有当要解决的计算问题是可以大量并行计算的时候才能发挥CUDA的作用。</p><h4 id="cudnn">cuDNN</h4><p>NVIDIA <a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">cuDNN</a>是用于深度神经网络的GPU加速库。它强调性能、易用性和低内存开销。</p><h3 id="安装">安装</h3><p>必须要安装对应版本的CUDA、cuDNN和tensorflow</p><p>我在实验室服务器R740上的安装版本如下，是可以运行的</p><blockquote><p>CUDA： V10.1 # nvcc --version</p><p>cuDNN：V7</p><p>tensorflow-gpu：1.14.0</p></blockquote><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda install python==3.6.10  <span class="comment">#这样可以 ，但是为什么 python==3.6.1 和  python==3.6.0 是不可以的呢？？</span></span><br><span class="line">pip install tensorflow-gpu==1.14.0  <span class="comment">#安装成功gpu版本</span></span><br><span class="line"><span class="comment">#用conda装tensorflow时候，会自动下载cuda和cudnn，所以推荐用pip安装</span></span><br><span class="line"></span><br><span class="line">pip install tensorflow-gpu==1.2 <span class="comment">#如果安装错误，可以用pip卸载，没测试过。 或者直接再新建一个虚拟环境也可以</span></span><br></pre></td></tr></tbody></table></figure><h3 id="测试tensorflow-gpu">测试tensorflow-gpu</h3><p>测试安装的tensorflow是否可用GPU，测试如下：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pyhton <span class="comment">#进入python操作环境</span></span><br><span class="line"></span><br><span class="line">import tensorflow as tf </span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))</span><br></pre></td></tr></tbody></table></figure><p>显示如下则表示tensorflow支持的，输出如下：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">2020-09-11 08:30:54.735834: Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA</span><br><span class="line">2020-09-11 08:30:54.821023:  Successfully opened dynamic library libcuda.so.1</span><br><span class="line">2020-09-11 08:30:55.698894:  XLA service 0x5654b4f86600 executing computations on platform CUDA. Devices:</span><br><span class="line">2020-09-11 08:30:55.699000:   StreamExecutor device (0): Tesla M60, Compute Capability 5.2</span><br><span class="line">2020-09-11 08:30:55.699022:   StreamExecutor device (1): Tesla M60, Compute Capability 5.2</span><br><span class="line">2020-09-11 08:30:55.699042:   StreamExecutor device (2): Tesla M60, Compute Capability 5.2</span><br><span class="line">2020-09-11 08:30:55.699062:   StreamExecutor device (3): Tesla M60, Compute Capability 5.2</span><br><span class="line">2020-09-11 08:30:55.732911:   CPU Frequency: 2100000000 Hz</span><br><span class="line">2020-09-11 08:30:55.738953: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5654b54aa810 executing computations on platform Host. Devices:</span><br><span class="line">2020-09-11 08:30:55.739001: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;</span><br><span class="line">2020-09-11 08:30:55.741878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: </span><br><span class="line">name: Tesla M60 major: 5 minor: 2 memoryClockRate(GHz): 1.1775</span><br><span class="line">pciBusID: 0000:b1:00.0</span><br><span class="line">2020-09-11 08:30:55.742665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: </span><br><span class="line">name: Tesla M60 major: 5 minor: 2 memoryClockRate(GHz): 1.1775</span><br><span class="line">pciBusID: 0000:b2:00.0</span><br><span class="line">2020-09-11 08:30:55.743420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: </span><br><span class="line">name: Tesla M60 major: 5 minor: 2 memoryClockRate(GHz): 1.1775</span><br><span class="line">pciBusID: 0000:da:00.0</span><br><span class="line">2020-09-11 08:30:55.744263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: </span><br><span class="line">name: Tesla M60 major: 5 minor: 2 memoryClockRate(GHz): 1.1775</span><br><span class="line">pciBusID: 0000:db:00.0</span><br><span class="line">2020-09-11 08:30:55.744692: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library <span class="string">'libcudart.so.10.0'</span>; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dell2/.mujoco/mjpro150/bin:/usr/<span class="built_in">local</span>/cuda-10.1/lib64:</span><br><span class="line">2020-09-11 08:30:55.744798: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library <span class="string">'libcublas.so.10.0'</span>; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dell2/.mujoco/mjpro150/bin:/usr/<span class="built_in">local</span>/cuda-10.1/lib64:</span><br><span class="line">2020-09-11 08:30:55.744891: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library <span class="string">'libcufft.so.10.0'</span>; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dell2/.mujoco/mjpro150/bin:/usr/<span class="built_in">local</span>/cuda-10.1/lib64:</span><br><span class="line">2020-09-11 08:30:55.744980: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library <span class="string">'libcurand.so.10.0'</span>; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dell2/.mujoco/mjpro150/bin:/usr/<span class="built_in">local</span>/cuda-10.1/lib64:</span><br><span class="line">2020-09-11 08:30:55.745070: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library <span class="string">'libcusolver.so.10.0'</span>; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dell2/.mujoco/mjpro150/bin:/usr/<span class="built_in">local</span>/cuda-10.1/lib64:</span><br><span class="line">2020-09-11 08:30:55.745166: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library <span class="string">'libcusparse.so.10.0'</span>; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dell2/.mujoco/mjpro150/bin:/usr/<span class="built_in">local</span>/cuda-10.1/lib64:</span><br><span class="line">2020-09-11 08:30:55.750141: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7</span><br><span class="line">2020-09-11 08:30:55.750170: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1663] Cannot dlopen some GPU libraries. Skipping registering GPU devices...</span><br><span class="line">2020-09-11 08:30:55.750542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:</span><br><span class="line">2020-09-11 08:30:55.750706:       0 1 2 3 </span><br><span class="line">2020-09-11 08:30:55.750797:  0:   N Y Y Y </span><br><span class="line">2020-09-11 08:30:55.750887:  1:   Y N Y Y </span><br><span class="line">2020-09-11 08:30:55.750974:  2:   Y Y N Y </span><br><span class="line">2020-09-11 08:30:55.751059:  3:   Y Y Y N </span><br><span class="line">Device mapping:</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_GPU:0 -&gt; device: XLA_GPU device</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_GPU:1 -&gt; device: XLA_GPU device</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_GPU:2 -&gt; device: XLA_GPU device</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_GPU:3 -&gt; device: XLA_GPU device</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_CPU:0 -&gt; device: XLA_CPU device</span><br><span class="line">2020-09-11 08:30:55.757190: I tensorflow/core/common_runtime/direct_session.cc:296] Device mapping:</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_GPU:0 -&gt; device: XLA_GPU device</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_GPU:1 -&gt; device: XLA_GPU device</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_GPU:2 -&gt; device: XLA_GPU device</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_GPU:3 -&gt; device: XLA_GPU device</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_CPU:0 -&gt; device: XLA_CPU device</span><br></pre></td></tr></tbody></table></figure><p>表示tensorflow支持device：CPU：0 ，支持device：<code>GPU：0,1,2,3</code>，共4块GPU</p><p>比如CPU在TensorFlow中的名称为/cpu:0。<strong>在默认情况下，即使机器有多个CPU，TensorFlow也不会区分它们，所有的CPU都使用/cpu:0作为名称。</strong></p><p>而一台机器上不同GPU的名称是不同的，第n个GPU在TensorFlow中的名称为/gpu:n。比如第一个GPU的名称为/gpu:0，第二个GPU名称为/gpu:1，以此类推。</p><p>作者：博文视点 链接：https://www.jianshu.com/p/26ac409dfb38 来源：简书 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p><h3 id="ubuntu中查看显卡信息">Ubuntu中查看显卡信息</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lspci | grep -i vga <span class="comment">#显卡</span></span><br></pre></td></tr></tbody></table></figure><p>显示结果如下：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">03:00.0 VGA compatible controller: Matrox Electronics Systems Ltd. Integrated Matrox G200eW3 Graphics Controller (rev 04)</span><br><span class="line">b1:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br><span class="line">b2:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br><span class="line">da:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br><span class="line">db:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br></pre></td></tr></tbody></table></figure><h3 id="ubuntu中查看nvidia-gpu">Ubuntu中查看nvidia GPU</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lspci | grep -i nvidia <span class="comment">#查看gpu信息</span></span><br></pre></td></tr></tbody></table></figure><p>显示结果如下：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">b1:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br><span class="line">b2:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br><span class="line">da:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br><span class="line">db:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br></pre></td></tr></tbody></table></figure><h3 id="查看nvidia的显卡信息和使用情况">查看Nvidia的显卡信息和使用情况</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></tbody></table></figure><p>显示如下：</p><p><img src="https://i.loli.net/2020/09/11/OQZjHpocke5S9FE.png" alt="image-20200910221947824"></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps aux | grep train.py #我的实验名称为train.py</span><br></pre></td></tr></tbody></table></figure><p><img src="https://i.loli.net/2020/09/11/7lujWDbiqnV6zwG.png" alt="image-20200910222011793"></p><p>可以看到，我的实验进程号是<code>21195</code>，在<code>processes</code>中可以看到使用了<code>GPU1,2</code></p><h3 id="指定gpu实验加速">指定GPU实验加速</h3><p>如果电脑有多个GPU，tensorflow默认全部使用。</p><p>如果想只使用部分GPU，可以设置<code>CUDA_VISIBLE_DEVICES</code>。</p><h4 id="命令行指定">命令行指定</h4><p>在执行python程序时，可以通过：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=1 python train.py <span class="comment">#只使用GPU1</span></span><br></pre></td></tr></tbody></table></figure><p>以下为一些使用指导：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Environment Variable Syntax      Results</span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=1           Only device 1 will be seen</span><br><span class="line">CUDA_VISIBLE_DEVICES=0,1         Devices 0 and 1 will be visible</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="string">"0,1"</span>       Same as above, quotation marks are optional</span><br><span class="line">CUDA_VISIBLE_DEVICES=0,2,3       Devices 0, 2, 3 will be visible; device 1 is masked</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="string">""</span>          No GPU will be visible1234567</span><br></pre></td></tr></tbody></table></figure><h4 id="代码中指定">代码中指定</h4><p>在Python代码中添加以下内容：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"1"</span> <span class="comment">#只使用GPU1</span></span><br></pre></td></tr></tbody></table></figure><h3 id="设置tensorflow使用的显存大小">设置tensorflow使用的显存大小</h3><h4 id="定量设置显存">定量设置显存</h4><p>默认tensorflow是使用GPU尽可能多的显存（内存）。</p><p>用Tensorflow创建session的时候要注意设置内存使用情况，特别是内存资源不够而且要和别人共享一块GPU的时候（留一点给别人用）</p><p>可以通过下面的方式，来设置使用的GPU显存：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">0.7</span>)</span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))</span><br></pre></td></tr></tbody></table></figure><p>上面分配给tensorflow的GPU显存大小为：GPU实际显存*0.7。 可以按照需要，设置不同的值，来分配显存。</p><h4 id="按需设置显存">按需设置显存</h4><p>上面的只能设置固定的大小。如果想按需分配，可以使用allow_growth参数</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gpu_options = tf.GPUOptions(allow_growth=<span class="literal">True</span>)</span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))  </span><br><span class="line"><span class="comment"># 使用allow_growth option，刚一开始分配少量的GPU容量，然后按需慢慢的增加，由于不会释放内存，所以会导致碎片</span></span><br></pre></td></tr></tbody></table></figure><p>如果一个 TensorFlow 的 operation 中兼有 CPU 和 GPU 的实现, 当这个算子被指派设备时, GPU 有优先权. 比如<code>matmul</code>中 CPU 和 GPU kernel 函数都存在. 那么在 <code>cpu:0</code> 和 <code>gpu:0</code> 中, <code>matmul</code> operation 会被指派给 <code>gpu:0</code> .</p><h4 id="记录设备指派情况">记录设备指派情况</h4><p>为了获取你的 operations 和 Tensor 被指派到哪个设备上运行, 用 <code>log_device_placement</code> 新建一个 <code>session</code>, 并设置为 <code>True</code>.</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建一个 graph.</span></span><br><span class="line">a = tf.constant([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>], shape=[<span class="number">2</span>, <span class="number">3</span>], name=<span class="string">'a'</span>)</span><br><span class="line">b = tf.constant([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>], shape=[<span class="number">3</span>, <span class="number">2</span>], name=<span class="string">'b'</span>)</span><br><span class="line">c = tf.matmul(a, b)</span><br><span class="line"><span class="comment"># 新建session with log_device_placement并设置为True.</span></span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(log_device_placement=<span class="literal">True</span>))</span><br><span class="line"><span class="comment"># 运行这个 op.</span></span><br><span class="line"><span class="keyword">print</span> sess.run(c)</span><br></pre></td></tr></tbody></table></figure><p>你应该能看见以下输出:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Device mapping:</span><br><span class="line">/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: Tesla K40c, pci bus</span><br><span class="line">id: <span class="number">0000</span>:<span class="number">05</span>:<span class="number">00.0</span></span><br><span class="line">b: /job:localhost/replica:<span class="number">0</span>/task:<span class="number">0</span>/gpu:<span class="number">0</span></span><br><span class="line">a: /job:localhost/replica:<span class="number">0</span>/task:<span class="number">0</span>/gpu:<span class="number">0</span></span><br><span class="line">MatMul: /job:localhost/replica:<span class="number">0</span>/task:<span class="number">0</span>/gpu:<span class="number">0</span></span><br><span class="line">[[ <span class="number">22.</span>  <span class="number">28.</span>]</span><br><span class="line"> [ <span class="number">49.</span>  <span class="number">64.</span>]]</span><br></pre></td></tr></tbody></table></figure><h4 id="section"></h4><h3 id="gpu和cpu">GPU和CPU</h3><p>一个GPU被多个实验使用，但是如果实验超过显存大小，就会都被挂掉，会显示<code>stopped</code>字样</p><p>一个实验可以用多个GPU，但是需要更改部分代码，让其支持多GPU</p><p>不要tensorflow-gpu和tensorflow(cpu版)一起装，因为这样装有个先后顺序问题，先安装tensorflow-gpu再安装tensorflow，gpu版本直接不能用了。</p><p>如果想测试cpu和gpu版本性能的，最好创建两个python的虚拟环境，一个装tensorflow-gpu，另一个装tensorflow。</p><hr><p>在Tensorflow中使用gpu和cpu是有很大的差别的。在小数据集的情况下，cpu和gpu的性能差别不大。不过在大数据集的情况下，cpu的时间显著增加，而gpu变化并不明显。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> timeit</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cpu_run</span><span class="params">(num)</span>:</span></span><br><span class="line">  <span class="keyword">with</span> tf.device(<span class="string">'/cpu:0'</span>):</span><br><span class="line">    cpu_a=tf.random.normal([<span class="number">1</span>,num])</span><br><span class="line">    cpu_b=tf.random.normal([num,<span class="number">1</span>])</span><br><span class="line">    c=tf.matmul(cpu_a,cpu_b)</span><br><span class="line">  <span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gpu_run</span><span class="params">(num)</span>:</span></span><br><span class="line">  <span class="keyword">with</span> tf.device(<span class="string">'/gpu:0'</span>):</span><br><span class="line">    gpu_a=tf.random.normal([<span class="number">1</span>,num])</span><br><span class="line">    gpu_b=tf.random.normal([num,<span class="number">1</span>])</span><br><span class="line">    c=tf.matmul(gpu_a,gpu_b)</span><br><span class="line">  <span class="keyword">return</span> c</span><br><span class="line">k=<span class="number">10</span></span><br><span class="line">m=<span class="number">7</span></span><br><span class="line">cpu_result=np.arange(m,dtype=np.float32)</span><br><span class="line">gpu_result=np.arange(m,dtype=np.float32)</span><br><span class="line">x_time=np.arange(m)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">  k=k*<span class="number">10</span></span><br><span class="line">  x_time[i]=k</span><br><span class="line">  cpu_str=<span class="string">'cpu_run('</span>+str(k)+<span class="string">')'</span></span><br><span class="line">  gpu_str=<span class="string">'gpu_run('</span>+str(k)+<span class="string">')'</span></span><br><span class="line">  <span class="comment">#print(cpu_str)</span></span><br><span class="line">  cpu_time=timeit.timeit(cpu_str,<span class="string">'from __main__ import cpu_run'</span>,number=<span class="number">10</span>)</span><br><span class="line">  gpu_time=timeit.timeit(gpu_str,<span class="string">'from __main__ import gpu_run'</span>,number=<span class="number">10</span>)</span><br><span class="line">  <span class="comment"># 正式计算10次，取平均时间</span></span><br><span class="line">  cpu_time=timeit.timeit(cpu_str,<span class="string">'from __main__ import cpu_run'</span>,number=<span class="number">10</span>)</span><br><span class="line">  gpu_time=timeit.timeit(gpu_str,<span class="string">'from __main__ import gpu_run'</span>,number=<span class="number">10</span>)</span><br><span class="line">  cpu_result[i]=cpu_time</span><br><span class="line">  gpu_result[i]=gpu_time</span><br><span class="line"></span><br><span class="line">print(cpu_result)</span><br><span class="line">print(gpu_result)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.set_xscale(<span class="string">"log"</span>)</span><br><span class="line">ax.set_adjustable(<span class="string">"datalim"</span>)</span><br><span class="line">ax.plot(x_time,cpu_result)</span><br><span class="line">ax.plot(x_time,gpu_result)</span><br><span class="line">ax.grid()</span><br><span class="line">plt.draw()</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure><p><img src="https://i.loli.net/2020/09/11/tRxAb2wY5qKGF4D.png" alt="在这里插入图片描述"> 蓝线是cpu的耗时，而红线是gpu的耗时。</p><p>更多gpu内容可参考</p><blockquote><p><a href="https://docs.pythontab.com/tensorflow/how_tos/using_gpu/" target="_blank" rel="noopener">tensorflow官方文档，使用 GPUs</a></p><p><a href="https://www.cnblogs.com/nxf-rabbit75/p/10639833.html" target="_blank" rel="noopener">Tensorflow检验GPU是否安装成功 及 使用GPU训练注意事项</a></p><p><a href="https://www.jianshu.com/p/26ac409dfb38" target="_blank" rel="noopener">TensorFlow：实战Google深度学习框架（第2版）:GPU加速</a></p></blockquote><h3 id="tensorflow匹配的关系">tensorflow匹配的关系</h3><p><img src="https://i.loli.net/2020/09/13/FqJ1cXThMzKHvA5.png" alt="image-20200913144848843"></p><p><img src="E:\myBlog\source_posts\FqJ1cXThMzKHvA5.png"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录加速过程以及知识点
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-09-07-实验日志</title>
    <link href="http://yoursite.com/2020/09/07/2020-09-07-%E5%AE%9E%E9%AA%8C%E6%97%A5%E5%BF%97/"/>
    <id>http://yoursite.com/2020/09/07/2020-09-07-%E5%AE%9E%E9%AA%8C%E6%97%A5%E5%BF%97/</id>
    <published>2020-09-07T12:44:43.000Z</published>
    <updated>2020-10-02T13:11:18.491Z</updated>
    
    <content type="html"><![CDATA[<h3 id="虚拟环境配置">虚拟环境配置</h3><h4 id="笔记本">笔记本</h4><table><thead><tr class="header"><th>名称</th><th>配置</th><th>用处</th></tr></thead><tbody><tr class="odd"><td>sijian36</td><td>tf 1.9.0</td><td>普通跑实验</td></tr><tr class="even"><td>python714</td><td>tf 1.14.0</td><td>RKN</td></tr><tr class="odd"><td>ronghe</td><td>tf 1.14.0</td><td>transformer和RKN</td></tr></tbody></table><h4 id="r740服务器">R740服务器</h4><p>cuda-10.2</p><table><thead><tr class="header"><th>名称</th><th>配置</th><th>用处</th></tr></thead><tbody><tr class="odd"><td>sijian1</td><td>tf 1.13.0</td><td>一般实验</td></tr><tr class="even"><td>pytorth030</td><td>torch 0.3</td><td>哈佛torch版transformer</td></tr><tr class="odd"><td>lsjRKN</td><td>tf 1.14.0</td><td>RKN</td></tr><tr class="even"><td>ronghe</td><td>tf 1.14.0</td><td>transformer和RKN</td></tr><tr class="odd"><td>ronghe6</td><td>tf-gpu1.14.0</td><td>gpu加速融合</td></tr></tbody></table><h3 id="日志">日志</h3><h4 id="section"><strong>2020-09-06</strong></h4><h5 id="主要内容">主要内容</h5><p>笔记本的RKN实验</p><p>跑通是在RKNmaster文件跑</p><hr><p>哈佛torch版transformer实验</p><p>R740中 LSJ/annotated-transformer1/main5.py(pytorch030)</p><p>是之前上传到R740跑的实验</p><p>LSJ/annotated-transformer是前一阵为了将函数改成直通型流程而从笔记本上上传的</p><h5 id="出现问题">出现问题</h5><p>在R740跑RKN实验</p><p><code>attributeerror: module 'tensorflow.keras.initializers'  has no attribute 'normal'</code> 解决</p><p>将RKN.py 77行 normal 改为 <strong>RandomNormal</strong> 还是出错</p><p>再次出错 keep.dim出错</p><p>修改 将keep.dim=True参数去掉 再运行</p><p>​ <img src="https://i.loli.net/2020/09/08/h7Ma3lm82eFSuWX.png" alt="img"></p><ul><li>运行结果是没有tf.matrix_band_part 这个参数，于是百度发现，</li><li>新版本：tf.matrix_band_part变成tf.linalg.band_part 于是修改再运行</li></ul><p>运行结果显示</p><p>​ <img src="https://i.loli.net/2020/09/08/h7Ma3lm82eFSuWX.png" alt="img"></p><p>于是百度，原因是</p><p>The image from your input pipeline is of type 'uint8', you need to type cast it to 'float32', You can do this after the image jpeg decoder:</p><p>以下更改，在RKN.py中插入h = tf.cast(h, tf.float32)</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def _prop_through_layers(inputs, layers):</span><br><span class="line"></span><br><span class="line">​    """propagates inputs through layers"""</span><br><span class="line"></span><br><span class="line">​    h = inputs</span><br><span class="line"></span><br><span class="line">h = tf.cast(h, tf.float32)</span><br><span class="line"></span><br><span class="line">​    for layer in layers:</span><br><span class="line"></span><br><span class="line">​        h = layer(h)</span><br><span class="line"></span><br><span class="line">​    return h</span><br></pre></td></tr></tbody></table></figure><p>还是报错</p><p><strong>放弃使用sijian1 以及刚刚对RKNmaser的修改</strong></p><p>将笔记本中的RKNmaster 复制为rknmas上传到R740 名字为<strong>rknmas</strong></p><p>参考了笔记本中的虚拟环境，在R740新建lsjRKN的虚拟环境，<strong>tf版本为1.14 python：3.6</strong></p><p>可以跑通实验</p><p>实验可以在R740跑起来，但是为什么论文作者的github代码上tensorflow版本是1.13 不好使，但是在tensorflow1.14就可以跑起来？？？？</p><p>在笔记本上跑的 设置epoch=5</p><p>​ <img src="https://i.loli.net/2020/09/08/h7Ma3lm82eFSuWX.png" alt="img"></p><h4 id="section-1"><strong>2020-09-07</strong></h4><h5 id="主要内容-1">主要内容</h5><p>配置transformer和RKN融合的实验虚拟环境 测试代码</p><p>下载的是<a href="https://github.com/Kyubyong/transformer" target="_blank" rel="noopener">Kyubyong/transformer</a> 代码，准备融合RKN</p><p>具体的配置如下：</p><hr><p><strong>Requirements</strong></p><ul><li>python==3.x (Let's move on to python 3 if you still use python 2)</li><li>tensorflow==1.12.0</li><li>numpy&gt;=1.15.4</li><li>sentencepiece==0.1.8</li><li>tqdm&gt;=4.28.1 #显示进度条的包</li></ul><hr><p>github下载代码，放到<code>C:\Users\Administrator\PycharmProjects</code>目录下，文件名为 <code>transformer-master</code></p><p><code>python714</code>是可以运行RKN的，在笔记本上，根据<code>python714</code> clone了<code>ronghe</code> ，并添加所需要的包</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda install tqdm</span><br><span class="line"></span><br><span class="line">pip install  sentencepiece==0.1.8 <span class="comment"># conda 安装出错 ，于是用pip安装</span></span><br></pre></td></tr></tbody></table></figure><h5 id="出现问题-1"><strong>出现问题</strong></h5><p>此代码不是官方代码，虽然可以实现transformer，但是使用的数据集是小型的<code>IWSLT 2016 de-en</code>，而不是transformer论文中使用的大型数据集WMT，但是官方代码又很难读，而且有很多用不到的接口</p><p>在纠结，要用目前的代码进行融合，还是用官方的代码呢？</p><p>问过师兄，现在还是不用官方的transformer代码，就用目前的代码，只是验证，不用管实验数据集，先将现在的代码结合RKN再说</p><h4 id="section-2"><strong>2020-09-08</strong></h4><h5 id="主要内容-2">主要内容</h5><p>阅读整理RKN的代码</p><p>将昨天的transformer数据集无法读取的问题解决</p><p>将RKN在R740上跑，并保存在<code>test1.txt</code>文件中，可以用<code>less</code> 查看</p><h5 id="遇到问题">遇到问题</h5><p>RKN代码读的一脸懵</p><p>transformer代码bug还未修复 <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f62d.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f62d.png?v8">😭</span></p><h4 id="section-3"><strong>2020-09-09</strong></h4><h5 id="主要内容-3">主要内容</h5><p>在R740新建环境<code>ronghe</code>，根据虚拟环境<code>lsjRKN</code>来建的</p><p>第三方包也安装成功</p><h5 id="遇到问题-1"><strong>遇到问题</strong></h5><ol type="1"><li></li><li>添加上encoding='ascii',error='ignore'就可以解决</li></ol><p><img src="https://i.loli.net/2020/09/11/vCfMGWJ975VEiRl.png" alt="image-20200909094144959"></p><h6 id="注">注</h6><p>在解决完之后，一定要看报错的位置，可能这个已解决，但是其它相同的问题不同位置也会报错，同样解决就可以了</p><ol start="2" type="1"><li>在笔记本上跑此实验，发现内存不够，超出内容超过10%</li></ol><p><code>Allocation of 1196032000 exceeds 10% of system memory</code></p><p><strong>解决</strong></p><p>减少<code>banch_size</code> ， 但是还是超出，但是应该是在现有环境下实验可以跑通的，于是想着在R740上跑</p><p>在R740跑<code>prepro.py</code>实验，如下输出，并<code>INFO：done</code> （表示完成）</p><p><img src="https://i.loli.net/2020/09/11/BAb9krnJ8dCYKTX.png" alt="image-20200909132740936"></p><p>开始跑<code>train.py</code> 并将输出保存在train99.txt中（9月9日）</p><p><img src="https://i.loli.net/2020/09/11/7UpXhTBcnGNILtH.png" alt="image-20200909134011883"></p><p>这个WARNING是什么意思呢？</p><p>猜想：源代码需要的是<code>tf1.12</code>版本 我配置的是<code>tf 1.14</code>版本，不知道是不是这个原因 。晚上回寝百度一下</p><ol start="3" type="1"><li>在740中跑的太慢了，不知道具体原因。在看源代码进行修改</li></ol><h4 id="section-4">2020-09-10</h4><h5 id="主要内容-4">主要内容</h5><p>更改虚拟环境，可以使用GPU对实验进行加速</p><p>阅读transformer的代码，明天融合</p><p>对跑实验的一些warning都已经修改了，复制项目名字为<code>transformer-mas</code></p><p>上传到R740中，命名<code>transformer-mas</code></p><h5 id="遇到问题-2">遇到问题</h5><p><img src="https://i.loli.net/2020/09/11/HUMOjGrYSiZlPo5.png" alt="image-20200910200948426" style="zoom:200%;"></p><p>新建<code>ronghe3</code>虚拟环境</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda install python==3.6.10  <span class="comment">#这样可以 ，但是为什么 python==3.6.1 和  python==3.6.0 是不可以的呢？？</span></span><br><span class="line">pip install tensorflow-gpu==1.13.1</span><br></pre></td></tr></tbody></table></figure><p>在已经安装了tensorflow-gpu的<code>ronghe3</code>基础上，克隆了<code>ronghe4</code>，进行接下来的操作</p><h6 id="注-1">注</h6><p>如果执行<code>conda install tensorflow==1.13.1</code></p><p>安装错误 ，导入不了tensorflow-gpu，应该是和CUDA版本不匹配</p><p><img src="https://i.loli.net/2020/09/11/CgXZf5vQzdODpyU.png" alt="image-20200910211644840"></p><h5 id="参考">参考</h5><p><a href="https://www.tensorflow.org/install/gpu?hl=zh-cn" target="_blank" rel="noopener">tensorflow官方，GPU 支持</a></p><p><code>ronghe5</code></p><p><code>pip install tensorflow-gpu==1.12.0</code></p><p>还是跑不通</p><p><code>ronghe6</code></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda install python==3.6.10  <span class="comment">#这样可以 ，但是为什么 python==3.6.1 和  python==3.6.0 是不可以的呢？？</span></span><br><span class="line">pip install tensorflow-gpu==1.14.0</span><br></pre></td></tr></tbody></table></figure><p>终于可以跑通了，不会报错了！！！</p><p>测试安装的tensorflow是否可用GPU，可以使用。测试如下：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pyhton <span class="comment">#进入python操作环境</span></span><br><span class="line"></span><br><span class="line">import tensorflow as tf </span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))</span><br></pre></td></tr></tbody></table></figure><p>RKN实验跑完了，保存在test2.txt中</p><blockquote><p>tensorflow-gpu 1.5版本及以上要求CUDA版本为9.0</p><p>tensorflow-gpu 1.3及以上版本要求cudnn版本为V6及以上</p></blockquote><h4 id="section-5">2020-09-11</h4><h5 id="主要内容-5">主要内容</h5><p>解决在linux显示图形的问题</p><p>解决transformer实验报错</p><h5 id="遇到问题-3">遇到问题</h5><ol type="1"><li>用xshell在服务器linux端只能显示控制台输出，如果想要显示图像，比如<code>matplotlib</code>包，则要下载<code>xmanage</code></li></ol><p>由于需要收费，没有下载</p><p><img src="https://i.loli.net/2020/09/11/zkqMvhElw2ubg9U.png" alt="image-20200911212759446"></p><p>解决方法： 可以用<code>plt.savafig</code>保存到服务器，再保存在本地笔记本</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">'Agg'</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.font_manager <span class="keyword">import</span> FontProperties</span><br><span class="line">X = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">dataY = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>]</span><br><span class="line">plt.xlabel(<span class="string">"x轴"</span>);</span><br><span class="line">plt.ylabel(<span class="string">"y轴"</span>);</span><br><span class="line">plt.savefig(<span class="string">"./lisijian.png"</span>,dpi=<span class="number">100</span>) <span class="comment">#保存在本文件夹下的lisijian.png</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure><p>报错<code>_tkinter.TclError: couldn't connect to display "localhost:32.0"</code></p><p>原因： 问题在于，您使用的是一个交互式后端，它试图为您创建图形窗口，但由于您断开了启动模拟时可用的x服务器，所以失败了。</p><p>解决方法：使用非交互式后端(请参见<a href="https://matplotlib.org/faq/usage_faq.html#what-is-a-backend" target="_blank" rel="noopener">后端</a>？)比如：Agg(用于Png格式，PDF, SVG或PS。在生成图形的脚本中，只需在import matplotlib.pyplot as plt之前调用matplotlib.use(）即可</p><p>比如<code>matplotlib.use('Agg')</code></p><ol start="2" type="1"><li><p>在transformer实验中，才开始没注意，今天才发现有一个错误，如下:</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AssertionError: Bad argument number <span class="keyword">for</span> Name: 3, expecting 4</span><br></pre></td></tr></tbody></table></figure></li></ol><p>解决方法：因为对结果的影响不可观,所以就没去在意 ,后面发现用其他docker并没有多少问题,而且每次都出现一堆warning很影响美观性,于是百度准备解决这个问题</p><p><strong>后来发现是有个gast的库版本太高,导致不兼容的问题,降级gast即可解决</strong></p><p>使用pip进行降级</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --user gast==0.2.2</span><br></pre></td></tr></tbody></table></figure><p><strong>待解决：</strong></p><p><strong>tensorflow的兼容性问题 cuda的兼容性问题 ？？</strong></p><p><strong>一般如果要对服务器上的实验进行更改的话，怎能会简单一些？？</strong></p><h4 id="section-6">2020-09-13</h4><h5 id="主要内容-6">主要内容</h5><p>解决transformer报错的问题</p><p>解决tensorflow目前不支持CUDA10.1的问题</p><p>修改：</p><p>将batch 由 128 改为 32</p><p>将maxlen1 和maxlen2 由100改为101</p><h5 id="遇到问题-4">遇到问题</h5><ol type="1"><li><p>在运行transformer代码的时候，程序报错如下（部分内容，具体参考<code>train911.txt</code>）：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"train.py"</span>, line 81, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    hypotheses = get_hypotheses(num_eval_batches, num_eval_samples, sess, y_hat, m.idx2token)</span><br><span class="line">  File <span class="string">"/home/dell2/LSJ/transformer-master/utils.py"</span>, line 144, <span class="keyword">in</span> get_hypotheses</span><br><span class="line">    h = sess.run(tensor)</span><br><span class="line">  File <span class="string">"/home/dell2/anaconda3/envs/ronghe6/lib/python3.6/site-packages/tensorflow/python/client/session.py"</span>, line 950, <span class="keyword">in</span> run</span><br><span class="line">    run_metadata_ptr)</span><br><span class="line">  File <span class="string">"/home/dell2/anaconda3/envs/ronghe6/lib/python3.6/site-packages/tensorflow/python/client/session.py"</span>, line 1173, <span class="keyword">in</span> _run</span><br><span class="line">    feed_dict_tensor, options, run_metadata)</span><br><span class="line">  File <span class="string">"/home/dell2/anaconda3/envs/ronghe6/lib/python3.6/site-packages/tensorflow/python/client/session.py"</span>, line 1350, <span class="keyword">in</span> _do_run</span><br><span class="line">    run_metadata)</span><br><span class="line">  File <span class="string">"/home/dell2/anaconda3/envs/ronghe6/lib/python3.6/site-packages/tensorflow/python/client/session.py"</span>, line 1370, <span class="keyword">in</span> _do_call</span><br><span class="line">    raise <span class="built_in">type</span>(e)(node_def, op, message)</span><br><span class="line">tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[111,100] = 100 is not <span class="keyword">in</span> [0, 100)</span><br><span class="line"> [[node encoder_1/positional_encoding/embedding_lookup (defined at /home/dell2/LSJ/transformer-master/modules.py:290) ]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Original stack trace <span class="keyword">for</span> <span class="string">'encoder_1/positional_encoding/embedding_lookup'</span>:</span><br><span class="line">  File <span class="string">"train.py"</span>, line 48, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    y_hat, eval_summaries = m.eval(xs, ys)</span><br><span class="line">  File <span class="string">"/home/dell2/LSJ/transformer-master/model.py"</span>, line 176, <span class="keyword">in</span> <span class="built_in">eval</span></span><br><span class="line">    memory, sents1, src_masks = self.encode(xs, False)</span><br><span class="line">  File <span class="string">"/home/dell2/LSJ/transformer-master/model.py"</span>, line 53, <span class="keyword">in</span> encode</span><br><span class="line">    enc += positional_encoding(enc, self.hp.maxlen1)</span><br><span class="line"></span><br><span class="line">  File <span class="string">"/home/dell2/LSJ/transformer-master/modules.py"</span>, line 290, <span class="keyword">in</span> positional_encoding</span><br><span class="line">     outputs = tf.nn.embedding_lookup(position_enc, position_ind)</span><br></pre></td></tr></tbody></table></figure><p>可以追溯到位置编码部分，出现了<code>InvalidArgumentError: indices[111,100] = 100 is not in [0, 100)</code>的错误</p><p>于是在我将超参数maxlen由100改为101，可以正常运行</p><h4 id="参考-1">参考</h4></li><li><p>在rognhe6中安装的tensorflow-gpu：1.14是不支持CUDA10.1版本的，只支持到CUDA10.0版本。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.test.is_gpu_available()</span><br></pre></td></tr></tbody></table></figure><p>输出如下：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pciBusID: 0000:db:00.0</span><br><span class="line">2020-09-13 09:32:43.541828: Could not dlopen library <span class="string">'libcudart.so.10.0'</span>; </span><br><span class="line">dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory;</span><br><span class="line"></span><br><span class="line">False</span><br></pre></td></tr></tbody></table></figure></li></ol><p>可见是不支持目前ubuntu中的CUDA环境，参考了博客，修改如下：</p><p>将<code>cudatoolkit=10.0</code>安装到当前环境下</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install cudatoolkit=10.0</span><br></pre></td></tr></tbody></table></figure><p>问题解决</p><h5 id="参考-2">参考</h5><blockquote><p><a href="https://blog.csdn.net/qq_28193019/article/details/103146116" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/qq_28193019/article/details/103146116</a></p><p><a href="https://zhuanlan.zhihu.com/p/115611908" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/115611908</a></p></blockquote><ol start="3" type="1"><li>可以继续跑实验，可以用GPU，但是还是出现了一些问题</li></ol><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Resource exhausted: OOM when allocating tensor with shape[1024,98,64] and <span class="built_in">type</span> <span class="built_in">float</span> on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc</span><br></pre></td></tr></tbody></table></figure><p>显示内存不够，于是我将batch_size从128改为32 ，可以正常运行了</p><p>或者可以考虑使用多个GPU呢？</p><h5 id="参考-3">参考</h5><blockquote><p><a href="https://blog.csdn.net/Will_Ye/article/details/89878588" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/Will_Ye/article/details/89878588</a></p><p><a href="https://blog.csdn.net/Will_Ye/article/details/89878588" target="_blank" rel="noopener">OOM ResourceExhaustedError 的完美解决方法</a></p></blockquote><h3 id="section-7">2020-09-13</h3><p>transformer-mas训练部分已经跑了8个epoch，只用了一个GPU，跑的有点慢，于是暂停，以后再跑。</p><p>开始跑test.py文件，但是在跑的时候，<code>TypeError: stat: path should be string, bytes, os.PathLike or integer, &gt; not NoneType</code></p><p>路径写的不对，在ckpt中添加路径即可</p><h3 id="section-8">2020-09-29</h3><p>利用最新的ckpt进行测试，显示的是</p><p>想着可能最新的epoch的图和数据没有完全写入文件中，所以我在log/1文件夹中将最新的ckpt删除了，让次新的ckpt来进行测试。</p><p>发现结果还是unk ，不知道为什么？ 是不是因为我一个epoch保存了多个ckpt</p><h3 id="section-9">2020-09-30</h3><p>今天的实验终于解决了，可以有好的结果了。这段时间真的太煎熬了。不过还是学到了不少东西。</p><p>之前修改的其它地方是没有问题的，不需要再变，是在epoch</p><p>计划以及疑问：</p><p>如何锁死进程， 多个的话，会显示显存不足</p><p>为什么必须要跑完才能显示结果呢？ 在哪体现的呢</p><p>平时想要快速测试代码是否好用？ 有什么办法</p><p>哪些人tensorflow用的好，以后经常请教</p><p>模型验证的作用是啥？ 在代码中没有体现出来啊</p><p>总结遇到的困难以及学到的知识</p><p>解决onetab保存的标签</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录在跑实验的一些配置以及遇到的问题解决，保持更新
    
    </summary>
    
    
    
      <category term="故障排除" scheme="http://yoursite.com/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4/"/>
    
  </entry>
  
  <entry>
    <title>2020-09-06-学习工作杂记</title>
    <link href="http://yoursite.com/2020/09/06/2020-09-06-%E5%AD%A6%E4%B9%A0%E5%B7%A5%E4%BD%9C%E6%9D%82%E8%AE%B0/"/>
    <id>http://yoursite.com/2020/09/06/2020-09-06-%E5%AD%A6%E4%B9%A0%E5%B7%A5%E4%BD%9C%E6%9D%82%E8%AE%B0/</id>
    <published>2020-09-06T06:38:39.000Z</published>
    <updated>2020-09-19T14:02:42.167Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言">前言</h3><p>多做总结，提高效率，不要拖延</p><h3 id="怎样从熬夜中恢复过来">怎样从熬夜中恢复过来</h3><p>1． 不要打盹，5min不能够得到休息</p><p>2． 吃早餐 一个小时内吃早餐（全谷物和蛋白质） ，可以充满活力，认知能力可以提高，最好不摄入糖，会让人发困</p><p>3． 出去走。自然光可以让身体发热</p><p>4． 开始办公时候，喝一杯咖啡</p><p>5． 工作：首先完成最困难的部分，最开始的几个小时是一天中效率最高的时候</p><p>6． 会议之前可以喝一杯咖啡，有效时间是半小时</p><p>7． 午饭不吃过多的糖，会犯困</p><p>8． 下午可以喝一杯咖啡这时候是最困的时候。三点之后不能摄入咖啡，有效时间7 小时</p><p>9． 下午可以做一下简单的事情</p><h3 id="在家寝室学习">在家&amp;寝室学习</h3><ol type="1"><li><p>行为影响态度。换掉睡衣，接近类似学校的状态。希望自己成为什么样子， 就穿成什么样子</p></li><li></li></ol><p><img src="https://i.loli.net/2020/09/06/QDutkAwlLGgKTBo.png"></p><ol start="3" type="1"><li>先做一道题再说。（计划太多，无从下手。过分犹豫）不要想太多，直接动手</li></ol><p><img src="https://i.loli.net/2020/09/06/CerZI164jAU85qO.png"></p><ol start="4" type="1"><li>拒绝含糖食物</li></ol><p>自控力需要能量的供给，学习前可以吃块糖，可以补充能量。但是减少高gi食物，如酸奶果汁薯片，或者碳水类食物（米饭面条土豆）。多吃瘦肉、蔬菜、水果，能够增强自控力，还能瘦</p><ol start="5" type="1"><li><p>不要用时间做计划，用学习量做计划。（因为会拖延）拒绝整点学习、计划学习时间，采用今天背多少单词等，一个清晰明确的目标会事半功倍</p></li><li><p>保持工作区的整洁，不放无关的物品。使手机飞行模式、黑白模式</p></li></ol><p><img src="https://i.loli.net/2020/09/06/UO5JydTCmLIKa12.png"></p><h3 id="戒掉手机避免用意志力来克制">戒掉手机（避免用意志力来克制）</h3><p>1． 替代法 并不是真正想做，而是习惯了某种行为。可以买一个手机模型，终止大脑的无意识行为，给大脑一个选择的机会</p><p>2． 心理暗示。‘我不玩手机‘ 而不是’我不能玩手机‘</p><p>3． 优化环境。环境的影响很大。搭建一个良好的环境。睡觉前把手机放在客厅，学习时增加获得手机的难度</p><p>4． 负面反馈。人们对于损失和负面事件的敏感度高于正面事件的敏感</p><p>5． 看实时学习视频，看到别人学习 自己也不好意思玩</p><p>休息放空自己，会使得注意力更集中</p><p>把社交软件放在小文件夹里再放到手指不容易碰到的地方，如果一段时间又习惯了点这个位置的社交软件，就再更换桌面排布</p><h3 id="自己习惯">自己习惯</h3><p>对于我自己来说，习惯睡觉前进行一些文字记录的工作，比如写博客做总结，就是不会再去接触一些新知识。把第二天要做的事情列好，或者直接找好第二天最难工作内容的参考资料，对第二天工作内容有一个大概的印象，这样第二天一早就可以直攻克艰难的部分，避免其它琐碎的事情</p><p>起床的时候，提前找好第二天要穿的衣服，同时可以适量补充水分</p><p>在进行学习的时候，先设置5分钟，休息5分钟，再逐渐增加时间，进入状态，多学习时间不休息</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      之前看的一个b站up主关于如何高效学习的视频，觉得受到了启发，于是记录了下来，以此找到更适合自己的学习习惯
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-09-06-不确定性研究</title>
    <link href="http://yoursite.com/2020/09/06/2020-09-06-%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%A0%94%E7%A9%B6/"/>
    <id>http://yoursite.com/2020/09/06/2020-09-06-%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%A0%94%E7%A9%B6/</id>
    <published>2020-09-05T16:06:55.000Z</published>
    <updated>2020-10-10T14:04:27.458Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言">前言</h3><p>近日，旷视上海研究院长危夷晨在将门技术社群做了一次题为《Uncertainty Learning for Visual Recognition》(不确定性学习在视觉计算中的应用) Online Talk，共分为4个部分：</p><ol type="1"><li>Preliminary（基础知识）</li><li>Uncertainty in Deep Learning（深度学习中的不确定性问题）</li><li>Uncertainty in Computer Vision（不确定性的计算机视觉应用）</li><li>Summary（总结）</li></ol><p>我主要参考了前三部分的内容</p><h3 id="基础知识">基础知识</h3><h4 id="何为不确定性估计">何为不确定性估计</h4><p>要理解何为不确定性估计，我们可以先从<strong>确定性预测（deterministic prediction）</strong>开始。假设要对两张人脸进行对比，验证是否是同一个人的照片，那么可以使用人脸识别系统分别对这两张人脸图片提取特征，并使用某种度量指标衡量所提取的两个特征的相似程度，根据所预测出的相似程度来判断两张人脸图像是否从属同一个人。如果相似度很高（比如95%），则可以判断这两张人脸属于同一个人。这种通过预测一个确定性的人脸特征用来判断的方式被称为确定性预测（deterministic prediction）。</p><p>然而这个<strong>相似度分数并不总是有效</strong>，以下图中第二个例子为例，可以看到在输入图像中，一张非常清晰，另一张十分模糊，然而这个时候人脸识别系统依然给二者打出很高的相似度分数，那么面对这种情况，我们是否要相信系统给出的答案，我们是否有办法来判断系统给出这个分数的可靠程度？</p><p>为此，人们提出了另一个<strong>辅助判断的指标</strong>，即判断机器给出的答案是否可信，可信程度多少的分数被称为<strong>confidence score（置信度分数）</strong>。如下图第二行中，系统给出相似度95%，然而confidence score却只有10%，表明<strong>系统给出的相似度分数的可信度很低，因此我们在采纳系统给出的这个判断答案的时候需要十分谨慎。</strong></p><p>从这个案例可以知道，<strong>在confidence score分数背后存在一个核心思想，即很多时候机器学习系统给出的判断不一定是靠谱的，即，系统对于给出的判断具有一定程度的“不确定性”。</strong>那么此时人们就需要知道系统给出这个判断到底有几成把握，因此我们需要诸如置信度分数或者“不确定性”分数这样的额外信息来帮助我们做出更好的决策。</p><p><img src="https://i.loli.net/2020/09/06/xBqNOnrsRiM7o85.jpg" alt="img"></p><h4 id="为何不确定性重要">为何不确定性重要</h4><p>上面介绍完之后，我们再来谈谈它为什么重要。简单来讲，不确定性估计在深度学习之中有着广泛的应用场景，为其落地发挥着不可替代的重要作用，下面讲一些比较要代表性的场景：</p><ol type="1"><li><strong>高风险应用场景</strong>。这类场景<strong>需要非常精确的估计</strong>，因为一旦估计错误，可能出现严重的后果，例如医疗图像诊断、自动驾驶。</li><li><strong>大量机器学习场景</strong>。比如，在主动学习（Active Learning）这种技术框架中，模型需要确定哪些样本更值得被打标签。这也涉及到系统对于估计样本“价值程度”不确定性。同时，研究人员往往也会发现单纯使用机器学习系统进行判断时，会存在少量样本系统无法做出很好的判断，因此这时人们会邀请专家来标记这部分困难样本，以训练模型。</li><li><strong>强化学习</strong>。强化学习由于经常要权衡exploration和exploitation操作，因此如何确定每一台机器的概率分布是否被准确估计，就是对这台机器模型参数的不确定性估计。</li><li><strong>对处于训练数据分布之外情况的检测</strong>。由于很多时候测试数据并不在训练数据中，因此如果测试数据超出了训练数据的数据分布，那这样的预测是没有准确度可言的，这时候就需要一个额外的不确定性估计来确认对当前的预测有多大把握。</li></ol><h4 id="两种不确定性">两种不确定性</h4><p>接下来，我们界定一下不确定性的分类问题。一般来讲，不确定性可以分为两类：</p><ol type="1"><li><strong>数据的不确定性</strong>：也被称为偶然（Aleatoric）不确定性，它描述的是<strong>数据中内在的噪声，即无法避免的误差，这个现象不能通过增加采样数据来削弱。</strong>例如有时候拍照的手稍微颤抖画面便会模糊，这种数据是不能通过增加拍照次数来消除的。因此解决这个问题的方法一般是提升数据采集时候的稳定性，或者提升衡量指标的精度以囊括各类客观影响因素。</li><li><strong>模型的不确定性</strong>：也被称为认知（Epistemic）不确定性。它指出，<strong>模型自身对输入数据的估计可能因为训练不佳、训练数据不够等原因而不准确，与某一单独的数据无关</strong>。因此，认知不确定性测量的，是训练过程本身所估计的模型参数的不确定性。这种不确定性是可以通过有针对性的调整（增加训练数据等方式）来缓解甚至解决的。</li></ol><h3 id="深度学习中的不确定性问题">深度学习中的不确定性问题</h3><p><strong>如果单看深度学习网络本身，它是确定性的，例如简单的多层前馈网络，在训练好以后，其结构、权重以及对某一个样本所输出类别的概率都是确定的。因此，在深度神经网络中引入不确定性的一个方法就是引入贝叶斯法则，从而得到贝叶斯神经网络（BNN）。</strong></p><p>简单而言，如下图，贝叶斯神经网络的<strong>权重不像普通神经网络是一个具体数值，而是一个概率分布，表示每一个权重w遵循一个分布，而非之前是一个确定的数值</strong>。因此在训练和推理中，网络的权重会变化，<strong>根据分布来随机采样</strong>。通过这种方法可以建模各个参数本身存在的不确定性。</p><p><img src="https://i.loli.net/2020/09/06/6IRjbGw4cfT8mSB.jpg" alt="img"></p><p>然而，由于在实际应用中参数量十分巨大，要严格根据贝叶斯公式计算后验概率几乎不现实，因此为了将网络应用于大型数据集，就<strong>需要高效的近似计算方法</strong>。早期比较有名的方法是通过马尔科夫链蒙特卡洛采样法（MCMC-sampling）来逼近假定的参数分布，但是由于这种方法很慢，因此发展出了一系列更好的<strong>近似计算后验概率</strong>的方法，如下：</p><h4 id="变分推断">变分推断</h4><p>变分推断的基本方法就是<strong>引入变分分布对BNN优化过程中涉及到的后验概率进行近似估计，这种方法较为高效。</strong></p><p><img src="https://i.loli.net/2020/09/06/nQzKO2i1PYNkvuU.jpg"></p><h4 id="dropoutbnnvi">Dropout=BNN+VI</h4><p><img src="https://i.loli.net/2020/09/06/aQRWjzwDKIJl6eL.jpg" alt="img"></p><p>这种<strong>dropout方法</strong>也称为蒙特卡洛dropout，进一步简化了对后验概率分布的近似计算，它认为常见的dropout技术实际上等于在贝叶斯网络中进行变分推断。通过上图的对比，我们可以直观理解标准神经网络经过dropout之后，在每一层随机取消一些神经元，把连接变稀疏的网络是什么样子。</p><p>可以证明，<strong>在假设每一个神经元都服从一个离散的伯努利分布的情况下，经dropout方法处理的神经网络的优化过程实际上等价于在一个贝叶斯网络中进行变分推断。</strong>由于这种结构中每个节点的权重是被多个子网络共享的，因此它的训练和推理相对高效。这项理论成果近年来得到了较多的应用。</p><p>我们在前向传播的时候，让某个神经元的激活值以<strong>一定的概率p停止工作</strong>（每一个批次都是随机），这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征。</p><p><strong>dropout掉不同的隐藏神经元就类似在训练不同的网络，随机删掉一半隐藏神经元导致网络结构已经不同，整个dropout过程就相当于对很多个不同的神经网络取平均。而不同的网络产生不同的过拟合，一些互为“反向”的拟合相互抵消就可以达到整体上减少过拟合。</strong></p><h5 id="dropout具体工作流程">Dropout具体工作流程</h5><p>假设我们要训练这样一个神经网络，如图所示。</p><p><img src="https://i.loli.net/2020/09/06/SetbpsjYxEX1yQZ.jpg" alt="标准的神经网络"></p><p>输入是x输出是y，正常的流程是：我们首先把x通过网络前向传播，然后把误差反向传播以决定如何更新参数让网络进行学习。使用Dropout之后，过程变成如下：</p><p>（1）首先<strong>随机（临时）</strong>删掉网络中一半（dropout=0.5时）的隐藏神经元，输入输出神经元保持不变（图中虚线为部分临时被删除的神经元）</p><p><img src="https://i.loli.net/2020/09/06/GnirX4u39lSmyUg.jpg" alt="部分临时被删除的神经元"></p><p>（2） 然后把输入x通过修改后的网络前向传播，然后把得到的损失结果通过修改的网络反向传播。一小批训练样本执行完这个过程后，在<strong>没有被删除的神经元上</strong>按照随机梯度下降法更新对应的参数（w，b）。</p><p>（3）然后继续重复这一过程：</p><ul><li><strong>恢复被删掉的神经元</strong>（此时被删除的神经元保持原样，而没有被删除的神经元已经有所更新）</li><li>从隐藏层神经元中<strong>随机选择</strong>一个一半大小的子集临时删除掉（备份被删除神经元的参数）。</li><li>对一小批训练样本，先前向传播然后反向传播损失并根据随机梯度下降法更新参数（w，b） （没有被删除的那一部分参数得到更新，删除的神经元参数保持被删除前的结果）。</li></ul><p>不断重复这一过程。</p><h5 id="参考">参考</h5><blockquote><p><a href="https://zhuanlan.zhihu.com/p/38200980" target="_blank" rel="noopener">深度学习中Dropout原理解析</a></p></blockquote><h4 id="模型融合">模型融合</h4><p>这也是一种进行不确定性估计的基本方法，其大致思路是，<strong>从一个数据集中进行多次随机采样，分别训练模型，然后再将这些模型的推理结果综合，其均值作为预测结果，方差作为预测的不确定性。</strong>另外需要强调的是，蒙特卡洛dropout可以认为是一种特殊的模型融合方法。</p><p><img src="https://i.loli.net/2020/09/06/noXFIR2ACtwpmk1.jpg" alt="img"></p><h3 id="回归问题中的数据不确定性">回归问题中的数据不确定性</h3><p>这是一种数据估计的标准做法。<strong>给定输入x_i，解一个函数f(x_i)，使得它逼近ground truth y_i。假设这个函数f(x_i)遵循一个高斯分布，那么其均值就是y_i，方差就是σ（也依赖于x_i）。</strong></p><p><strong>这时，如果对这个高斯分布取似然度，再取负的log值，那么就可以得到下图中的损失函数L。因此在优化的时候，除了希望优化f(x_i)逼近y_i，同时也需要优化σ(x_i)，它表示这个高斯分布的不确定性，σ越大越不确定。</strong></p><p>因此当f很容易逼近y的时候，那么公式中第一项L2范数就会很小，这时即便σ也小，但结果依然不会很大；当f很难逼近y，即f很难学习的时候，第一项中的L2范数就会很大，这时优化过程就会使得σ也变大，从而使得整个第一项减小，因此学到的σ会随着数据学习的难度做自我调整。</p><p><img src="https://i.loli.net/2020/09/06/nlD62kW1pXygAV4.jpg" alt="img"></p><h4 id="简单例子">简单例子</h4><p>我们借助一个直观例子来理解模型不确定性与数据不确定性。首先这里的<strong>ground truth函数为一个正弦函数</strong>，即图中橙色的点是测试数据，而<strong>训练数据是从[-5，+5]区间采样的蓝色点，研究人员对每一个蓝色点都添加了高斯噪声，因此可以看到这些蓝色点明显偏离ground truth。</strong></p><p>下方左图是用贝叶斯网络加dropout进行的<strong>模型不确定性估计</strong>。<strong>红色曲线为估计出来的预测值，延其上下分布的黄色面积则为每一个点对应的方差</strong>。在进行模型不确定性估计时，系统会对每个输入点估计多次，每次会随机采样模型的权重，以求出对每个输入点多次预测所得到的均值和方差。可以发现，蓝色点区域之外的部分预测的方差很大，这是因为模型没有见过这样的数据。（<strong>因为蓝色是训练数据</strong>，其它是测试数据，没见过的，所以方差就会较大，也就是不确定性较高）</p><p>下方右图中红色曲线为估计出来的预测值，是<strong>数据不确定性估计</strong>，曲线上下的黄色跨度就是每一个点通过数据不确定性估计方法所学出的方差。可以发现，原本输入数据中有噪声的部分，其预测出的方差比较大，反映出模型对这样的输出拥有较大的不确定性。</p><p><img src="https://i.loli.net/2020/09/06/EjFQnPko6pVhYH5.jpg" alt="img"></p><h3 id="不确定性的计算机视觉应用">不确定性的计算机视觉应用</h3><p><img src="https://i.loli.net/2020/09/06/Gw6pNAvuisDe18a.png" alt="img"></p><p>尽管不确定性在机器学习中已经有很长历史，但是直到2017年（就我所知）随着NeurlPS论文<em>What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision</em>的提出，它才开始真正应用在基于深度学习的视觉预测任务中。这篇论文本身没有太多方法创新，通过将已知的方法 用于语义分割与深度回归任务，取得了不错的结果。<strong>通过在模型中引入不确定性估计的已有理论成果，使得原本任务的精度得到了显著提升。</strong></p><p>通过论文给出的定性结果可以较为直观的理解模型不确定性和数据不确定性。如下图，系统估计出来的不确定性是有明确含义即很容易理解的，图中上半部分做语义分割，下半部分做深度估计。</p><p><img src="https://picb.zhimg.com/80/v2-cf9cf0d7715af33b38dc8fa8b71b8aa0_1440w.jpg" alt="img"></p><p><strong>整张图的第4、5列分别是数据不确定性和模型不确定性的结果。红色部分表示不确定程度较大，蓝色部分表示较为确定。从数据不确定性结果（第4列）可以看到，红色部分往往出现在物体边界处，表示这些区域的像素更加具有二义性，系统不太清楚这部分像素究竟属于前景还是背景，另外这部分信息在训练数据中（即ground truth）往往也较模糊。可以发现，系统给出的数据不确定结果符合人类直观理解。</strong></p><p><strong>从模型不确定性结果（第5列）可以看到，模型对出现人的部分给出了很高的不确定性，这是因为模型在训练中很少遇到人的数据，因此模型很难估计出人所处位置的深度，将该区域标记为高度不确定。</strong></p><h4 id="物体检测中的数据不确定性">物体检测中的数据不确定性</h4><p><img src="https://i.loli.net/2020/09/06/RrKDqx7kFG8mJyl.jpg" alt="img"></p><p>在物体检测任务中，很大一部分不确定性来源于标注数据的不确定。上图给出了几个典型例子，可以看到，在标注边界框的时候，由于存在各种物体角度、遮挡，所以往往很难评价一个边界框标注的好坏。由于标注规则不一、数据本身存在的各种不确定性，因此具有二义性的数据标注会导致具有二义性的学习结果，从而将不确定性引入了模型，进一步输出结果也是不确定的。</p><p>针对这个问题，有研究人员在CVPR 2019、ICCV 2019提出了两篇颇有价值的论文，其核心思想类似，将每一个边界框的4个坐标均认为呈高斯分布，然后分别估计其均值和方差。用上述介绍的数据不确定性回归公式来替代传统的L1损失，将原来所需要预测的4个变量扩充为8个变量。</p><p>因此，这种方法除了可以估计边界框每一个坐标之外，还让它们都带有了一个不确定性参数。利用这些不确定性数据，可以进一步做很多事情（比如在NMS中作为权重来对边界框位置进行投票）。</p><h4 id="人脸识别中的模型不确定性">人脸识别中的模型不确定性</h4><p><img src="https://i.loli.net/2020/09/06/nWDBsXI2dNfaHTV.jpg" alt="img"></p><p>对于在人脸识别任务中如何估计模型不确定性，推荐大家上图中的论文工作，其核心思想是，将BNN+dropout用到人脸识别任务中，如图所示，dropout层（红色）被加在每一个卷积block之后，从而构建了一个蒙特卡洛Dropout网络。在训练过程中，每当流程到达这些层的时候，就会随机丢掉一些神经元，从而实现模拟参数分布的效果。在测试过程中，每一个图像都会经过该网络多次，进而可以多这些结果估计均值与方差，将方差作为预测结果的不确定性。</p><h4 id="人脸识别中的数据不确定性pfe方法">人脸识别中的数据不确定性：PFE方法</h4><p><img src="https://i.loli.net/2020/09/06/qPMvAkWN1UHK2e9.jpg" alt="img"></p><p>PFE方法全称为Probabilistic Face Embeddings，其核心思想是用概率分布来替代传统确定的人脸嵌入特征。传统的方法会将输入图像映射到一个高维空间中，得到一个表示特征的向量，然而对于这些方法而言，输出的向量都是确定的，因此被称为deterministic embedding。PFE引入了不确定性，将输出向量认为是一个概率分布，而不再是一个确定的向量，它有一个均值μ、方差σ。</p><p>均值代表对图像的嵌入，方差描述了模型对输入数据的不确定性。该方法希望同时估计μ和σ，并且σ能够根据输入图像的质量、包含噪声的程度进行自适应的学习。在上图右方的示例中可以看到，每一个输出的特征z不再是一个点，而是一个高斯形状的概率分布（椭圆），椭圆的大小就描述了估计的不确定性。</p><p><img src="https://i.loli.net/2020/09/06/O8mvS1VTIHodxZ5.png" alt="img"></p><p>从具体实现方法来看，PFE的创新值得借鉴，它并不直接去估计每一个均值μ，而是通过一个事先已经训练好的人脸识别模型来抽取每个样本的特征μ_i，然后研究人员再在网络中加入一个小分支，来对每个样本输出一个方差（比如假设μ_i是一个512维的向量，那么此时也会输出一个对μ_i的每一维度单独估计方差的512维方差向量）。</p><p>进一步，论文提出了一种新的metric——mutual likelihood score（MLS），来衡量两个分布间的距离。上图公式中x_i和x_j是两个样本在特定空间中的高斯分布，两个分布所得到的MLS数值就代表了其相似度。在训练过程中，针对所有positive 样本，计算负的MLS数值作为损失，并最小化该损失目标函数，进而可以估计新增加分支（估计方差的分支）的参数。</p><p><img src="https://picb.zhimg.com/80/v2-b2a72843a1b2199fb213df0e93e9d570_1440w.jpg" alt="img"></p><p>上图是论文对方差的解释，较为直观。可以发现红框标注出来的（方差超过一定阈值）图片都是姿态有较大变化、模糊、或者有遮挡的图片，系统都认为它们识别起来有较大不确定性；而正面、高清的图片不确定性普遍较小。为了进一步验证学习出来的不确定性是否能够有效解释图像质量，PFE在下方左图中进行了有关在低质量图像之间使用传统cosine相似度计算是否可靠的研究。</p><p>研究人员对清晰图片添加了不同程度的噪声，蓝色线代表原图与模糊图之间的相似度分数，而红色代表两张来自不同ID的图随模糊程度的增加所计算的相似度。可以发现对于同一ID（蓝线），随着模糊程度增加，相似度也逐渐降低；而对于不同ID，随着模糊程度增加相似度却在增加。这说明依据该相似度可能会将两张来自不同ID的模糊图像错认为是同一张图。这一现象在其它很多论文中也同样被观测到。</p><p><img src="https://picb.zhimg.com/80/v2-e38487eb964f4dc56b7ba89689ea5158_1440w.jpg" alt="img"></p><p>然而在经过PFE论文提出的MLS相似度修正之后，情况得到了很大改善。如右图，当图片模糊度增加时，对同样ID的图来说，其相似度没有变得太小，而不同ID图像的相似度也没有变得太大。这个实验证明这种计算图像相似度的新metric在面对低质量图片时更加鲁棒。</p><h4 id="pfe方法的缺陷">PFE方法的缺陷</h4><p>虽然PFE方法取得了重要进展，但是缺点也很明显，因为它并没有学习身份特征（identity-feature），每一个identity的特征嵌入是确定的，PFE只是增加了一个估计方差的小网络分支，这导致必须用一个新的metric（即MLS）来计算所有样本对的距离。而使用MLS这个度量函数带来的缺陷在实际工业应用中是代价较高的：第一，我们需要额外存储方差向量；第二，相比传统的余弦相似度，MLS相似度的计算资源消耗也更大。</p><p>受此启发，我们团队在投递给CVPR 2020的新论文中不仅做到了估计方差，同时也能更新每个样本的特征。下图为传统方法、PFE与我们团队方法的对比。</p><p><img src="https://i.loli.net/2020/09/06/pYSInMZ9R64euEC.jpg" alt="img"></p><p>可以发现，在图（a）中，虚线框出的蓝色椭圆代表一个类别，圈外存在一个正样本和负样本，而对于传统相似度计算方法来说，很难将负样本和正样本区分开来；而（b）中PFE方法对每个样本估计了一个分布，在带有分布的特征表示下，利用MLS就能够有效将正样本和负样本区分开来，但是PFE中正负样本本身是确定的；在（c）中，我们团队方法能够在估计正负样本方差的同时，也让特征本身修正得更好。</p><p><img src="https://i.loli.net/2020/09/06/ayVXfSxm1DYk5dG.png" alt="img"></p><p>上图是三种方法的对比，可以看到在最后计算相似度的时候，由于特征本身经过了调整，只需要使用cosine相似度来计算两个均值向量就可以得出答案。具体而言，我们团队提出了两种实现方法，如下：</p><h3 id="法1从头学习一个分类模型"><strong>法1：从头学习一个分类模型</strong></h3><p><img src="https://i.loli.net/2020/09/06/yZWVciHGd8bwK74.jpg" alt="img"></p><p>这种方法的主要部分与通用识别模型的结构一致，区别在于，在输出特征的位置，我们让模型输出一个有关每个样本特征的均值μ，以及一个方差σ。进一步，对于每个样本的每一次迭代而言，都随机采样一个ε（如上图最下方）。</p><p>通过这种方式得到的新样本特征s_i就是遵从均值μ、方差为σ的高斯分布采出的值，它可以模拟一个服从高斯分布的特征。通过这种简单的重新采样的技巧，就可以很好进行模型训练。在测试的时候不再需要采样，仅需要将已经得到的均值μ作为特征来计算相似度即可。</p><p><img src="https://i.loli.net/2020/09/06/8PcKyqBlErgUQAm.png" alt="img"></p><p>该方法的损失函数除了包含softmax以及其一切合理变种之外，还有一个KL损失，它使得每一个学出来特征的分布尽可能逼近单位高斯分布。这个损失项的引入来自于2016年一篇名为<em>Deep variational information bottleneck</em>的论文。进一步整个损失函数就可以用标准SGD方法来优化。下图解释了整个损失函数中softmax与kl损失是如何起到平衡的作用的。</p><p><img src="https://i.loli.net/2020/09/06/9wxoyQuj8M2AWem.jpg" alt="img"></p><h3 id="法2从现有模型出发学习回归模型"><strong>法2：从现有模型出发学习回归模型</strong></h3><p><img src="https://i.loli.net/2020/09/06/k8rDhcJY5ZaMQnU.jpg" alt="img"></p><p>这种方法假设输出的特征μ遵循高斯分布，目的是让它逼近期望的特征w。与PFE类似，假设输入的模型已经固定，且输出的特征μ属于类别c，则让μ逼近这个类别c的特征中心w_c（w_c来自事先训练好的人脸分类模型）。这种方法适用于当已经有一个训练好的模型，但依然希望做不确定性估计的情况。相对于PFE而言，它多做了样本特征的学习。下图解释了该损失函数中σ起到的平衡作用。</p><p><img src="https://i.loli.net/2020/09/06/3qWYVXC4QIx1vh8.png" alt="img"></p><p><strong>实验结果：</strong>在三种损失函数上的对比测试结果显示，我们团队提出的分类方法（HUM_cls）在最困难的数据集IJB-C（具有大量模糊、噪声图像）上效果最佳；在LFW、CFP-FP、YTF这些较成熟的数据集上我们提出的两种方法同其他方法区别不大；在较困难的MegFace(R1)数据集上我们团队的分类方法效果最佳。</p><p><img src="https://i.loli.net/2020/09/06/9e3k4ImOhET5Wgo.jpg" alt="img"></p><p>下图展示了在三种数据集上学习出来的方差分布情况，展示了位于不同方差位置的图像的样子。</p><p><img src="https://i.loli.net/2020/09/06/81X3Pk4o9IHZTxE.jpg" alt="img"></p><p>进一步，我们团队使用了ResNet-64作为backbone（与PFE的SOTA模型backbone深度一致），来将本文方法同SOTA方法在最困难的数据集IJB-C上进行性能对比，结果显示在每一个指标上我们团队方法均实现了领先。为了测试本文方法对噪声信息干扰的鲁棒性，团队对图片人工施加了高斯噪声（从0到40%），可以发现，当噪声越明显的时候，本文引入的不确定估计方法的优越性也约高。</p><p><img src="https://i.loli.net/2020/09/06/4VLqFkPgIvaYSm2.jpg" alt="img"></p><h3 id="参考-1">🚀参考</h3><blockquote><p><a href="https://zhuanlan.zhihu.com/p/95774787" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/95774787</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      深度学习模型的不确定性估计，摘自几篇不错的博客
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-09-05-知识点杂</title>
    <link href="http://yoursite.com/2020/09/05/2020-09-05-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%9D%82/"/>
    <id>http://yoursite.com/2020/09/05/2020-09-05-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%9D%82/</id>
    <published>2020-09-05T11:56:22.000Z</published>
    <updated>2020-10-17T13:34:54.908Z</updated>
    
    <content type="html"><![CDATA[<h3 id="对数似然">对数似然</h3><p>最大化对数似然，因此值越大越好。例如，对数似然值 -3 比 -7 好。</p><p>对数为负值是完全可能的，如下图log函数</p><p><img src="https://i.loli.net/2020/09/12/UFihCbxJk9gBfuz.png" alt="对数- 维基百科，自由的百科全书" style="zoom: 33%;"></p><h3 id="高斯分布中考虑对数似然而不是似然">高斯分布中考虑对数似然而不是似然</h3><p>通过最大似然函数来确定高斯分布中未知参数的值，实际上，<strong>最大化似然函数的对数更方便</strong>。因为对数是其论证的单调递增函数，函数的对数的最大化等价于函数本身的最大化。logaithm不仅简化了后续的数学分析，而且还有助于数学计算，<strong>因为大量小概率的乘积很容易使计算机的数值精度下降，但是log就可以通过计算总和来解决</strong>。</p><ol type="1"><li>当要计算随机变量的joint likelihood时很有用，他们之间独立，并且分布相同。</li></ol><p><img src="https://i.loli.net/2020/09/12/jAqSrXz7v39mE2p.png" alt="image-20200905213103449"></p><p>联合概率是所有点的概率的乘积：</p><p><img src="https://i.loli.net/2020/09/12/2sf4RyCm7IVxFpt.png" alt="image-20200905213136550"></p><p><strong>如果是log，则只需要求和即可</strong></p><ol start="2" type="1"><li>由于是<strong>高斯分布</strong>，使用log避免了计算指数</li></ol><p><img src="https://i.loli.net/2020/09/12/pbN4OgBAyoEWv2Y.png" alt="image-20200905213239871"></p><p>可以写成：</p><p><img src="https://i.loli.net/2020/09/12/YHpEnC951eJfvkj.png" alt="image-20200905213249229"></p><ol start="3" type="1"><li>ln x是单调递增的函数，因此log-likelihood和likelihood有相同的关系</li></ol><p><img src="https://i.loli.net/2020/09/12/1NHzhmdvcIZEkQl.png" alt="image-20200905213303446"></p><p><strong>负对数似然</strong>是一种用于解决分类问题的 损失函数 ，它是似然函数得一种自然对数形式，可用于测量两种概率分布之间的相似性，其取负号是为了让最大似然值和最小损失相对应，是最大似然估计及相关领域的常见函数形式。</p><p>机器学习中，习惯用优化 算法 求最小值，因此会用到负对数似然，这是分类问题中的常见的损失函数，且能拓展到 多分类 问题。</p><h3 id="负对数似然和似然估计">负对数似然和似然估计</h3><p><strong>负对数似然</strong>是一种用于解决分类问题的 损失函数 ，它是似然函数的一种自然对数形式，可用于测量两种概率分布之间的相似性，其取负号是为了让最大似然值和最小损失相对应，是最大似然估计及相关领域的常见函数形式。</p><p>机器学习中，习惯用优化 算法 求最小值，因此会用到负对数似然，这是分类问题中的常见的损失函数，且能拓展到 多分类 问题。</p><h3 id="最大似然估计">最大似然估计</h3><blockquote><p><a href="https://zhuanlan.zhihu.com/p/32803109" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/32803109</a></p></blockquote><h3 id="epochiterationbatch_size">Epoch、Iteration、Batch_size</h3><p><a href="https://blog.csdn.net/program_developer/article/details/78597738" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/program_developer/article/details/78597738</a></p><h3 id="tf.tile用法">tf.tile()用法</h3><p><a href="https://blog.csdn.net/tsyccnh/article/details/82459859" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/tsyccnh/article/details/82459859</a></p><h3 id="dataset-api-和-iterator">Dataset API 和 Iterator</h3><p>Dataset API 和 Iterator</p><p><a href="https://blog.csdn.net/briblue/article/details/80962728" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/briblue/article/details/80962728</a></p><p>TensorFlow中的Dataset API</p><p><a href="https://blog.csdn.net/dqcfkyqdxym3f8rb0/article/details/79342369" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/dqcfkyqdxym3f8rb0/article/details/79342369</a></p><p>TensorFlow data模块详解</p><p><a href="https://www.weaf.top/posts/cd5ba0c4/" target="_blank" rel="noopener" class="uri">https://www.weaf.top/posts/cd5ba0c4/</a></p><p>使用Tensorflow的DataSet和Iterator读取数据</p><p><a href="https://www.jianshu.com/p/bcff8a99b15b" target="_blank" rel="noopener" class="uri">https://www.jianshu.com/p/bcff8a99b15b</a></p><p>tensorflow数据读取机制（附代码）</p><p><a href="https://zhuanlan.zhihu.com/p/27238630" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/27238630</a></p><p>Dataset API入门教程</p><p><a href="https://zhuanlan.zhihu.com/p/30751039" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/30751039</a></p><p>Dataset.from_generator</p><p><a href="https://blog.csdn.net/foreseerwang/article/details/80572182" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/foreseerwang/article/details/80572182</a></p><p>看个简单的示例：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#创建一个Dataset对象</span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices([1,2,3,4,5,6,7,8,9])</span><br><span class="line"></span><br><span class="line">#创建一个迭代器</span><br><span class="line">iterator = dataset.make_one_shot_iterator()</span><br><span class="line"></span><br><span class="line">#get_next()函数可以帮助我们从迭代器中获取元素</span><br><span class="line">element = iterator.get_next()</span><br><span class="line"></span><br><span class="line">#遍历迭代器，获取所有元素</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">   for i in range(9):</span><br><span class="line">       print(sess.run(element))</span><br></pre></td></tr></tbody></table></figure><p>以上打印结果为：1 2 3 4 5 6 7 8 9</p><p>from_generator</p><p>创建Dataset由其生成元素的元素generator。</p><p>函数形式：from_generator(generator,output_types,output_shapes=None,args=None)</p><p>参数generator:一个可调用对象，它返回支持该iter()协议的对象 。如果args未指定，generator则不得参数; 否则它必须采取与有值一样多的参数args。 参数output_types：tf.DType对应于由元素生成的元素的每个组件的对象的嵌套结构generator。 参数output_shapes:tf.TensorShape 对应于由元素生成的元素的每个组件的对象 的嵌套结构generator 参数args:tf.Tensor将被计算并将generator作为NumPy数组参数传递的对象元组。</p><p>具体例子</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#定义一个生成器</span><br><span class="line">def data_generator():</span><br><span class="line">    dataset = np.array(range(9))</span><br><span class="line">    for i in dataset:</span><br><span class="line">        yield i</span><br><span class="line"></span><br><span class="line">#接收生成器，并生产dataset数据结构</span><br><span class="line">dataset = tf.data.Dataset.from_generator(data_generator, (tf.int32))</span><br><span class="line"></span><br><span class="line">iterator = concat_dataset.make_one_shot_iterator()</span><br><span class="line"></span><br><span class="line">element = iterator.get_next()</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">   for i in range(3):</span><br><span class="line">       print(sess.run(element))</span><br></pre></td></tr></tbody></table></figure><p>以上代码运行结果：0 1 2</p><h3 id="strip-和-split">strip() 和 split()</h3><p><a href="https://blog.csdn.net/hjxu2016/article/details/78676859" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/hjxu2016/article/details/78676859</a></p><h3 id="summary用法--tensorborad可视化">Summary用法 -tensorborad可视化</h3><p><a href="https://www.cnblogs.com/lyc-seu/p/8647792.html" target="_blank" rel="noopener" class="uri">https://www.cnblogs.com/lyc-seu/p/8647792.html</a></p><h3 id="math.ceil">math.ceil()</h3><p><a href="https://www.runoob.com/python/func-number-ceil.html" target="_blank" rel="noopener" class="uri">https://www.runoob.com/python/func-number-ceil.html</a></p><h3 id="format-格式化函数">.format() 格式化函数</h3><p><a href="https://www.runoob.com/python/att-string-format.html" target="_blank" rel="noopener" class="uri">https://www.runoob.com/python/att-string-format.html</a></p><h3 id="tf.shapea-和-a.get_shape.as_list-和-tf.split">tf.shape(A) 和 A.get_shape().as_list() 和 tf.split()</h3><p><a href="https://www.itread01.com/content/1544436557.html" target="_blank" rel="noopener" class="uri">https://www.itread01.com/content/1544436557.html</a></p><p><a href="https://blog.csdn.net/xc_zhou/article/details/85632109" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/xc_zhou/article/details/85632109</a></p><ul><li>tf.shape(A) # 獲取張量A（陣列，list, tensor張量）的大小，返回的是一個list</li><li>x.get_shape()，只有<strong>tensor</strong>才可以使用這種方法，返回的是一個元組</li><li>tf.split(dimension, num_split, input)：dimension的意思就是輸入張量的哪一個維度，如果是0就表示對第0維度進行切割。num_split就是切割的數量，如果是2就表示輸入張量被切成2份，每一份是一個列表。</li></ul><h3 id="tf.range">tf.range()</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w=tf.range(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">print</span> (sess.run(w))<span class="comment">#输出[0 1 2]</span></span><br></pre></td></tr></tbody></table></figure><h3 id="os.path">os.path（）</h3><table><thead><tr class="header"><th style="text-align: left;">方法</th><th style="text-align: left;">说明</th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">os.path.abspath(path)</td><td style="text-align: left;">返回绝对路径</td></tr><tr class="even"><td style="text-align: left;">os.path.basename(path)</td><td style="text-align: left;">返回文件名</td></tr><tr class="odd"><td style="text-align: left;">os.path.join(path1[, path2[, ...]])</td><td style="text-align: left;">把目录和文件名合成一个路径</td></tr><tr class="even"><td style="text-align: left;">os.path.dirname(path)</td><td style="text-align: left;">返回文件路径</td></tr><tr class="odd"><td style="text-align: left;">os.path.exists(path)</td><td style="text-align: left;">如果路径 path 存在，返回 True；如果路径 path 不存在，返回 False。</td></tr><tr class="even"><td style="text-align: left;">os.path.split(path)</td><td style="text-align: left;">把路径分割成 dirname 和 basename，返回一个元组</td></tr></tbody></table><blockquote><p><a href="https://www.runoob.com/python/python-os-path.html" target="_blank" rel="noopener" class="uri">https://www.runoob.com/python/python-os-path.html</a></p></blockquote><h3 id="embedding_lookup">embedding_lookup()</h3><p>tf.nn.embedding_lookup()就是根据input_ids中的id，寻找embeddings中的第id行。比如input_ids=[1,3,5]，则找出embeddings中第1，3，5行，组成一个tensor返回。</p><blockquote><p><a href="https://www.jianshu.com/p/7bb87873f89e" target="_blank" rel="noopener" class="uri">https://www.jianshu.com/p/7bb87873f89e</a></p><p><a href="https://www.zhihu.com/question/52250059" target="_blank" rel="noopener" class="uri">https://www.zhihu.com/question/52250059</a></p></blockquote><h3 id="模型保存和加载">模型保存和加载</h3><p>Saver的作用是将我们训练好的模型的参数保存下来，以便下一次继续用于训练或测试；Restore的用法是将训练好的参数提取出来。</p><p>1.Saver类训练完后，是以<strong>checkpoints文件形式</strong>保存。提取的时候也是从checkpoints文件中恢复变量。 Checkpoints文件是一个二进制文件，它把变量名映射到对应的tensor值 。</p><p>2.通过for循环，Saver类可以自动的生成checkpoint文件。这样我们就可以<strong>保存多个训练结果</strong>。例如，我们可以保存每一步训练的结果。但是为了避免填满整个磁盘，<strong>Saver可以自动的管理Checkpoints文件</strong>。例如，我们可以指定保存最近的N个Checkpoints文件。</p><h3 id="tensorflow模型保存和读取tf.train.saver">Tensorflow模型保存和读取tf.train.Saver</h3><p>目标：训练网络后想保存训练好的模型，以及在程序中读取以保存的训练好的模型。</p><p>首先，保存和恢复都需要实例化一个 tf.train.Saver。</p><blockquote><p>saver = tf.train.Saver()</p></blockquote><p>然后，在训练循环中，定期调用 saver.save() 方法，向文件夹中写入包含了当前模型中所有可训练变量的 checkpoint 文件。</p><blockquote><p>saver.save(sess, save_path, global_step=step)</p></blockquote><p>之后，就可以使用 saver.restore() 方法，重载模型的参数，继续训练或用于测试数据。</p><blockquote><p>saver.restore(sess, save_path)</p></blockquote><p>模型的恢复用的是restore()函数，它需要两个参数restore(sess, save_path)，save_path指的是保存的模型路径。我们可以使用<code>tf.train.latest_checkpoint（）</code>来自动获取最后一次保存的模型。如：</p><figure class="highlight javascript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model_file=tf.train.latest_checkpoint(<span class="string">'ckpt/'</span>)</span><br><span class="line">saver.restore(sess,model_file)</span><br></pre></td></tr></tbody></table></figure><p>一次 saver.save() 后可以在文件夹中看到新增的四个文件，</p><p><img src="https://i.loli.net/2020/09/29/kRYmSZn8BbwJ4NK.png" alt="image-20200929102459806"></p><p>实际上每调用一次保存操作会创建后3个数据文件并创建一个检查点（checkpoint）文件，简单理解就是权重等参数被保存到 .ckpt.data 文件中，以字典的形式；图和元数据被保存到 .ckpt.meta 文件中，可以被 tf.train.import_meta_graph 加载到当前默认的图。</p><p>saver.restore()时填的文件名，因为在saver.save的时候，每个checkpoint会保存三个文件，如 <code>my-model-10000.meta</code>, <code>my-model-10000.index</code>, <code>my-model-10000.data-00000-of-00001</code></p><p>在<code>import_meta_graph</code>时填的就是<code>meta</code>文件名，我们知道权值都保存在my-model-10000.data-00000-of-00001这个文件中，但是如果在restore方法中填这个文件名，就会报错，应该填的是前缀，这个前缀可以使用<code>tf.train.latest_checkpoint(checkpoint_dir)</code>这个方法获取。</p><p>下面代码是简单的保存和读取模型：（不包括加载图数据）</p><figure class="highlight javascript"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"> </span><br><span class="line">#用numpy产生数据</span><br><span class="line">x_data = np.linspace(-1,1,300)[:, np.newaxis] #转置</span><br><span class="line">noise = np.random.normal(<span class="number">0</span>,<span class="number">0.05</span>, x_data.shape)</span><br><span class="line">y_data = np.square(x_data)<span class="number">-0.5</span>+noise</span><br><span class="line"> </span><br><span class="line">#输入层</span><br><span class="line">x_ph = tf.placeholder(tf.float32, [None, <span class="number">1</span>])</span><br><span class="line">y_ph = tf.placeholder(tf.float32, [None, <span class="number">1</span>])</span><br><span class="line"> </span><br><span class="line">#隐藏层</span><br><span class="line">w1 = tf.Variable(tf.random_normal([<span class="number">1</span>,<span class="number">10</span>]))</span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">10</span>])+<span class="number">0.1</span>)</span><br><span class="line">wx_plus_b1 = tf.matmul(x_ph, w1) + b1</span><br><span class="line">hidden = tf.nn.relu(wx_plus_b1)</span><br><span class="line"> </span><br><span class="line">#输出层</span><br><span class="line">w2 = tf.Variable(tf.random_normal([<span class="number">10</span>,<span class="number">1</span>]))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">1</span>])+<span class="number">0.1</span>)</span><br><span class="line">wx_plus_b2 = tf.matmul(hidden, w2) + b2</span><br><span class="line">y = wx_plus_b2</span><br><span class="line"> </span><br><span class="line">#损失</span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(y_ph-y),reduction_indices=[<span class="number">1</span>]))</span><br><span class="line">train_op = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"> </span><br><span class="line">#保存模型对象saver</span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"> </span><br><span class="line">#判断模型保存路径是否存在，不存在就创建</span><br><span class="line"><span class="keyword">if</span> not os.path.exists(<span class="string">'tmp/'</span>):</span><br><span class="line">    os.mkdir(<span class="string">'tmp/'</span>)</span><br><span class="line"> </span><br><span class="line">#初始化</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    if os.path.exists('tmp/checkpoint'):         #判断模型是否存在</span><br><span class="line">        saver.restore(sess, 'tmp/model.ckpt')    #存在就从模型中恢复变量</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        init = tf.global_variables_initializer() #不存在就初始化变量</span><br><span class="line">        sess.run(init)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">        _,loss_value = sess.run([train_op,loss], feed_dict={<span class="attr">x_ph</span>:x_data, <span class="attr">y_ph</span>:y_data})</span><br><span class="line">        <span class="keyword">if</span>(i%<span class="number">50</span>==<span class="number">0</span>):</span><br><span class="line">            save_path = saver.save(sess, <span class="string">'tmp/model.ckpt'</span>)</span><br><span class="line">            print(<span class="string">"迭代次数：%d , 训练损失：%s"</span>%(i, loss_value))</span><br></pre></td></tr></tbody></table></figure><p>注：</p><ul><li>saver 的操作必须在 sess 建立后进行。</li><li>model.ckpt 必须存在给定文件夹中，‘tmp/model.ckpt’ 这里至少要有一层文件夹，否则无法保存。</li><li>恢复模型时同保存时一样，是 ‘tmp/model.ckpt’，和那3个文件名都不一样。</li></ul><p>如果不用<code>tf.train.latest_checkpoint（）</code>来自动获取最后一次保存的模型，则怎么做呢？</p><blockquote><p><a href="https://www.jianshu.com/p/7ebee4d10e49" target="_blank" rel="noopener" class="uri">https://www.jianshu.com/p/7ebee4d10e49</a></p><p><a href="https://blog.csdn.net/mylove0414/article/details/55097486" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/mylove0414/article/details/55097486</a></p></blockquote><h3 id="saver中的max_to_keep-参数">Saver中的max_to_keep 参数</h3><h3 id="keras中的timedistributed函数">keras中的TimeDistributed函数</h3><blockquote><p><a href="https://blog.csdn.net/u012193416/article/details/79477220" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/u012193416/article/details/79477220</a></p><p><a href="https://keras.io/zh/layers/wrappers/" target="_blank" rel="noopener" class="uri">https://keras.io/zh/layers/wrappers/</a></p><p><a href="https://blog.csdn.net/zh_JNU/article/details/85160379" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/zh_JNU/article/details/85160379</a></p><p><a href="https://www.cnblogs.com/CheeseZH/p/13408658.html" target="_blank" rel="noopener" class="uri">https://www.cnblogs.com/CheeseZH/p/13408658.html</a></p></blockquote><h3 id="tf.concat详解">tf.concat()详解</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.concat([tensor1, tensor2, tensor3,...], axis)</span><br><span class="line"><span class="comment"># axis=0     代表在第0个维度拼接</span></span><br><span class="line"><span class="comment"># axis=1     代表在第1个维度拼接 </span></span><br><span class="line"><span class="comment">#axis=-1 代表倒数第一个维度</span></span><br></pre></td></tr></tbody></table></figure><blockquote><p><a href="https://blog.csdn.net/leviopku/article/details/82380118" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/leviopku/article/details/82380118</a></p></blockquote><h3 id="归纳偏置inductive-bias">归纳偏置(Inductive Bias)</h3><p>在机器学习中，很多学习算法经常会对学习的问题做一些<strong>假设</strong>，这些假设就称为归纳偏置(Inductive Bias)。</p><p><strong>归纳(Induction)</strong>是自然科学中常用的两大方法之一(归纳与演绎, induction and deduction)，指的是从一些例子中寻找共性、泛化，形成一个比较通用的规则的过程；<strong>偏置(Bias)</strong>是指我们对模型的偏好。</p><p>因此，归纳偏置可以理解为，从现实生活中观察到的现象中归纳出一定的规则(heuristics)，然后对模型做一定的约束，从而可以起到“模型选择”的作用，即从假设空间中选择出更符合现实规则的模型。其实，贝叶斯学习中的“<strong>先验(Prior)</strong>”这个叫法，可能比“归纳偏置”更直观一些。</p><p>在深度学习方面也是一样。以神经网络为例，各式各样的网络结构/组件/机制往往就来源于归纳偏置。</p><p>在卷积神经网络中，我们假设特征具有局部性(Locality)的特性，即当我们把相邻的一些特征放在一起，会更容易得到“解”；在循环神经网络中，我们假设每一时刻的计算依赖于历史计算结果；还有注意力机制，也是基于从人的直觉、生活经验归纳得到的规则。</p><p>CNN的inductive bias应该是locality和spatial invariance，即空间相近的grid elements有联系而远的没有，和空间不变性（kernel权重共享）</p><p>RNN的inductive bias是sequentiality和time invariance，即序列顺序上的timesteps有联系，和时间变换的不变性（rnn权重共享）</p><h3 id="图灵完备turing-complete">图灵完备（turing complete）</h3><p>在<a href="https://link.jianshu.com?t=https%3A%2F%2Fbaike.baidu.com%2Fitem%2F%E5%8F%AF%E8%AE%A1%E7%AE%97%E6%80%A7%E7%90%86%E8%AE%BA" target="_blank" rel="noopener">可计算性理论</a>里，如果一系列操作数据的规则（如指令集、编程语言、细胞自动机）按照一定的顺序可以计算出结果，被称为图灵完备（turing complete）。</p><p>一个有图灵完备指令集的设备被定义为<a href="https://link.jianshu.com?t=http%3A%2F%2Fbaike.baidu.com%2Fitem%2F%E9%80%9A%E7%94%A8%E8%AE%A1%E7%AE%97%E6%9C%BA" target="_blank" rel="noopener">通用计算机</a>。如果是图灵完备的，它（计算机设备）有能力执行条件跳转（if、while、goto语句）以及改变内存数据。 如果某个东西展现出了图灵完备，它就有能力表现出可以模拟原始计算机，而即使最简单的计算机也能模拟出最复杂的计算机。所有的通用编程语言和现代计算机的指令集都是图灵完备的（C++ template就是图灵完备的），都能解决内存有限的问题。图灵完备的机器都被定义有无限内存，但是机器指令集却通常定义为只工作在特定的、有限数量的RAM上。</p><h3 id="shape">shape</h3><p>numpy数据的形状：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.shape()</span><br></pre></td></tr></tbody></table></figure><p>list 数据的形状：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.shape(x)</span><br></pre></td></tr></tbody></table></figure><p><strong>注：</strong>如果写<code>x.shape()</code> , 则会报错<code>ValueError: invalid literal for int() with base 10</code></p><p>torsor形状：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x.get_shape()</span><br></pre></td></tr></tbody></table></figure><h3 id="keras-的-fit函数">keras 的 fit函数</h3><p>fit中以call()方法的形式来run session</p><blockquote><p><a href="https://blog.csdn.net/u012526436/article/details/102488164" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/u012526436/article/details/102488164</a></p></blockquote><h3 id="model-类继承">Model 类继承</h3><p><strong>可以通过继承 <code>Model</code> 类并在 <code>call</code> 方法中实现你自己的前向传播，以创建你自己的完全定制化的模型，</strong>（<code>Model</code> 类继承 API 引入于 Keras 2.2.0）。</p><p>这里是一个用 <code>Model</code> 类继承写的简单的多层感知器的例子：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleMLP</span><span class="params">(keras.Model)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, use_bn=False, use_dp=False, num_classes=<span class="number">10</span>)</span>:</span></span><br><span class="line">        super(SimpleMLP, self).__init__(name=<span class="string">'mlp'</span>)</span><br><span class="line">        self.use_bn = use_bn</span><br><span class="line">        self.use_dp = use_dp</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line"></span><br><span class="line">        self.dense1 = keras.layers.Dense(<span class="number">32</span>, activation=<span class="string">'relu'</span>)</span><br><span class="line">        self.dense2 = keras.layers.Dense(num_classes, activation=<span class="string">'softmax'</span>)</span><br><span class="line">        <span class="keyword">if</span> self.use_dp:</span><br><span class="line">            self.dp = keras.layers.Dropout(<span class="number">0.5</span>)</span><br><span class="line">        <span class="keyword">if</span> self.use_bn:</span><br><span class="line">            self.bn = keras.layers.BatchNormalization(axis=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">        x = self.dense1(inputs)</span><br><span class="line">        <span class="keyword">if</span> self.use_dp:</span><br><span class="line">            x = self.dp(x)</span><br><span class="line">        <span class="keyword">if</span> self.use_bn:</span><br><span class="line">            x = self.bn(x)</span><br><span class="line">        <span class="keyword">return</span> self.dense2(x)</span><br><span class="line"></span><br><span class="line">model = SimpleMLP()</span><br><span class="line">model.compile(...)</span><br><span class="line">model.fit(...)</span><br></pre></td></tr></tbody></table></figure><p>网络层定义在 <code>__init__(self, ...)</code> 中，前向传播在 <code>call(self, inputs)</code> 中指定。在 <code>call</code> 中，你可以指定自定义的损失函数，通过调用 <code>self.add_loss(loss_tensor)</code> （就像你在自定义层中一样）。</p><p>在类继承模型中，模型的拓扑结构是由 Python 代码定义的（而不是网络层的静态图）。这意味着该模型的拓扑结构不能被检查或序列化。因此，以下方法和属性<strong>不适用于类继承模型</strong>：</p><ul><li><code>model.inputs</code> 和 <code>model.outputs</code>。</li><li><code>model.to_yaml()</code> 和 <code>model.to_json()</code>。</li><li><code>model.get_config()</code> 和 <code>model.save()</code>。</li></ul><p><strong>关键点</strong>：为每个任务使用正确的 API。<code>Model</code> 类继承 API 可以为实现复杂模型提供更大的灵活性，但它需要付出代价（比如缺失的特性）：它更冗长，更复杂，并且有更多的用户错误机会。如果可能的话，尽可能使用函数式 API，这对用户更友好。</p><blockquote><p><a href="https://blog.csdn.net/qq_27825451/article/details/90517036" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/qq_27825451/article/details/90517036</a></p></blockquote><h3 id="关于tensorflow的sessiontensorshape等基础知识整理">关于tensorflow的session、tensor、shape等基础知识（整理）</h3><p>在tensorflow程序中，tensor只是占位符，在会话层没有run出tensor的值之前，我们是无法获知tensor的值的</p><blockquote><p><a href="https://blog.csdn.net/jiongnima/article/details/78524551" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/jiongnima/article/details/78524551</a></p><p><a href="https://www.tensorflow.org/guide/tensor?hl=zh-cn" target="_blank" rel="noopener" class="uri">https://www.tensorflow.org/guide/tensor?hl=zh-cn</a></p><p><a href="https://www.jianshu.com/p/75a903a44cf2" target="_blank" rel="noopener" class="uri">https://www.jianshu.com/p/75a903a44cf2</a></p></blockquote><h3 id="tf.layers.flatten">tf.layers.flatten</h3><p>在保留第0轴的情况下对输入的张量进行Flatten(扁平化)</p><p>代码示例：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x=tf.placeholder(shape=(<span class="literal">None</span>,<span class="number">4</span>,<span class="number">4</span>),dtype=<span class="string">'float32'</span>)</span><br><span class="line"></span><br><span class="line">y=tf.layers.flatten(x)</span><br><span class="line"></span><br><span class="line">print(y)</span><br></pre></td></tr></tbody></table></figure><p>输出： 将后两维进行合并</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Tensor("flatten/Reshape:0", shape=(?, 16), dtype=float32)</span><br></pre></td></tr></tbody></table></figure><h3 id="tf.layers.dense">tf.layers.dense</h3><p>全连接层 ，相当于添加一个层。只<strong>改变输入的最后一维</strong></p><h3 id="python---tensorflow中-none-1和之间的区别">python - Tensorflow中 None，-1和？之间的区别</h3><p><code>None</code>表示未指定的维度。因此，如果您定义了一个占位符，您可以使用<code>None</code>来表示“这个维度可以有任何大小”。 占位符可以有多个<code>None</code>维度这仅仅意味着多个维度可以是不同的大小甚至整个形状都可以<code>None</code>来指定未知的维数。 <code>-1</code>是TensorFlow的一条指令，用于自行推断维度的大小。在<code>tf.reshape(input, [-1, input_size])</code>中，这意味着“重塑它，使第二个维度<code>input_size</code>，第一个维度是匹配元素总数所需的任何内容”。 这并不一定意味着维数是未知的，因为对于<code>None</code>如果输入张量的已知大小为10个元素，并且将其重塑为<code>[-1, 2]</code>，则张量流能够推断出完整的形状<code>[5, 2]</code>。 <code>-1</code>纯粹是为了方便。你可以把形状写下来，而不是让Tensorflow推断出来<code>None</code>另一方面，对于接受可变大小张量是必要的。 一个形状中只能有一个<code>-1</code>。多个是没有意义的，因为不可能推断出形状。例如，如果一个张量中有12个元素，则未定义将其重塑为<code>[-1, -1, 2]</code>——我们是否应该这样做？<code>[3, 2, 2]</code>？<code>[2, 3, 2]</code>？… 最后，问号正是tensorflow在打印张量和/或其形状时用来标记“未知”维度的内容。您发布的示例实际上会产生语法错误——您不能自己使用问号。未知维度的原因当然可以是具有<code>[6, 1, 2]</code>维度的占位符，并且通常根据占位符定义的张量（即应用于它们的某些运算的结果）也将具有未知维度。此外，有些操作可能没有指定（部分）它们的输出形状，这也可能导致未知。 这里可能还有一些我遗漏的技术细节，但根据经验：使用<code>None</code>作为占位符，使用<code>None</code>进行整形。这应该涵盖大多数用例。</p><blockquote><p><code>？</code>== <code>None</code> ，维度是未知的</p><p><code>-1</code>代表根据推断之后的维度</p><p><code>(3,)</code> 表明张量是一个一维数组，这个数组的长度为3</p></blockquote><blockquote><p><a href="https://www.coder.work/article/2032326" target="_blank" rel="noopener" class="uri">https://www.coder.work/article/2032326</a></p></blockquote><h3 id="keras的-call-函数build-函数">keras的 call 函数、build 函数</h3><p>build() 用来初始化定义weights, 这里可以用父类的self.add_weight() 函数来初始化数据, 该函数必须将 self.built 设置为True, 以保证该 Layer 已经成功 build , 通常如上所示, 使用 super(MyLayer, self).build(input_shape) 来完成。</p><p>call() 用来执行 Layer 的职能, x就是该层的输入，x与权重kernel做点积，生成新的节点层，即当前 Layer 所有的计算过程均在该函数中完成。</p><p><code>__init__()</code>和<code>build()</code>函数都在对Layer进行初始化，都初始化了一些成员函数</p><p><code>__init__()</code>：保存成员变量的设置</p><p><code>build()</code>：在<code>call()</code>函数第一次执行时会被调用一次，这时候可以知道输入数据的<code>shape</code>。返回去看一看，果然是<code>__init__()</code>函数中只初始化了输出数据的<code>shape</code>，而输入数据的<code>shape</code>需要在<code>build()</code>函数中动态获取，这也解释了为什么在有<code>__init__()</code>函数时还需要使用<code>build()</code>函数</p><p><code>call()</code>函数则是在该layer被调用时执行。</p><blockquote><p><a href="https://blog.csdn.net/qq_32623363/article/details/104128497" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/qq_32623363/article/details/104128497</a></p><p><a href="https://blog.csdn.net/qq_27825451/article/details/90517036" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/qq_27825451/article/details/90517036</a></p></blockquote><h3 id="tf.expand_dims">tf.expand_dims（）</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.expand_dims(input, dim, name=<span class="literal">None</span>) <span class="comment">#在指定位置增加维度</span></span><br></pre></td></tr></tbody></table></figure><blockquote><p><a href="https://blog.csdn.net/jasonzzj/article/details/60811035" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/jasonzzj/article/details/60811035</a></p></blockquote><h3 id="tf.boolean_mask">tf.boolean_mask（）</h3><p>选择张量的特定维度的值</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tf.boolean_mask(tensor,mask,name=<span class="string">'boolean_mask'</span>,axis=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#1-D example</span></span><br><span class="line">tensor = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">mask = np.array([<span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">False</span>])</span><br><span class="line">boolean_mask(tensor, mask)  <span class="comment"># [0, 2]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2-D example</span></span><br><span class="line">tensor = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>]]</span><br><span class="line">mask = np.array([<span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">True</span>])</span><br><span class="line">boolean_mask(tensor, mask)  <span class="comment"># [[1, 2], [5, 6]]</span></span><br></pre></td></tr></tbody></table></figure><blockquote><p><a href="https://blog.csdn.net/wuguangbin1230/article/details/81334544" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/wuguangbin1230/article/details/81334544</a></p></blockquote><h3 id="pytorch里面的torch.nn.parameter">PyTorch里面的torch.nn.Parameter()</h3><p><strong>作用</strong>：对于<code>self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))</code>，也就是将一个不可训练的类型<code>Tensor</code>转换成可以训练的类型<code>parameter</code>并将这个<code>parameter</code>绑定到这个<code>module</code>里面(<code>net.parameter()</code>中就有这个绑定的<code>parameter</code>，所以在参数优化的时候可以进行优化的)，所以经过类型转换这个<code>self.v</code>变成了模型的一部分，成为了模型中根据训练可以改动的参数了。</p><p>使用这个函数的目的也是想让某些变量在学习的过程中不断的修改其值以达到最优化。</p><blockquote><p><a href="https://www.jianshu.com/p/d8b77cc02410" target="_blank" rel="noopener" class="uri">https://www.jianshu.com/p/d8b77cc02410</a></p></blockquote><h3 id="pytorch的nn.linear">PyTorch的nn.Linear（）</h3><p>用于设置网络中的<strong>全连接层的</strong></p><blockquote><p><a href="https://blog.csdn.net/qq_42079689/article/details/102873766" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/qq_42079689/article/details/102873766</a></p></blockquote><h3 id="pytorch-nn.embedding-词向量">pytorch nn.embedding() 词向量</h3><p>词嵌入在 pytorch 中非常简单，只需要调用 <code>torch.nn.Embedding(m, n)</code> 就可以了，m 表示单词的总数目，n 表示词嵌入的维度，其实词嵌入就相当于是一个大矩阵，矩阵的每一行表示一个单词。</p><p><strong>随机初始化</strong></p><blockquote><p><a href="https://blog.csdn.net/david0611/article/details/81090371" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/david0611/article/details/81090371</a></p></blockquote><h3 id="pytorch中的torch.mean">pytorch中的torch.mean()</h3><p><strong>torch.mean(input, dim, keepdim=False, out=None)</strong></p><p>返回新的张量，其中包含输入张量input指定维度dim中每行的平均值。</p><p>若keepdim值为True，则在输出张量中，除了被操作的dim维度值降为1，其它维度与输入张量input相同。否则，dim维度相当于被执行torch.squeeze()维度压缩操作，导致此维度消失，最终输出张量会比输入张量少一个维度。</p><p><strong>参数：</strong></p><ul><li>input (Tensor) - 输入张量</li><li>dim (int) - 指定进行均值计算的维度</li><li>keepdim (bool, optional) - 输出张量是否保持与输入张量有相同数量的维度</li><li>out (Tensor) - 结果张量</li></ul><p><strong>例子：</strong></p><blockquote><p>a = torch.randn(4, 5) a 0.3168 0.4953 -0.6758 -0.5559 -0.6906 0.2241 2.2450 1.5735 -1.3815 -1.5199 0.0033 0.5236 -0.9070 -0.5961 -2.1281 0.9605 1.5314 -0.6555 -1.2584 -0.4160 [torch.FloatTensor of size 4x5] torch.mean(a, 1, True) -0.2220 0.2283 -0.6209 0.0324 [torch.FloatTensor of size 4x1]</p></blockquote><h3 id="np.triu-np.tril">np.triu() &amp; np.tril()</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">triu</span>（<span class="title">m</span>， <span class="title">k</span>）：</span></span><br><span class="line"><span class="function">#取上三角阵  </span></span><br><span class="line"><span class="function">#<span class="title">m</span>：表示一个矩阵</span></span><br><span class="line"><span class="function">#<span class="title">K</span>：表示对角线的起始位置（<span class="title">k</span>取值默认为0）</span></span><br><span class="line"><span class="function"></span></span><br><span class="line">#k=0表示正常的上三角矩阵</span><br><span class="line"><span class="comment">#k=-1表示对角线的位置下移1个对角线</span></span><br><span class="line"><span class="comment">#k=1表示对角线的位置上移1个对角线</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#同理，np.tril取下三角阵</span></span><br></pre></td></tr></tbody></table></figure><p>参考</p><blockquote><p><a href="https://blog.csdn.net/weixin_37724529/article/details/102881776" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/weixin_37724529/article/details/102881776</a></p></blockquote><h3 id="python的einops-rearrange函数">python的einops rearrange()函数</h3><p>例子：</p><p>假设我有一个3-D数组：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[[[0,1,2],</span><br><span class="line">  [0,1,2],</span><br><span class="line">  [0,1,2]],</span><br><span class="line"></span><br><span class="line"> [[3,4,5],</span><br><span class="line">  [3,4,5],</span><br><span class="line">  [3,4,5]]]</span><br></pre></td></tr></tbody></table></figure><p>我想按列重新排列：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[0,1,2,3,4,5],</span><br><span class="line"> [0,1,2,3,4,5],</span><br><span class="line"> [0,1,2,3,4,5]]</span><br></pre></td></tr></tbody></table></figure><p>使用einops：</p><figure class="highlight py"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">einops.rearrange(a, <span class="string">'x y z -&gt; y (x z) '</span>)</span><br></pre></td></tr></tbody></table></figure><p>并且我建议根据上下文（例如时间，高度等）为轴指定有意义的名称（而不是xyz）。 这将使您易于理解代码的作用</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">In : einops.rearrange(a, 'x y z -&gt; y (x z) ')</span><br><span class="line">Out:</span><br><span class="line">array([[0, 1, 2, 3, 4, 5],</span><br><span class="line">       [0, 1, 2, 3, 4, 5],</span><br><span class="line">       [0, 1, 2, 3, 4, 5]])</span><br></pre></td></tr></tbody></table></figure><h3 id="目标检测">🚀 目标检测</h3><blockquote><p><a href="https://bbs.cvmart.net/topics/3056" target="_blank" rel="noopener" class="uri">https://bbs.cvmart.net/topics/3056</a></p></blockquote><h3 id="二分图匹配bipartite-matching">🚀 二分图匹配（bipartite matching ）</h3><blockquote><p><a href="https://liam.page/2016/04/03/Hungarian-algorithm-in-the-maximum-matching-problem-of-bigraph/" target="_blank" rel="noopener" class="uri">https://liam.page/2016/04/03/Hungarian-algorithm-in-the-maximum-matching-problem-of-bigraph/</a></p></blockquote><p><a href="https://blog.csdn.net/COCO56/article/details/100058599" target="_blank" rel="noopener">解决vscode乱码问题，VSCode设置自动推导文件编码</a></p><h3 id="pytorch-中forward的使用以及原理---pytorch使用">pytorch 中forward的使用以及原理 --pytorch使用</h3><p>https://blog.csdn.net/u011501388/article/details/84062483</p><h3 id="pytorch里面的torch.nn.parameter详解">PyTorch里面的torch.nn.Parameter()详解</h3><p>https://cloud.tencent.com/developer/article/1608348</p><p>chrome中github插件</p><p>https://www.bilibili.com/video/BV1Kt4y1X7fw/?spm_id_from=trigger_reload</p><h3 id="论文阅读的思维导图">论文阅读的思维导图</h3><p>conda 安装新版本python之后，会覆盖之前的版本</p><h3 id="linux-杀死暂停继续后台运行进程">LINUX 杀死、暂停、继续、后台运行进程</h3><p>ctrl + z</p><p>可以将一个正在前台执行的命令放到后台，并且暂停</p><p>若想恢复到前台，则</p><ol type="1"><li>jobs #查看当前有多少在后台运行的命令 会有序号 job号</li><li>fg 〔<em>job</em>号〕 将后台中的命令调至前台继续运行 如： fg %1</li></ol><p>https://blog.csdn.net/QQ1910084514/article/details/80390671</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录杂乱的知识点，持续更新
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-09-05-讨论总结</title>
    <link href="http://yoursite.com/2020/09/05/2020-09-05-%E8%AE%A8%E8%AE%BA%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2020/09/05/2020-09-05-%E8%AE%A8%E8%AE%BA%E6%80%BB%E7%BB%93/</id>
    <published>2020-09-05T07:33:34.000Z</published>
    <updated>2020-09-05T07:40:45.081Z</updated>
    
    <content type="html"><![CDATA[<p>研究生阶段想要重点去研究透彻某个知识点，还是要去系统学习。不要只是依赖博客</p><p>博客缺点</p><ol type="1"><li>一般不成体系，比较片面</li><li>不管是翻译外国博客还是自己的总结，由于博主本身的能力，导致在写的时候，都会出现一定的误差，可信度不抵论文和书籍</li><li>讲的不深入</li></ol><p>和师兄讨论了卡尔曼滤波的内容，师兄针对我的问题也给了很好的建议，让我有方向去继续。发现一直以来我对卡尔曼滤波理解的太浅显，不深刻，理解只是停留结合例子理解卡尔曼滤波那五个公式，知道计算过程，但是没有去深入理解来源以及公式的意义，变量的含义等等，没有真正转化为自己的东西 因为卡尔曼滤波是RKN的核心基础，所以必须要深入理解，这样才能更好地运用卡尔曼滤波，也更好地理解模型。 因为融合到transformer中，也要讲清楚为什么融合之后效果好，或者为什么不好，只有将本质讲清楚，去理论分析的时候才有信服力。避免只是简单的拼接。</p><p>为什么这么做，这么做的好处。公式间的逻辑关系， 买了本卡尔曼滤波的书，意义和含义，背景和理论公式一步一步推导</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录讨论后的一些研究方法感想
    
    </summary>
    
    
    
      <category term="研究方法" scheme="http://yoursite.com/tags/%E7%A0%94%E7%A9%B6%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>2020-09-04-transformer直观理解</title>
    <link href="http://yoursite.com/2020/09/04/2020-09-04-transformer%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/"/>
    <id>http://yoursite.com/2020/09/04/2020-09-04-transformer%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/</id>
    <published>2020-09-04T13:16:46.000Z</published>
    <updated>2020-10-12T02:46:59.336Z</updated>
    
    <content type="html"><![CDATA[<h3 id="直观attention-模型">直观“Attention 模型”</h3><p>本文试着从直观的角度解析“Attention模型”，应用场景：原文--译文，具体选择 中文--英文，即在<strong>将中文翻译为英文</strong>这一场景中，直观解析“Attention模型”。</p><h4 id="概括">概括</h4><p>一句中文A翻译为一句英文B主要是完成以下“<strong>两项任务</strong>”：</p><ol type="1"><li><p>理解中文A的意思为X；</p></li><li><p>将意思X用英文表达出来，即英文B；</p></li></ol><p>在用计算机完成以上任务前，需要以下三点“<strong>准备工作</strong>”：</p><ol type="i"><li><p>需要将中文的字和英文的单词转换为计算机可以理解（计算）的数（即一个字/单词对应转换为一个向量，称为字向量/单词向量），然后计算机才有可能完成以上两项任务，实现翻译； <code>单词-&gt;单词向量</code></p></li><li><p>另外针对一句中文翻译为一句英文，每个字在句子中的位置也对意思的表达会产生很大的影响，所以每个字在句子中的位置也要定义一个向量来表达（即一个位置对应转换为一个向量，称为位置向量）； <code>位置向量</code></p></li><li><p>将字向量/单词向量加上位置向量（定义两种向量的维度相同，如都是512维，便于此处元素相加），能更好更全面的代表这句话，为更好的翻译做好准备；<code>单词向量+位置向量</code></p></li></ol><p>“Attention模型”实现以上内容，具体情况如下图所示：</p><p><img src="https://i.loli.net/2020/09/05/bEpK5wcj9rkAGCU.jpg" alt="img"></p><p>以下针对“准备工作”、任务1和任务2展开讨论；</p><h4 id="准备工作">准备工作</h4><p>包括字向量/单词向量、位置向量；此处也称为<strong>词嵌入，位置编码</strong>；</p><ol type="a"><li>字向量/单词向量分别是<code>随机产生产生的一组512维向量</code>，如字向量，假设选用了3000个常用汉字，每个字对应一个512维的随机向量，则整个字向量就是一个3000 X 512 的二维矩阵，每一行代表一个字；</li></ol><p><strong>之所以用随机且选择较大维度（如512维），是为了让生成的各个向量间尽可能的独立，即没有相关性</strong>，就像“你、我、他、拿、和、中”指代的具体意思在最初定义时是可以随机互换的，之间也无关系，他们之间的相关性/关系是在该语系语境中根据语义、语法、文化等因素形成的，即上述任务1需要完成的。</p><p>（词嵌入，每个词之间没有关系）</p><p><img src="https://i.loli.net/2020/09/05/9tSTwmsdnfuW7Ol.jpg" alt="img"></p><ol start="2" type="a"><li>位置向量是代表一个字在句子中的位置信息，也定义为一个512维的向量，但并<strong>不是随机产生</strong>的，而是根据位置确切计算得来，即<strong>一个位置对应转化为一个512维向量；</strong></li></ol><p><img src="https://i.loli.net/2020/09/05/FAR6vuDZgBoJwTX.jpg" alt="img"></p><ol start="3" type="a"><li>假设翻译时定义一句话最大长度是10个字，则该句话对应的字向量是一个10 X 512的二维矩阵（每一行代表一个字），位置向量也是一个10 X 512的二维矩阵（每一行代表对应字的位置信息）；<strong>两个矩阵相加得新的二维矩阵能更好更全面的表达这句话；</strong></li></ol><h4 id="任务1编码">任务1：编码</h4><p><strong>理解</strong>一句中文A的意思为X；此处也称为“编码”</p><ol type="i"><li><p>翻译时中文中的“你”、“我”大多时候对应着英文的“you”、“me”，如果都是这样的简单一一对应关系，那翻译是很简单的；而实际情况是<strong>绝大多数都是一对多的关系，即同一个中文字在不同的语境中对应的英文是不一样的单词</strong>，如“和”字在不同语境中翻译为英文可能是“and”、“sum”、“peace”等。</p></li><li><p>一个字从多个可能的意思中选择一个是<strong>根据语境</strong>来确定的，即<strong>根据这个字与句子中所有字的相关关系来确定</strong>；<strong>一句话需要计算该句话中每个字与该句子中所有字的相关关系来确定这句话中每个字在该语境中的意思，即确认中文语境</strong>；</p></li><li><p><span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8">⭐</span> 在计算相关性之前，对每一个<strong>字对应的向量进行相应的线性变换</strong>以便于<strong>更好的计算相关性</strong>确认最终意思；计算完相关性（确认中文语境）并以此更新向量矩阵后（即self-attention，确认每个字在当前这句话的语境下的“确切意思”），再<strong>进行一次线性变换</strong>，对这个“确切意思”进行再次拟合校准；</p></li></ol><p>具体情况，如下图所示；</p><p><img src="https://i.loli.net/2020/09/05/ZT4OvczK3tyCdGX.jpg" alt="img"></p><p>Notes：i~iii是一个处理单元，<strong>输入“向量矩阵”和输出“新向量矩阵X”的维度是一样的</strong>；完成任务1是以上处理单元循环N次（<strong>强化上述效果</strong>），设定义N=3（论文中N=8）；即由3个处理单元依次链接完成任务1，如下图所示：</p><p><img src="https://i.loli.net/2020/09/05/ZS4YMITXOWyr8kf.jpg" alt="img"></p><h4 id="任务2解码">任务2：解码</h4><p>将意思X用英文表达出来，即英文B；此处也称为“解码”</p><p>和任务1类似，<strong>差异</strong>在于：</p><p>I. 任务1仅考虑中文语境即可，任务2<strong>既考虑中文语境（vanilla-attention），也考虑英文语境（self-attention）；</strong></p><ol start="2" type="i"><li>和任务1类似，经过N个处理单元后获得的向量矩阵，经过“最后一次线性变换”转换为对应英文语系中各个单词的值，然后由softmax转换为是各个英文单词的概率，完成翻译；</li></ol><p>图示如下：</p><p><img src="https://i.loli.net/2020/09/05/yKDA2Fs3Xc4HkIo.jpg" alt="img"></p><p>整体简化图示如下：</p><p><img src="https://i.loli.net/2020/09/05/6epU1uboH2AGP7k.jpg" alt="img"></p><h3 id="attention注意力">Attention注意力</h3><p><img src="https://i.loli.net/2020/09/05/R2XINUW16u4anTs.jpg" alt="img"></p><p>上图是attention模型的总体结构，包含了模型所有节点及流程（因为有循环结构，流程不是特别清楚，下文会详细解释）；模型总体分为两个部分：编码部分和解码部分，分别是上图的左边和右边图示；以下选取翻译情景，以<strong>模型训练</strong>为例解释整个过程；</p><p><strong>训练样本：原文译文(一一对应)</strong></p><h4 id="编码部分inputs">编码部分（inputs）</h4><h5 id="input-embedding">Input embedding:</h5><p>1.1 将原文的所有单词汇总统计频率，删除低频词汇（比如出现次数小于20次的统一</p><p>定义为’<unk>’）；</unk></p><p>此时总共选出了假设10000个单词，则用数字编号为0~9999，一一对应，定义该对应表为word2num；</p><p>然后用<code>xaviers方法</code>生成随机矩阵Matrix ：<strong>10000行N列</strong>（10000行是确定的，对应10000个单词，N列自定义）；这样就可以将10000个不同的单词通过word2num映射成10000个不同的数字（int），然后将10000个不同的数字通过Matrix映射成10000个不同的N维向量（如何映射？比如数字0，3，经过 Matrix映射分别变为向量Matrix[0],Matrix[3]，维度为N维）；</p><p>这样，<strong>任何一个单词，都可以被映射成为唯一的一个N维向量</strong>；</p><p><img src="https://i.loli.net/2020/09/05/86ByVmtDIGfd2bx.png" alt="img"></p><p><strong>Note：此处N自定义为512</strong></p><p>1.2 翻译的时候是<strong>一个句子一个句子的翻译</strong>，所以需要定义一个句子的标准长度，比如10个单词；如果一句话不足10个单词则用0填充（<strong>对应的word即word2num表中的<pad></pad></strong>），如果多了，删掉；</p><p>这样一句话就是标准的10个单词；比如句子 “中国人有中国梦。”，这句话共有八个字（最后一个是结束符），<strong>经过word2num变为一列X：<a href="注：100代表的word是结束符">1,7,3,2,1,7,6,100,0,0</a>,X经过Matrix映射为10行N列的矩阵matX</strong>= [Matrix[1], Matrix[7], Matrix[3], Matrix[2] , Matrix[1] , Matrix[7] , Matrix[6], Matrix[100] , Matrix[0] , Matrix[0]]; embedding 到此基本结束，即完成了将一句话变为 一个矩阵，矩阵的每一行代表一个特定的单词；此处还可以scale一下，即<code>matX*N**(1/2)</code>; （<code>**代表次方，即matX中的每一个元素都乘以N的1/2次方，此时N=512，以此来缩放</code>）</p><p><img src="https://i.loli.net/2020/09/05/xOJBLyNruSIX9s2.png" alt="img"></p><h5 id="positional-encoding">Positional encoding:</h5><p>2.1 单词在句子中的不同位置体现了不同信息，所以需要对位置进行编码，体现不同的信息情况，此处是对绝对位置进行编码，即位置数字0，1，2，3，…N等，进行运算编码，具体编码如下：</p><p>2.1.1 对于句子中的每一个字，其位置pos∈<a href="每句话10个字">0,1,2,…,9</a>,每个字是N（512）维向量，维度 i （i∈[ 0,1,2,3,4,..N]）带入<strong>函数计算</strong>，</p><p><img src="https://i.loli.net/2020/09/05/dR4rAa9DkZJKNQC.png" alt="img"></p><blockquote><p>用sin和cos是因为在后面运算过程中会近似出现sin(a)sin(b)+cos(a)cos(b)的形式，根据三角函数公式上式恰好等于cos(a-b)，当a和b差小时（即两个字离得近）值大，反之小。这在一定程度上可以表达两个字的距离。</p></blockquote><p>2.1.2 经过如上函数运行一次后，获得了一个<strong>10行N列的矩阵matP</strong>；每一行代表一个绝对位置信息，此时matP的shape和matX的shape相同；</p><p><img src="https://i.loli.net/2020/09/05/xFKDaYu1pSNZ7lo.png" alt="img"></p><p>2.1.3 <strong>对于矩阵matP的每一行，第0，2，4，6,...等偶数列上的值用sin()函数激 活，第1，3，5，。。。等奇数列的值用cos()函数激活，以此更新matP</strong>；即 matP[:,0::2]=sin(matP[:,0::2]), matP[:,1::2]=cos(matP[:,1::2])；</p><p><img src="https://i.loli.net/2020/09/05/w1FJXfzq5IRrPCS.png" alt="img"></p><p>2.2 至此positional encoding结束，最后通常也会scale一次，即对更新后的matP进行<code>matP*N**(1/2)</code>运算，得到再次更新的matP，此时的matP的shape还是和matX相同；<strong>然后将matP和matX相加即matEnc=matP+matX，矩阵matEnc其shape=[10，512]；</strong></p><h5 id="multi-head-attention循环单元">Multi-head attention循环单元</h5><p>3.1 然后matEnc进入模型编码部分的循环，即Figure1中左边红色框内部分，每个循环单元又分为4个小部分：multi-head attention, add&amp;norm, feedForward, add&amp;norm；</p><p>3.2 Multi-head attention</p><p><img src="https://i.loli.net/2020/09/05/np9H73tSVYogJG4.jpg" alt="img"></p><p>3.2.1 Multi-head attention 由三个输入，分别为V，K，Q，此处<strong>V=K=Q=matEnc</strong>（在解码部分multi-head attention中的VKQ三者不是这种关系）;</p><p>3.2.2 首先分别对V，K，Q三者分别进行线性变换，即将三者分别输入到三个单层神经网络层，激活函数选择relu，输出新的V，K，Q（三者shape都和原来shape相同，即<strong>经过线性变换时输出维度和输入维度相同</strong>）；</p><p>3.2.3 然后将Q在最后一维上进行切分为num_heads(假设为8)段，然后对切分完的矩阵在axis=0维上进行concat链接起来(纵向连接)；对V和K都进行和Q一样的操作；操作后的矩阵记为Q_,K_,V_；</p><p><strong>可以变化其维度， 由[1,10,512]变为[8,10,64]</strong></p><p><img src="https://i.loli.net/2020/09/05/PqJYGOb4fvTmsFw.png" alt="img"></p><p><img src="https://i.loli.net/2020/09/05/2npJkGobFc4RXwu.png" alt="img"></p><p>3.2.4 <strong>Q_矩阵相乘 K_的转置（对最后2维）</strong>，生成结果记为outputs，然后对outputs 进行scale一次更新为outputs；<strong>此次矩阵相乘是计算词与词的相关性，切成多个num_heads进行计算是为了实现对词与词之间深层次相关性进行计算；</strong></p><p><img src="https://i.loli.net/2020/09/05/imn5tKIUxzyfwLW.png" alt="img"></p><p><code>shape（outputs） = （8,10,10）</code></p><p>3.2.5 对outputs进行softmax运算，更新outputs，即outputs=softmax(outputs);</p><p>3.2.6 最新的outputs（即K和Q的相关性） 矩阵相乘 V_， 其值更新为outputs；</p><p><img src="https://i.loli.net/2020/09/05/oZalMTkQeRVqsUy.png" alt="img"></p><p><code>shape（outputs）= (8,10,64)</code></p><p>3.2.7 最后将outputs在axis=0维上切分为num_heads段，然后在axis=2维上合并， <strong>恢复原来Q的维度</strong>；</p><p><img src="https://i.loli.net/2020/09/05/JrFbIdWauXxA4nK.png" alt="img"></p><p>3.3 Add&amp;norm</p><p>3.3.1 类似ResNet，将<strong>最初的输入与其对应的输出叠加一次</strong>，即outputs=outputs+Q， 使网络有效叠加，<strong>避免梯度消失</strong>；</p><p><img src="https://i.loli.net/2020/09/05/falSI79c3xD2Ey8.png" alt="img"></p><p>3.3.2 标准化矫正一次，在outputs对最后一维计算均值和方差，用outputs减去均值除以方差+spsilon得值更新为outputs，然后变量gamma*outputs+变量beta；（Norm操作）</p><p>3.4 feed Forward （就是dense layer 全连接层）</p><p>3.4.1 对outputs进行第一次卷积操作，结果更新为outputs（卷积核为1*1，每一次卷积操作的计算发生在一个词对应的向量元素上，卷积核数目即最后一维向量长度，也就是一个词对应的向量维数）；</p><p>3.4.2 对最新outputs进行第二次卷积操作，卷积核仍然为1*1，卷积核数目为N；</p><p><img src="https://i.loli.net/2020/09/05/esShU1Nx32AYt8Z.png" alt="img"></p><p>3.5 Add&amp;norm : 和3.3相同，经过以上操作后，此时最新的output和matEnc的shape相同；</p><p>3.6 <strong>令matEnc=outputs, 完成一次循环，然后返回到3.2开始第二次循环</strong>；共循环Nx（自定义；每一次循环其结构相同，但对应的参数是不同的，即是独立训练的）；完成Nx次后，模型的编码部分完成，仍然令matEnc=outputs，准备进入解码部分；</p><p>解码部分：</p><p>​ <strong>此时的outputs指的是上一时间点解码器的输出</strong></p><ol type="1"><li><p>Outputs：<strong>shifted right右移一位</strong>？？？？，是为了解码区最初初始化时第一次输入，并将其统一定义为特定值（在word2num中提前定义）；</p></li><li><p>Outputs embedding: 同编码部分；更新outputs；</p></li><li><p>Positional embedding：同编码部分；更新outputs； （前三步是准备工作）</p></li><li><p>进入解码区循环体； （以下是解码器的顺序操作）</p></li></ol><p>4.1 Masked multi-head attention: 和编码部分的multi-head attention类似，但是多了一 次<strong>masked</strong>，因为在解码部分，解码的时候是从左到右依次解码的，当解出第一个字的时候，第一个字只能与第一个字计算相关性，当解出第二个字的时候，只能计算出第二个字与第一个字和第二个字的相关性，...；所以需要进行一次mask；</p><p><img src="https://i.loli.net/2020/09/05/54eVnEgmh7CdqKH.jpg" alt="img"></p><p>为什么是10*10呢？？？</p><p>4.2 Add&amp;norm：同编码部分，更新outputs；</p><p>4.3 Multi-head attention：同编码部分，但是Q和K，V不再相同，Q=outputs，K=V=matEnc；(outputs是上层的输出，k,v是来自编码器的输出)</p><p>4.4 Add&amp;norm:同编码部分，更新outputs；</p><p>4.5 Feed-Forward：同编码部分，更新outputs；</p><p>4.6 Add&amp;norm: 同编码部分，更新outputs；</p><p>4.7 最新outputs和最开始进入该循环时候的outputs的shape相同；回到4.1，开始第 二次循环。。。；直到完成Nx次循环（自定义；<strong>每一次循环layer结构相同，但对应的参数是不同的，即独立训练的</strong>）；</p><ol start="5" type="1"><li><p>Linear: 将最新的outputs，输入到单层神经网络中，输出层维度为“译文”有效单词总数；更新outputs；</p></li><li><p>Softmax: 对outputs进行softmax运算，确定模型译文和原译文比较计算loss，进行网络优化（参数更新）；</p></li></ol><h4 id="注">注</h4><p>1.解码器的<code>outputs embedding</code> ：在训练的时候就是对应原文的译文，其中第一字统一定义为0,作为输入；在预测时第一次输入也是全是0,然后每循环一次，预测一个字直到出现终止符。</p><p>2.对于matEnc=matP+matX，这里为什么要用add,而不是contact ?</p><p>matX是一个10行512列的矩阵，每一行代表一个字；</p><p>matP是一个10行512列的矩阵，每一行代表一个位置；</p><p><strong>对于不一样的句子，matX是不一样的，matP是完全一样的；</strong></p><p>则对于不一样的句子，add后是不一样的，contact后至少一半是一样的，从直观上，add似乎更好；</p><p>对于一个字，其出现的位置不同，可能表达的意思完全不一样，比如“和”，如果其在句首或者句中出现更可能是“and”的意思，如果在句末出现，更可能是“sum”的意思，而这两个意思几乎完全不一样，即他们的向量完全不一样似乎更合理，而非contact的至少一半一样；</p><p>matP矩阵的特点从上到下对应各元素是递增的，matX是随机产生的（比如均值为0的随机数），即大约在0附近波动的数，与matP做add运算后，相当于均值被依次提高，以此代表融入每个字位置信息；因为每次训练的时候均值被提高的量是一定的，所以可以期望模型训练后能“意识”到这一点；</p><p>add产生“信息混淆”，比如两个字在两个不同的位置上分别add后，结果相近，从直观上这可能会造成问题；这个问题可以通过加大向量维度来降低其出现概率，比如选择512维是很长的维度了，出现这种概率的问题还是很小的；</p><p>如果用contact实际就是在每个字向量后面追加一个位置信息以示区别，做这种区别无需太多维，也许一两维即可；</p><p>深度学习算法的可解释性差，分析大多属于理论上的“纸上谈兵”，最可靠的方式，仍是分别以add和contact两种方式建模，大量测试后的结果更为可靠。</p><ol start="3" type="1"><li><p>待探究</p><p>你文章中的逻辑是，对原始Q/K/V做不同线性变换（三个权重矩阵）得到新的Q/K/V→对新的Q/K/V在最后一个维度做切分得到多头（8组Q/K/V）→各组Q/K/V计算attetion值→8组Q/K/V的attetion值concat得到最终的attention值。</p><p>而原论文的逻辑是，对原始的Q/K/V做不同的线性变换（8（组）×3个权重矩阵）得到新的8组Q/K/V值→各组Q/K/V计算attention值→8组Q/K/V的attention值concat→concat结果经过一个线性变换（为了还原到最初的维度）得到最终的attention值。</p><p>论文提到multi-head attention是为了从不同表征子空间提取信息。个人理解实现这种差异化的提取，是通过多组权重矩阵来实现的，而不是通过embedding值不同分段获取。</p></li><li><p>在<strong>预测阶段</strong>，每次预测后底部decoder的输入是可变的，首先是[<bos>]，然后是[<bos>, word1 ]，再输入[<bos>, word1, word2 ]……，那么decoder内部如何保证它送入linear层的输出是(1, N)的向量呢？</bos></bos></bos></p><p><strong>答</strong>：[<bos>]时，经过解码区的循环部分后 是一个[1, 512]的矩阵， 经过linear层是准备预测1个字的；</bos></p><p>[<bos>, word1 ]时，经过解码区的循环部分 是一个[2, 512]的矩阵；经过linear层是准备预测2个字的；以此类推。</bos></p><p>也就是说，输入bos，输出word1；然后将bos word1输入，再输出word1 word2；再输入bos word1 word2......每次都把输出的最后一个字加到下一轮输入。</p></li><li><p>假设target是<bos>我爱中国<eos>，这算6个字，训练时decoder是不是也输出6个vocab-size长度的向量，那么第一个vocab-size长度的向量预测的是<bos>还是"我"呢？</bos></eos></bos></p><p><strong>答</strong>：预测的第一个是“我”,<bos>作为一个起始引导使用。</bos></p></li><li><p>第一个问题是训练和预测时解码端如何运行，我理解训练时使用mask一次性对所有时间步并行进行解码，预测时则需要先预测出上一步的词，再输入预测下一步，所以不能并行。如果我上面说的没错的话，第一个问题是为什么训练时mask没有掩盖自身，也就是对角线不mask，这样的话不就泄露了要预测那个词吗？第二个问题是预测时该如何进行，因为训练时，输入多少个时间步的词就会输出多少个时间步的预测值，但是在预测解码阶段，假设为t，要预测t + 1该如何操作？难道是先将t + 1随便加一个pad上去然后看预测值softmax吗？</p><p><strong>答</strong>：<strong>在训练时，用mask是一次性的解码</strong>，因为训练时所有label是已知的，用mask实现同时并行运算；<strong>预测时label是未知的，需要一个一个词预测</strong>，当预测第一个词时只能知道第一个词和第一个词的相关性，然后再运行模型一遍，预测出第一个词和第二词，依次循环直到出现终止符，这个过程不是并行的。</p><p>个人理解： 在训练时，把一整句话都作为解码器的输入，这样可以实现并行运算，因为每一个label都是已知的。而在预测时，需要一步一步来</p></li></ol><h3 id="参考">🚀参考</h3><blockquote><p><a href="https://zhuanlan.zhihu.com/p/62397974" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/62397974</a></p><p><a href="https://zhuanlan.zhihu.com/p/44731789" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/44731789</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      摘自一篇不错的博客
    
    </summary>
    
    
      <category term="transformer" scheme="http://yoursite.com/categories/transformer/"/>
    
    
      <category term="transformer" scheme="http://yoursite.com/tags/transformer/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-31-一周论文分享（第1期）</title>
    <link href="http://yoursite.com/2020/08/31/2020-08-31-%E4%B8%80%E5%91%A8%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%EF%BC%88%E7%AC%AC1%E6%9C%9F%EF%BC%89/"/>
    <id>http://yoursite.com/2020/08/31/2020-08-31-%E4%B8%80%E5%91%A8%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%EF%BC%88%E7%AC%AC1%E6%9C%9F%EF%BC%89/</id>
    <published>2020-08-31T12:43:16.000Z</published>
    <updated>2020-09-04T08:00:41.608Z</updated>
    
    <content type="html"><![CDATA[<h3 id="reformerthe-eficient-transformer">reformer：the eficient transformer</h3><h4 id="论文概况">论文概况</h4><ul><li>来源：ICLR 2020</li><li>arXiv: 1901.02860</li><li>作者：Nikita Kitaev ，Anselm Levskaya</li><li>论文地址：<a href="https://openreview.net/forum?id=rkgNKkHtvB" target="_blank" rel="noopener" class="uri">https://openreview.net/forum?id=rkgNKkHtvB</a></li><li>Code url：<a href="https://github.com/google/trax/tree/master/trax/models/reformer" target="_blank" rel="noopener" class="uri">https://github.com/google/trax/tree/master/trax/models/reformer</a></li><li>论文组会报告于<code>2020.08.30</code></li></ul><h4 id="背景">背景</h4><p>Transformer架构被广泛用于自然语言处理中，并在许多任务上产生了最新的结果</p><h5 id="问题">问题</h5><ol type="1"><li>大型的 Transformer 可以在许多任务上实现 sota，但是面临着参数过多的问题，导致所占内存过大，造成资源紧张.</li></ol><p>在最大的配置中，参数数量已经超过了 5亿/层，层数多达 64。</p><ol start="2" type="1"><li><p>具有 <em>N</em> 层的模型要消耗 <em>N</em> 倍于单层模型的内存，因为每一层中的激活都需要存储以进行反向传播。</p></li><li><p>由于点乘注意力本身的局限性，导致不能处理长序列数据，否则会导致效率不高</p></li></ol><p>也就是说transformer的上下文窗口有限制范围。最多也就几千个单词。</p><blockquote><p>Transformer 的强大来源于注意力机制 ，通过这一机制，Transformer 将上下文窗口内所有可能的单词对纳入考虑，以理解它们之间的联系。因此，如果文本包含 10 万个单词，Transformer 将需要评估 100 亿单词对（10 万 x 10 万），这显然不切实际。</p><p>另一个问题是如何保存每个模型层的输出 。对于使用大型上下文窗口的应用来说，存储多个模型层输出的内存需求会迅速变得过大。这意味着，实际使用大量层的 Transformer 模型只能用于生成几小段落的文本或一小段的音乐。</p></blockquote><h5 id="解决方案">解决方案</h5><ol type="1"><li><p>使用可逆残差（reversible residual layers）代替标准残差（standard residuals），这使得存储在训练过程中仅激活一次，而不是 n 次（此处 n 指层数），更有效地使用可用内存</p></li><li><p>将点乘注意力（dot-product attention）替换为一个使用局部敏感哈希（locality-sensitive hashing）的点乘注意力，将复杂度从 O(L2 ) 变为 O(L log L)，此处 L 指序列的长度，来降低长序列的处理复杂度</p></li></ol><p><strong>Reformer与使用完全Transformer所获得的结果相匹配，但运行速度要快得多，尤其是在文本任务上，并且内存效率要高几个数量级。</strong></p><h4 id="注意力问题">注意力问题</h4><h5 id="原始注意力">原始注意力</h5><p>公式如下：<span class="math inline">\(Attention (Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}\right) V\)</span></p><p>self-attention操作的核心 ——<span class="math inline">\(QK^T\)</span> 表示key和query之间的相似度得分</p><p>计算带有所有k的q的点积，并用√dk进行缩放，然后应用softmax函数来获得v的权重。用来消除hidden size这个参数对注意力分布的影响。对于每个query，我们在所有keys上计算一个softmax，以确保矩阵的每一行和为1—— 确保新的隐藏状态的大小不依赖于序列长度。</p><p>最后，我们用我们的注意力矩阵乘以我们的values矩阵，为每个token生成一个新的隐藏表示。</p><hr><blockquote><h5 id="例子">例子</h5><p>Key:(batch, length,d_model)</p><p>Query:(batch, length,d_model)</p><p>-&gt; <span class="math inline">\(QK^T\)</span>　:(batch, length,length)</p><p>-&gt; 复杂度： O(<span class="math inline">\(L^2\)</span> )</p><p>-&gt;原始的transformer结构难以处理过长的序列长度</p></blockquote><p><img src="https://i.loli.net/2020/09/03/9mdzrXcGKZ5FPi3.png" alt="image-20200903163000933"></p><p><img src="https://i.loli.net/2020/09/03/6QvMn1qxGXzwKmC.png" alt="image-20200903161441529"></p><p>其实，在softmax中，对于每个查询 <em>q</em>，我们只需要注意最接近 <em>q</em> 的键 <em>k</em>。<strong>并不一定需要那些注意力权重很小的token。</strong></p><p>例如，如果序列长度是 64K，对于每个 <em>q</em>，我们可以只考虑 32 或 64 个最近的键的一个小子集。因为这些是和<em>q</em>最需要注意的</p><h5 id="局部敏感哈希lsh">局部敏感哈希(LSH)</h5><p><img src="https://i.loli.net/2020/09/03/zQI9n2ubZYDV7SL.png" alt="image-20200903163152560"></p><p>局部敏感哈希使用<code>球形投影点的随机旋转</code>，通过argmax在有符号轴投影上<code>建立桶（bucket）</code>。 在此高度简化的2D描绘中，对于三个不同的角度hash，两个点x和y不太可能共享相同的哈希桶（上方），除非它们的球面投影彼此靠近（下方）。</p><p>该图演示了一个用<code>4个桶进行3轮哈希的设置</code>。下面的图中的向量映射到了同一个bucket，因为它们的输入很接近，而上一张图中的向量映射到第一个和最后一个bucket。</p><p>LSH是一组将高维向量映射到一组离散值(桶/集群)的方法。是解决在高维空间中快速找到最近邻居（最相似）的问题。</p><p><code>基本思想</code>：选择 <em>hash</em> 函数，对于两个点 p 和 q，如果 q 接近 p，那么很有可能我们有 hash(q) == hash(p)</p><h5 id="lsh注意力">LSH注意力</h5><p><img src="https://i.loli.net/2020/09/03/KgnJ7iB2kImcshX.png" alt="image-20200903163641310"></p><p>完全不同的方法来处理序列长度问题，丢弃了<code>query投影</code>（Q=K）（实验结果发现，学习不同的keys和queries的投影并不是严格必要的），<code>并将注意力权重替换为key的函数（hash函数）</code>，以此降低复杂度</p><p>步骤如下：</p><p>1.使用LSH为每个token计算一个桶</p><p>2.根据相同的桶进行归类排序</p><p>3.分块并将标准的点乘注意力应用到桶中的token的块上，从而大大降低计算负载</p><h4 id="内存问题">内存问题</h4><p>单层能够执行长序列的单模型。但是，当使用梯度下降训练多层模型时，由于需要保存每一层的激活（函数），以用于执行逆推。一个传统的 Transformer 模型具有十几个或更多的层，通过缓存这些层的值，内存将会很快用完。</p><p>可逆层：在反向传播时，按需重新计算每个层的输入，而不是将其保存在内存中。其中来自网络最后一层的激活用于还原来自任何中间层的激活。</p><p>原始的残差网络：<span class="math inline">\(Y=F(x)\)</span></p><p>可逆层的残差网络： 注意我们如何从它的输出(Y ₁, Y ₂)计算物体的输入(X ₁, X ₂)。</p><p><span class="math inline">\(\begin{array}{ll}y_{1}=x_{1}+F\left(x_{2}\right) &amp; y_{2}=x_{2}+G\left(y_{1}\right) \\ x_{2}=y_{2}-G\left(y_{1}\right) &amp; x_{1}=y_{1}-F\left(x_{2}\right) \\ Y_{1}=X_{1}+\text { Attention }\left(X_{2}\right) &amp; Y_{2}=X_{2}+\text { FeedForward }\left(Y_{1}\right)\end{array}\)</span></p><p>示意图如下</p><p><img src="https://i.loli.net/2020/09/03/WX3lcQrmB16pI2Y.png" alt="image-20200903164816966"></p><p><img src="https://i.loli.net/2020/09/03/FgHKa4QNrsjlzMh.png" alt="image-20200903164907447"></p><h4 id="实验">实验</h4><p>作者分别对图像生成任务 <em>imagenet64</em>(长度为 12K)和文本任务 <em>enwik8</em>(长度为 64K)进行了实验，评价了可逆 Transformer 和 LSH 哈希对内存、精度和速度的影响。</p><p>🎉可逆 Transformer 匹配基准：他们的实验结果表明，可逆的 Transformer 可以节省内存不牺牲精度：</p><p><img src="https://i.loli.net/2020/09/03/LwSPM5qFuBfQhaZ.png" alt="null"></p><p>在 enwik8 和 imagenet64 训练中，可逆性对性能的影响</p><p>🎉LSH 注意力匹配基准：注意 LSH 注意力是一个近似的全注意力，其准确性随着散列值的增加而提高。当哈希值为 8 时，LSH 的注意力几乎等于完全注意力：</p><p><img src="https://i.loli.net/2020/09/03/t4zNAXOf6iEZ7cH.jpg" alt="null"></p><p>LSH 注意力作为散列循环对 imagenet64 的影响</p><p>🎉他们也证明了传统注意力的速度随着序列长度的增加而变慢，而 LSH 注意力速度保持稳定，它运行在序列长度~ 100k 在 8GB 的 GPU 上的正常速度：</p><p><img src="https://i.loli.net/2020/09/03/aGRcA42EiNSBz8v.jpg" alt="null"></p><p>注意力评估的速度作为全注意力和 LSH 注意力的输入长度的函数</p><blockquote><p>与 Transformer 模型相比，最终的 Reformer 模型具有更高的存储效率和更快的存储速度。</p></blockquote><h4 id="参考">🚀参考</h4><blockquote><p><a href="https://www.6aiq.com/article/1583729200869" target="_blank" rel="noopener" class="uri">https://www.6aiq.com/article/1583729200869</a></p><p><a href="https://thinkwee.top/2020/02/07/reformer/" target="_blank" rel="noopener" class="uri">https://thinkwee.top/2020/02/07/reformer/</a></p><p><a href="https://aijishu.com/a/1060000000100293" target="_blank" rel="noopener" class="uri">https://aijishu.com/a/1060000000100293</a></p></blockquote><h3 id="transformer-xl-attentive-language-models-beyond-a-fixed-length-context">Transformer-XL : Attentive Language Models Beyond a Fixed-Length Context</h3><h4 id="论文概况-1">论文概况</h4><ul><li>来源：ACL 2019</li><li>arXiv: 1901.02860</li><li>作者：ZihangDai , ZhilinYang , YimingYang</li><li>论文地址： <a href="https://arxiv.org/abs/1901.02860" target="_blank" rel="noopener" class="uri">https://arxiv.org/abs/1901.02860</a></li><li>Code url：<a href="https://github.com/kimiyoung/transformer-xl" target="_blank" rel="noopener" class="uri">https://github.com/kimiyoung/transformer-xl</a></li><li>论文组会报告于<code>2020.08.15</code></li></ul><h4 id="背景-1">背景</h4><h5 id="问题-1">问题</h5><p>Transformer存在局限性：</p><p>1.在语言建模时的设置受到固定长度（segment）的限制。对长距离依赖的建模能力仍然不足</p><p>2.因为transformer将文本等分为相同的片段，导致了上下文碎片</p><h5 id="解决方案-1">解决方案</h5><p>使学习不再仅仅依赖于定长，且不破坏时间的相关性。</p><ol type="1"><li>提出<strong>片段级递归机制(segment-level recurrence mechanism)</strong>，引入一个<strong>记忆(memory)</strong>模块（类似于cache或cell） 之前计算过了不需要重复计算，直接为后面片段使用。</li></ol><ul><li>使得<code>长距离依赖的建模</code>成为可能；</li><li>使得片段之间产生交互，解决上下文碎片化问题</li></ul><p>2.提出<strong>相对位置编码机制</strong>，代替绝对位置编码。 Transformer的绝对位置编码指的是一个片段中，为1 为2 。如果是多个片段同时考虑的话，那么这种1，2就会重复，所以使用了相对位置编码的方法。这样可以在多个片段（segment）中使用相对编码。具体内容见论文</p><p>注：两者是一起使用的，共同解决transformer存在的局限性</p><h4 id="模型-transformer-xl">模型 transformer-XL</h4><h5 id="原始transformer">原始transformer</h5><p><img src="https://i.loli.net/2020/09/04/YU3mC2hIOA9ncrj.gif" alt="v2-732805e00feb35e41f1d00f8df516950_b"></p><h5 id="片段注意力机制">片段注意力机制</h5><p>为了解决长距离依赖，文章引入一个memory状态。</p><p>在训练过程中，每个片段的表示为最后的隐层状态，表示片段的序号，表示片段的长度，表示隐层维度。</p><p>在计算片段的表示时，用memory缓存片段层的隐层状态，用来更新，这样就给下一个片段同了上文，长距离依赖也通过memory保存了下来。并且，最大可能的依赖长度线性增长，达到**N*L**</p><p><img src="https://i.loli.net/2020/09/04/IjUWo7DahsNPAkv.gif" alt="v2-a8210cd2f9bfb9307ba81d694dc4e4b4_b"></p><h5 id="评估阶段">评估阶段</h5><h6 id="原始transformer-1">原始transformer</h6><p><img src="https://i.loli.net/2020/09/04/epOcXjYTy835dJv.gif" alt="v2-13a38126e684b838e5ed207fd5cae944_b"></p><h6 id="transformer-xl">Transformer-XL</h6><p><img src="https://i.loli.net/2020/09/04/qdYL5RsQEOFS8nG.gif" alt="v2-502e1e1fec12b326ace579e059b3b3df_b"></p><h4 id="实验-1">实验</h4><p>实验部分是对基于Transformer-XL的语言模型进行评估，分为字符级和词级。评价指标分别是bpc(每字符位数)和PPL(困惑度)，越小越好。enwiki8和text8用的是bpc。Transformer-XL在多个语言模型基准测试中实现了最先进的结果。 Transformer-XL第一个在char级语言模型基准enwiki8上突破1.0。</p><p><strong>去除实验：</strong></p><p><img src="https://i.loli.net/2020/09/04/ZV1lpewdtanoWi9.png" alt="image-20200904153950861"></p><p>重点是本文设计的相对位置编码<strong>优于</strong>其他工作，memory的设计也有很大的提升。</p><p>最后，Transformer-XL在评估阶段的速度也明显快于 vanilla Transformer，特别是对于较长的上下文。例如，对于 800 个字符的上下文长度，Transformer-XL 比Vanilla Transformer 快 363 倍；而对于 3800 字符的上下文，Transformer-XL 快了 1874 倍。</p><h4 id="创新点">创新点</h4><ul><li>提出了片段级递归机制和相对位置编码机制</li><li>依赖关系比原始Transformer长450％，并且在评估过程中，其速度比原始Transformer快1800倍以上</li></ul><h4 id="参考-1">🚀参考</h4><blockquote><p><a href="https://www.cnblogs.com/shona/p/12041055.html" target="_blank" rel="noopener" class="uri">https://www.cnblogs.com/shona/p/12041055.html</a></p><p><a href="https://zhuanlan.zhihu.com/p/83062195" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/83062195</a></p><p><a href="https://www.cnblogs.com/mj-selina/p/12373636.html" target="_blank" rel="noopener" class="uri">https://www.cnblogs.com/mj-selina/p/12373636.html</a></p><p><a href="https://zhuanlan.zhihu.com/p/70745925" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/70745925</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录每周值得分享的论文，周一发布、
《reformer-the eficient transformer》、
《Transformer-XL-Attentive Language Models Beyond a Fixed-Length Context》

    
    </summary>
    
    
      <category term="论文分享" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"/>
    
    
      <category term="论文" scheme="http://yoursite.com/tags/%E8%AE%BA%E6%96%87/"/>
    
      <category term="transformer" scheme="http://yoursite.com/tags/transformer/"/>
    
      <category term="论文分享" scheme="http://yoursite.com/tags/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-31-git进阶</title>
    <link href="http://yoursite.com/2020/08/31/2020-08-31-git%E8%BF%9B%E9%98%B6/"/>
    <id>http://yoursite.com/2020/08/31/2020-08-31-git%E8%BF%9B%E9%98%B6/</id>
    <published>2020-08-31T08:41:49.000Z</published>
    <updated>2020-09-05T08:34:47.989Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言">前言</h3><p>之前总结过git的一些基本命令，后来使用了更多git，写博客用于记录。不断更新 ，在实践中总结git知识点。</p><p>回顾下之前的git基本操作</p><ul><li>将现有的项目添加提交并上传到远程仓库</li></ul><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">git add . #添加当前文件夹下的所有文件</span><br><span class="line"></span><br><span class="line">git commit -m "first commit " # 引号内是本次的提交说明 </span><br><span class="line"></span><br><span class="line">git push -u origin master # 提交本地分支到远程分支</span><br><span class="line">(若出现failed to push som refs to， 则执行git pull origin master，</span><br><span class="line">将远程服务器github上的master拉下来，再重新push)</span><br></pre></td></tr></tbody></table></figure><ul><li>clone代码</li></ul><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone   https://github.com/raymond-zhao/cat-mall.git   ../Github/cat-mall </span><br><span class="line">#将cat-mall代码克隆到  ../Github/cat-mall 中</span><br></pre></td></tr></tbody></table></figure><h3 id="git-status-和-git-diff">git status 和 git diff</h3><p>在对文件进行修改之后，可以用 <code>git status</code> 查看结果，可以让我们时刻掌握仓库当前的状态</p><p><img src="https://i.loli.net/2020/08/31/fTmxaAeZG1iSCLd.png" alt="image-20200831180231338" style="zoom:67%;"></p><p>可以看到在<code>modified</code>部分，可以看到有四个文件被修改了，<strong>但是还没有进行提交（<code>commit</code>）修改</strong></p><p>而下半部分的<code>untracked files</code>表示的是<strong>之前从未提交到仓库分支</strong>的文件（一个markd文件，一个照片）</p><p>上述只是看到被修改的文件，但如果能看看具体修改了什么内容就好了，<code>git diff</code> 可以实现这个功能</p><p><img src="https://i.loli.net/2020/08/31/nVd3hGKLJy6f7zH.png" alt="image-20200831194816455"></p><p>可以看到修改的详细细节（红色为修改前的内容，绿色为修改后的内容）。向下箭头可以下拉文本，<code>q</code>退出查看 （quit）</p><p>这样就可以放心的添加（add）到仓库的暂存区，并提交（commit）到仓库分支</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m 20/8/31/commit1</span><br></pre></td></tr></tbody></table></figure><h4 id="小结">小结</h4><ul><li>要随时掌握工作区的状态，使用<code>git status</code>命令。</li><li>如果<code>git status</code>告诉你有文件被修改过，用<code>git diff</code>可以查看修改内容。</li></ul><h3 id="版本回退">版本回退</h3><p>每当文件修改到一定程度的时候，就可以“保存一个快照”，这个快照在Git中被称为<code>commit</code>。一旦你把文件改乱了，或者误删了文件，还可以从最近的一个<code>commit</code>恢复，然后继续工作，而不是把几个月的工作成果全部丢失。</p><p>在Git中，我们用<code>git log</code>命令查看：</p><p><img src="https://i.loli.net/2020/08/31/4lC7ufP6ZmbUvWT.png" alt="image-20200831233324006" style="zoom:80%;"></p><p><code>git log</code>命令显示从最近到最远的提交日志，每一次<code>commit</code>很详细</p><p>可以加上<code>--pretty=oneline</code>参数，来简化显示。推荐使用</p><p><img src="https://i.loli.net/2020/08/31/xNXAn7Pt8rT2mcE.png" alt="image-20200831233340202" style="zoom:80%;"></p><p>其中前面编号类似<code>012214236e...</code>的是<code>commit id</code>（版本号），是一个<code>SHA1</code>计算出来的一个非常大的数字，用十六进制表示</p><p>每个人的编号不一样，因为Git是分布式的版本控制系统，多人在同一个版本库里工作，如果大家都用1，2，3……作为版本号，那肯定就冲突了。</p><blockquote><p><a href="https://1024tools.com/hash" target="_blank" rel="noopener">Hash在线计算、md5计算、sha1计算、sha256计算、sha512计算</a></p></blockquote><h4 id="回退到历史版本">回退到历史版本</h4><p>这样我们就可以进行回退操作</p><p>首先，Git必须知道当前版本是哪个版本。</p><p>在Git中，用<code>HEAD</code>表示当前版本，也就是最新的提交<code>012214236e...</code>，上一个版本就是<code>HEAD^</code>，上上一个版本就是<code>HEAD^^</code>，当然往上100个版本写100个<code>^</code>比较容易数不过来，所以写成<code>HEAD~100</code>。</p><p>我们可以使用<code>git reset</code>命令：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard HEAD^ <span class="comment">#回退到上一版本</span></span><br></pre></td></tr></tbody></table></figure><p><img src="https://i.loli.net/2020/08/31/k37ptdoMJxGcufR.png" alt="image-20200831233416378"></p><p>结果显示出现在是<code>ca41b0a</code>，也就是上一次<code>commit</code>的版本。我们成功回退版本！</p><p>当我们再查看日志的时候，发现已经没有<code>20/8/31/commit1</code>版本了</p><p><img src="https://i.loli.net/2020/08/31/xWIlbtTwazUJNdO.png" alt="image-20200831233446124"></p><hr><h4 id="还原到最新版本">还原到最新版本</h4><p>如果想要再还原到<code>20/8/31/commit1</code>版本呢？</p><p>也是可以的，只要<strong><code>上面的命令行窗口还没有被关掉</code></strong>，就可以顺着往上找，找到那个<code>20/8/31/commit1</code>版本的<code>commit id</code>是<code>012214236e...</code>，于是就可以指定回到未来的某个版本：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard 0221423</span><br></pre></td></tr></tbody></table></figure><p><img src="https://i.loli.net/2020/08/31/9pK7UsnRrv1loSD.png" alt="image-20200831233507305"></p><p>版本号没必要写全，前几位就可以了，Git会自动去找。当然也不能只写前一两位，因为Git可能会找到多个版本号，就无法确定是哪一个了。</p><p>这样就实现了还原到最后<code>commit</code>版本</p><p>Git的版本回退速度非常快，因为Git在内部有个指向当前版本的<code>HEAD</code>指针，当你回退版本的时候，Git仅仅是把HEAD从指向历史版本，再将工作区的文件更新即可</p><p>如果回退到了某个版本，关掉了命令行窗口，后悔想恢复到新版本但是找不到新版本的<code>commit id</code>怎么办？</p><p>在Git中，总是有后悔药可以吃的。Git提供了一个命令<code>git reflog</code>用来记录你的每一次命令：</p><p><img src="https://i.loli.net/2020/09/01/Ly4MDnv6WAEwQlV.png" alt="image-20200901000008019"></p><p>知道<code>commit_id</code>，还原版本就十分滴完美！</p><blockquote><p><strong>注！！！</strong></p><p>如果从历史版本回到最后的版本，也只能还原到最后<code>commit</code>后的版本。</p><p>我才开始<code>commit</code>了版本A，之后又写了一部分内容 B(未<code>commit</code>)。还原到了A-1版本，之后又想还原到A+B版本，操作完之后发现还原后的没有B部分，也就是我只能还原到A。</p><p>原因就是我在最后一次<code>commit</code>就是A，而写完B之后，没有<code>commit</code> ，于是无法还原。 （多多<code>commit</code>，</p><p>，还原需谨慎。我是真的折腾）<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f62d.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f62d.png?v8">😭</span></p></blockquote><h4 id="小结-1">小结</h4><ul><li><code>HEAD</code>指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令<code>git reset --hard commit_id</code>。 （commit_id也写成HEAD^）</li><li>穿梭前，用<code>git log</code>可以查看提交历史，以便确定要回退到哪个版本。</li><li>要重返未来，用<code>git reflog</code>查看命令历史，以便确定要回到未来的哪个版本。</li></ul><h4 id="参考">参考</h4><blockquote><p><a href="http://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html" target="_blank" rel="noopener">常用git命令清单-阮一峰</a></p><p><a href="http://www.ruanyifeng.com/blog/2012/08/how_to_read_diff.html" target="_blank" rel="noopener">读懂diff-阮一峰</a></p><p><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="noopener">git教程-廖雪峰</a></p><p><a href="http://www.runoob.com/git/git-install-setup.html" target="_blank" rel="noopener">git教程-菜鸟教程</a></p><p><a href="https://git-scm.com/book/zh/v2" target="_blank" rel="noopener">gitbook</a></p><p><a href="http://gitbook.liuhui998.com/index." target="_blank" rel="noopener">Git Community Book</a></p><p><a href="https://juejin.im/post/6844903586023866375" target="_blank" rel="noopener">从只会git add .的菜鸟到掌握git基本功能</a></p></blockquote><h3 id="工作区和暂存区">工作区和暂存区</h3><h4 id="工作区working-directory">工作区（Working Directory）</h4><p>就是在电脑里能看到的目录，比如我的<code>mynlog</code>文件夹就是一个工作区：</p><p><img src="https://i.loli.net/2020/09/01/lp9hvTzLtVuMPG5.png" alt="image-20200901000937480" style="zoom:80%;"></p><h4 id="版本库repository">版本库（Repository）</h4><p>也就是本地仓库</p><p>工作区有一个隐藏目录<code>.git</code>，这个不算工作区，而是Git的版本库。（选择<code>隐藏文件可见</code>就可以看到）</p><p>Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫<code>index</code>）的暂存区，还有Git为我们自动创建的第一个分支<code>master</code>，以及指向<code>master</code>的一个指针叫<code>HEAD</code>。</p><p><img src="https://i.loli.net/2020/09/01/wBe5iWuajDJKxdV.png" alt="image-20200901001300425" style="zoom:80%;"></p><p><img src="https://i.loli.net/2020/09/01/KywEFn2dtMJeBkq.png" alt="image-20200901001406385" style="zoom:80%;"></p><p>前面讲了我们把文件往Git版本库里添加的时候，是分两步执行的：</p><p>第一步是用<code>git add</code>把文件添加进去，实际上就是把文件修改添加到暂存区(<code>index</code>)；</p><p>第二步是用<code>git commit</code>提交更改，实际上就是把暂存区的所有内容提交到当前分支(<code>master</code>)。</p><p>因为我们创建Git版本库时，Git自动为我们创建了唯一一个<code>master</code>分支，所以，现在，<code>git commit</code>就是往<code>master</code>分支上提交更改。</p><p>你可以简单理解为，<strong>需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。</strong> 也就是可以多次<code>git add .</code> ,之后再一次性<code>git commit</code></p><p>我对文件进行修改之后，<code>git status</code> 显示如下：</p><p><img src="https://i.loli.net/2020/09/01/qZ4JcAzCrBOQng5.png" alt="image-20200901003431025"></p><p>这是对文件进行了修改，但是未添加（add）到暂存区和提交（commit）到仓库分支。 并且出现了之前从未提交的文件（四张png图片）</p><p>然后<code>git add .</code>,再查看目前的状态 <code>git status</code></p><p><img src="https://i.loli.net/2020/09/01/leMQO9F83N5DxUq.png" alt="image-20200901003844459"></p><p>出现了绿色的<code>new file</code>字样和<code>modified</code>，代表已添加到缓存区。</p><p>现在，暂存区的状态就变成这样了（原文是添加的readme和LICENSE文件）：</p><p><img src="https://i.loli.net/2020/09/01/MHQiJkB674jcAE5.png" alt="image-20200901003951252"></p><p>所以，<code>git add</code>命令实际上就是把要提交的所有修改放到暂存区（index），然后，执行<code>git commit</code>就可以一次性把暂存区的所有修改提交到分支。</p><p><img src="https://i.loli.net/2020/09/01/1uzidT9knarwNMU.png" alt="image-20200901004202394"></p><p>这时候再 <code>git status</code>，则是干净的</p><p>现在版本库变成了这样，暂存区就没有任何内容了：</p><p><img src="https://i.loli.net/2020/09/01/kCXlv3FiurZNbIO.jpg" alt="git-stage-after-commit"></p><h4 id="小结-2">小结</h4><p>了解工作区和暂存区的概念，并通过例子加强<code>git status</code> 、<code>git add</code>、<code>git commit</code>的理解</p><p>如果不用<code>git add</code>到暂存区，那就不会加入到<code>commit</code>中。也就是说<code>commit</code>只会提交暂存区里的内容</p><h3 id="撤销修改">撤销修改</h3><h4 id="在工作区撤销修改">在工作区撤销修改</h4><p>在工作区写的内容想要撤销，当然可以手动删除。同时还有另外的一种方法</p><p><code>git status</code> 查看一下状态</p><p><img src="https://i.loli.net/2020/09/01/qT7BN95PkQeSumd.jpg" alt="img"></p><p>根据git提示，可以知道如下信息：</p><ol type="1"><li><code>changes not staged for commit</code>：表示没有更改添加到暂存区，也就是对于当前的修改还没有进行<code>add</code>操作</li></ol><p><img src="https://i.loli.net/2020/09/01/NfZ2vXuB4etLHxF.jpg" alt="img"></p><ol start="2" type="1"><li><p>可以看到修改的部分是<code>2020-08-31-git 进阶.md</code>文件，不能显示中文，所以用编码表示</p></li><li><p>同时<code>next</code>文件也做了修改。这个每次都有提示，猜想应该是因为next是我<code>clone</code>下来的文件，所以存在<code>.git</code>文件，将<code>.git</code>文件删除就ok了</p></li><li><p>提示显示，<code>git checkout -- file</code>可以丢弃工作区（work directory）的修改</p></li></ol><h5 id="git-checkout----file">git checkout -- file</h5><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git checkout -- <span class="built_in">source</span>/_posts/2020-08-31-git进阶.md （注意--不要遗漏，同时后面有一个空格）</span><br><span class="line"><span class="comment"># git checkout -- .  这种写法也是可以的，表示全部撤销</span></span><br></pre></td></tr></tbody></table></figure><p>命令<code>git checkout -- filename</code>意思就是，把<code>filename</code>文件在工作区的修改全部撤销，这里有两种情况：</p><ul><li>一种是文件自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态；</li><li>一种是文件已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。</li></ul><p>总之，就是让这个文件回到最近一次<code>git commit</code>或<code>git add</code>时的状态。</p><p><code>git checkout</code>其实是<strong>用版本库里的版本替换工作区的版本</strong>，无论工作区是修改还是删除，都可以“一键还原”。</p><h5 id="注">注</h5><ul><li>文件必须写当前git bash 下的完整路径，可以参考<code>git status</code>下的modified部分路径名称，如上的<code>source/_posts/</code></li><li>文件名必须写中文（就是正常的文件名），不能按照modified部分的编码后的名称</li></ul><p><img src="https://i.loli.net/2020/09/01/2l6Nxsh14bdpAY8.jpg" alt="img"></p><p>这是错误过程，可以看到最后一次没有提示，表示成功撤销修改</p><p>打开git进阶文件可以看到内容已经撤销</p><h4 id="添加到暂存区后的撤销">添加到暂存区后的撤销</h4><p>如果在工作区已经修改，并且添加到暂存区了，在<code>commit</code>之前，发现了这个问题。用<code>git status</code>查看一下，修改只是添加到了暂存区，还没有提交：</p><p><img src="https://i.loli.net/2020/09/01/CIASBwaTMEY3Gh1.png" alt="添加到暂存区前"></p><p><img src="https://i.loli.net/2020/09/01/T8jefu37XvFnZMJ.png" alt="添加到暂存区后"></p><ul><li>在添加到暂存区后，可以看到在<code>changes to be committed</code> 部分，添加的部分已经变成绿色，等待被<code>commit</code>提交</li><li>根据git提示，用命令<code>git reset HEAD &lt;file&gt;</code>可以把暂存区的修改撤销掉（<code>unstage</code>），重新放回工作区：</li></ul><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset HEAD .</span><br></pre></td></tr></tbody></table></figure><blockquote><p><code>git reset</code>命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用<code>HEAD</code>时，表示最新的版本。</p></blockquote><p>撤销到工作区的内容可以根据上述内容撤销其修改</p><h4 id="提交到版本库后的撤销">提交到版本库后的撤销</h4><p>前提是<strong>还没有把自己的本地版本库推送到远程</strong>。</p><p>可以利用上述的<code>版本回退</code>功能</p><h4 id="小结-3">小结</h4><ul><li>场景1：当你改乱了<code>工作区</code>某个文件的内容，想直接丢弃工作区的修改时，用命令<code>git checkout -- file</code>。</li><li>场景2：当你不但改乱了工作区某个文件的内容，还<code>添加到了暂存区</code>时，想丢弃修改，分两步，第一步用命令<code>git reset HEAD &lt;file&gt;</code>，就回到了场景1，第二步按场景1操作，用命令<code>git checkout -- file</code>。</li><li>场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考<code>版本回退</code>，不过前提是没有推送到远程库。</li></ul><h3 id="远程仓库">远程仓库</h3><h4 id="section"></h4><p>已经在本地创建了一个Git仓库后，又想在GitHub创建一个Git仓库，并且让这两个仓库进行远程同步，这样，GitHub上的仓库既可以作为备份，又可以让其他人通过该仓库来协作。</p><p>首先，登陆GitHub，然后，在右上角找到“Create a new repo”按钮，创建一个新的仓库</p><p>在Repository name填入<code>shijian</code>，其他保持默认设置，点击“Create repository”按钮，就成功地创建了一个新的Git仓库。出现以下界面：</p><p><img src="https://i.loli.net/2020/09/01/vMnFmb9aQU6xuXp.png" alt="image-20200901142716798"></p><p>复制仓库的SSH链接</p><p>根据提示，可以返回到需要上传的文件夹目录下，右键选择<code>git bash</code></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git init  <span class="comment">#创建.git隐藏文件，用于本地仓库</span></span><br><span class="line"></span><br><span class="line">git remote add origin git@github.com:OopsAaron/shijian.git <span class="comment">#关联本地仓库和github远程仓库</span></span><br></pre></td></tr></tbody></table></figure><p>添加后，<strong>远程库的名字就是<code>origin</code></strong>，这是Git默认的叫法，也可以改成别的，但是<code>origin</code>这个名字一看就知道是远程库。</p><p>接下来就是git的基本三样操作，添加提交并推送</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">git add . <span class="comment">#添加当前文件夹下的所有文件</span></span><br><span class="line"></span><br><span class="line">git commit -m <span class="string">"first commit "</span> <span class="comment"># 引号内是本次的提交说明 </span></span><br><span class="line"></span><br><span class="line">git push -u origin master <span class="comment"># 提交本地分支到远程分支</span></span><br><span class="line">(若出现failed to push som refs to， 则执行git pull origin master，</span><br><span class="line">将远程服务器github上的master拉下来，再重新push)</span><br></pre></td></tr></tbody></table></figure><p>把本地库的内容推送到远程，用<code>git push</code>命令，实际上是把当前分支<code>master</code>推送到远程。这时候在github界面就可以看到推送的文件</p><blockquote><p>第一次push的时候可以添加参数 <code>-u</code> ，之后可以不添加</p><p>由于远程库是空的，我们第一次推送<code>master</code>分支时，加上了<code>-u</code>参数，Git不但会把本地的<code>master</code>分支内容推送的远程新的<code>master</code>分支，还会把本地的<code>master</code>分支和远程的<code>master</code>分支关联起来，在以后的推送或者拉取时就可以简化命令。</p></blockquote><h4 id="section-1"></h4><h3 id="分支">分支</h3><p>分支暂时用不到，就没有学习</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      不断更新 ，在实践中总结git知识点。
    
    </summary>
    
    
      <category term="git" scheme="http://yoursite.com/categories/git/"/>
    
    
      <category term="git" scheme="http://yoursite.com/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-30-阅读论文</title>
    <link href="http://yoursite.com/2020/08/30/2020-08-30-%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87/"/>
    <id>http://yoursite.com/2020/08/30/2020-08-30-%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87/</id>
    <published>2020-08-30T07:11:28.000Z</published>
    <updated>2020-09-05T06:42:17.124Z</updated>
    
    <content type="html"><![CDATA[<p>一篇论文至少要看三遍。 第一遍，仔细阅读论文中的标题、摘要和关键词。 第二遍，阅读文中的导言、结论以及图表，快速扫描一下论文剩下的内容。 这一步主要是要把握论文中的关键信息，不光是导言和结论，还包括文章中任何小结论的总 结，文中涉及的补充信息都跳过。 第三遍，阅读论文的整个部分，但是要跳过任何可能陌生看不懂的数学公式，技术术语。</p><p>不过，如果你需要对这个专业领域有一个「深入」的理解，那就必须要搞懂那些公式术语 了。</p><blockquote><p>参考</p><p><a href="https://mp.weixin.qq.com/s?__biz=MzA5ODEzMjIyMA==&amp;mid=2247501483&amp;idx=1&amp;sn=9b21f8e62fa2b4b33045900a1e721d30&amp;chksm=9094cf38a7e3462ed5901bd8b0b8ebf99a892b31d75aa6eaf8b3c8cc7698b1d708fd0891ab3e&amp;mpshare=1&amp;scene=1&amp;srcid=08304BRBOlTyXb4qDBM5SGTj&amp;sharer_sharetime=1598771438122&amp;sharer_shareid=2c9f868695c34cf5ff5f7a42eab3d2ed&amp;key=9b9af4fa8e2c96d71311b901f9c755ada338c70880cf596dfe4bc2b5ca69cfb094a0a310cf713fb50591ef0933e5f438e73110d797ab7406eeefa5dd5f4c460076a3e94537447c235df683c3eb24a048c7472ad2cdef063ec759505ebb6902987eb9a08ca55be656525ace69f39c8cdbedf7f2b71fa3d2c7c2c4b0dd2e660589&amp;ascene=1&amp;uin=ODEyNzQwMTM5&amp;devicetype=Windows+10+x64&amp;version=62090529&amp;lang=zh_CN&amp;exportkey=A4y9BBn%2B1GAGlkX0mhK71n0%3D&amp;pass_ticket=tS9Bcx3H%2FQ34yaxv%2F0nHTttU4aZeBoKDlw2k4Zwl5JMpqZkqPjEwcrpqIlAybtka" target="_blank" rel="noopener">沈向阳：读论文的三个层次</a></p><p><a href="https://www.youtube.com/watch?v=Du7qLsToW-o&amp;t=443s" target="_blank" rel="noopener">youtube视频，沈向阳读论文</a></p><p><a href="https://mp.weixin.qq.com/s?subscene=19&amp;__biz=MzIzNjc1NzUzMw==&amp;mid=2247546863&amp;idx=2&amp;sn=275577791d4cee894bd874eedc846f88&amp;chksm=e8d0809ddfa7098b90f2d601d59c1ea11162180387dd9677a96c03e666c1b1e05f8e719d989e&amp;scene=7&amp;ascene=1&amp;devicetype=Windows+10+x64&amp;version=62090529&amp;nettype=cmnet&amp;abtest_cookie=AAACAA%3D%3D&amp;lang=zh_CN&amp;exportkey=Ax%2BhWVV2Xr753%2BtDF%2BAIKRw%3D&amp;pass_ticket=sT%2F05g2Sqp72CoAfTsiZ8TDrxTKg0f%2FTh968brMSrSyOqE%2F1GuTq0PTOveYYBqof&amp;wx_header=0&amp;key=573aef4c1f9b4b5fc4e631a99eb0547e4182bf3ee5dd048cf4487f739b93c9b004f67e751713dea6880a5a922c03ceb30730558ff6be83d973abec53f6fb592491c98a1e205921d9c380c59d6f30c92ea2b1836956318f54b99e962b4d620a7ca074f2e317b259e495570360cc981c43758194fb5e38587a176b8af431cca351&amp;uin=ODEyNzQwMTM5" target="_blank" rel="noopener">吴恩达教你如何读论文：绘制进度表格，论文至少看三遍，还要问自己问题</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      阅读沈向阳教授的《读论文的三个层次》总结
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-08-27-edge还原到旧版本问题</title>
    <link href="http://yoursite.com/2020/08/27/2020-08-27-edge%E8%BF%98%E5%8E%9F%E5%88%B0%E6%97%A7%E7%89%88%E6%9C%AC%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2020/08/27/2020-08-27-edge%E8%BF%98%E5%8E%9F%E5%88%B0%E6%97%A7%E7%89%88%E6%9C%AC%E9%97%AE%E9%A2%98/</id>
    <published>2020-08-27T02:06:02.000Z</published>
    <updated>2020-09-04T07:00:20.595Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言">前言</h3><p>win10自动更新edge，但是新版的edge用的是Chromium内核，新功能添加不少，也全部支持chrome的插件，但是对pdf的支持不友好，和chrome一个德行<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f611.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f611.png?v8">😑</span>。导致我在旧版本edge阅读论文时做的笔记在新版edge体验感极差，于是想着回退到旧版本 （edge不就是用来阅读论文的 ）<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8">😆</span></p><h3 id="版本回退">版本回退</h3><p>百度后发现将新版本的edge删除，就可以自己回退到旧版本的edge</p><p>geek<code>强制删除</code>新版edge之后，系统回退到旧版edge了。但是同时发现原来的一些设置消失了，系统不太稳定，可能是强制删除了一些系统配置文件。不太清楚具体原因，待解决</p><p>导致如下两个功能消失</p><ul><li>在开始栏中不显示安装的软件</li><li>在文件夹右键不能使用<code>发送到</code>功能</li></ul><p>目前发现这两个不能使用的功能。可能还存在其它故障。平时经常通过<code>开始栏</code>打开软件，不显示之后有点麻烦</p><h3 id="解决">解决</h3><p>用<code>listary</code>软件快速搜索软件名称，（双击ctrl键打开搜索框），然后添加到Rolan中，如图所示</p><p><img src="https://i.loli.net/2020/09/04/Kbk3ERwsMJ9AhlP.png" alt="image-20200904145340602" style="zoom:80%;"></p><h3 id="小结">小结</h3><ul><li>下次还是少用geek强制删除吧，乖乖在<code>程序与功能</code>中卸载删除吧，有可能涉及系统配置文件的就不要轻易删除</li><li>等待新版edge友好支持论文阅读</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      edge还原到旧版本出现的问题
    
    </summary>
    
    
    
      <category term="故障排除" scheme="http://yoursite.com/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-25-chrome插件</title>
    <link href="http://yoursite.com/2020/08/25/2020-08-25-chrome%E6%8F%92%E4%BB%B6/"/>
    <id>http://yoursite.com/2020/08/25/2020-08-25-chrome%E6%8F%92%E4%BB%B6/</id>
    <published>2020-08-25T12:21:35.000Z</published>
    <updated>2020-08-31T12:16:47.636Z</updated>
    
    <content type="html"><![CDATA[<h3 id="下载提速"><strong>下载提速</strong></h3><ul><li><h4 id="使用场景"><strong>使用场景</strong></h4></li></ul><p>Chrome的下载速度，有时候确实是慢得可以跟某网盘相媲美了，甚至赶不上某些国产浏览器。</p><p>这是因为，Google为了兼容所有的电脑性能和带宽，在Chrome中采取的是保守<strong>单线程下载机制</strong>，这就导致很多时候下载速度非常慢了。</p><p><img src="https://i.loli.net/2020/08/25/5ZMgPIUfc2YndtE.png" alt="img"></p><p>不过，很多人都不知道的是，Chrome其实也是自带多线程下载功能的。所谓多线程下载，就是可以同时对资源建立多个连接，提升下载速度。</p><p>只是这个功能是默认关闭的，需要用户手动去开启。</p><ul><li><h4 id="使用方法"><strong>使用方法</strong></h4></li></ul><p>在浏览器地址栏输入以下网址并回车：</p><p><strong>chrome://flags/#enable-parallel-downloading</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D1XlU0QfU3GnNfPmPtO4D3rncDTK3kFcCxQMtjnyMUqI5hTIZydfXEDTnp06YjKEBIbdlnvUoFj3ht3ibXUatiaw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img"></p><p>在Parallel downloading的后面选项里，把「default」改为「Enabled」，并按照提示重启浏览器。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D1XlU0QfU3GnNfPmPtO4D3rncDTK3kFcYca3x5SEBJpOky2icdUADwP04jUYiaib6WvUQZ9XlSNHdeiach2RMydRGg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img"></p><p>这样就可以开启多线程下载了，经过实际测试，下载速度至少提高了三倍左右（也有可能下载速度飙升一段时间又跌回去）。</p><h3 id="link-to-text-fragment">Link to Text Fragment</h3><p>实际上就是带锚点功能的网页分享工具。</p><p>所谓锚文本，简单来说就像是关键词的定位，将关键字指向指向另一个页面的链接就是锚文本。这个工具则可以让你将网页上选中的文本片段生成为一个锚文本。</p><p><strong>当你点击这个锚文本时，就会直接跳转到该网页对应标记的锚点上了。</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D1XlU0QfU3FtLAG0sobAP0xrYk6LJk6m3AU0icjVgSjiavYp3msxibjM7D9U6PXFbzm4wUeZ6OkaFibhPXLFeIBLOQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img"></p><h4 id="使用方法-1"><strong>使用方法</strong></h4><h5 id="生成锚文本"><strong>生成锚文本</strong></h5><p>鼠标划词选中文本，在右键菜单中选择【Copy Link to Text Fragment】，然后可以看到该文本被黄色标记。</p><p><img src="https://i.loli.net/2020/08/25/ns29PiDENtvJp3R.gif" alt="img"></p><h5 id="打开锚文本"><strong>打开锚文本</strong></h5><p>此时，锚文本已经自动生成并复制到你的剪贴板上，你可以将它发送给需要分享的好友，或者在浏览器中打开，另存为书签。</p><p>可以看到，在浏览器内打开这个锚文本，网页会自动定位到我们做了锚点的文本部分，再也不需要我们自行阅读查找，非常方便。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/D1XlU0QfU3FtLAG0sobAP0xrYk6LJk6m5F5vhCQoN8IeaxDibdMzqk2jFVjhDDhGMJdY3ZHpibCicN5yWbsRoN9Bg/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt="img"></p><p>需要注意的是，这个锚文本也<strong>仅限在安装了Link to Text Fragment插件的浏览器上打开</strong>，若没有安装则不会跳转对应位置。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录用到的chrome插件
    
    </summary>
    
    
      <category term="chrome" scheme="http://yoursite.com/categories/chrome/"/>
    
    
      <category term="chrome" scheme="http://yoursite.com/tags/chrome/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-23-google搜索的高效使用</title>
    <link href="http://yoursite.com/2020/08/23/2020-08-23-google%E6%90%9C%E7%B4%A2%E7%9A%84%E9%AB%98%E6%95%88%E4%BD%BF%E7%94%A8/"/>
    <id>http://yoursite.com/2020/08/23/2020-08-23-google%E6%90%9C%E7%B4%A2%E7%9A%84%E9%AB%98%E6%95%88%E4%BD%BF%E7%94%A8/</id>
    <published>2020-08-23T09:04:44.000Z</published>
    <updated>2020-08-24T11:51:36.784Z</updated>
    
    <content type="html"><![CDATA[<h3 id="section">“”</h3><p>以整个短语作为搜索关键词，而不是拆开成每个词。</p><p>表示完全匹配，结果中必须出现与搜索文本完全相同的内容。</p><h3 id="a--b">A -B</h3><p>搜索包含A但不包含B的结果（请注意A后面的<strong>空格不能省略</strong>）</p><p><img src="https://i.loli.net/2020/08/23/pjDWIreKGtJU7Oa.png" alt="image-20200823173525379" style="zoom: 67%;"></p><p>当加上 <code>-poweredge</code> 时，就可以屏蔽掉机架式服务器关键字中所有含有poweredge的内容</p><p><img src="https://i.loli.net/2020/08/23/k2vbVtdCMBYzJfQ.png" alt="image-20200823173614387" style="zoom:67%;"></p><h3 id="filetype">filetype</h3><p>搜索对应类型的文件。例如：<code>时间简史 filetype:pdf</code>，即为搜索包含关键字时间简史的pdf文件。（请注意<strong>使用英文的冒号</strong>） （一般不加filetype也可以）</p><p><img src="https://i.loli.net/2020/08/23/UBJHv4YmfiGRhuy.png" alt="image-20200823174000514" style="zoom:67%;"></p><h3 id="site">site</h3><p>在某个网站内搜索，比如：site:<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com">http://pan.baidu.com</a> 特别好用，用来搜百度云里的资源。再如：</p><p>在我们实验室网站查找<code>招生</code>关键字，则 <code>招生 site:http://www.ubinec.org/</code>，十分便捷。</p><p>（直接招生 site:ubinec.org/ 也可以 ，中间不要加空格 ）</p><p><img src="https://i.loli.net/2020/08/24/aypbHTDAnF79CIi.png" alt="image-20200824160653772" style="zoom:67%;"></p><h3 id="section-1">*</h3><p>很多时候想搜一个东西但是不确定具体名字，可以用星号代替忘了的字，可以代替多个字</p><h3 id="define">define</h3><p><strong>当字典或快速查找意思</strong>，如[define:right]，还能看到单词在书籍中出现频率的年代变化，词源等；</p><p><img src="https://i.loli.net/2020/08/24/skUBwAFtVMm6OWJ.png" alt="image-20200824162755266" style="zoom:67%;"></p><h3 id="section-2">~</h3><p>同时搜索近义词。如搜“higher education” 和 “university”</p><h3 id="or-或逻辑">OR (或)逻辑</h3><p>通过<em>OR</em> 搜索, 可以得到和两个关键词分别相关的结果, 而不仅仅是和两个关键词都同时相关的结果.</p><p><img src="E:\myBlog\source\_posts\image-20200824193744947.png" alt="image-20200824193744947" style="zoom:67%;"></p><p><img src="E:\myBlog\source\_posts\image-20200824193731306.png" alt="image-20200824193731306" style="zoom:67%;"></p><h3 id="限定年份">限定年份</h3><ol type="1"><li>在google工具选项中可以选择时间</li></ol><p><img src="E:\myBlog\source\_posts\image-20200824194504266.png" alt="image-20200824194504266" style="zoom:67%;"></p><ol start="2" type="1"><li><code>世界杯 2010..2014</code></li></ol><h3 id="参考">参考</h3><p><img src="https://i.loli.net/2020/08/24/uqRyUOdYnGJbxHN.jpg" alt="preview"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      高效利用google搜索，记录使用技巧
    
    </summary>
    
    
    
  </entry>
  
</feed>
