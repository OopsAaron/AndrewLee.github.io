<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>æ€å»ºçš„NLPä¹‹æ—…</title>
  
  <subtitle>æ²‰æ·€è‡ªå·±</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-08-13T16:08:43.796Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>ææ€å»º</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>2020-08-14-è§£è¯»å¡å°”æ›¼æ»¤æ³¢</title>
    <link href="http://yoursite.com/2020/08/14/2020-08-14-%E8%A7%A3%E8%AF%BB%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2/"/>
    <id>http://yoursite.com/2020/08/14/2020-08-14-%E8%A7%A3%E8%AF%BB%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2/</id>
    <published>2020-08-13T16:03:56.000Z</published>
    <updated>2020-08-13T16:08:43.796Z</updated>
    
    <content type="html"><![CDATA[<script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      å¯¹å¡å°”æ›¼æ»¤æ³¢çŸ¥è¯†ç‚¹çš„æ€»ç»“
    
    </summary>
    
    
      <category term="ç ”ç©¶æ–¹å‘" scheme="http://yoursite.com/categories/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91/"/>
    
    
      <category term="å¡å°”æ›¼æ»¤æ³¢" scheme="http://yoursite.com/tags/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2/"/>
    
      <category term="RKN" scheme="http://yoursite.com/tags/RKN/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-12-æ›´æ¢hexoæ¸²æŸ“å™¨æ”¯æŒLatex</title>
    <link href="http://yoursite.com/2020/08/12/2020-08-12-%E6%9B%B4%E6%8D%A2hexo%E6%B8%B2%E6%9F%93%E5%99%A8%E6%94%AF%E6%8C%81Latex/"/>
    <id>http://yoursite.com/2020/08/12/2020-08-12-%E6%9B%B4%E6%8D%A2hexo%E6%B8%B2%E6%9F%93%E5%99%A8%E6%94%AF%E6%8C%81Latex/</id>
    <published>2020-08-12T15:44:37.000Z</published>
    <updated>2020-08-12T16:41:07.645Z</updated>
    
    <content type="html"><![CDATA[<h3 id="å‰è¨€">å‰è¨€</h3><blockquote><p><code>LATEX</code> æ˜¯ä¸€ç§åŸºäº <code>TEX</code> çš„æ’ç‰ˆç³»ç»Ÿï¼Œåˆ©ç”¨è¿™ç§æ ¼å¼ï¼Œå¯ä»¥è¿…é€Ÿç”Ÿæˆå¤æ‚è¡¨æ ¼å’Œæ•°å­¦å…¬å¼ç­‰ï¼Œå¯¹äºæˆ‘ä»¬å†™åšå®¢å¸®åŠ©ååˆ†å¤§ã€‚</p></blockquote><h3 id="åˆçº§">åˆçº§</h3><h4 id="ç‰ˆæœ¬">ç‰ˆæœ¬</h4><p>æˆ‘ä½¿ç”¨çš„æ˜¯hexo + Next ï¼Œç‰ˆæœ¬å·å¦‚ä¸‹ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Hexo: <span class="number">4.2</span><span class="number">.1</span>  <span class="comment">#åœ¨ ~\package.jsonä¸­æŸ¥çœ‹</span></span><br><span class="line">NexT: <span class="number">7.8</span><span class="number">.0</span>  <span class="comment"># åœ¨~\themes\next\package.jsonä¸­æŸ¥çœ‹</span></span><br></pre></td></tr></tbody></table></figure><h4 id="mathjax-æ’ä»¶">MathJax æ’ä»¶</h4><p>æ¸²æŸ“æ•°å­¦å…¬å¼éœ€è¦MathJaxæ’ä»¶ï¼Œæœ‰äº› Hexo ä¸»é¢˜è‡ªå¸¦ MathJax æ’ä»¶ï¼Œä¾‹å¦‚ <a href="http://theme-next.iissnan.com/" target="_blank" rel="noopener">NexT</a>åªéœ€å¯ç”¨è¯¥æ’ä»¶å³å¯</p><p>å¦‚æœæ²¡æœ‰çš„è¯ï¼Œå¯ä»¥æ‰‹åŠ¨å®‰è£…ï¼š</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-math --save</span><br></pre></td></tr></tbody></table></figure><h4 id="å¯ç”¨">å¯ç”¨</h4><p>NexT ä¸»é¢˜çš„ MathJax æ’ä»¶é»˜è®¤æ˜¯ç¦ç”¨çš„ï¼Œæ‰“å¼€ä¸»é¢˜é…ç½®æ–‡ä»¶ï¼Œå°†<code>mathjax</code>çš„<code>enable</code> çš„å€¼æ”¹ä¸º <code>true</code> å³å¯å¯ç”¨ <code>MathJax</code></p><p>æ³¨æ„ <code>per_page</code> ä¸Šé¢çš„æ³¨é‡Šï¼Œæ³¨é‡Šè¡¨æ˜äº†ï¼ŒMathJax åªæ¸²æŸ“åœ¨æ–‡ä»¶å‰ç«¯æ³¨æ˜ <code>mathjax: true</code> å­—æ®µçš„æ–‡ç« ï¼Œ</p><p>æ‰€ä»¥ä¸ºäº†ä»¥ååœ¨æ¯ä¸€ä¸ªæ–°å»ºçš„æ–‡ä»¶éƒ½é»˜è®¤å¸¦æœ‰<code>mathjax: true</code> ï¼Œå¯ä»¥åœ¨<code>~\scaffolds\post.md</code>ä¸­ä¿®æ”¹æ–‡ç« å¤´éƒ¨ï¼Œæ·»åŠ <code>mathjax: true</code> å³å¯</p><h4 id="æ•ˆæœ">æ•ˆæœ</h4><p>è¡Œå†…å…¬å¼ï¼š</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">è¿™æ˜¯ä¸€ä¸ªè¡Œå†…å…¬å¼ï¼š$sin^2\theta + cos^2\theta = 1$</span><br></pre></td></tr></tbody></table></figure><p>æ•ˆæœï¼š</p><p>è¿™æ˜¯ä¸€ä¸ªè¡Œå†…å…¬å¼ï¼š<span class="math inline">\(sin^2\theta + cos^2\theta = 1\)</span></p><p>æ•´è¡Œå…¬å¼ï¼š</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$$sin^2\theta + cos^2\theta = 1$$</span><br></pre></td></tr></tbody></table></figure><p>æ•ˆæœï¼š</p><p><span class="math display">\[sin^2\theta + cos^2\theta = 1\]</span></p><h4 id="è·å–latexå…¬å¼mathpix-snipping-tool">è·å–Latexå…¬å¼ï¼šMathpix Snipping Tool</h4><p>å¦‚æœè¦å†™Latexå…¬å¼çš„è¯ï¼Œéœ€è¦æŒæ¡å¾ˆå¤šLatexè¯­æ³•ï¼Œæ“ä½œèµ·æ¥æ¯”è¾ƒéº»çƒ¦ï¼Œå­¦ä¹ æˆæœ¬ä¹Ÿé«˜ã€‚å†åŠ ä¸Šå¹³æ—¶æˆ‘éƒ½æ˜¯ç›´æ¥copyæ‰€è¯»è®ºæ–‡ä¸­çš„å…¬å¼ï¼Œäºæ˜¯æˆ‘ä½¿ç”¨äº†<code>Mathpix Snipping Tool</code> è½¯ä»¶ã€‚</p><p><code>Mathpix Snipping Tool</code> ï¼š é€šè¿‡å¯¹æ‰€è¦è·å–çš„å…¬å¼è¿›è¡Œæˆªå›¾ï¼Œå¯ä»¥å¾—åˆ°å…¬å¼çš„Latexè¡¨è¾¾å½¢å¼ï¼Œå¤åˆ¶åˆ°åšå®¢ä¸­å³å¯ã€‚æ“ä½œç®€å•é«˜æ•ˆã€‚ä½¿ç”¨æ–¹æ³•ä¸å†èµ˜è¿°ï¼Œç½‘ä¸Šèµ„æºå¾ˆå¤šã€‚</p><h3 id="é«˜çº§">é«˜çº§</h3><h4 id="å±æ¸²æŸ“å¤æ‚latexæ•°å­¦å…¬å¼å‡ºç°é—®é¢˜">å±ï¼šæ¸²æŸ“å¤æ‚LaTeXæ•°å­¦å…¬å¼å‡ºç°é—®é¢˜</h4><p>å‘ç°ä¸€ä¸ªé—®é¢˜å°±æ˜¯ç¼–è¾‘å¥½çš„LaTexå…¬å¼å¯ä»¥åœ¨ Markdown ç¼–è¾‘å™¨ï¼ˆTyporaï¼‰ä¸­æ˜¾ç¤ºå‡ºæ¥ï¼Œä½†éƒ¨ç½²ä¹‹åï¼Œå…¬å¼å‡ºç°æ— æ³•è¢«æ¸²æŸ“</p><p>ä¹‹åé€šè¿‡Googleä¹‹åï¼Œå‘ç°é—®é¢˜çš„ä¸€äº›æºå¤´</p><blockquote><p>å°†<code>MathJax</code>æ”¹ä¸ºtrueåå‘ç°ï¼Œ<strong>åªèƒ½æ¸²æŸ“éƒ¨åˆ†ç®€å•çš„å…¬å¼</strong>ï¼Œå¯¹äºç¨å¾®å¤æ‚ä¸€ç‚¹çš„ï¼Œç‰¹åˆ«æ˜¯æœ‰ä¸‹åˆ’çº¿ ' _ ' ç¬¦å·çš„å…¬å¼ï¼Œå‡ ä¹éƒ½æ— æ³•è¢«æ¸²æŸ“ã€‚</p><p>hexoé»˜è®¤ä½¿ç”¨marked.jså»è§£ææˆ‘ä»¬å†™çš„markdownï¼Œæ¯”å¦‚ä¸€äº›ç¬¦å·ï¼Œ_ä»£è¡¨æ–œä½“ï¼Œä¼šè¢«å¤„ç†ä¸º*æ ‡ç­¾ï¼Œæ¯”å¦‚x_iåœ¨å¼€å§‹è¢«æ¸²æŸ“çš„æ—¶å€™ï¼Œå¤„ç†ä¸ºxiï¼Œæ¯”å¦‚__init__ä¼šè¢«å¤„ç†æˆ<strong>initã€‚</strong>*</p><p>Hexo å¯¹ Markdown æ–‡ä»¶çš„å¤„ç†å®é™…ä¸Šåˆ†ä¸ºä¸¤ä¸ªæ­¥éª¤ï¼š</p><ol type="1"><li>Hexo ä¸­çš„ Markdown å¼•æ“æŠŠ Markdown å˜ä¸º html æ–‡ä»¶</li><li>MathJax è´Ÿè´£è§£é‡Š html çš„æ•°å­¦å…¬å¼</li></ol></blockquote><p>æ‰€ä»¥ç°æœ‰çš„hexoæ¸²æŸ“å™¨æ˜¯æ— æ³•è§£å†³å½“å‰çš„é—®é¢˜ï¼Œæ‰€ä»¥å°±è¦æ›´æ¢æ¸²æŸ“å™¨</p><h4 id="ä¸‹è½½pandoc">ä¸‹è½½pandoc</h4><p>æ‰“å¼€powershellï¼Œè¾“å…¥ä»¥ä¸‹å‘½ä»¤è¡Œ</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install Pandoc</span><br></pre></td></tr></tbody></table></figure><h4 id="å®‰è£…-hexo-renderer-pandoc">å®‰è£… hexo-renderer-pandoc</h4><p>åœ¨blogæ–‡ä»¶å¤¹ä¸‹æ‰“å¼€git bash</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-renderer-marked --save #å¸è½½æ—§ç‰ˆæœ¬</span><br><span class="line"><span class="meta">#</span><span class="bash">å› ä¸ºä¹‹å‰ä¸ºäº†æ”¯æŒemojiï¼Œæˆ‘å·²ç»å°†hexo-renderer-markedæ¢æˆäº†hexo-renderer-markdown-itï¼Œæ‰€ä»¥æˆ‘å¸è½½åè€…</span></span><br><span class="line">npm install hexo-renderer-pandoc --save #å®‰è£…æ–°ç‰ˆæœ¬</span><br></pre></td></tr></tbody></table></figure><h4 id="æ›´æ–°éƒ¨ç½²">æ›´æ–°éƒ¨ç½²</h4><p>å¯ä»¥çœ‹åˆ°å¯¹äºå¤æ‚çš„å…¬å¼ä¹Ÿæ˜¯æ”¯æŒçš„~</p><figure><img src="https://i.loli.net/2020/08/13/cXzadkQeCvAIwfB.png" alt="image-20200813003737055"><figcaption>image-20200813003737055</figcaption></figure><h3 id="æ³¨æ„äº‹é¡¹">æ³¨æ„äº‹é¡¹</h3><p>å¦‚æœä½ ä½¿ç”¨è¿™æ¬¾ Pandoc rendererï¼Œé‚£ä¹ˆä¹¦å†™ Markdown æ—¶å€™éœ€è¦éµå¾ª <a href="https://pandoc.org/MANUAL.html#pandocs-markdown" target="_blank" rel="noopener">Pandoc å¯¹ Markdown çš„è§„å®š</a>ã€‚</p><p>æœ‰ä¸€äº›æ¯”è¾ƒæ˜æ˜¾çš„éœ€è¦æ³¨æ„çš„äº‹é¡¹ï¼šæ­£å¸¸çš„æ–‡å­—åé¢å¦‚æœè·Ÿçš„æ˜¯<a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#lists" target="_blank" rel="noopener"><code>list</code></a>, <a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#tables" target="_blank" rel="noopener"><code>table</code></a>æˆ–è€…<a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#blockquotes" target="_blank" rel="noopener"><code>quotation</code></a>ï¼Œæ–‡å­—åé¢éœ€è¦ç©ºä¸€è¡Œï¼Œå¦‚æœä¸ç©ºè¡Œï¼Œè¿™äº›ç¯å¢ƒå°†ä¸èƒ½è¢« Pandoc renderer æ­£å¸¸æ¸²æŸ“ã€‚</p><h3 id="å‚è€ƒ">å‚è€ƒ</h3><blockquote><p>Hexoæ¸²æŸ“Latexå‡ºç°çš„é—®é¢˜ï¼š https://zhuanlan.zhihu.com/p/35988761</p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      æ›´æ¢hexoæ¸²æŸ“å™¨æ”¯æŒLatex
    
    </summary>
    
    
      <category term="hexo" scheme="http://yoursite.com/categories/hexo/"/>
    
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
      <category term="Latex" scheme="http://yoursite.com/tags/Latex/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-12-hexoæ·»åŠ emojiè¡¨æƒ…</title>
    <link href="http://yoursite.com/2020/08/12/2020-08-12-hexo%E6%B7%BB%E5%8A%A0emoji%E8%A1%A8%E6%83%85/"/>
    <id>http://yoursite.com/2020/08/12/2020-08-12-hexo%E6%B7%BB%E5%8A%A0emoji%E8%A1%A8%E6%83%85/</id>
    <published>2020-08-12T09:16:54.000Z</published>
    <updated>2020-08-13T16:04:50.737Z</updated>
    
    <content type="html"><![CDATA[<h3 id="å‰è¨€">å‰è¨€</h3><p>markdownæ”¯æŒåœ¨æ–‡æœ¬ä¸­ä½¿ç”¨emojiï¼Œåœ¨Typoraä¸­å¯ä»¥å¾ˆæ–¹ä¾¿åœ°ä½¿ç”¨è¡¨æƒ…ã€‚ä¾‹å¦‚è¾“å…¥ <code>:star:</code> ,å¯ä»¥æ˜¾ç¤ºå‡º:star:è¡¨æƒ…ï¼Œå³è¡¨æƒ…çš„<code>aliases</code> ç¼–ç æ ¼å¼ã€‚ä½†æ˜¯åœ¨éƒ¨ç½²åˆ°ç½‘ç«™çš„æ—¶å€™ï¼Œ<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8">â­</span>å´æ¸²æŸ“ä¸å‡ºæ¥ï¼Œæˆ‘å¯»æ‰¾äº†å¾ˆä¹…çš„è§£å†³æ–¹æ¡ˆï¼Œç»ˆäºè§£å†³ <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8">ğŸ˜†</span></p><h3 id="æ›´æ¢hexoæ¸²æŸ“å™¨">æ›´æ¢hexoæ¸²æŸ“å™¨</h3><p>æˆ‘çš„hexoç‰ˆæœ¬æ˜¯version 4.2.1, å¯ä»¥åœ¨åœ¨æ ¹ç›®å½•ä¸‹ packge.json æ–‡ä»¶é‡Œé¢çœ‹åˆ°ä½¿ç”¨hexoåˆå§‹åŒ–çš„ç»“æœã€‚</p><p>å°†markdown å˜æˆhtmlçš„è½¬æ¢å™¨å«åš<code>markdownæ¸²æŸ“å™¨</code>.åœ¨Hexoä¸­é»˜è®¤çš„markdownæ¸²æŸ“å™¨ ä½¿ç”¨çš„æ˜¯<a href="https://github.com/hexojs/hexo-renderer-marked" target="_blank" rel="noopener">hexo-renderer-marked</a>,æ˜¯Hexoç‰ˆæœ¬ï¼Œè¿™ä¸ªæ¸²æŸ“å™¨ä¸æ”¯æŒæ’ä»¶æ‰©å±•ã€‚å¦å¤–ä¸€ä¸ª markdown æ¸²æŸ“å™¨ <a href="https://github.com/celsomiranda/hexo-renderer-markdown-it" target="_blank" rel="noopener">hexo-renderer-markdown-it</a>ï¼Œè¿™ä¸ªæ”¯æŒæ’ä»¶é…ç½®ï¼Œå¯ä»¥ä½¿ç”¨ <a href="https://github.com/markdown-it/markdown-it-emoji" target="_blank" rel="noopener">markwon-it-emoji</a>æ’ä»¶æ¥æ”¯æŒemojiã€‚</p><p>è§£å†³æ–¹æ¡ˆï¼šå°†åŸæ¥çš„ <code>marked</code> æ¸²æŸ“å™¨æ¢æˆ <code>markdown-it</code>æ¸²æŸ“å™¨ã€‚</p><h4 id="å®‰è£…æ–°çš„æ¸²æŸ“å™¨">å®‰è£…æ–°çš„æ¸²æŸ“å™¨</h4><p>é¦–å…ˆè¿›å…¥åšå®¢ç›®å½•,å¸è½½hexoé»˜è®¤çš„<code>marked</code>æ¸²æŸ“å™¨ï¼Œå®‰è£…<code>markdown-it</code>æ¸²æŸ“å™¨ï¼Œè¿è¡Œçš„å‘½ä»¤å¦‚ï¼š</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd Documents/blog</span><br><span class="line">npm un hexo-renderer-marked --save  #å¸è½½æ—§çš„æ¸²æŸ“å™¨</span><br><span class="line">npm i hexo-renderer-markdown-it --save #æš—è½¬æ–°çš„æ¸²æŸ“å™¨</span><br></pre></td></tr></tbody></table></figure><p>ä¹‹åå®‰è£…<code>markdown-it-emoji</code>æ’ä»¶ï¼š</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install markdown-it-emoji --save</span><br></pre></td></tr></tbody></table></figure><h4 id="ç¼–è¾‘ç«™ç‚¹é…ç½®æ–‡ä»¶">ç¼–è¾‘ç«™ç‚¹é…ç½®æ–‡ä»¶</h4><p>è¿™é‡Œçš„ç«™ç‚¹é…ç½®æ–‡ä»¶æ˜¯æŒ‡ä½äºåšå®¢æ ¹ç›®å½•ä¸‹çš„ <code>_config.yml</code>ï¼Œç¼–è¾‘å®ƒï¼Œç„¶ååœ¨æœ«å°¾æ·»åŠ å¦‚ä¸‹å†…å®¹ï¼š</p><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Markdown-it config</span></span><br><span class="line"><span class="comment">## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki</span></span><br><span class="line"><span class="attr">markdown:</span></span><br><span class="line">  <span class="attr">render:</span></span><br><span class="line">    <span class="attr">html:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">xhtmlOut:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">breaks:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">linkify:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">typographer:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">quotes:</span> <span class="string">'â€œâ€â€˜â€™'</span></span><br><span class="line">  <span class="attr">plugins:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-abbr</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-footnote</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-ins</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-sub</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-sup</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">markdown-it-emoji</span>  <span class="comment"># add emoji</span></span><br><span class="line">  <span class="attr">anchors:</span></span><br><span class="line">    <span class="attr">level:</span> <span class="number">2</span></span><br><span class="line">    <span class="attr">collisionSuffix:</span> <span class="string">'v'</span></span><br><span class="line">    <span class="attr">permalink:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">permalinkClass:</span> <span class="string">header-anchor</span></span><br><span class="line">    <span class="attr">permalinkSymbol:</span> <span class="string">Â¶</span></span><br></pre></td></tr></tbody></table></figure><p>ä¸Šé¢çš„æ˜¯<code>hexo-renderer-markdown-it</code>çš„æ‰€æœ‰é€‰é¡¹çš„é…ç½®ï¼Œè¯¦ç»†çš„æ¯ä¸€é¡¹é…ç½®è¯´æ˜ï¼Œéœ€è¦åˆ°<a href="https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki/Advanced-Configuration" target="_blank" rel="noopener">Advanced Configuration</a>ä¸­æŸ¥çœ‹ã€‚</p><p>è¿™ä¸ªæ—¶å€™å°±å¯ä»¥ç”¨è¡¨æƒ…çš„<code>aliases</code> ç¼–ç æ ¼å¼å•¦</p><p>å¦‚æœè§‰å¾—è¡¨æƒ…æ¸²æŸ“çš„ä¸å¥½çœ‹ï¼Œé‚£ä¹ˆå¯ä»¥å®‰è£…<a href="https://github.com/twitter/twemoji" target="_blank" rel="noopener">twemoji</a>ï¼Œå¯¹è¡¨æƒ…è¿›è¡Œä¼˜åŒ–ã€‚ä½†æ˜¯æˆ‘å¯¹ç°åœ¨çš„æ¸²æŸ“æ„Ÿåˆ°æ»¡æ„ï¼Œå°±æ²¡æœ‰ç»§ç»­å®‰è£…ã€‚</p><h4 id="æŸ¥æ‰¾emoji">æŸ¥æ‰¾emoji</h4><p>è¡¨æƒ…çš„<code>aliases</code> ç¼–ç å¯ä»¥å‚è€ƒ<a href="https://www.webfx.com/tools/emoji-cheat-sheet/" target="_blank" rel="noopener">emoji-cheat-sheet</a>ï¼Œè¡¨æƒ…å¾ˆå…¨ï¼Œå¯ä»¥æ‰¾åˆ°æ¯ä¸ªè¡¨æƒ…çš„è¡¨ç¤ºï¼Œè¿ç”¨åˆ°è‡ªå·±çš„æ–‡ç« é‡Œ</p><h3 id="unicodeç¼–ç æ–¹æ¡ˆ">Unicodeç¼–ç æ–¹æ¡ˆ</h3><p>å¦‚æœä¸æ›´æ¢hexoæ¸²æŸ“å™¨ï¼Œé‚£ä¹ˆå¯ä»¥ä½¿ç”¨è¡¨æƒ…çš„<code>Unicode</code>è¡¨è¾¾æ–¹å¼ã€‚ä¸è¿‡ä¸æ¨èæ­¤æ–¹å¼ï¼Œæ„Ÿè§‰è¿‡äºéº»çƒ¦</p><p>è¯­æ³•ï¼š <code>&amp;#xCODE ;</code></p><p>å…¶ä¸­<code>CODE</code>æ˜¯æ¯ä¸ªè¡¨æƒ…çš„ç¼–ç æ–¹å¼ï¼Œå¯ä»¥é€šè¿‡ <a href="https://link.zhihu.com/?target=https%3A//apps.timwhitlock.info/emoji/tables/unicode%23block-4-enclosed-characters">Emoji Unicode Tables</a>æŸ¥è¯¢å¾—åˆ°</p><p><strong>ä¾‹å­ï¼š</strong> æŸ¥åˆ°äº† è¡¨æƒ…å¯¹åº”çš„ <strong>Unicode</strong> ç¼–ç ä¸º <code>U+1F34E</code>ï¼Œåˆ™ä¸æ­¤è¡¨æƒ…å¯¹åº”çš„ <code>CODE</code> ä¸º <code>1F34E</code> (èˆå¼ƒå‰é¢çš„ <strong>U+</strong>)ã€‚è¾“å…¥markdownæ–‡æ¡£å†…å³å¯</p><h3 id="åç»­">åç»­</h3><p>å› ä¸ºè¦è¯»è®ºæ–‡ï¼Œç„¶è€Œåœ¨è®ºæ–‡ä¸­ä¼šå‡ºç°å¾ˆå¤šçš„æ•°å­¦å…¬å¼ï¼Œè¿™æ—¶å€™éœ€è¦è¿ç”¨Latexï¼ŒåŸå§‹çš„hexoæ¸²æŸ“å™¨<a href="https://github.com/hexojs/hexo-renderer-marked" target="_blank" rel="noopener">hexo-renderer-marked</a>å¯¹æ¸²æŸ“ä¸äº†å…¬å¼ï¼Œåœ¨ä¸ºäº†èƒ½å¤Ÿæ·»åŠ emojiè€Œæ›´æ¢çš„æ–°æ¸²æŸ“å™¨ <a href="https://github.com/celsomiranda/hexo-renderer-markdown-it" target="_blank" rel="noopener">hexo-renderer-markdown-it</a>è¿˜æ˜¯æ— æ³•æ¸²æŸ“Latexå…¬å¼<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f610.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f610.png?v8">ğŸ˜</span></p><p>äºæ˜¯æˆ‘åˆå‡†å¤‡æ›´æ¢hexoæ¸²æŸ“å™¨ï¼Œæ¥è®©æ–°çš„æ¸²æŸ“å™¨æ”¯æŒæ•°å­¦å…¬å¼ï¼Œäºæ˜¯æˆ‘å°±æ›´æ¢äº† <a href="https://github.com/wzpan/hexo-renderer-pandoc" target="_blank" rel="noopener">hexo-renderer-pandoc</a>ï¼Œæ”¯æŒMathjaxè¯­æ³•ï¼Œååˆ†é è°±ï¼Œç„¶è€Œé—®é¢˜æ¥äº†ï¼Œé‚£å°±æ˜¯ä¸æ”¯æŒemojiäº† <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f610.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f610.png?v8">ğŸ˜</span></p><p>åœ¨æˆ‘å‡†å¤‡åœ¨ä¸¤è€…ä¸­èˆå¼ƒä¸€ä¸ªï¼Œæˆ–è€…ç”¨emojiçš„Unicodeç¼–ç æ¥ä»£æ›¿æ¸²æŸ“å™¨çš„æ—¶å€™ï¼Œæˆ‘å‘ç°äº†ä¸€ä¸ªæ’ä»¶ï¼Œå°±å°è¯•åœ¨ç°æœ‰çš„æ¸²æŸ“å™¨åŸºç¡€ä¸Šæ·»åŠ äº†ä¸€ä¸ªhexoæ’ä»¶ <a href="https://github.com/crimx/hexo-filter-github-emojis" target="_blank" rel="noopener">hexo-filter-github-emojis</a> ï¼Œå‘ç°æ­¤æ’ä»¶å¯ä»¥æœ‰æ•ˆæ”¯æŒemojiè¡¨æƒ…ï¼Œäºæ˜¯ä¸¤å…¨å…¶ç¾å•¦<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8">ğŸ˜†</span></p><hr><p>ä¸‹é¢æ˜¯æ’ä»¶çš„ä½¿ç”¨è¯´æ˜</p><h4 id="å®‰è£…æ’ä»¶">å®‰è£…æ’ä»¶</h4><p>ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£… <a href="https://github.com/crimx/hexo-filter-github-emojis" target="_blank" rel="noopener">hexo-filter-github-emojis</a> æ’ä»¶ï¼š</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-filter-github-emojis --save</span><br></pre></td></tr></tbody></table></figure><h4 id="å¯ç”¨æ’ä»¶">å¯ç”¨æ’ä»¶</h4><p>å‘ç«™ç‚¹é…ç½®æ–‡ä»¶ <code>hexo_root\_config.yml</code> ä¸­æ·»åŠ å¦‚ä¸‹è®¾ç½®ï¼š</p><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">githubEmojis:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">className:</span> <span class="string">github-emoji</span></span><br><span class="line">  <span class="attr">unicode:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">styles:</span></span><br><span class="line">    <span class="attr">display:</span> <span class="string">inline</span></span><br><span class="line">    <span class="attr">vertical-align:</span> <span class="string">middle</span> <span class="comment"># Freemindé€‚ç”¨</span></span><br><span class="line">  <span class="attr">localEmojis:</span></span><br></pre></td></tr></tbody></table></figure><p>å…·ä½“çš„æ¯ä¸ªé…ç½®é¡¹å«ä¹‰å‚è§ <a href="https://github.com/crimx/hexo-filter-github-emojis" target="_blank" rel="noopener">è¯´æ˜æ–‡æ¡£</a>ã€‚</p><h4 id="ä½¿ç”¨æ–¹æ³•">ä½¿ç”¨æ–¹æ³•</h4><p>å’Œä¸Šè¿°ä½¿ç”¨æ–¹æ³•ä¸€æ ·ï¼Œå¾ˆæ–¹ä¾¿ï¼ <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f308.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f308.png?v8">ğŸŒˆ</span></p><h3 id="å‚è€ƒ">å‚è€ƒ</h3><blockquote><p>hexoä¸­æ·»åŠ è¡¨æƒ…ï¼š https://www.cnblogs.com/fsong/p/5929773.html</p><p>hexo ä½¿ç”¨emojiï¼š https://spacefan.github.io/2018/06/30/hexo-emoji/</p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      è§£å†³hexoæ— æ³•æ¸²æŸ“emojiè¡¨æƒ…çš„é—®é¢˜
    
    </summary>
    
    
      <category term="hexo" scheme="http://yoursite.com/categories/hexo/"/>
    
    
      <category term="æ•…éšœæ’é™¤" scheme="http://yoursite.com/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4/"/>
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-12-æ–°é¡µé¢æ·»åŠ å‹é“¾</title>
    <link href="http://yoursite.com/2020/08/12/2020-08-12-%E6%96%B0%E9%A1%B5%E9%9D%A2%E6%B7%BB%E5%8A%A0%E5%8F%8B%E9%93%BE/"/>
    <id>http://yoursite.com/2020/08/12/2020-08-12-%E6%96%B0%E9%A1%B5%E9%9D%A2%E6%B7%BB%E5%8A%A0%E5%8F%8B%E9%93%BE/</id>
    <published>2020-08-12T06:19:06.000Z</published>
    <updated>2020-08-12T16:52:21.740Z</updated>
    
    <content type="html"><![CDATA[<h3 id="å‰è¨€">å‰è¨€</h3><p>NexT ä¸»é¢˜è‡ªå¸¦çš„å‹æƒ…é“¾æ¥çš„ä½ç½®æ˜¯åœ¨ä¾§æ çš„ Social Link ä¸­ï¼Œä½ç½®ä¸å¤ªæ˜æ˜¾ï¼Œè€Œä¸”å®¹é‡æ¯”è¾ƒå°ï¼Œä¸ç¾è§‚ã€‚å› æ­¤å¯ä»¥è‡ªå®šä¹‰ä¸€ä¸ªç‰¹å®šçš„é¡µé¢ï¼Œå•ç‹¬æ˜¾ç¤ºå‹æƒ…é“¾æ¥</p><h3 id="æ–°å»ºlinks.swig-æ–‡ä»¶">æ–°å»º<code>links.swig</code> æ–‡ä»¶</h3><p>é¦–å…ˆï¼Œåœ¨ <code>~/themes/next/layout/</code> ç›®å½•ä¸‹æ–°å»ºä¸€ä¸ª <code>links.swig</code> æ–‡ä»¶ï¼Œå¹¶å†™å…¥ä»¥ä¸‹å†…å®¹ï¼š</p><!-- æ‰€åœ¨ç›®å½•ï¼š~/themes/next/layout/ --><figure class="highlight html"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line">{% block content %}</span><br><span class="line">  {######################}</span><br><span class="line">  {###  LINKS BLOCK   ###}</span><br><span class="line">  {######################}</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">"links"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">style</span>&gt;</span></span><br><span class="line"><span class="css">        <span class="selector-class">.links-content</span>{</span></span><br><span class="line"><span class="css">            <span class="selector-tag">margin-top</span><span class="selector-pseudo">:1rem</span>;</span></span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line"><span class="css">        <span class="selector-class">.link-navigation</span><span class="selector-pseudo">::after</span> {</span></span><br><span class="line">            content: " ";</span><br><span class="line">            display: block;</span><br><span class="line">            clear: both;</span><br><span class="line">        }</span><br><span class="line">        </span><br><span class="line"><span class="css">        <span class="selector-class">.card</span> {</span></span><br><span class="line">            width: 240px;</span><br><span class="line">            font-size: 1rem;</span><br><span class="line">            padding: 10px 20px;</span><br><span class="line">            border-radius: 4px;</span><br><span class="line"><span class="css">            <span class="selector-tag">transition-duration</span>: 0<span class="selector-class">.15s</span>;</span></span><br><span class="line">            margin-bottom: 1rem;</span><br><span class="line"><span class="css">            <span class="selector-tag">display</span><span class="selector-pseudo">:flex</span>;</span></span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="keyword">@media</span> (<span class="attribute">max-width:</span> <span class="number">767px</span>) {</span></span><br><span class="line"><span class="css"><span class="selector-class">.card</span><span class="selector-pseudo">:nth-child(odd)</span> {</span></span><br><span class="line">                float: left;</span><br><span class="line">            }</span><br><span class="line"><span class="css">            <span class="selector-class">.card</span><span class="selector-pseudo">:nth-child(even)</span> {</span></span><br><span class="line">                float: left !important;</span><br><span class="line">            }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="css">        <span class="selector-class">.card</span><span class="selector-pseudo">:nth-child(odd)</span> {</span></span><br><span class="line">            float: left;</span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span><span class="selector-pseudo">:nth-child(even)</span> {</span></span><br><span class="line">            float: right;</span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span><span class="selector-pseudo">:hover</span> {</span></span><br><span class="line"><span class="css">            <span class="selector-tag">transform</span>: <span class="selector-tag">scale</span>(1<span class="selector-class">.1</span>);</span></span><br><span class="line"><span class="css">            <span class="selector-tag">box-shadow</span>: 0 2<span class="selector-tag">px</span> 6<span class="selector-tag">px</span> 0 <span class="selector-tag">rgba</span>(0, 0, 0, 0<span class="selector-class">.12</span>), 0 0 6<span class="selector-tag">px</span> 0 <span class="selector-tag">rgba</span>(0, 0, 0, 0<span class="selector-class">.04</span>);</span></span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span> <span class="selector-tag">a</span> {</span></span><br><span class="line"><span class="css">            <span class="selector-tag">border</span><span class="selector-pseudo">:none</span>; </span></span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span> <span class="selector-class">.ava</span> {</span></span><br><span class="line">            width: 3rem!important;</span><br><span class="line">            height: 3rem!important;</span><br><span class="line"><span class="css">            <span class="selector-tag">margin</span><span class="selector-pseudo">:0</span>!<span class="selector-tag">important</span>;</span></span><br><span class="line">            margin-right: 1em!important;</span><br><span class="line"><span class="css">            <span class="selector-tag">border-radius</span><span class="selector-pseudo">:4px</span>;</span></span><br><span class="line">            </span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span> <span class="selector-class">.card-header</span> {</span></span><br><span class="line">            font-style: italic;</span><br><span class="line">            overflow: hidden;</span><br><span class="line">            width: 100%;</span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span> <span class="selector-class">.card-header</span> <span class="selector-tag">a</span> {</span></span><br><span class="line">            font-style: normal;</span><br><span class="line"><span class="css">            <span class="selector-tag">color</span>: <span class="selector-id">#2bbc8a</span>;</span></span><br><span class="line">            font-weight: bold;</span><br><span class="line">            text-decoration: none;</span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span> <span class="selector-class">.card-header</span> <span class="selector-tag">a</span><span class="selector-pseudo">:hover</span> {</span></span><br><span class="line"><span class="css">            <span class="selector-tag">color</span>: <span class="selector-id">#a166ab</span>;</span></span><br><span class="line">            text-decoration: none;</span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-class">.card</span> <span class="selector-class">.card-header</span> <span class="selector-class">.info</span> {</span></span><br><span class="line"><span class="css">            <span class="selector-tag">font-style</span><span class="selector-pseudo">:normal</span>;</span></span><br><span class="line"><span class="css">            <span class="selector-tag">color</span>:<span class="selector-id">#a3a3a3</span>;</span></span><br><span class="line"><span class="css">            <span class="selector-tag">font-size</span><span class="selector-pseudo">:14px</span>;</span></span><br><span class="line">            min-width: 0;</span><br><span class="line">            overflow: hidden;</span><br><span class="line">            white-space: nowrap;</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line"><span class="css">        <span class="selector-tag">span</span><span class="selector-class">.focus-links</span> {</span></span><br><span class="line">            font-style: normal;</span><br><span class="line">            margin-left: 10px;</span><br><span class="line">            position: unset;</span><br><span class="line">            left: 0;</span><br><span class="line">            padding: 0 7px 0 5px;</span><br><span class="line">            font-size: 11px;</span><br><span class="line"><span class="css">            <span class="selector-tag">border-color</span>: <span class="selector-id">#42c02e</span>;</span></span><br><span class="line">            border-radius: 40px;</span><br><span class="line">            line-height: 24px;</span><br><span class="line">            height: 22px;</span><br><span class="line"><span class="css">            <span class="selector-tag">color</span>: <span class="selector-id">#fff</span> !<span class="selector-tag">important</span>;</span></span><br><span class="line"><span class="css">            <span class="selector-tag">background-color</span>: <span class="selector-id">#42c02e</span>;</span></span><br><span class="line">            display: inline-block;</span><br><span class="line">        }</span><br><span class="line"><span class="css">        <span class="selector-tag">span</span><span class="selector-class">.focus-links</span><span class="selector-pseudo">:hover</span>{</span></span><br><span class="line"><span class="css">            <span class="selector-tag">background-color</span>: <span class="selector-id">#318024</span>;</span></span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line"><span class="css">        <span class="selector-class">.friends-btn</span>{</span></span><br><span class="line">            text-align: center;</span><br><span class="line"><span class="css">            <span class="selector-tag">color</span>: <span class="selector-id">#555</span>!<span class="selector-tag">important</span>;</span></span><br><span class="line"><span class="css">            <span class="selector-tag">background-color</span>: <span class="selector-id">#fff</span>;</span></span><br><span class="line">            border-radius: 3px;</span><br><span class="line">            font-size: 15px;</span><br><span class="line"><span class="css">            <span class="selector-tag">box-shadow</span>: <span class="selector-tag">inset</span> 0 0 10<span class="selector-tag">px</span> 0 <span class="selector-tag">rgba</span>(0,0,0,<span class="selector-class">.35</span>);</span></span><br><span class="line">            border: none!important;</span><br><span class="line">            transition-property: unset;</span><br><span class="line">            padding: 0 15px;</span><br><span class="line">            margin: inherit;</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line"><span class="css">        <span class="selector-class">.friends-btn</span><span class="selector-pseudo">:hover</span>{</span></span><br><span class="line">            color: rgb(255, 255, 255) !important;</span><br><span class="line">            border-radius: 3px;</span><br><span class="line">            font-size: 15px;</span><br><span class="line"><span class="css">            <span class="selector-tag">box-shadow</span>: <span class="selector-tag">inset</span> 0<span class="selector-tag">px</span> 0<span class="selector-tag">px</span> 10<span class="selector-tag">px</span> 0<span class="selector-tag">px</span> <span class="selector-tag">rgba</span>(0, 0, 0, 0<span class="selector-class">.35</span>);</span></span><br><span class="line"><span class="css">            <span class="selector-tag">background-image</span>: <span class="selector-tag">linear-gradient</span>(90<span class="selector-tag">deg</span>, <span class="selector-id">#a166ab</span> 0%, <span class="selector-id">#ef4e7b</span> 25%, <span class="selector-id">#f37055</span> 50%, <span class="selector-id">#ef4e7b</span> 75%, <span class="selector-id">#a166ab</span> 100%);</span></span><br><span class="line">            margin: inherit;</span><br><span class="line">        }</span><br><span class="line">    <span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"links-content"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"link-navigation"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">            {% for link in theme.mylinks %}</span><br><span class="line">            </span><br><span class="line">                <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"card"</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">img</span> <span class="attr">class</span>=<span class="string">"ava"</span> <span class="attr">src</span>=<span class="string">"{{ link.avatar }}"</span>/&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"card-header"</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">div</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"{{ link.site }}"</span> <span class="attr">target</span>=<span class="string">"_blank"</span>&gt;</span> {{ link.nickname }}<span class="tag">&lt;/<span class="name">a</span>&gt;</span> <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"{{ link.site }}"</span>&gt;</span><span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"focus-links"</span>&gt;</span>å…³æ³¨<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"info"</span>&gt;</span>{{ link.info }}<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">            </span><br><span class="line">            {% endfor %}</span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">        {{ page.content }}</span><br><span class="line">        <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">     {##########################}</span><br><span class="line">  {###   END LINKS BLOCK  ###}</span><br><span class="line">  {##########################}</span><br><span class="line">{% endblock %}</span><br></pre></td></tr></tbody></table></figure><p>å¯ä»¥æ ¹æ®å–œå¥½è‡ªå·±æ›´æ”¹æ ·å¼</p><h3 id="ä¿®æ”¹page.swigæ–‡ä»¶">ä¿®æ”¹<code>page.swig</code>æ–‡ä»¶</h3><p>å°†ä»£ç è¡Œå‰<code>+</code>çš„ä»£ç æ·»åŠ åˆ°æ–‡ä»¶ä¸­</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">{% extends '_layout.swig' %}</span><br><span class="line">{% import '_macro/sidebar.swig' as sidebar_template with context %}</span><br><span class="line"></span><br><span class="line">  {% block title %}</span><br><span class="line">    {%- set page_title_suffix = ' | ' + title %}</span><br><span class="line"></span><br><span class="line">{%- if page.type === 'categories' and not page.title %}</span><br><span class="line">  {{- __('title.category') + page_title_suffix }}</span><br><span class="line">{%- elif page.type === 'tags' and not page.title %}</span><br><span class="line">  {{- __('title.tag') + page_title_suffix }}</span><br><span class="line"></span><br><span class="line">+ {%- elif page.type === 'links' and not page.title %}</span><br><span class="line">+{{- __('title.links') + page_title_suffix }}</span><br><span class="line">{%- elif page.type === 'schedule' and not page.title %}</span><br><span class="line">  {{- __('title.schedule') + page_title_suffix }}</span><br><span class="line">{%- else %}</span><br><span class="line">  {{- page.title + page_title_suffix }}</span><br><span class="line">{%- endif %}</span><br><span class="line">{% endblock %}</span><br><span class="line"></span><br><span class="line">{% block content %}</span><br><span class="line"></span><br><span class="line">  &lt;div class="posts-expand"&gt;</span><br><span class="line">    {##################}</span><br><span class="line">    {### PAGE BLOCK ###}</span><br><span class="line">    {##################}</span><br><span class="line">    &lt;div class="post-block" lang="{{ page.lang or page.language or config.language }}"&gt;</span><br><span class="line">      {% include '_partials/page/page-header.swig' %}</span><br><span class="line">      {#################}</span><br><span class="line">      {### PAGE BODY ###}</span><br><span class="line">      {#################}</span><br><span class="line">      &lt;div class="post-body{%- if page.direction and page.direction.toLowerCase() === 'rtl' %} rtl{%- endif %}"&gt;</span><br><span class="line">        {%- if page.type === 'tags' %}</span><br><span class="line">          &lt;div class="tag-cloud"&gt;</span><br><span class="line">            &lt;div class="tag-cloud-title"&gt;</span><br><span class="line">              {{ _p('counter.tag_cloud', site.tags.length) }}</span><br><span class="line">            &lt;/div&gt;</span><br><span class="line">            &lt;div class="tag-cloud-tags"&gt;</span><br><span class="line">              {{ tagcloud({min_font: theme.tagcloud.min, max_font: theme.tagcloud.max, amount: theme.tagcloud.amount, color: true, start_color: theme.tagcloud.start, end_color: theme.tagcloud.end}) }}</span><br><span class="line">            &lt;/div&gt;</span><br><span class="line">          &lt;/div&gt;</span><br><span class="line">        {% elif page.type === 'categories' %}</span><br><span class="line">          &lt;div class="category-all-page"&gt;</span><br><span class="line">            &lt;div class="category-all-title"&gt;</span><br><span class="line">              {{ _p('counter.categories', site.categories.length) }}</span><br><span class="line">            &lt;/div&gt;</span><br><span class="line">            &lt;div class="category-all"&gt;</span><br><span class="line">              {{ list_categories() }}</span><br><span class="line">            &lt;/div&gt;</span><br><span class="line">          &lt;/div&gt;</span><br><span class="line">+       {% elif page.type === 'links' %}</span><br><span class="line">+         {% include 'links.swig' %}</span><br><span class="line">        {% elif page.type === 'schedule' %}</span><br><span class="line">          &lt;div class="event-list"&gt;</span><br><span class="line">          &lt;/div&gt;</span><br><span class="line">          {% include '_scripts/pages/schedule.swig' %}</span><br><span class="line">        {% else %}</span><br><span class="line">          {{ page.content }}</span><br><span class="line">        {%- endif %}</span><br><span class="line">      &lt;/div&gt;</span><br><span class="line">      {#####################}</span><br><span class="line">      {### END PAGE BODY ###}</span><br><span class="line">      {#####################}</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">    {% include '_partials/page/breadcrumb.swig' %}</span><br><span class="line">    {######################}</span><br><span class="line">    {### END PAGE BLOCK ###}</span><br><span class="line">    {######################}</span><br><span class="line">  &lt;/div&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">{% endblock %}</span><br><span class="line"></span><br><span class="line">{% block sidebar %}</span><br><span class="line">  {{ sidebar_template.render(true) }}</span><br><span class="line">{% endblock %}</span><br></pre></td></tr></tbody></table></figure><h3 id="æ–°å»ºpageç•Œé¢">æ–°å»ºpageç•Œé¢</h3><p>æ–°å»ºåä¸ºlinksçš„pageï¼Œå…·ä½“å¯ä»¥å‚è€ƒæˆ‘çš„å¦å¤–ä¸€ç¯‡åšå®¢<a href="%5Bhttps://lisijian.cn/2020/08/08/2020-08-08-hexo%E6%96%B0%E5%BB%BApage/%5D(https://lisijian.cn/2020/08/08/2020-08-08-hexoæ–°å»ºpage/)">2020-08-08-hexoæ–°å»ºpage</a></p><p>æ³¨æ„ï¼š åœ¨<code>links</code> æ–‡ä»¶å¤¹ï¼Œæ‰“å¼€å…¶ä¸­çš„ <code>index.md</code> æ–‡ä»¶ï¼Œåœ¨æ ‡é¢˜å¤´ä¸­å†™å…¥ <code>type = "links"</code> è¿™ä¸ªå±æ€§å¤´ï¼Œå¦‚ä¸‹ï¼š</p><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">title:</span> <span class="string">å‹æƒ…é“¾æ¥</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2020</span><span class="number">-08</span><span class="number">-10</span> <span class="number">13</span><span class="string">:08:43</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">"links"</span></span><br></pre></td></tr></tbody></table></figure><h3 id="ä¿®æ”¹ä¸»é¢˜é…ç½®æ–‡ä»¶">ä¿®æ”¹ä¸»é¢˜é…ç½®æ–‡ä»¶</h3><p>åœ¨ä¸»é¢˜é…ç½®æ–‡ä»¶ <code>~/themes/next/_config.yml</code> æ–‡ä»¶ä¸­æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æ·»åŠ å‹é“¾ï¼š</p><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">mylinks:</span></span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">nickname:</span> <span class="comment"># æ˜µç§°</span></span><br><span class="line">    <span class="attr">avatar:</span> <span class="comment"># å¤´åƒåœ°å€</span></span><br><span class="line">    <span class="attr">site:</span> <span class="comment">#å‹é“¾åœ°å€</span></span><br><span class="line">    <span class="attr">info:</span> <span class="comment">#ç›¸å…³è¯´æ˜</span></span><br><span class="line"></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">nickname:</span> <span class="comment"># æ˜µç§°</span></span><br><span class="line">    <span class="attr">avatar:</span> <span class="comment"># å¤´åƒåœ°å€</span></span><br><span class="line">    <span class="attr">site:</span> <span class="comment">#å‹é“¾åœ°å€</span></span><br><span class="line">    <span class="attr">info:</span> <span class="comment">#ç›¸å…³è¯´æ˜</span></span><br></pre></td></tr></tbody></table></figure><h3 id="å‚è€ƒ">å‚è€ƒ</h3><blockquote><p>Hexo-NexT ä¸»é¢˜ä¸ªæ€§ä¼˜åŒ– https://guanqr.com/tech/website/hexo-theme-next-customization/</p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      åœ¨æ–°é¡µé¢æ·»åŠ å‹é“¾
    
    </summary>
    
    
      <category term="next" scheme="http://yoursite.com/categories/next/"/>
    
    
      <category term="next" scheme="http://yoursite.com/tags/next/"/>
    
      <category term="åšå®¢" scheme="http://yoursite.com/tags/%E5%8D%9A%E5%AE%A2/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-11-æ‚è®°</title>
    <link href="http://yoursite.com/2020/08/11/2020-08-11-%E6%9D%82%E8%AE%B0/"/>
    <id>http://yoursite.com/2020/08/11/2020-08-11-%E6%9D%82%E8%AE%B0/</id>
    <published>2020-08-11T01:20:00.000Z</published>
    <updated>2020-08-11T09:43:45.828Z</updated>
    
    <content type="html"><![CDATA[<div id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <div class="hbe-input-container">  <input type="password" id="hbePass" placeholder="" />    <label for="hbePass">è¾“å…¥å¯†ç ï¼ŒæŸ¥çœ‹æ–‡ç« </label>    <div class="bottom-line"></div>  </div>  <script id="hbeData" type="hbeData" data-hmacdigest="60538e9416c404b4b7457c2693fcb1c80ad4730351f64da5488d3b397a8b1058">b2636caa15154e7869096a6b870b46d4f9822c1e031b2d83b47c9c2cc6713956b74f0bf410c1d2c65843fb3c558f4afedd38e18d2f3ac178a01e97d68d8064885dd59d51fff996e09068e1a036158bcc6c3fe8b8fdf67083ddc8c4f595e9d6e8ed0a8ec2db6d74cc502e5071431c9be605cc093e4db8411eff873f63eb41f80ea803e12db33955033004441a9abd8820ddf306abfb79a99592a22f53964c9315ed223ed01005a3f81225eedda0e6e499388623037cd44645f87eb63ca01343c645b39e915e16281248b499092c688da74afe2935123576adad39ed6dba05d7da2faa5e1bf2762b8ba5c54cf70c808451d47fa9be8345594ce669e784c20c90bbc5c559c541d8ef9a27ce02db76b9e381dcc6ac1ff513a06b2d5872f5c716fb7f5d86363d3f475d28a81858b32df00fa15d6cfac6299ea1b3febc4eacd17147a307e9b90c94860f56389366d4f9609a68e8c876ec767a4eb7205bd25a773709320eab3787e03723c41cc1a2bfda9a969ac88dc8d205dd9c159f06be3b075d7d751912735a72d3e757b4e02b7f9092da5bec29216c989caf2b9a2c191bdccbf5228d86a6ec4926c5078cb62aae6458f16dea8617eb6cbd27d4d4cf04ab010045425128a33e092a052e984ce0763f91d3c070e5e784a45d0b56709659b7d7b73bb297498456207f4850aece54a967984fd2e196ab8cac1446e757d1def14d4b63afa3adbe86c8f9053b8d1610505c9c5f23c7d11ff4bbc0f9a77fbfa17b1d997f882ea3ab2946d5e144749e671eb7f4acdd07ea06b5c562ad14efcee487b016efd0df4ec1f00ccbfb74dd3f8d84b35d319b2fe560563b22eac16e69ad27434c71f6a1e4eb7b83ab19be1b76d2e0378d0330f98d4093e7f2cd2d2c29414ecbd578bd8221210b0b9eebedaf19904bebd5f7ba83f4144f60ec20b599aaec7bb43597536716d88e2a057f9bcb84e12a944031cc</script></div><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      è®°å½•æ—¥å¸¸
    
    </summary>
    
    
      <category term="æ‚è®°" scheme="http://yoursite.com/categories/%E6%9D%82%E8%AE%B0/"/>
    
    
      <category term="æ‚è®°" scheme="http://yoursite.com/tags/%E6%9D%82%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-09-å¸¸ç”¨chromeå¿«æ·é”®</title>
    <link href="http://yoursite.com/2020/08/09/2020-08-09-%E5%B8%B8%E7%94%A8chrome%E5%BF%AB%E6%8D%B7%E9%94%AE/"/>
    <id>http://yoursite.com/2020/08/09/2020-08-09-%E5%B8%B8%E7%94%A8chrome%E5%BF%AB%E6%8D%B7%E9%94%AE/</id>
    <published>2020-08-09T06:43:06.000Z</published>
    <updated>2020-08-10T16:16:20.533Z</updated>
    
    <content type="html"><![CDATA[<p>chromeæ˜¯æˆ‘æ—¥å¸¸ä½¿ç”¨çš„æµè§ˆå™¨ï¼Œå¹³æ—¶ä¹Ÿä¼šä½¿ç”¨å¿«æ·é”®æ¥æé«˜æ•ˆç‡ã€‚chromeçš„å¿«æ·é”®çœŸçš„å¾ˆå¥½ä½¿ï¼Œå¯ä»¥</p><p>æ‘†è„±å¾ˆå¤šä¸å¿…è¦çš„é¼ æ ‡ç‚¹å‡»ï¼Œé”®ç›˜ç›´æ¥æå®šã€‚æ€»ç»“ä¸€ä¸‹æˆ‘å¸¸ç”¨çš„å¿«æ·é”®ã€‚</p><table><thead><tr class="header"><th style="text-align: center;">æè¿°</th><th style="text-align: center;">å¿«æ·é”®</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;">æ‰“å¼€æ–°çª—å£</td><td style="text-align: center;">Ctrl + n</td></tr><tr class="even"><td style="text-align: center;">åœ¨éšèº«æ¨¡å¼ä¸‹æ‰“å¼€æ–°çª—å£</td><td style="text-align: center;">Ctrl + Shift + n</td></tr><tr class="odd"><td style="text-align: center;">-----</td><td style="text-align: center;"></td></tr><tr class="even"><td style="text-align: center;">æ‰“å¼€æ–°çš„æ ‡ç­¾é¡µï¼Œå¹¶è·³è½¬åˆ°è¯¥æ ‡ç­¾é¡µ</td><td style="text-align: center;">Ctrl + t</td></tr><tr class="odd"><td style="text-align: center;">æ¢å¤å·²å…³é—­çš„æ ‡ç­¾é¡µ</td><td style="text-align: center;">Ctrl + Shift + t</td></tr><tr class="even"><td style="text-align: center;">è·³è½¬åˆ°ä¸‹ä¸€ä¸ªæ ‡ç­¾é¡µ</td><td style="text-align: center;">Ctrl + Tab</td></tr><tr class="odd"><td style="text-align: center;">è·³è½¬åˆ°ä¸Šä¸€ä¸ªæ ‡ç­¾é¡µ</td><td style="text-align: center;">Ctrl + Shift + Tab</td></tr><tr class="even"><td style="text-align: center;">å…³é—­å½“å‰æ ‡ç­¾é¡µ</td><td style="text-align: center;">Ctrl + w</td></tr><tr class="odd"><td style="text-align: center;">------</td><td style="text-align: center;"></td></tr><tr class="even"><td style="text-align: center;">æ‰“å¼€å½“å‰æ ‡ç­¾é¡µæµè§ˆè®°å½•ä¸­çš„ä¸Šä¸€ä¸ªé¡µé¢</td><td style="text-align: center;">alt ï¼‹å·¦ç®­å¤´</td></tr><tr class="odd"><td style="text-align: center;">æ‰“å¼€å½“å‰æ ‡ç­¾é¡µæµè§ˆè®°å½•ä¸­çš„ä¸‹ä¸€ä¸ªé¡µé¢</td><td style="text-align: center;">alt ï¼‹å³ç®­å¤´</td></tr><tr class="even"><td style="text-align: center;">------</td><td style="text-align: center;"></td></tr><tr class="odd"><td style="text-align: center;">ä¿å­˜å½“å‰æ ‡ç­¾é¡µä¸ºä¹¦ç­¾</td><td style="text-align: center;">Ctrl + d</td></tr><tr class="even"><td style="text-align: center;">å°†æ‰€æœ‰æ‰“å¼€çš„æ ‡ç­¾é¡µä»¥ä¹¦ç­¾çš„å½¢å¼ä¿å­˜åœ¨æ–°æ–‡ä»¶å¤¹ä¸­</td><td style="text-align: center;">Ctrl + Shift + d</td></tr><tr class="odd"><td style="text-align: center;">------</td><td style="text-align: center;"></td></tr><tr class="even"><td style="text-align: center;">è·³è½¬åˆ°ä¸æŸ¥æ‰¾æ ä¸­æœç´¢å­—è¯ç›¸åŒ¹é…çš„ä¸‹ä¸€æ¡å†…å®¹</td><td style="text-align: center;">Ctrl + g</td></tr><tr class="odd"><td style="text-align: center;">è·³è½¬åˆ°ä¸æŸ¥æ‰¾æ ä¸­æœç´¢å­—è¯ç›¸åŒ¹é…çš„ä¸Šä¸€æ¡å†…å®¹</td><td style="text-align: center;">Ctrl + Shift + g</td></tr><tr class="even"><td style="text-align: center;">æµè§ˆä¸‹ä¸€ä¸ªå¯ç‚¹å‡»é¡¹</td><td style="text-align: center;">Tab</td></tr><tr class="odd"><td style="text-align: center;">æµè§ˆä¸Šä¸€ä¸ªå¯ç‚¹å‡»é¡¹</td><td style="text-align: center;">Shift + Tab</td></tr></tbody></table><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      è®°å½•å¸¸ç”¨chromeå¿«æ·é”®
    
    </summary>
    
    
      <category term="æŠ€æœ¯" scheme="http://yoursite.com/categories/%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="æŠ€æœ¯" scheme="http://yoursite.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="chrome" scheme="http://yoursite.com/tags/chrome/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-08-hexoæ–°å»ºpage</title>
    <link href="http://yoursite.com/2020/08/08/2020-08-08-hexo%E6%96%B0%E5%BB%BApage/"/>
    <id>http://yoursite.com/2020/08/08/2020-08-08-hexo%E6%96%B0%E5%BB%BApage/</id>
    <published>2020-08-08T11:10:50.000Z</published>
    <updated>2020-08-12T10:39:49.750Z</updated>
    
    <content type="html"><![CDATA[<h3 id="å‰è¨€">å‰è¨€</h3><p>åœ¨åšå®¢ä¸­éœ€è¦ä¸€äº›ä¸ªæ€§åŒ–è®¾ç½®ï¼Œæ·»åŠ ä¸€äº›pageç­‰ ï¼Œè®°å½•ä¸‹æˆ‘çš„æ“ä½œ</p><h3 id="æ·»åŠ page-ç•Œé¢">æ·»åŠ page ç•Œé¢</h3><p>æˆ‘æƒ³è¦æ·»åŠ ä¸€ä¸ªâ€œä¸€å¥è¯æ„Ÿæƒ³â€çš„pageï¼Œäºæ˜¯å¯ä»¥è¿™æ ·æ“ä½œ</p><p>step 1.hexoæ–°å»ºæ–°çš„pageç•Œé¢</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new page onesentence  <span class="comment"># onesentence æ˜¯æ–°å»ºpageçš„åç§° ï¼ˆæœ€å¥½æ˜¯è‹±æ–‡åï¼‰</span></span><br></pre></td></tr></tbody></table></figure><p>è¿™æ—¶å€™åœ¨åšå®¢çš„sourceæ–‡ä»¶å¤¹é‡Œä¼šæœ‰ä¸€ä¸ªonesentenceçš„æ–‡ä»¶å¤¹ï¼Œå¹¶ä¸”é‡Œé¢ç”Ÿæˆäº†ä¸€ä¸ªindex.mdæ–‡ä»¶ï¼Œç”¨äºå†™ä¸€å¥è¯æ„Ÿæƒ³çš„å†…å®¹</p><p>step 2.åœ¨ä¸»é¢˜çš„é…ç½®æ–‡ä»¶ _config.yml æ–‡ä»¶ä¸­çš„ menu ä¸­è¿›è¡ŒåŒ¹é…ï¼Œå¦‚ä¸‹å›¾ï¼Œæ·»åŠ ä¸€ä¸ªonesentenceé¡¹ï¼Œ<code>/onesentence</code>è¡¨ç¤ºæŒ‚æ¥åˆ°ä¸Šè¿°çš„æ–°å»ºæ–‡ä»¶å¤¹é‡Œï¼Œ</p><p>åœ¨è¿™é‡Œä¹Ÿå¯ä»¥è®¾ç½®å›¾æ ‡ï¼Œåœ¨fontawesomeç½‘ç«™é‡Œæ‰¾ï¼Œæˆ‘æ‰¾äº†ä¸€ä¸ªä¿é¾„çƒ<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f3b3.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3b3.png?v8">ğŸ³</span>çš„å›¾æ ‡ï¼Œå’Œpageä¸»é¢˜æ²¡å•¥è”ç³»ï¼Œå°±æ˜¯çœ‹ç€é¡ºçœ¼ <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8">ğŸ˜†</span></p><p>æ­¤æ—¶<code>hexo s -g</code> å°±å¯ä»¥çœ‹åˆ°å·²ç»æœ‰äº†è¿™ä¸ªç•Œé¢ï¼Œä¸è¿‡æ˜¯è‹±æ–‡çš„æ–‡ä»¶åï¼Œæ‰€ä»¥æ­¤æ—¶è¿˜è¦è®¾ç½®ä¸€ä¸‹æ­¤æ–‡ä»¶åçš„ä¸­æ–‡åæ˜ å°„</p><figure><img src="https://i.loli.net/2020/08/08/jiUOEvuzWnT7Kmp.png" alt="image-20200808192748174"><figcaption>image-20200808192748174</figcaption></figure><p>step 3. æ‰“å¼€**themes*ï¼Œæˆ‘ç”¨çš„æ˜¯zh-CNï¼Œæ‰“å¼€æ­¤æ–‡ä»¶ï¼Œåœ¨menuä¸‹æ·»åŠ <code>onesentence: ä¸€å¥è¯</code>ï¼Œå³å¯å®Œæˆä¸­æ–‡æ˜ å°„ï¼Œ</p><p>æ­¤æ—¶ hexo s -g ,å°±å¯ä»¥åœ¨æœ¬åœ°æœåŠ¡å™¨çš„ä¾§è¾¹æ éƒ¨åˆ†çœ‹åˆ°æ–°æ·»åŠ çš„â€œä¸€å¥è¯â€page</p><figure><img src="https://i.loli.net/2020/08/08/cCymB2KXMh1OPN5.png" alt="image-20200808193652117"><figcaption>image-20200808193652117</figcaption></figure><p><img src="https://i.loli.net/2020/08/08/ZrQkcR8IPspHMdi.png" alt="image-20200808194045722" style="zoom: 67%;"></p><p>step 4. ç¼–è¾‘â€œä¸€å¥è¯â€é¡µé¢ä¸‹çš„mdæ–‡ä»¶ï¼Œéƒ¨ç½²å°±èƒ½çœ‹åˆ°å†…å®¹</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      æ–°å»ºpageé¡µ
    
    </summary>
    
    
      <category term="next" scheme="http://yoursite.com/categories/next/"/>
    
    
      <category term="next" scheme="http://yoursite.com/tags/next/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-08-nextç¼ºå°‘custom.stylçš„é—®é¢˜</title>
    <link href="http://yoursite.com/2020/08/08/2020-08-08-%E7%BC%BA%E5%B0%91custom-styl%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2020/08/08/2020-08-08-%E7%BC%BA%E5%B0%91custom-styl%E7%9A%84%E9%97%AE%E9%A2%98/</id>
    <published>2020-08-08T10:56:09.000Z</published>
    <updated>2020-08-10T07:20:00.982Z</updated>
    
    <content type="html"><![CDATA[<h3 id="å‰è¨€">å‰è¨€</h3><p>åœ¨ next7.x ç‰ˆæœ¬ä¸­æ²¡æœ‰custom.stylæ–‡ä»¶ã€‚å¦‚æœæˆ‘ä»¬æƒ³è¦åœ¨åšå®¢ä¸­æ·»åŠ è‡ªå·±çš„cssæ ·å¼ï¼Œå¯ä»¥åœ¨æ­¤æ–‡ä»¶ä¸­æ·»åŠ ï¼Œä¸‹é¢ä»‹ç»ä¸€ä¸‹</p><h3 id="æ“ä½œ">æ“ä½œ</h3><p>step1 ï¼šæ·»åŠ custom.stylæ–‡ä»¶</p><p>æ–‡ä»¶è·¯å¾„ï¼š<code>~\themes\next\source\css</code> ,æ·»åŠ <code>_custom</code>æ–‡ä»¶å¤¹ã€‚ç„¶ååœ¨<code>_custom</code>ä¸­åˆ›å»º<code>custom.styl</code>æ–‡ä»¶ã€‚æˆ‘ä»¬è‡ªå·±çš„æ ·å¼å°±å¯ä»¥åœ¨æ­¤æ–‡ä»¶ä¸­æ·»åŠ </p><p>step2ï¼š æ·»åŠ å¼•ç”¨</p><p>åœ¨<code>~\themes\next\source\css</code>ä¸­çš„<code>main.styl</code>æ–‡ä»¶æœ«å°¾åŠ å…¥å¼•ç”¨å³å¯</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//My Layer</span><br><span class="line">@import "_custom/custom.styl";</span><br></pre></td></tr></tbody></table></figure><p>step3ï¼š æ·»åŠ æ ·å¼</p><p>ç”¨vscodeæ‰“å¼€<code>custom.styl</code>ï¼Œåšå®¢èƒŒæ™¯ä»¥åŠå‰é¡µçš„ä¸é€æ˜åº¦ç­‰ç­‰ï¼Œå°±å¯ä»¥æ›´æ¢æ ·å¼äº†ã€‚</p><p>å¯¹äºç½‘é¡µçš„ç»„ä»¶ï¼ŒF12æ‰“å¼€è°ƒè¯•ç•Œé¢ï¼Œå°±å¯ä»¥çŸ¥é“æ¯ä¸ªç»„ä»¶çš„åç§°ç­‰ä¿¡æ¯ï¼Œä¾¿äºæ›´æ”¹æ ·å¼</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      next7.x ç‰ˆæœ¬æ²¡æœ‰custom.stylæ–‡ä»¶
    
    </summary>
    
    
      <category term="next" scheme="http://yoursite.com/categories/next/"/>
    
    
      <category term="æ•…éšœæ’é™¤" scheme="http://yoursite.com/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4/"/>
    
      <category term="next" scheme="http://yoursite.com/tags/next/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-08-vimå¸¸è§æ“ä½œ</title>
    <link href="http://yoursite.com/2020/08/08/2020-08-08-vim%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/"/>
    <id>http://yoursite.com/2020/08/08/2020-08-08-vim%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/</id>
    <published>2020-08-08T05:22:42.000Z</published>
    <updated>2020-08-10T16:16:14.191Z</updated>
    
    <content type="html"><![CDATA[<h3 id="å¸¸è§„æ“ä½œ">å¸¸è§„æ“ä½œ</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">vim a.txt  <span class="comment"># åˆ›å»ºa.txtæ–‡ä»¶å¹¶è¿›å…¥ç¼–è¾‘çŠ¶æ€ ã€‚ å¦‚æœa.txt å·²ç»å­˜åœ¨ï¼Œåˆ™ç›´æ¥è¿›å…¥ç¼–è¾‘çŠ¶æ€</span></span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> æŒ‰ä¸‹ié”®ï¼Œä¸‹ç«¯æ˜¾ç¤º â€“INSERTâ€“ã€‚å¯ä»¥è¿›è¡Œæ’å…¥ï¼Œè¾“å…¥æ–‡æœ¬ </span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> è¾“å…¥äº†ä¹‹å æŒ‰Escé”®é€€å‡ºç¼–è¾‘çŠ¶æ€</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> é”®å…¥ :wq! å¼ºåˆ¶ä¿å­˜æ–‡ä»¶å¹¶é€€å‡º  <span class="comment"># !æ˜¯å¼ºåˆ¶æ‰§è¡Œï¼Œæ³¨ï¼šæœ‰äº›æ–‡ä»¶è®¾ç½®äº†åªè¯»ï¼Œä¸€èˆ¬ä¸æ˜¯ä¿®æ”¹æ–‡ä»¶çš„ï¼Œä½†æ˜¯å¦‚æœä½ æ˜¯`æ–‡ä»¶çš„owneræˆ–è€…rootçš„è¯ï¼Œé€šè¿‡wq!è¿˜æ˜¯èƒ½ä¿å­˜æ–‡ä»¶é€€å‡ºã€‚:wqä¸å¯ä»¥</span></span><br><span class="line"></span><br><span class="line">   :w åœ¨ç¼–è¾‘çš„è¿‡ç¨‹ä¸­ä¿å­˜æ–‡ä»¶,ç›¸å½“äºwordä¸­çš„ctrl+s    </span><br><span class="line"></span><br><span class="line">   :wq ä¿å­˜æ–‡ä»¶å¹¶é€€å‡º <span class="comment">#ä¸€èˆ¬ä½¿ç”¨è¿™ä¸ªå‘½ä»¤é€€å‡º</span></span><br></pre></td></tr></tbody></table></figure><blockquote><p>æ³¨ï¼šä»¥<strong><code>:</code></strong>å’Œ<strong><code>/</code></strong>å¼€å¤´çš„å‘½ä»¤éƒ½æœ‰å†å²çºªå½•ï¼Œå¯ä»¥é¦–å…ˆé”®å…¥:æˆ–/ç„¶åæŒ‰<strong>ä¸Šä¸‹ç®­å¤´</strong>æ¥é€‰æ‹©æŸä¸ªå†å²å‘½ä»¤</p></blockquote><h3 id="vimæ¨¡å¼">Vimæ¨¡å¼</h3><p>(éƒ½æ˜¯åœ¨è‹±æ–‡è¾“å…¥ç¯å¢ƒä¸‹æ“ä½œ)</p><ul><li><strong>Normal</strong> æ¨¡å¼ï¼šè¿›å…¥Vimåçš„ä¸€èˆ¬æ¨¡å¼ã€‚</li><li><strong>Insert</strong> æ¨¡å¼ï¼šæŒ‰ä¸‹<code>i</code>é”®åè¿›å…¥æ’å…¥æ¨¡å¼ï¼Œå¯ä»¥ä¿®æ”¹æ–‡æ¡£ã€‚</li><li><strong>Visual</strong> æ¨¡å¼ï¼šæŒ‰ä¸‹<code>v</code>é”®åè¿›å…¥é€‰æ‹©æ¨¡å¼ï¼Œå¯ä»¥é€‰æ‹©æ–‡æ¡£å†…å®¹ã€‚</li></ul><h3 id="vimæ‰“å¼€å’Œåˆ‡æ¢æ–‡ä»¶">Vimæ‰“å¼€å’Œåˆ‡æ¢æ–‡ä»¶</h3><ul><li><code>:ls</code>æ˜¾ç¤ºæ‰“å¼€çš„æ–‡ä»¶ï¼Œå¯ä»¥ä½¿ç”¨<code>:bn</code>åœ¨æ–‡ä»¶é—´åˆ‡æ¢( nä¹Ÿå¯ä»¥æ¢æˆ<code>:ls</code>é‡Œç»™å‡ºçš„æ–‡ä»¶åºå· )ã€‚</li><li>åœ¨ç»ˆç«¯<code>vim -o file1 file2 ...</code>å¯ä»¥æ‰“å¼€å¤šä¸ªæ–‡ä»¶(æ¨ªå‘åˆ†éš”å±å¹•)ã€‚</li><li>ç»ˆç«¯<code>vim -O file1 file2 ...</code>å¯ä»¥æ‰“å¼€å¤šä¸ªæ–‡ä»¶(çºµå‘åˆ†éš”å±å¹•)ã€‚ <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8">â­</span></li><li><code>Ctrl</code>+<code>w</code>+<code>æ–¹å‘é”®</code>åœ¨çª—å£é—´åˆ‡æ¢å…‰æ ‡</li></ul><h3 id="vimé€€å‡º">Vimé€€å‡º</h3><ul><li><p><code>:q</code>ï¼šé€€å‡ºã€‚</p></li><li><p><code>:q!</code>ï¼šå¼ºåˆ¶é€€å‡ºï¼Œæ”¾å¼ƒæ‰€æœ‰ä¿®æ”¹ã€‚</p></li><li><p><code>:wq</code>ï¼šä¿å­˜ä¿®æ”¹å¹¶é€€å‡ºã€‚<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8">â­</span></p></li></ul><h3 id="å¸¸ç”¨å¿«æ·é”®">å¸¸ç”¨å¿«æ·é”®</h3><ul><li><p><code>gg</code>åˆ°æ–‡æ¡£é¦–è¡Œï¼Œ<code>G</code>ï¼ˆshift+gï¼‰åˆ°æ–‡æ¡£ç»“å°¾ã€‚</p></li><li><p><code>pageUp</code>ä¸‹ä¸€é¡µï¼Œ<code>pageDown</code>ä¸Šä¸€é¡µã€‚</p></li><li><p><code>ctrl + d</code> å‘ä¸‹ç¿»åŠé¡µ(down)ï¼Œ <code>ctrl + u</code> å‘ä¸Šç¿»åŠé¡µ(up) <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8">â­</span></p></li><li><p><code>H</code>å°†å…‰æ ‡ç§»åŠ¨åˆ°å±å¹•é¦–è¡Œï¼Œ<code>M</code>å°†å…‰æ ‡ç§»åŠ¨åˆ°å±å¹•ä¸­é—´è¡Œï¼Œ<code>L</code>å°†å…‰æ ‡ç§»åŠ¨åˆ°å±å¹•æœ€åä¸€è¡Œã€‚</p></li><li><p><code>q:</code>æ˜¾ç¤º<strong>å‘½ä»¤è¡Œå†å²è®°å½•</strong>ï¼ˆæ˜¾ç¤ºå¼€å¤´ä¸º:çš„å†å²å‘½ä»¤è¡Œï¼‰çª—å£ï¼Œå¯ä»¥é€‰æ‹©å‘½ä»¤è¡Œæ‰§è¡Œã€‚è‹¥æ˜¯<code>q/</code>,åˆ™ä¼šæ˜¾ç¤ºå¼€å¤´ä¸º/çš„å†å²å‘½ä»¤è¡Œ</p></li><li><p><code>u</code> æ’¤é”€ (undo) <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8">â­</span></p></li><li><p><code>w</code> ä¸‹ä¸€ä¸ªå•è¯ word</p></li><li><p><code>b</code> å‰ä¸€ä¸ªå•è¯ behind</p></li><li><p><code>e</code> æœ¬å•è¯æœ«å°¾ end</p></li><li><p><code>:set nu</code> æ˜¾ç¤ºè¡Œå· (number ) ã€€</p></li><li><p><code>:set nonu</code> éšè—è¡Œå· ( number)</p></li><li><p><code>:98</code>è·³è½¬åˆ°ç¬¬98è¡Œã€‚</p></li><li><p><code>:5,10d</code> //å›è½¦åï¼Œç¬¬5~10è¡Œè¢«åˆ é™¤</p></li><li><p><code>:5,$d</code> //å›è½¦åï¼Œç¬¬5~æœ€åä¸€è¡Œè¢«åˆ é™¤</p></li><li><p><code>:5,10y</code> //å›è½¦åï¼Œç¬¬5~10è¡Œè¢«å¤åˆ¶</p></li></ul><h3 id="å¤åˆ¶ç²˜è´´">å¤åˆ¶ç²˜è´´</h3><ul><li>åœ¨<strong>Visual</strong>æ¨¡å¼ä¸‹é€‰æ‹©æ–‡æ¡£å†…å®¹åæŒ‰<code>y</code>é”®ï¼Œå¤åˆ¶è¢«é€‰æ‹©å†…å®¹ã€‚ä¸»è¦ç”¨äº<strong>å¤šè¡Œæ–‡å­—</strong>ï¼ˆå¤åˆ¶å®Œä¹‹åvimè‡ªåŠ¨é€€å‡ºVisualæ¨¡å¼ï¼‰</li><li>åœ¨<strong>Visual</strong>æ¨¡å¼ä¸‹é€‰æ‹©æ–‡æ¡£å†…å®¹åæŒ‰<code>d</code>åˆ é™¤</li><li>æŒ‰<code>p</code>é”®ç²˜è´´ï¼Œæ³¨æ„ç²˜è´´ä»<strong>ç´§è·Ÿå…‰æ ‡åçš„é‚£ä¸ªå­—ç¬¦</strong>ä¹‹åæ‰å¼€å§‹ã€‚ï¼ˆä¸éœ€è¦è¿›å…¥Visualæ¨¡å¼ï¼‰</li><li><code>yy</code>å¤åˆ¶å½“å‰è¡Œï¼Œ<code>dd</code>åˆ é™¤(å‰ªè´´)å½“å‰è¡Œã€‚ ç”¨äº<strong>ä¸€è¡Œæ–‡å­—</strong></li><li><code>:5,10y</code> //å›è½¦åï¼Œç¬¬5~10è¡Œè¢«å¤åˆ¶</li></ul><p>å¦‚æœåœ¨vimå¤–çš„å…¶å®ƒæ–‡ä»¶é‡Œå¤åˆ¶å†…å®¹åˆ°vimé‡Œï¼Œåˆ™æ— æ³•ä½¿ç”¨<code>p</code>è¿›è¡Œç²˜è´´ï¼Œæ­¤æ—¶å³é”®ç²˜è´´å³å¯ï¼ˆæ— éœ€è¿›å…¥insetæ¨¡å¼ï¼‰</p><h3 id="æŸ¥æ‰¾">æŸ¥æ‰¾</h3><ul><li>åœ¨<strong>Normal</strong>æ¨¡å¼ä¸‹ï¼ŒæŒ‰<code>/</code>è¿›å…¥æŸ¥æ‰¾æ¨¡å¼ï¼Œè¾“å…¥<code>/word</code>åå›è½¦ï¼Œé«˜äº®æ˜¾ç¤ºæ‰€æœ‰æ–‡æ¡£<code>word</code>ï¼ŒæŒ‰<code>n</code>è·³åˆ°ä¸‹ä¸€ä¸ª<code>word</code>,æŒ‰<code>N</code>è·³åˆ°ä¸Šä¸€ä¸ªã€‚ï¼ˆé»˜è®¤å¤§å°å†™æ•æ„Ÿï¼‰</li><li>è‹¥è¾“å…¥<code>/word\c</code>ä»£è¡¨å¤§å°å†™ä¸æ•æ„ŸæŸ¥æ‰¾ï¼Œ<code>\C</code>ä»£è¡¨å¤§å°å†™æ•æ„Ÿã€‚</li><li>åœ¨<strong>Normal</strong>æ¨¡å¼ä¸‹æŒ‰<code>q</code>+<code>/</code>æ˜¾ç¤º<strong>æŸ¥æ‰¾å†å²è®°å½•</strong>çª—å£ã€‚</li><li>å¦‚æœä¸€ä¸ªè¯å¾ˆé•¿ï¼Œé”®å…¥éº»çƒ¦ï¼Œå¯ä»¥å°†å…‰æ ‡ç§»åŠ¨åˆ°è¯¥è¯ä¸Šï¼ŒæŒ‰<code>*</code>é”®å³å¯ä»¥è¯¥å•è¯è¿›è¡Œæœç´¢ï¼Œç›¸å½“äº/æœç´¢ã€‚</li></ul><figure><img src="https://i.loli.net/2020/08/11/GZszjJB9uIUMFTq.png" alt="img"><figcaption>img</figcaption></figure><h3 id="å‚è€ƒ">å‚è€ƒ</h3><blockquote><p>vimçš„å¸¸ç”¨æ“ä½œ https://www.cnblogs.com/doseoer/p/6241443.html</p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      vimå¸¸è§æ“ä½œçš„æ€»ç»“
    
    </summary>
    
    
      <category term="linux" scheme="http://yoursite.com/categories/linux/"/>
    
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
      <category term="vim" scheme="http://yoursite.com/tags/vim/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-07-transformerXLè§£è¯»</title>
    <link href="http://yoursite.com/2020/08/07/2020-08-07-transformerXL%E8%A7%A3%E8%AF%BB/"/>
    <id>http://yoursite.com/2020/08/07/2020-08-07-transformerXL%E8%A7%A3%E8%AF%BB/</id>
    <published>2020-08-07T10:20:34.000Z</published>
    <updated>2020-08-10T16:15:46.034Z</updated>
    
    <content type="html"><![CDATA[<p>Transformeræœ€å¤§çš„é—®é¢˜ï¼šåœ¨è¯­è¨€å»ºæ¨¡æ—¶çš„è®¾ç½®å—åˆ°å›ºå®šé•¿åº¦ä¸Šä¸‹æ–‡çš„é™åˆ¶ã€‚</p><p>æœ¬æ–‡æå‡ºçš„Transformer-XLï¼Œä½¿å­¦ä¹ ä¸å†ä»…ä»…ä¾èµ–äºå®šé•¿ï¼Œä¸”ä¸ç ´åæ—¶é—´çš„ç›¸å…³æ€§ã€‚</p><p>Transformer-XLåŒ…å«segment-level å¾ªç¯æœºåˆ¶å’Œpositionalç¼–ç æ¡†æ¶ã€‚ä¸ä»…å¯ä»¥æ•æ‰é•¿æ—¶ä¾èµ–ï¼Œè¿˜å¯ä»¥è§£å†³ä¸Šä¸‹æ–‡æ–­ç‰‡é—®é¢˜ fragmentation problemã€‚å¯ä»¥å­¦åˆ°æ¯”RNNsé•¿80%çš„ä¾èµ–ï¼Œæ¯”vanilla Transformersé•¿450%ã€‚åœ¨é•¿çŸ­åºåˆ—ä¸Šéƒ½å–å¾—äº†æ›´å¥½çš„ç»“æœã€‚ä¸vanilla Transformerç›¸æ¯”ï¼ŒTransformer-XLçš„å¦ä¸€ä¸ªä¼˜åŠ¿æ˜¯å®ƒå¯ä»¥è¢«ç”¨äºå•è¯çº§å’Œå­—ç¬¦çº§çš„è¯­è¨€å»ºæ¨¡ã€‚</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      æœ€è¿‘è¯»çš„è®ºæ–‡transformer-XL
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-08-06-pytorchå‡½æ•°ä¹‹nn.Linear</title>
    <link href="http://yoursite.com/2020/08/06/2020-08-06-pytorch%E5%87%BD%E6%95%B0%E4%B9%8BLinear/"/>
    <id>http://yoursite.com/2020/08/06/2020-08-06-pytorch%E5%87%BD%E6%95%B0%E4%B9%8BLinear/</id>
    <published>2020-08-06T02:29:09.000Z</published>
    <updated>2020-08-08T06:51:12.414Z</updated>
    
    <content type="html"><![CDATA[<h1 id="section"></h1><p>class torch.nn.Linearï¼ˆin_featuresï¼Œout_featuresï¼Œbias = True ï¼‰</p><p>å¯¹ä¼ å…¥æ•°æ®åº”ç”¨çº¿æ€§å˜æ¢ï¼šy = A x+ b</p><p>å‚æ•°ï¼š</p><p>in_features - æ¯ä¸ªè¾“å…¥æ ·æœ¬çš„å¤§å°</p><p>out_features - æ¯ä¸ªè¾“å‡ºæ ·æœ¬çš„å¤§å°</p><p>bias - å¦‚æœè®¾ç½®ä¸ºFalseï¼Œåˆ™å›¾å±‚ä¸ä¼šå­¦ä¹ é™„åŠ åå·®ã€‚é»˜è®¤å€¼ï¼šTrue</p><p>ä»£ç ï¼š</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">m = nn.Linear(20, 30)</span><br><span class="line"></span><br><span class="line">input = autograd.Variable(torch.randn(128, 20))</span><br><span class="line"></span><br><span class="line">output = m(input)</span><br><span class="line"></span><br><span class="line">print(output.size())</span><br></pre></td></tr></tbody></table></figure><p>è¾“å‡ºï¼š</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([128, 30])</span><br></pre></td></tr></tbody></table></figure><p>åˆ†æ:</p><p>output.size()=çŸ©é˜µsize(128,20)*çŸ©é˜µsizeï¼ˆ20,30ï¼‰=(128,30)</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      Linearå‡½æ•°
    
    </summary>
    
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-05-BPEç®—æ³•</title>
    <link href="http://yoursite.com/2020/08/05/2020-08-05-%E7%AE%97%E6%B3%95/"/>
    <id>http://yoursite.com/2020/08/05/2020-08-05-%E7%AE%97%E6%B3%95/</id>
    <published>2020-08-05T08:35:26.000Z</published>
    <updated>2020-08-10T16:15:43.534Z</updated>
    
    <content type="html"><![CDATA[<h3 id="æ€»è¯´"><strong>æ€»è¯´</strong></h3><p>BPEï¼Œï¼ˆbyte pair encoderï¼‰å­—èŠ‚å¯¹ç¼–ç ï¼Œä¹Ÿå¯ä»¥å«åšdigram codingåŒå­—æ¯ç»„åˆç¼–ç ï¼Œ<code>ä¸»è¦ç›®çš„æ˜¯ä¸ºäº†æ•°æ®å‹ç¼©</code>ï¼Œç®—æ³•æè¿°ä¸º<code>å­—ç¬¦ä¸²é‡Œé¢‘ç‡æœ€å¸¸è§çš„ä¸€å¯¹å­—ç¬¦è¢«ä¸€ä¸ªæ²¡æœ‰åœ¨è¿™ä¸ªå­—ç¬¦ä¸­å‡ºç°çš„å­—ç¬¦ä»£æ›¿çš„å±‚å±‚è¿­ä»£è¿‡ç¨‹</code>ã€‚å…·ä½“åœ¨ä¸‹é¢æè¿°ã€‚</p><h3 id="ç®—æ³•">ç®—æ³•</h3><ol type="1"><li>å‡†å¤‡è¶³å¤Ÿå¤§çš„è®­ç»ƒè¯­æ–™</li><li>ç¡®å®šæœŸæœ›çš„<strong>subwordè¯è¡¨å¤§å°</strong></li><li>å°†å•è¯æ‹†åˆ†ä¸ºå­—ç¬¦åºåˆ—å¹¶åœ¨<strong>æœ«å°¾æ·»åŠ åç¼€â€œ &lt;/ w&gt;â€</strong>ï¼Œç»Ÿè®¡å•è¯é¢‘ç‡ã€‚ æœ¬é˜¶æ®µçš„subwordçš„ç²’åº¦æ˜¯å­—ç¬¦ã€‚ ä¾‹å¦‚ï¼Œâ€œ lowâ€çš„é¢‘ç‡ä¸º5ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°†å…¶æ”¹å†™ä¸ºâ€œ l o w &lt;/ w&gt;â€ï¼š5</li><li>ç»Ÿè®¡æ¯ä¸€ä¸ªè¿ç»­å­—èŠ‚å¯¹çš„å‡ºç°é¢‘ç‡ï¼Œé€‰æ‹©æœ€é«˜é¢‘è€…åˆå¹¶æˆæ–°çš„subword</li><li>é‡å¤ç¬¬4æ­¥ç›´åˆ°è¾¾åˆ°ç¬¬2æ­¥è®¾å®šçš„subwordè¯è¡¨å¤§å°æˆ–ä¸‹ä¸€ä¸ªæœ€é«˜é¢‘çš„å­—èŠ‚å¯¹å‡ºç°é¢‘ç‡ä¸º1</li></ol><p>åœæ­¢ç¬¦""çš„æ„ä¹‰åœ¨äºè¡¨ç¤ºsubwordæ˜¯è¯åç¼€ã€‚ä¸¾ä¾‹æ¥è¯´ï¼š"st"å­—è¯ä¸åŠ ""å¯ä»¥å‡ºç°åœ¨è¯é¦–å¦‚"st ar"ï¼ŒåŠ äº†""è¡¨æ˜æ”¹å­—è¯ä½äºè¯å°¾ï¼Œå¦‚"wide st"ï¼ŒäºŒè€…æ„ä¹‰æˆªç„¶ä¸åŒã€‚</p><p>æ¯æ¬¡åˆå¹¶åè¯è¡¨å¯èƒ½å‡ºç°3ç§å˜åŒ–ï¼š</p><ul><li>+1ï¼Œè¡¨æ˜åŠ å…¥åˆå¹¶åçš„æ–°å­—è¯ï¼ŒåŒæ—¶åŸæ¥çš„2ä¸ªå­è¯è¿˜ä¿ç•™ï¼ˆ2ä¸ªå­—è¯ä¸æ˜¯å®Œå…¨åŒæ—¶è¿ç»­å‡ºç°ï¼‰</li><li>+0ï¼Œè¡¨æ˜åŠ å…¥åˆå¹¶åçš„æ–°å­—è¯ï¼ŒåŒæ—¶åŸæ¥çš„2ä¸ªå­è¯ä¸­ä¸€ä¸ªä¿ç•™ï¼Œä¸€ä¸ªè¢«æ¶ˆè§£ï¼ˆä¸€ä¸ªå­—è¯å®Œå…¨éšç€å¦ä¸€ä¸ªå­—è¯çš„å‡ºç°è€Œç´§è·Ÿç€å‡ºç°ï¼‰</li><li>-1ï¼Œè¡¨æ˜åŠ å…¥åˆå¹¶åçš„æ–°å­—è¯ï¼ŒåŒæ—¶åŸæ¥çš„2ä¸ªå­è¯éƒ½è¢«æ¶ˆè§£ï¼ˆ2ä¸ªå­—è¯åŒæ—¶è¿ç»­å‡ºç°ï¼‰</li></ul><p>å®é™…ä¸Šï¼Œéšç€åˆå¹¶çš„æ¬¡æ•°å¢åŠ ï¼Œè¯è¡¨å¤§å°é€šå¸¸å…ˆå¢åŠ åå‡å°ã€‚</p><h4 id="ä¾‹å­1"><strong>ä¾‹å­1</strong></h4><p>è¾“å…¥ï¼š</p><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w e s t &lt;/w&gt;': 6, 'w i d e s t &lt;/w&gt;': 3}</span><br></pre></td></tr></tbody></table></figure><p>Iter 1, æœ€é«˜é¢‘è¿ç»­å­—èŠ‚å¯¹"e"å’Œ"s"å‡ºç°äº†6+3=9æ¬¡ï¼Œåˆå¹¶æˆ"es"ã€‚è¾“å‡ºï¼š</p><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w es t &lt;/w&gt;': 6, 'w i d es t &lt;/w&gt;': 3}</span><br></pre></td></tr></tbody></table></figure><p>Iter 2, æœ€é«˜é¢‘è¿ç»­å­—èŠ‚å¯¹"es"å’Œ"t"å‡ºç°äº†6+3=9æ¬¡, åˆå¹¶æˆ"est"ã€‚è¾“å‡ºï¼š</p><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w est &lt;/w&gt;': 6, 'w i d est &lt;/w&gt;': 3}</span><br></pre></td></tr></tbody></table></figure><p>Iter 3, ä»¥æ­¤ç±»æ¨ï¼Œæœ€é«˜é¢‘è¿ç»­å­—èŠ‚å¯¹ä¸º"est"å’Œ"" è¾“å‡ºï¼š</p><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w est&lt;/w&gt;': 6, 'w i d est&lt;/w&gt;': 3}</span><br></pre></td></tr></tbody></table></figure><p>â€¦â€¦</p><p>Iter n, ç»§ç»­è¿­ä»£<strong>ç›´åˆ°è¾¾åˆ°é¢„è®¾çš„subwordè¯è¡¨å¤§å°æˆ–ä¸‹ä¸€ä¸ªæœ€é«˜é¢‘çš„å­—èŠ‚å¯¹å‡ºç°é¢‘ç‡ä¸º1</strong>ã€‚</p><h3 id="bpeå®ç°">BPEå®ç°</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re, collections</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_stats</span><span class="params">(vocab)</span>:</span></span><br><span class="line">    pairs = collections.defaultdict(int)</span><br><span class="line">    <span class="keyword">for</span> word, freq <span class="keyword">in</span> vocab.items():</span><br><span class="line">        symbols = word.split()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(symbols)<span class="number">-1</span>):</span><br><span class="line">            pairs[symbols[i],symbols[i+<span class="number">1</span>]] += freq</span><br><span class="line">    <span class="keyword">return</span> pairs</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_vocab</span><span class="params">(pair, v_in)</span>:</span></span><br><span class="line">    v_out = {}</span><br><span class="line">    bigram = re.escape(<span class="string">' '</span>.join(pair))</span><br><span class="line">    p = re.compile(<span class="string">r'(?&lt;!\S)'</span> + bigram + <span class="string">r'(?!\S)'</span>)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> v_in:</span><br><span class="line">        w_out = p.sub(<span class="string">''</span>.join(pair), word)</span><br><span class="line">        v_out[w_out] = v_in[word]</span><br><span class="line">    <span class="keyword">return</span> v_out</span><br><span class="line"></span><br><span class="line">vocab = {<span class="string">'l o w &lt;/w&gt;'</span>: <span class="number">5</span>, <span class="string">'l o w e r &lt;/w&gt;'</span>: <span class="number">2</span>, <span class="string">'n e w e s t &lt;/w&gt;'</span>: <span class="number">6</span>, <span class="string">'w i d e s t &lt;/w&gt;'</span>: <span class="number">3</span>}</span><br><span class="line">num_merges = <span class="number">1000</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(num_merges):</span><br><span class="line">    pairs = get_stats(vocab)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> pairs:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    best = max(pairs, key=pairs.get)</span><br><span class="line">    vocab = merge_vocab(best, vocab)</span><br><span class="line">    print(best)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print output</span></span><br><span class="line"><span class="comment"># ('e', 's')</span></span><br><span class="line"><span class="comment"># ('es', 't')</span></span><br><span class="line"><span class="comment"># ('est', '&lt;/w&gt;')</span></span><br><span class="line"><span class="comment"># ('l', 'o')</span></span><br><span class="line"><span class="comment"># ('lo', 'w')</span></span><br><span class="line"><span class="comment"># ('n', 'e')</span></span><br><span class="line"><span class="comment"># ('ne', 'w')</span></span><br><span class="line"><span class="comment"># ('new', 'est&lt;/w&gt;')</span></span><br><span class="line"><span class="comment"># ('low', '&lt;/w&gt;')</span></span><br><span class="line"><span class="comment"># ('w', 'i')</span></span><br><span class="line"><span class="comment"># ('wi', 'd')</span></span><br><span class="line"><span class="comment"># ('wid', 'est&lt;/w&gt;')</span></span><br><span class="line"><span class="comment"># ('low', 'e')</span></span><br><span class="line"><span class="comment"># ('lowe', 'r')</span></span><br><span class="line"><span class="comment"># ('lower', '&lt;/w&gt;')</span></span><br></pre></td></tr></tbody></table></figure><h3 id="ç¼–ç å’Œè§£ç ">ç¼–ç å’Œè§£ç </h3><ul><li><h4 id="ç¼–ç ">ç¼–ç </h4></li></ul><p>åœ¨ä¹‹å‰çš„ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬å·²ç»å¾—åˆ°äº†<strong>subwordè¯è¡¨</strong>ï¼Œ<strong>å¯¹è¯¥è¯è¡¨æŒ‰ç…§å­è¯é•¿åº¦ç”±å¤§åˆ°å°æ’åº</strong>ã€‚ç¼–ç æ—¶ï¼Œ<strong>å¯¹äºæ¯ä¸ªå•è¯ï¼Œéå†æ’å¥½åºçš„å­è¯è¯è¡¨å¯»æ‰¾æ˜¯å¦æœ‰tokenæ˜¯å½“å‰å•è¯çš„å­å­—ç¬¦ä¸²ï¼Œå¦‚æœæœ‰ï¼Œåˆ™è¯¥tokenæ˜¯è¡¨ç¤ºå•è¯çš„tokensä¹‹ä¸€</strong>ã€‚</p><p>æˆ‘ä»¬ä»æœ€é•¿çš„tokenè¿­ä»£åˆ°æœ€çŸ­çš„tokenï¼Œå°è¯•å°†æ¯ä¸ªå•è¯ä¸­çš„å­å­—ç¬¦ä¸²æ›¿æ¢ä¸ºtokenã€‚ æœ€ç»ˆï¼Œæˆ‘ä»¬å°†è¿­ä»£æ‰€æœ‰tokensï¼Œå¹¶å°†æ‰€æœ‰å­å­—ç¬¦ä¸²æ›¿æ¢ä¸ºtokensã€‚ å¦‚æœä»ç„¶æœ‰å­å­—ç¬¦ä¸²æ²¡è¢«æ›¿æ¢ä½†æ‰€æœ‰tokenéƒ½å·²è¿­ä»£å®Œæ¯•ï¼Œåˆ™å°†å‰©ä½™çš„å­è¯æ›¿æ¢ä¸ºç‰¹æ®Štokenï¼Œå¦‚<unk>ã€‚</unk></p><h4 id="ä¾‹å­2">ä¾‹å­2</h4><p>ç”¨å¾—åˆ°subwordè¯è¡¨å»è¡¨ç¤ºå«æœ‰å¤šä¸ªå•è¯çš„å¥å­</p><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ç»™å®šå•è¯åºåˆ—</span></span><br><span class="line">[â€œthe&lt;/w&gt;â€, â€œhighest&lt;/w&gt;â€, â€œmountain&lt;/w&gt;â€]</span><br><span class="line"></span><br><span class="line"><span class="comment"># å‡è®¾å·²æœ‰æ’å¥½åºçš„subwordè¯è¡¨</span></span><br><span class="line">[â€œerrrr&lt;/w&gt;â€, â€œtain&lt;/w&gt;â€, â€œmounâ€, â€œest&lt;/w&gt;â€, â€œhighâ€, â€œthe&lt;/w&gt;â€, â€œa&lt;/w&gt;â€]</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¿­ä»£ç»“æœ</span></span><br><span class="line">"the&lt;/w&gt;" -&gt; ["the&lt;/w&gt;"]</span><br><span class="line">"highest&lt;/w&gt;" -&gt; ["high", "est&lt;/w&gt;"]</span><br><span class="line">"mountain&lt;/w&gt;" -&gt; ["moun", "tain&lt;/w&gt;"]</span><br></pre></td></tr></tbody></table></figure><p>ç¼–ç çš„è®¡ç®—é‡å¾ˆå¤§ã€‚ åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬å¯ä»¥pre-tokenizeæ‰€æœ‰å•è¯ï¼Œå¹¶åœ¨è¯å…¸ä¸­ä¿å­˜å•è¯tokenizeçš„ç»“æœã€‚ å¦‚æœæˆ‘ä»¬çœ‹åˆ°å­—å…¸ä¸­ä¸å­˜åœ¨çš„æœªçŸ¥å•è¯ã€‚ æˆ‘ä»¬åº”ç”¨ä¸Šè¿°ç¼–ç æ–¹æ³•å¯¹å•è¯è¿›è¡Œtokenizeï¼Œç„¶åå°†æ–°å•è¯çš„tokenizationæ·»åŠ åˆ°å­—å…¸ä¸­å¤‡ç”¨ã€‚</p><ul><li><h4 id="è§£ç ">è§£ç </h4></li></ul><p><strong>å°†æ‰€æœ‰çš„tokensæ‹¼åœ¨ä¸€èµ·</strong>ã€‚</p><figure class="highlight"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ç¼–ç åºåˆ—</span></span><br><span class="line">[â€œthe&lt;/w&gt;â€, â€œhighâ€, â€œest&lt;/w&gt;â€, â€œmounâ€, â€œtain&lt;/w&gt;â€]</span><br><span class="line"></span><br><span class="line"><span class="comment"># è§£ç åºåˆ—</span></span><br><span class="line">â€œthe&lt;/w&gt; highest&lt;/w&gt; mountain&lt;/w&gt;â€</span><br></pre></td></tr></tbody></table></figure><h4 id="ä¾‹å­3">ä¾‹å­3</h4><p>æ¯”å¦‚æˆ‘ä»¬æƒ³ç¼–ç ï¼š</p><p>aaabdaaabac</p><p>æˆ‘ä»¬ä¼šå‘ç°è¿™é‡Œçš„aaå‡ºç°çš„è¯æ•°æœ€é«˜ï¼ˆæˆ‘ä»¬è¿™é‡Œåªçœ‹ä¸¤ä¸ªå­—ç¬¦çš„é¢‘ç‡ï¼‰ï¼Œé‚£ä¹ˆç”¨è¿™é‡Œæ²¡æœ‰çš„å­—ç¬¦Zæ¥æ›¿ä»£aaï¼š</p><p>ZabdZabac</p><p>Z=aa</p><p>æ­¤æ—¶ï¼Œåˆå‘ç°abå‡ºç°çš„é¢‘ç‡æœ€é«˜ï¼Œé‚£ä¹ˆåŒæ ·çš„ï¼ŒYæ¥ä»£æ›¿abï¼š</p><p>ZYdZYac</p><p>Y=ab</p><p>Z=aa</p><p>åŒæ ·çš„ï¼ŒZYå‡ºç°çš„é¢‘ç‡å¤§ï¼Œæˆ‘ä»¬ç”¨Xæ¥æ›¿ä»£ZYï¼š</p><p>XdXac</p><p>X=ZY</p><p>Y=ab</p><p>Z=aa</p><p>æœ€åï¼Œè¿ç»­ä¸¤ä¸ªå­—ç¬¦çš„é¢‘ç‡éƒ½ä¸º1äº†ï¼Œä¹Ÿå°±ç»“æŸäº†ã€‚å°±æ˜¯è¿™ä¹ˆç®€å•ã€‚</p><p>è§£ç çš„æ—¶å€™ï¼Œå°±æŒ‰ç…§ç›¸åçš„é¡ºåºæ›´æ–°æ›¿æ¢å³å¯ã€‚</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      BPEæ˜¯æ•°æ®å‹ç¼©ï¼Œå¸¸ç”¨äºNLPä»»åŠ¡ä¸­
    
    </summary>
    
    
      <category term="ç®—æ³•" scheme="http://yoursite.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="ç®—æ³•" scheme="http://yoursite.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-04-åšå®¢ä¼˜åŒ–ä»¥åŠé—®é¢˜è§£å†³</title>
    <link href="http://yoursite.com/2020/08/04/2020-08-04-%E5%8D%9A%E5%AE%A2%E4%BC%98%E5%8C%96%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2020/08/04/2020-08-04-%E5%8D%9A%E5%AE%A2%E4%BC%98%E5%8C%96%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98/</id>
    <published>2020-08-04T09:45:51.000Z</published>
    <updated>2020-08-10T13:19:31.332Z</updated>
    
    <content type="html"><![CDATA[<h3 id="ä¿®æ”¹git-bashçš„é»˜è®¤æ‰“å¼€å·¥ä½œè·¯å¾„">ä¿®æ”¹Git Bashçš„é»˜è®¤æ‰“å¼€å·¥ä½œè·¯å¾„</h3><p>æˆ‘æ¯æ¬¡æƒ³åœ¨æˆ‘çš„åšå®¢æ–‡ä»¶å¤¹é‡Œè¿›å…¥git bashï¼Œå¿…é¡»è¦æ‰“å¼€æ–‡ä»¶å¤¹æ‰èƒ½è¿›å…¥ï¼Œæ“ä½œç¹çï¼Œäºæ˜¯åœ¨æ¡Œé¢å»ºç«‹git bash å¿«æ·æ–¹å¼ï¼Œå¹¶å°†git bash çš„é»˜è®¤æ‰“å¼€è·¯å¾„æ›´æ”¹ä¸ºæˆ‘çš„åšå®¢æ–‡ä»¶å¤¹ä¸‹ï¼Œè¿™æ ·ç‚¹å‡»å›¾æ ‡ï¼Œå³èƒ½è¿›å…¥æœ¬åœ°gitä»“åº“</p><p>1.æ‰¾åˆ°git bashï¼Œå³é”®å±æ€§ï¼Œå¯ä»¥çœ‹åˆ°ç›®æ ‡æ åŠèµ·å§‹ä½ç½®æ ã€‚</p><p><img src="https://i.loli.net/2020/08/04/tPL1uzsVApn5FvC.png" alt="img" style="zoom: 80%;"></p><p>å°†ç›®æ ‡æ ä¸­çš„ --cd-to-home å»æ‰ï¼›å°†èµ·å§‹ä½ç½®ä¸­å¡«å†™ä¸ºæœ¬åœ°gitä»“åº“çš„è·¯å¾„ï¼Œå³å¯å®Œæˆæ“ä½œã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåšå®¢æ–‡ä»¶å¤¹ä½ç½®åœ¨<code>E:\myBlog</code></p><p><img src="https://i.loli.net/2020/08/04/Vw7Kg3U2OIZQ6R9.png" alt="image-20200804181206322" style="zoom: 50%;"></p><p>æ³¨ï¼š è‹¥åœ¨æ–‡ä»¶å¤¹é‡Œè¿›å…¥ git bashï¼Œåˆ™ç„¶åæŒ‰ä¸‹<code>shift+F10</code> ï¼ˆæ¿€æ´»å³é”®èœå•æ ï¼‰ï¼Œå†æŒ‰<code>s</code>è·³è½¬åˆ°git bashï¼Œæœ€åæŒ‰ä¸‹<code>enter</code>å³å¯</p><h3 id="åšå®¢æ‰“å¼€ç½‘ç«™å’Œæ›´æ–°ä¸å®Œå…¨">åšå®¢æ‰“å¼€ç½‘ç«™å’Œæ›´æ–°ä¸å®Œå…¨</h3><p>åœ¨è¿™å‡ å¤©åœ¨æœ¬åœ°æ–‡ä»¶å¤¹æ›´æ–°å®Œé…ç½®æ–‡ä»¶å¯¹åšå®¢è¿›è¡Œä¸ªæ€§åŒ–è®¾ç½®æ—¶ï¼Œä½¿ç”¨<code>localhost:4000</code>è®¿é—®æœ¬åœ°blogå¯ä»¥æ­£å¸¸æ˜¾ç¤ºæ›´æ”¹åçš„æ ·å¼ï¼Œä½†æ˜¯åœ¨ç™»å½•ç½‘ç«™åŸŸåå°±ä¼šå‡ºç°ä¸ä¸€è‡´çš„ç°è±¡ï¼Œæœ‰æ—¶ä¼šå“åº”é€Ÿåº¦æ…¢ï¼Œå»¶æ—¶é«˜ï¼Œç”šè‡³è¿æ¥è¶…æ—¶ã€‚</p><p>åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ä¸€ç›´æ²¡å‘ç°é—®é¢˜ï¼Œå› ä¸ºæœ¬åœ°localhostå’Œç½‘ç«™ä¸ä¸€è‡´å°±ä¸èƒ½ç†è§£ã€‚åæ¥æ‰å‘ç°ï¼Œæˆ‘çš„hexoå‘½ä»¤å†™é”™äº†ã€‚æœ¬åº”è¯¥æ˜¯hexo clean ï¼Œæˆ‘é”™å†™ä¸ºhexo clearï¼Œå¯¼è‡´ä¸èƒ½è½»è§¦ç¼“å­˜ï¼Œæ‰€ä»¥åœ¨ç½‘ç«™ä¸­ä¸èƒ½åŠæ—¶æ›´æ–°æ˜¾ç¤ºã€‚</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo clean <span class="comment"># æ¸…é™¤ç¼“å­˜ï¼Œç½‘é¡µæ­£å¸¸æƒ…å†µä¸‹å¯ä»¥å¿½ç•¥æ­¤å‘½ä»¤</span></span><br></pre></td></tr></tbody></table></figure><h3 id="åšå®¢æ— æ³•è¿æ¥">åšå®¢æ— æ³•è¿æ¥</h3><p>æœ¬åœ°æœåŠ¡å™¨å¯ä»¥æ­£å¸¸æ˜¾ç¤ºï¼Œä½†æ˜¯åšå®¢è¿æ¥ä¸ä¸Š</p><p>å¦‚ä½•å¯ä»¥ping é€šï¼Œåˆ™ä»£è¡¨ä¸æ˜¯åŸŸåæ–¹é¢çš„é—®é¢˜ï¼Œåº”è¯¥å°±æ˜¯æœåŠ¡å™¨çš„é—®é¢˜ï¼Œå¯èƒ½æ˜¯éƒ¨ç½²åœ¨githubä¸Šï¼Œæ‰€ä»¥ä¼šæœ‰ç‚¹æ…¢ï¼Œåç»­å‡†å¤‡ä¹°ä¸€ä¸ªé˜¿é‡Œäº‘çš„æœåŠ¡å™¨ã€‚</p><p>è§£å†³ï¼š</p><p>1.åšå®¢æ­£åœ¨åŠ è½½ï¼Œ ç­‰ä¸€æ®µæ—¶é—´åˆ·æ–°</p><p>2.å¦‚æœè¿˜æ˜¯ä¸è¡Œï¼Œåˆ™æ¸…ç†chromeçš„cookieç¼“å­˜å†åˆ·æ–°å³å¯ï¼Œ å¯ä»¥è§£å†³é—®é¢˜ï¼Œä½†æ˜¯æ“ä½œéº»çƒ¦ã€‚</p><figure><img src="https://i.loli.net/2020/08/10/Iwpk2yb5OAjuoKf.png" alt="image-20200810152929992"><figcaption>image-20200810152929992</figcaption></figure><p>3.æ¸…é™¤ç‰¹å®šç½‘ç«™ä¸‹çš„ç¼“å­˜ï¼š</p><p>æ‰“å¼€å¼€å‘è€…å·¥å…·ï¼ˆF12ï¼‰ï¼Œé€‰æ‹© Networkâ€”â€”Disable cache ã€‚éœ€è¦æ¸…é™¤æŸç½‘ç«™ç¼“å­˜æ—¶ F12 æ‰“å¼€å¼€å‘è€…å·¥å…·å°±ä¼šè‡ªåŠ¨æ¸…é™¤è¿™ä¸ªç½‘ç«™çš„ç¼“å­˜ï¼Œè€Œä¸å¿…æ¸…é™¤æ‰€æœ‰ç½‘ç«™çš„ç¼“å­˜äº†ã€‚</p><p>4.å¦‚æœåœ¨æ–‡ç« æ ‡é¢˜ä¸­ä½¿ç”¨äº†å½“å¤©çš„æ—¥æœŸï¼Œå¯èƒ½æ— æ³•åŠæ—¶å¾—åˆ°é¡µé¢æ›´æ–°ã€‚å› ä¸ºGithubä½¿ç”¨äº†æ ¼æ—å°¼æ²»æ ‡å‡†æ—¶é—´ï¼Œä¹Ÿå°±æ˜¯UTCã€‚ä¸­å›½æ˜¯ä¸œå…«æ—¶åŒºï¼ŒUTC+8ï¼Œå¯¹äºhexoæ¥è¯´æ˜¯ä¸€ä¸ªæœªæ¥çš„æ—¶é—´ï¼Œæ‰€ä»¥æ–°çš„Postsä¸ä¼šè¢«æ¸²æŸ“ã€‚</p><p>åœ¨hexoé…ç½®æ–‡ä»¶<code>_config.yml</code>ä¸­è®¾ç½®<code>timezone: Asia/Shanghai</code> (æœ‰æ•ˆè§£å†³é—®é¢˜) <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png?v8">â­</span></p><p>å‚è€ƒ</p><blockquote><p>åšå®¢æ— æ³•æ›´æ–°postæ–‡ç«  https://www.jianshu.com/p/b73c28e77760</p></blockquote><p>cloneçš„æ—¶å€™æ— æ³•clone nextçš„å†…å®¹</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      è®°å½•åœ¨ä¼˜åŒ–è‡ªå·±åšå®¢çš„æ—¶å€™é‡åˆ°çš„é—®é¢˜ä»¥åŠè§£å†³æ–¹æ¡ˆ
    
    </summary>
    
    
      <category term="åšå®¢" scheme="http://yoursite.com/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="æ•…éšœæ’é™¤" scheme="http://yoursite.com/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-01-hexo+nextä¸ªæ€§åŒ–è®¾ç½®</title>
    <link href="http://yoursite.com/2020/08/01/2020-08-10-hexo-next%E4%B8%AA%E6%80%A7%E5%8C%96%E8%AE%BE%E7%BD%AE/"/>
    <id>http://yoursite.com/2020/08/01/2020-08-10-hexo-next%E4%B8%AA%E6%80%A7%E5%8C%96%E8%AE%BE%E7%BD%AE/</id>
    <published>2020-08-01T09:28:10.000Z</published>
    <updated>2020-08-10T11:27:23.435Z</updated>
    
    <content type="html"><![CDATA[<p>ä¸€äº›åŸºæœ¬çš„ä¸ªæ€§åŒ–è®¾ç½®å¯ä»¥å‚è€ƒå…¶å®ƒåšå®¢ï¼Œæœ¬æ–‡åªè®°å½•åœ¨æˆ‘å®Œæˆ</p><h3 id="ä¿®æ”¹æ–‡ç« åº•éƒ¨çš„é‚£ä¸ªå¸¦å·çš„æ ‡ç­¾">ä¿®æ”¹æ–‡ç« åº•éƒ¨çš„é‚£ä¸ªå¸¦#å·çš„æ ‡ç­¾</h3><p>åœ¨åŸæœ¬nextè‡ªå¸¦çš„æ ‡ç­¾æ ¼å¼å¦‚ä¸‹æ‰€ç¤ºï¼š</p><figure><img src="https://i.loli.net/2020/08/10/GLtxuMpYd7WXmaV.png" alt="image-20200810180543537"><figcaption>image-20200810180543537</figcaption></figure><p>å‰é¢çš„<code>#</code>ä¸å¤ªå¥½çœ‹ï¼Œåœ¨è¿™é‡Œå¯ä»¥æ·»åŠ <code>font awesome</code>çš„<code>icon</code>ï¼Œä¸ªæ€§åŒ–æ ‡ç­¾æ˜¾ç¤º</p><p>ä¿®æ”¹æ¨¡æ¿ <code>/themes/next/layout/_macro/post.swig</code>ï¼Œæœç´¢ <code>rel="tag"</code>ï¼Œå°†<code>rel="tag"&gt;</code>æ¢æˆ<code>rel="tag"&lt;i class="fa fa-tag"&gt;&lt;/i&gt;</code> ï¼Œå…¶ä¸­"fa fa-tag"å¯ä»¥æ ¹æ®<code>font awesome</code>é‡Œè‡ªå·±é€‰æ‹©å–œæ¬¢çš„<code>icon</code></p><p>å› ä¸ºåœ¨ä»£ç ä¸­ä¸éœ€è¦<code>tag_indicate</code>ï¼Œæ‰€ä»¥å¯ä»¥å°†éƒ¨åˆ†ä»£ç åˆ å»ï¼Œå¦‚å›¾ä¸­çº¢æ¡†éƒ¨åˆ†</p><figure><img src="https://i.loli.net/2020/08/10/2zhlEdQjqyTcPRo.png" alt="image-20200810181951506"><figcaption>image-20200810181951506</figcaption></figure><p>ä¸ªæ€§åŒ–åå¦‚ä¸‹æ‰€ç¤ºï¼š</p><figure><img src="https://i.loli.net/2020/08/10/tuvBmHFRZ8JMk3S.png" alt="image-20200810180207065"><figcaption>image-20200810180207065</figcaption></figure><h3 id="hexo-æ–‡ç« åŠ å¯†">hexo æ–‡ç« åŠ å¯†</h3><blockquote><p><a href="https://vic.kim/2019/05/27/Hexoæ–‡ç« åŠ å¯†/" target="_blank" rel="noopener">https://vic.kim/2019/05/27/Hexo%E6%96%87%E7%AB%A0%E5%8A%A0%E5%AF%86/</a></p></blockquote><h3 id="åœ¨æ¯ç¯‡æ–‡ç« æœ«å°¾æ·»åŠ æœ¬æ–‡ç»“æŸæ ‡è®°">åœ¨æ¯ç¯‡æ–‡ç« æœ«å°¾æ·»åŠ â€œæœ¬æ–‡ç»“æŸâ€æ ‡è®°</h3><p>ä¿®æ”¹æ¨¡æ¿ <code>/themes/next/layout/_macro/post.swig</code>ï¼Œåœ¨<code></code>ä»£ç è¡Œä¸­æ·»åŠ <code>&lt;div style="text-align:center;color: #ccc;font-size:14px;"&gt;-------------æœ¬æ–‡ç»“æŸ&lt;i class="fa fa-paw"&gt;&lt;/i&gt;æ„Ÿè°¢æ‚¨çš„é˜…è¯»-------------&lt;/div&gt;</code>å³å¯å®Œæˆè®¾ç½®ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼Œçº¢æ¡†å†…æ˜¯æ·»åŠ å†…å®¹</p><figure><img src="https://i.loli.net/2020/08/10/TQEoIcbKLGaC5dr.png" alt="image-20200810182801218"><figcaption>image-20200810182801218</figcaption></figure><p>ä¸ªæ€§åŒ–å¦‚ä¸‹æ‰€ç¤ºï¼š</p><figure><img src="https://i.loli.net/2020/08/10/dCvbzpGBhs6excl.png" alt="image-20200810183022935"><figcaption>image-20200810183022935</figcaption></figure><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      è®°å½•åœ¨åšå®¢ä¸ªæ€§åŒ–è®¾ç½®è¿‡ç¨‹
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-08-01-teacher-foringä»¥åŠè§£å†³</title>
    <link href="http://yoursite.com/2020/08/01/2020-08-01-teacher-foring%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3/"/>
    <id>http://yoursite.com/2020/08/01/2020-08-01-teacher-foring%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3/</id>
    <published>2020-08-01T01:29:57.000Z</published>
    <updated>2020-08-01T02:18:22.987Z</updated>
    
    <content type="html"><![CDATA[<script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script&gt;
        document.querySelectorAll(&#39;.github-emoji&#39;)
          .forEach(el =&gt; {
            if (!el.dataset.src) { return; }
        
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-07-30-pytorchä½¿ç”¨æ‰‹å†Œ</title>
    <link href="http://yoursite.com/2020/07/30/2020-07-30-pytorch%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/"/>
    <id>http://yoursite.com/2020/07/30/2020-07-30-pytorch%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/</id>
    <published>2020-07-30T09:26:32.000Z</published>
    <updated>2020-07-30T09:30:59.629Z</updated>
    
    <content type="html"><![CDATA[<h3 id="pythonä¸­å¯¹äºå¯¹è±¡çš„æ‹·è´åˆ†ä¸ºæµ…æ‹·è´copyå’Œæ·±æ‹·è´deepcopyä¸¤ç§æ–¹å¼å…¶ä¸­æµ…æ‹·è´ç”±å®Œæˆè€Œæ·±æ‹·è´ç”±copyæ¨¡å—ä¸­deepcopyå‡½æ•°æ‹…ä»»"><strong>pythonä¸­å¯¹äºå¯¹è±¡çš„æ‹·è´åˆ†ä¸ºæµ…æ‹·è´(copy)å’Œæ·±æ‹·è´(deepcopy)ä¸¤ç§æ–¹å¼ã€‚å…¶ä¸­æµ…æ‹·è´ç”±â€œ=â€å®Œæˆã€‚è€Œæ·±æ‹·è´ç”±copyæ¨¡å—ä¸­deepcopy()å‡½æ•°æ‹…ä»»ã€‚</strong></h3><h3 id="æµ…æ‹·è´å’Œæ·±æ‹·è´çš„åŒºåˆ«æ˜¯æµ…æ‹·è´åªæ˜¯å°†åŸå¯¹è±¡åœ¨å†…å­˜ä¸­å¼•ç”¨åœ°å€æ‹·è´è¿‡æ¥äº†è®©æ–°çš„å¯¹è±¡æŒ‡å‘è¿™ä¸ªåœ°å€è€Œæ·±æ‹·è´æ˜¯å°†è¿™ä¸ªå¯¹è±¡çš„æ‰€æœ‰å†…å®¹éå†æ‹·è´è¿‡æ¥äº†ç›¸å½“äºè·ŸåŸæ¥æ²¡å…³ç³»äº†æ‰€ä»¥å¦‚æœä½ è¿™æ—¶å€™ä¿®æ”¹åŸæ¥å¯¹è±¡çš„å€¼è·Ÿä»–æ²¡å…³ç³»äº†ä¸ä¼šéšä¹‹æ›´æ”¹"><strong><em>*æµ…æ‹·è´å’Œæ·±æ‹·è´çš„åŒºåˆ«æ˜¯ï¼šæµ…æ‹·è´åªæ˜¯å°†åŸå¯¹è±¡åœ¨å†…å­˜ä¸­å¼•ç”¨åœ°å€æ‹·è´è¿‡æ¥äº†ã€‚è®©æ–°çš„å¯¹è±¡æŒ‡å‘è¿™ä¸ªåœ°å€ã€‚è€Œæ·±æ‹·è´æ˜¯å°†è¿™ä¸ªå¯¹è±¡çš„æ‰€æœ‰å†…å®¹éå†æ‹·è´è¿‡æ¥äº†ï¼Œç›¸å½“äºè·ŸåŸæ¥æ²¡å…³ç³»äº†ï¼Œæ‰€ä»¥å¦‚æœä½ è¿™æ—¶å€™ä¿®æ”¹åŸæ¥å¯¹è±¡çš„å€¼è·Ÿä»–æ²¡å…³ç³»äº†ï¼Œä¸ä¼šéšä¹‹æ›´æ”¹ã€‚*</em></strong></h3><h3 id="æµ…æ‹·è´çš„ä½¿ç”¨"><strong>1.æµ…æ‹·è´"="çš„ä½¿ç”¨</strong></h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.ä½¿ç”¨=å¤åˆ¶ä¸å¯å˜å¯¹è±¡çš„å€¼ï¼Œä»¥åŠå¤åˆ¶ä»¥åä¿®æ”¹å…¶å€¼åçš„å˜åŒ–ã€‚</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val1 = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val2 = val1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">"val1 is :{0},val2 is :{1}"</span>.format(val1,val2))<span class="comment">#val1 is :1000,val2 is :1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(id(val1),id(val2))  <span class="comment">#34052192 34052192</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#è¿™æ—¶å€™ä¿®æ”¹val1çš„å€¼ï¼Œå°½ç®¡val2æŒ‡å‘val1.ä½†å› ä¸ºval1æ˜¯ä¸å¯å˜ç±»å‹ï¼Œä¿®æ”¹å…¶å€¼ï¼Œä¼šé‡æ–°ç»™æ–°å€¼åˆ†é…å†…å­˜ï¼Œç„¶åæŒ‡å‘ä»–ã€‚</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val1 += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(val1,id(val1),val2,id(val2)) <span class="comment">#1001 10131616 1000 10131568  å€¼ä¸ä¸€æ ·ï¼Œå†…å­˜åœ°å€ä¹Ÿä¸ä¸€æ ·äº†</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#1.ä½¿ç”¨=å¤åˆ¶å¯å˜å¯¹è±¡çš„å€¼ï¼Œä»¥åŠå¤åˆ¶ä»¥åä¿®æ”¹å…¶å€¼åçš„å˜åŒ–ã€‚</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls1 =[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls2 = ls1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(id(ls1),id(ls2)) <span class="comment">#43702792 43702792 ç›´æ¥ä½¿ç”¨=å¤åˆ¶å˜é‡ï¼Œå†…å­˜åœ°å€ä¸€æ ·ï¼Œå€¼ä¹Ÿä¸€æ ·ã€‚</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(ls1,ls2) <span class="comment">#[1, 2, 3, 4] [1, 2, 3, 4]ç›´æ¥ä½¿ç”¨=å¤åˆ¶å˜é‡ï¼Œå†…å­˜åœ°å€ä¸€æ ·ï¼Œå€¼ä¹Ÿä¸€æ ·ã€‚</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#è¿™æ—¶å€™ä¿®æ”¹å¯å˜å¯¹çš„å€¼,å› ä¸ºå…¶å€¼å¯å˜ï¼Œæ‰€ä»¥åªéœ€è¦åœ¨åŸå†…å­˜åœ°å€ä¸Šä¿®æ”¹å³å¯ã€‚</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls1.append(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(id(ls1),id(ls2)) <span class="comment">#å¯å˜å¯¹è±¡ä¿®æ”¹å…¶å€¼ï¼Œå†…å­˜å¼•ç”¨ä¸å˜</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(ls1,ls2) <span class="comment">#[1, 2, 3, 4, 5] [1, 2, 3, 4, 5] å› ä¸ºä¸¤ä¸ªå˜é‡çš„å†…å­˜æŒ‡å‘ä¸€æ ·ï¼Œæ‰€ä»¥å€¼ä¹Ÿä¸€æ ·ã€‚</span></span><br></pre></td></tr></tbody></table></figure><h3 id="æ·±æ‹·è´copy.deepcopyå‡½æ•°">2.æ·±æ‹·è´ï¼šcopy.deepcopy()å‡½æ•°</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1.ä½¿ç”¨copy.deepcopy()æ‹·è´ä¸å¯å˜å¯¹è±¡çš„å€¼ï¼Œä»¥åŠå¤åˆ¶ä»¥åä¿®æ”¹å…¶å€¼åçš„å˜åŒ–ã€‚</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val1 = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val2 = copy.deepcopy(val1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">"val1 is :{0},val2 is :{1}"</span>.format(val1,val2))<span class="comment">#val1 is :1000,val2 is :1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(id(val1),id(val2))  <span class="comment">#33717408 33717408 å¯¹äºä¸å¯å˜å¯¹è±¡ï¼Œæ·±åº¦æ‹·è´å†…å­˜åœ°å€æ²¡æœ‰ä¿®æ”¹ã€‚</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val1 += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(val1,id(val1),val2,id(val2)) <span class="comment">#1001 33717904 1000 33717408</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#1.ä½¿ç”¨copy.deepcopy()å¤åˆ¶å¯å˜å¯¹è±¡çš„å€¼ï¼Œä»¥åŠå¤åˆ¶ä»¥åä¿®æ”¹å…¶å€¼åçš„å˜åŒ–ã€‚</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls1 =[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls2 = copy.deepcopy(ls1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(id(ls1),id(ls2)) <span class="comment">#34628472 34628712 æ³¨æ„å¯¹äºå¯å˜å¯¹è±¡æ·±åº¦æ‹·è´åå†…å­˜åœ°å€éƒ½ä¿®æ”¹äº†ã€‚</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(ls1,ls2) <span class="comment">#[1, 2, 3, 4] [1, 2, 3, 4]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls1.append(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(id(ls1),id(ls2)) <span class="comment">#34628472 34628712</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(ls1,ls2) <span class="comment">#[1, 2, 3, 4, 5] [1, 2, 3, 4] #æ³¨æ„è¿™ä¸ªæ—¶å€™ls2çš„å€¼æ²¡æœ‰éšç€ls1ä¿®æ”¹ã€‚</span></span><br></pre></td></tr></tbody></table></figure><h3 id="æ€»ç»“å…¶å®å¯¹äºæµ…æ‹·è´å’Œæ·±æ‹·è´æ¥è¯´å¦‚æœæ‹·è´å¯¹è±¡éƒ½æ˜¯ä¸å¯å˜å¯¹è±¡çš„è¯é‚£ä¹ˆä¸¤è€…æ•ˆæœæ˜¯ä¸€æ ·çš„å¦‚æœæ˜¯å¯å˜å¯¹è±¡çš„è¯æ‹·è´çš„æ–¹å¼åªæ˜¯æ‹·è´äº†å†…å­˜ä¸­çš„åœ°å€å¼•ç”¨ä¸¤ä¸ªå¯¹è±¡çš„åœ°å€å¼•ç”¨ä¸€æ ·æ‰€ä»¥ä¸¤ä¸ªå¯¹è±¡çš„å€¼ä¼šéšç€ä¸€æ–¹çš„ä¿®æ”¹è€Œä¿®æ”¹è€Œå¯¹äºdeepcopyæ¥è¯´å¦‚æœæ˜¯å¯å˜å¯¹è±¡çš„è¯é‚£ä¹ˆæ‹·è´å†…å®¹åæ–°å¯¹è±¡çš„å†…å­˜åœ°å€ä¹Ÿä¼šé‡æ–°åˆ†é…è·ŸåŸæ¥çš„å†…å­˜åœ°å€ä¸ä¸€æ ·äº†æ‰€ä»¥ä¸¤è€…ä»»æ„ä¿®æ”¹å˜é‡çš„å†…å®¹ä¸ä¼šå¯¹å¦ä¸€æ–¹é€ æˆå½±å“">æ€»ç»“ï¼šå…¶å®å¯¹äºæµ…æ‹·è´å’Œæ·±æ‹·è´æ¥è¯´ï¼Œå¦‚æœæ‹·è´å¯¹è±¡éƒ½æ˜¯ä¸å¯å˜å¯¹è±¡çš„è¯ï¼Œé‚£ä¹ˆä¸¤è€…æ•ˆæœæ˜¯ä¸€æ ·çš„ã€‚å¦‚æœæ˜¯å¯å˜å¯¹è±¡çš„è¯ï¼Œâ€œ=â€æ‹·è´çš„æ–¹å¼ï¼Œåªæ˜¯æ‹·è´äº†å†…å­˜ä¸­çš„åœ°å€å¼•ç”¨ï¼Œä¸¤ä¸ªå¯¹è±¡çš„åœ°å€å¼•ç”¨ä¸€æ ·ï¼Œæ‰€ä»¥ä¸¤ä¸ªå¯¹è±¡çš„å€¼ä¼šéšç€ä¸€æ–¹çš„ä¿®æ”¹è€Œä¿®æ”¹ã€‚è€Œå¯¹äºdeepcopy()æ¥è¯´ï¼Œå¦‚æœæ˜¯å¯å˜å¯¹è±¡çš„è¯ï¼Œé‚£ä¹ˆæ‹·è´å†…å®¹åæ–°å¯¹è±¡çš„å†…å­˜åœ°å€ä¹Ÿä¼šé‡æ–°åˆ†é…ï¼Œè·ŸåŸæ¥çš„å†…å­˜åœ°å€ä¸ä¸€æ ·äº†ã€‚æ‰€ä»¥ä¸¤è€…ä»»æ„ä¿®æ”¹å˜é‡çš„å†…å®¹ä¸ä¼šå¯¹å¦ä¸€æ–¹é€ æˆå½±å“ã€‚</h3><h3 id="æ³¨æ„ä¸€ä¸ªç‰¹æ®Šçš„copyè·Ÿæ·±æµ…æ‹·è´éƒ½æœ‰åŒºåˆ«æ…ç”¨">3.æ³¨æ„ä¸€ä¸ªç‰¹æ®Šçš„copy(),è·Ÿæ·±æµ…æ‹·è´éƒ½æœ‰åŒºåˆ«ï¼Œæ…ç”¨ã€‚</h3><ol type="1"><li>copy.copyå¯¹äºå¯å˜ç±»å‹ï¼Œä¼šè¿›è¡Œæµ…æ‹·è´</li><li>copy.copyå¯¹äºä¸å¯å˜ç±»å‹ï¼Œä¸ä¼šæ‹·è´ï¼Œä»…ä»…æ˜¯æŒ‡å‘</li></ol><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span>ä½¿ç”¨copy()æ‹·è´ä¸å¯å˜å¯¹è±¡</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val1 = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val2 = copy.copy(val1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(val1,val2)<span class="comment">##1000 1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(id(val1),id(val2))<span class="comment">#8551568 8551568</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">2.</span>ä½¿ç”¨copyï¼ˆï¼‰æ‹·è´å¯å˜å¯¹è±¡</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls1 =[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls2 = copy.copy(ls1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ls1.append(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(ls1,ls2)  <span class="comment">#[1, 2, 3, 4, 5] [1, 2, 3, 4]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">çœ‹ä¸Šå»copy()å‡½æ•°æ•ˆæœå’Œdeepcopy()æ•ˆæœä¸€æ ·ï¼Œå¯å˜å¯¹è±¡æ‹·è´åå€¼ä¹Ÿæ²¡æœ‰éšç€ä¸€ä¸ªå¯¹è±¡çš„ä¿®æ”¹è€Œä¿®æ”¹ã€‚</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ç„¶åçœŸå®æƒ…å†µçœŸæ˜¯è¿™æ ·å˜›ï¼Ÿè¯·çœ‹ä¸‹é¢çš„æ¡ˆä¾‹ï¼ŒåŒæ ·æ˜¯æ‹·è´å¯å˜å¯¹è±¡ã€‚</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">origin = [<span class="number">1</span>, <span class="number">2</span>, [<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cop1 = copy.copy(origin)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cop2 = copy.deepcopy(origin)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">origin[<span class="number">2</span>][<span class="number">0</span>] = <span class="string">"hey!"</span>  <span class="comment">#ä¿®æ”¹æ•°æ®æºçš„å€¼</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(cop1,cop2) <span class="comment">#[1, 2, ['hey!', 4]] [1, 2, [3, 4]]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">å¾ˆæ˜¾ç„¶è¿™æ—¶copyï¼ˆï¼‰å‡½æ•°æ‹·è´çš„å€¼éšç€åŸå¯¹è±¡çš„å€¼ä¿®æ”¹äº†ï¼Œè€Œdeepcopy()çš„å€¼æ²¡æœ‰éšç€åŸå¯¹è±¡çš„å€¼ä¿®æ”¹ã€‚</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ä¸»è¦æ˜¯å› ä¸ºdeepcopyä¼šå°†å¤æ‚å¯¹è±¡çš„æ¯ä¸€å±‚å¤åˆ¶ä¸€ä¸ªå•ç‹¬çš„ä¸ªä½“å‡ºæ¥å¯¹äºcopyï¼ˆï¼‰å‡½æ•°è¦æ…ç”¨ï¼Œæ…ç”¨ã€‚</span><br></pre></td></tr></tbody></table></figure><p>ç¥ç»ç½‘ç»œçš„å…¸å‹å¤„ç†å¦‚ä¸‹æ‰€ç¤ºï¼š</p><h3 id="å®šä¹‰å¯å­¦ä¹ å‚æ•°çš„ç½‘ç»œç»“æ„å †å å„å±‚å’Œå±‚çš„è®¾è®¡-2.-æ•°æ®é›†è¾“å…¥-3.-å¯¹è¾“å…¥è¿›è¡Œå¤„ç†ç”±å®šä¹‰çš„ç½‘ç»œå±‚è¿›è¡Œå¤„ç†ä¸»è¦ä½“ç°åœ¨ç½‘ç»œçš„å‰å‘ä¼ æ’­-4.-è®¡ç®—loss-ç”±losså±‚è®¡ç®—-5.-åå‘ä¼ æ’­æ±‚æ¢¯åº¦-6.-æ ¹æ®æ¢¯åº¦æ”¹å˜å‚æ•°å€¼æœ€ç®€å•çš„å®ç°æ–¹å¼sgdä¸º-weight-weight---learning_rate-gradient"><strong>1. å®šä¹‰å¯å­¦ä¹ å‚æ•°çš„ç½‘ç»œç»“æ„ï¼ˆå †å å„å±‚å’Œå±‚çš„è®¾è®¡ï¼‰ï¼› 2. æ•°æ®é›†è¾“å…¥ï¼› 3. å¯¹è¾“å…¥è¿›è¡Œå¤„ç†ï¼ˆç”±å®šä¹‰çš„ç½‘ç»œå±‚è¿›è¡Œå¤„ç†ï¼‰,ä¸»è¦ä½“ç°åœ¨ç½‘ç»œçš„å‰å‘ä¼ æ’­ï¼› 4. è®¡ç®—loss ï¼Œç”±Losså±‚è®¡ç®—ï¼› 5. åå‘ä¼ æ’­æ±‚æ¢¯åº¦ï¼› 6. æ ¹æ®æ¢¯åº¦æ”¹å˜å‚æ•°å€¼,æœ€ç®€å•çš„å®ç°æ–¹å¼ï¼ˆSGDï¼‰ä¸º:</strong> weight = weight - learning_rate * gradient</h3><p>ä¸‹é¢æ˜¯åˆ©ç”¨PyTorchå®šä¹‰æ·±åº¦ç½‘ç»œå±‚ï¼ˆOpï¼‰ç¤ºä¾‹ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeatureL2Norm</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        super(FeatureL2Norm, self).__init__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, feature)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        epsilon = <span class="number">1e-6</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#        print(feature.size())</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#        print(torch.pow(torch.sum(torch.pow(feature,2),1)+epsilon,0.5).size())</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        norm = torch.pow(torch.sum(torch.pow(feature,<span class="number">2</span>),<span class="number">1</span>)+epsilon,<span class="number">0.5</span>).unsqueeze(<span class="number">1</span>).expand_as(feature)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> torch.div(feature,norm)</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FeatureRegression</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, output_dim=<span class="number">6</span>, use_cuda=True)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        super(FeatureRegression, self).__init__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">225</span>, <span class="number">128</span>, kernel_size=<span class="number">7</span>, padding=<span class="number">0</span>),</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">64</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">0</span>),</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.linear = nn.Linear(<span class="number">64</span> * <span class="number">5</span> * <span class="number">5</span>, output_dim)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> use_cuda:</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            self.conv.cuda()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            self.linear.cuda()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        x = self.conv(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        x = self.linear(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></tbody></table></figure><p>ç”±ä¸Šä¾‹ä»£ç å¯ä»¥çœ‹åˆ°ï¼Œä¸è®ºæ˜¯åœ¨å®šä¹‰ç½‘ç»œç»“æ„è¿˜æ˜¯å®šä¹‰ç½‘ç»œå±‚çš„æ“ä½œï¼ˆOpï¼‰ï¼Œå‡éœ€è¦å®šä¹‰forwardå‡½æ•°ï¼Œä¸‹é¢çœ‹ä¸€ä¸‹<a href="https://pytorch.org/docs/stable/nn.html" target="_blank" rel="noopener">PyTorchå®˜ç½‘</a>å¯¹PyTorchçš„forwardæ–¹æ³•çš„æè¿°ï¼š</p><figure><img src="https://img-blog.csdnimg.cn/20181114105426553.PNG" alt="img"><figcaption>img</figcaption></figure><p>é‚£ä¹ˆè°ƒç”¨forwardæ–¹æ³•çš„å…·ä½“æµç¨‹æ˜¯ä»€ä¹ˆæ ·çš„å‘¢ï¼Ÿ<a href="https://blog.csdn.net/u012436149/article/details/70145598" target="_blank" rel="noopener">å…·ä½“æµç¨‹æ˜¯è¿™æ ·çš„ï¼š</a></p><h3 id="ä»¥ä¸€ä¸ªmoduleä¸ºä¾‹-1.-è°ƒç”¨moduleçš„callæ–¹æ³•-2.-moduleçš„callé‡Œé¢è°ƒç”¨moduleçš„forwardæ–¹æ³•-3.-forwardé‡Œé¢å¦‚æœç¢°åˆ°moduleçš„å­ç±»å›åˆ°ç¬¬1æ­¥å¦‚æœç¢°åˆ°çš„æ˜¯functionçš„å­ç±»ç»§ç»­å¾€ä¸‹-4.-è°ƒç”¨functionçš„callæ–¹æ³•-5.-functionçš„callæ–¹æ³•è°ƒç”¨äº†functionçš„forwardæ–¹æ³•-6.-functionçš„forwardè¿”å›å€¼-7.-moduleçš„forwardè¿”å›å€¼-8.-åœ¨moduleçš„callè¿›è¡Œforward_hookæ“ä½œç„¶åè¿”å›å€¼">ä»¥ä¸€ä¸ªModuleä¸ºä¾‹ï¼š <strong>1. è°ƒç”¨moduleçš„callæ–¹æ³• 2. moduleçš„callé‡Œé¢è°ƒç”¨moduleçš„forwardæ–¹æ³• 3. forwardé‡Œé¢å¦‚æœç¢°åˆ°Moduleçš„å­ç±»ï¼Œå›åˆ°ç¬¬1æ­¥ï¼Œå¦‚æœç¢°åˆ°çš„æ˜¯Functionçš„å­ç±»ï¼Œç»§ç»­å¾€ä¸‹ 4. è°ƒç”¨Functionçš„callæ–¹æ³• 5. Functionçš„callæ–¹æ³•è°ƒç”¨äº†Functionçš„forwardæ–¹æ³•ã€‚ 6. Functionçš„forwardè¿”å›å€¼ 7. moduleçš„forwardè¿”å›å€¼ 8. åœ¨moduleçš„callè¿›è¡Œforward_hookæ“ä½œï¼Œç„¶åè¿”å›å€¼ã€‚</strong></h3><p>ä¸Šè¿°ä¸­â€œè°ƒç”¨moduleçš„callæ–¹æ³•â€æ˜¯æŒ‡nn.Module çš„__call__æ–¹æ³•ã€‚å®šä¹‰__call__æ–¹æ³•çš„ç±»å¯ä»¥å½“ä½œå‡½æ•°è°ƒç”¨ï¼Œå…·ä½“å‚è€ƒPythonçš„é¢å‘å¯¹è±¡ç¼–ç¨‹ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå½“æŠŠå®šä¹‰çš„ç½‘ç»œæ¨¡å‹modelå½“ä½œå‡½æ•°è°ƒç”¨çš„æ—¶å€™å°±è‡ªåŠ¨è°ƒç”¨å®šä¹‰çš„ç½‘ç»œæ¨¡å‹çš„forwardæ–¹æ³•ã€‚nn.Module çš„__call__æ–¹æ³•éƒ¨åˆ†æºç å¦‚ä¸‹æ‰€ç¤ºï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, *input, **kwargs)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   result = self.forward(*input, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> hook <span class="keyword">in</span> self._forward_hooks.values():</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       <span class="comment">#å°†æ³¨å†Œçš„hookæ‹¿å‡ºæ¥ç”¨</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">       hook_result = hook(self, input, result)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="keyword">return</span> result</span><br></pre></td></tr></tbody></table></figure><p>å¯ä»¥çœ‹åˆ°ï¼Œå½“æ‰§è¡Œmodel(x)çš„æ—¶å€™ï¼Œåº•å±‚è‡ªåŠ¨è°ƒç”¨forwardæ–¹æ³•è®¡ç®—ç»“æœã€‚å…·ä½“ç¤ºä¾‹å¦‚ä¸‹ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        super(LeNet, self).__init__()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">layer1 = nn.Sequential()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">layer1.add_module(<span class="string">'conv1'</span>, nn.Conv(<span class="number">1</span>, <span class="number">6</span>, <span class="number">3</span>, padding=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">layer1.add_moudle(<span class="string">'pool1'</span>, nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">self.layer1 = layer1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">layer2 = nn.Sequential()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">layer2.add_module(<span class="string">'conv2'</span>, nn.Conv(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">layer2.add_moudle(<span class="string">'pool2'</span>, nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">self.layer2 = layer2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">layer3 = nn.Sequential()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">layer3.add_module(<span class="string">'fc1'</span>, nn.Linear(<span class="number">400</span>, <span class="number">120</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">layer3.add_moudle(<span class="string">'fc2'</span>, nn.Linear(<span class="number">120</span>, <span class="number">84</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">layer3.add_moudle(<span class="string">'fc3'</span>, nn.Linear(<span class="number">84</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">self.layer3 = layer3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = self.layer1(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = self.layer2(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = self.layer3(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> x</span><br></pre></td></tr></tbody></table></figure><h3 id="model-lenet-y-modelx"><strong>model = LeNet() y = model(x)</strong></h3><p>å¦‚ä¸Šåˆ™è°ƒç”¨ç½‘ç»œæ¨¡å‹å®šä¹‰çš„forwardæ–¹æ³•ã€‚</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      è®°å½•åœ¨é˜…è¯»pytorchä»£ç æ—¶é‡åˆ°çš„çŸ¥è¯†ç‚¹
    
    </summary>
    
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>2020-07-30-å¾…å†™åšå®¢</title>
    <link href="http://yoursite.com/2020/07/30/2020-07-30-%E5%BE%85%E5%86%99%E5%8D%9A%E5%AE%A2/"/>
    <id>http://yoursite.com/2020/07/30/2020-07-30-%E5%BE%85%E5%86%99%E5%8D%9A%E5%AE%A2/</id>
    <published>2020-07-30T08:34:51.000Z</published>
    <updated>2020-08-08T16:59:44.649Z</updated>
    
    <content type="html"><![CDATA[<h3 id="pytorch-ä¸­forwardçš„ä½¿ç”¨ä»¥åŠåŸç†---pytorchä½¿ç”¨">pytorch ä¸­forwardçš„ä½¿ç”¨ä»¥åŠåŸç† --pytorchä½¿ç”¨</h3><p>https://blog.csdn.net/u011501388/article/details/84062483</p><h4 id="é˜…è¯»ä»£ç æ—¶çš„é—®é¢˜-è®°å½•">é˜…è¯»ä»£ç æ—¶çš„é—®é¢˜ è®°å½•</h4><h3 id="section"></h3><h3 id="pytorché‡Œé¢çš„torch.nn.parameterè¯¦è§£">PyTorché‡Œé¢çš„torch.nn.Parameter()è¯¦è§£</h3><p>https://cloud.tencent.com/developer/article/1608348</p><h3 id="è®ºæ–‡é˜…è¯»çš„æ€ç»´å¯¼å›¾">è®ºæ–‡é˜…è¯»çš„æ€ç»´å¯¼å›¾</h3><p>conda å®‰è£…æ–°ç‰ˆæœ¬pythonä¹‹åï¼Œä¼šè¦†ç›–ä¹‹å‰çš„ç‰ˆæœ¬</p><h1 id="linux-æ€æ­»æš‚åœç»§ç»­åå°è¿è¡Œè¿›ç¨‹">LINUX æ€æ­»ã€æš‚åœã€ç»§ç»­ã€åå°è¿è¡Œè¿›ç¨‹</h1><p>ctrl + z</p><p>å¯ä»¥å°†ä¸€ä¸ªæ­£åœ¨å‰å°æ‰§è¡Œçš„å‘½ä»¤æ”¾åˆ°åå°ï¼Œå¹¶ä¸”æš‚åœ</p><p>è‹¥æƒ³æ¢å¤åˆ°å‰å°ï¼Œåˆ™</p><ol type="1"><li>jobs #æŸ¥çœ‹å½“å‰æœ‰å¤šå°‘åœ¨åå°è¿è¡Œçš„å‘½ä»¤ ä¼šæœ‰åºå· jobå·</li><li>fg ã€”<em>job</em>å·ã€• å°†åå°ä¸­çš„å‘½ä»¤è°ƒè‡³å‰å°ç»§ç»­è¿è¡Œ å¦‚ï¼š fg %1</li></ol><p>https://blog.csdn.net/QQ1910084514/article/details/80390671</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      è®°å½•ç­‰å¾…å†™çš„åšå®¢
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-07-28-transformerè§£è¯»-pytorchç‰ˆæœ¬</title>
    <link href="http://yoursite.com/2020/07/28/2020-07-28-transformer-pytorch/"/>
    <id>http://yoursite.com/2020/07/28/2020-07-28-transformer-pytorch/</id>
    <published>2020-07-28T08:43:03.000Z</published>
    <updated>2020-08-12T06:46:18.731Z</updated>
    
    <content type="html"><![CDATA[<h3 id="å‰è¨€">å‰è¨€</h3><p>æœ€è¿‘å‡ å¤©éƒ½åœ¨é˜…è¯»å“ˆä½›pytorchå®ç°transformerçš„ä»£ç ï¼Œä»£ç é£æ ¼å¾ˆå¥½ï¼Œå¾ˆå€¼å¾—å‚è€ƒå’Œç ”è¯»ã€‚å’Œå®éªŒå®¤å¸ˆå…„åˆåœ¨ä¸€èµ·è®¨è®ºäº†å‡ æ¬¡ï¼Œä»£ç æ€è·¯å’Œå®ç°è¿‡ç¨‹åŸºæœ¬éƒ½äº†è§£äº†ï¼Œå¯¹äºåŸè®ºæ–‡ <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">â€œAttention is All You Needâ€</a> ä¸­å…³äºtransformeræ¨¡å‹çš„ç†è§£åˆæ·±å…¥äº†è®¸å¤šã€‚æœç„¶è¦æƒ³äº†è§£æ¨¡å‹ï¼Œè¿˜æ˜¯è¦å¥½å¥½ç ”è¯»å®ç°ä»£ç ã€‚ä»¥ä¾¿äºåé¢è‡ªå·±ç»“åˆæ¨¡å‹çš„ç ”ç©¶ã€‚</p><p>æœ¬ç¯‡æ˜¯å¯¹å®ç°ä»£ç çš„æ³¨é‡Šï¼ŒåŠ ä¸Šäº†è‡ªå·±çš„ç†è§£ï¼Œä¹Ÿä¼šæœ‰ä¸€äº›å‡½æ•°çš„ä»‹ç»æ‰©å……ã€‚</p><h4 id="å‚è€ƒé“¾æ¥">å‚è€ƒé“¾æ¥</h4><blockquote><p>è§£è¯»çš„æ˜¯å“ˆä½›çš„ä¸€ç¯‡transformerçš„pytorchç‰ˆæœ¬å®ç°</p><p>http://nlp.seas.harvard.edu/2018/04/03/attention.html</p><p>å‚è€ƒå¦ä¸€ç¯‡åšå®¢</p><p>http://fancyerii.github.io/2019/03/09/transformer-codes/</p><p>Transformeræ³¨è§£åŠPyTorchå®ç°ï¼ˆä¸Šï¼‰</p><p>https://www.jiqizhixin.com/articles/2018-11-06-10</p><p>Transformeræ³¨è§£åŠPyTorchå®ç°ï¼ˆä¸‹ï¼‰</p><p>https://www.jiqizhixin.com/articles/2018-11-06-18</p><p>è®­ç»ƒè¿‡ç¨‹ä¸­çš„ Maskå®ç°</p><p>https://www.cnblogs.com/wevolf/p/12484972.html</p></blockquote><h3 id="the-annotated-transformer">The Annotated Transformer</h3><figure><img src="https://i.loli.net/2020/07/28/NUAyXWJ5DzHmjuv.png" alt="png"><figcaption>png</figcaption></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># !pip install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl numpy matplotlib spacy torchtext seaborn </span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> math, copy, time</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn</span><br><span class="line">seaborn.set_context(context=<span class="string">"talk"</span>)</span><br></pre></td></tr></tbody></table></figure><p>Transformerä½¿ç”¨äº†Self-Attentionæœºåˆ¶ï¼Œå®ƒåœ¨ç¼–ç æ¯ä¸€è¯çš„æ—¶å€™éƒ½èƒ½å¤Ÿæ³¨æ„(attend to)æ•´ä¸ªå¥å­ï¼Œä»è€Œå¯ä»¥è§£å†³é•¿è·ç¦»ä¾èµ–çš„é—®é¢˜ï¼ŒåŒæ—¶è®¡ç®—Self-Attentionå¯ä»¥ç”¨çŸ©é˜µä¹˜æ³•ä¸€æ¬¡è®¡ç®—æ‰€æœ‰çš„æ—¶åˆ»ï¼Œå› æ­¤å¯ä»¥å……åˆ†åˆ©ç”¨è®¡ç®—èµ„æº(CPU/GPUä¸Šçš„çŸ©é˜µè¿ç®—éƒ½æ˜¯å……åˆ†ä¼˜åŒ–å’Œé«˜åº¦å¹¶è¡Œçš„)ã€‚</p><h3 id="æ¨¡å‹ç»“æ„">æ¨¡å‹ç»“æ„</h3><p>Most competitive neural sequence transduction models have an encoder-decoder structure <a href="https://arxiv.org/abs/1409.0473" target="_blank" rel="noopener">(cite)</a>. Here, <code>the encoder maps an input sequence of symbol representations (x1,â€¦,xn)(x1,â€¦,xn) to a sequence of continuous representations z=(z1,â€¦,zn)z=(z1,â€¦,zn). Given z, the decoder then generates an output sequence (y1,â€¦,ym)(y1,â€¦,ym) of symbols one element at a time.</code> At each step the model is auto-regressive <a href="https://arxiv.org/abs/1308.0850" target="_blank" rel="noopener">(cite)</a>, consuming the previously generated symbols as additional input when generating the next.</p><p><strong>EncoderDecoderå®šä¹‰äº†ä¸€ç§é€šç”¨çš„Encoder-Decoderæ¶æ„</strong>ï¼Œå…·ä½“çš„Encoderã€Decoderã€src_embedã€target_embedå’Œgeneratoréƒ½æ˜¯æ„é€ å‡½æ•°ä¼ å…¥çš„å‚æ•°ã€‚è¿™æ ·æˆ‘ä»¬<strong>åšå®éªŒæ›´æ¢ä¸åŒçš„ç»„ä»¶å°±ä¼šæ›´åŠ æ–¹ä¾¿</strong>ã€‚</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderDecoder</span><span class="params">(nn.Module)</span>:</span> <span class="comment">#å®šä¹‰çš„æ˜¯æ•´ä¸ªæ¨¡å‹ ï¼Œä¸åŒ…æ‹¬generator</span></span><br><span class="line">    </span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">   æ ‡å‡†çš„Encoder-Decoderæ¶æ„ã€‚è¿™æ˜¯å¾ˆå¤šæ¨¡å‹çš„åŸºç¡€</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    classé‡Œï¼Œ initå‡½æ•°æ˜¯å®ä¾‹åŒ–ä¸€ä¸ªå¯¹è±¡çš„æ—¶å€™ç”¨äºåˆå§‹åŒ–å¯¹è±¡ç”¨çš„</span></span><br><span class="line"><span class="string">    forwardå‡½æ•°æ˜¯åœ¨æ‰§è¡Œè°ƒç”¨å¯¹è±¡çš„æ—¶å€™ä½¿ç”¨ï¼Œ éœ€è¦ä¼ å…¥æ­£ç¡®çš„å‚æ•° </span></span><br><span class="line"><span class="string">    åœ¨æ‰§è¡Œæ—¶å€™è°ƒç”¨__call__æ–¹æ³•ï¼Œç„¶åå†callé‡Œå†è°ƒç”¨forward</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, encoder, decoder, src_embed, tgt_embed, generator)</span>:</span></span><br><span class="line">        super(EncoderDecoder, self).__init__()</span><br><span class="line">        <span class="comment"># encoderå’Œdecoderéƒ½æ˜¯æ„é€ çš„æ—¶å€™ä¼ å…¥çš„ï¼Œè¿™æ ·ä¼šéå¸¸çµæ´»</span></span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line">        <span class="comment"># æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€çš„embeddingï¼ŒåŒ…æ‹¬embeddingå±‚å’Œposition encodeå±‚</span></span><br><span class="line">        self.src_embed = src_embed <span class="comment">#æºæ•°æ®é›†çš„åµŒå…¥</span></span><br><span class="line">        self.tgt_embed = tgt_embed <span class="comment">#ç›®æ ‡æ•°æ®é›†çš„åµŒå…¥ï¼Œä½œä¸ºdecoderçš„è¾“å…¥</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        generatoråé¢ä¼šè®²åˆ°ï¼Œå°±æ˜¯æ ¹æ®Decoderçš„éšçŠ¶æ€è¾“å‡ºå½“å‰æ—¶åˆ»çš„è¯</span></span><br><span class="line"><span class="string">    åŸºæœ¬çš„å®ç°å°±æ˜¯éšçŠ¶æ€è¾“å…¥ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œå…¨è¿æ¥å±‚çš„è¾“å‡ºå¤§å°æ˜¯è¯çš„ä¸ªæ•°</span></span><br><span class="line"><span class="string">ç„¶åæ¥ä¸€ä¸ªsoftmaxå˜æˆæ¦‚ç‡</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.generator = generator</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, src, tgt, src_mask, tgt_mask)</span>:</span></span><br><span class="line">        <span class="comment">#é¦–å…ˆè°ƒç”¨encodeæ–¹æ³•å¯¹è¾“å…¥è¿›è¡Œç¼–ç ï¼Œç„¶åè°ƒç”¨decodeæ–¹æ³•è§£ç </span></span><br><span class="line">        <span class="keyword">return</span> self.decode(self.encode(src, src_mask), src_mask,</span><br><span class="line">                            tgt, tgt_mask)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">encode</span><span class="params">(self, src, src_mask)</span>:</span></span><br><span class="line">        <span class="comment"># è°ƒç”¨encoderæ¥è¿›è¡Œç¼–ç ï¼Œä¼ å…¥çš„å‚æ•°embeddingçš„srcå’Œsrc_mask</span></span><br><span class="line">        <span class="keyword">return</span> self.encoder(self.src_embed(src), src_mask)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">decode</span><span class="params">(self, memory, src_mask, tgt, tgt_mask)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask) <span class="comment">#ç›®æ ‡æ˜¯è¾“å…¥çš„ä¸€éƒ¨åˆ†</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span>  <span class="comment">#decoderåé¢çš„linear+softmax</span></span><br><span class="line">    <span class="comment"># æ ¹æ®Decoderçš„éšçŠ¶æ€è¾“å‡ºä¸€ä¸ªè¯</span></span><br><span class="line"><span class="comment"># d_modelæ˜¯Decoderè¾“å‡ºçš„å¤§å°ï¼Œvocabæ˜¯è¯å…¸å¤§å° ï¼ˆæ•°æ®è¯­æ–™æœ‰å¤šå°‘è¯ ï¼‰</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, vocab)</span>:</span></span><br><span class="line">        super(Generator, self).__init__()</span><br><span class="line">        self.proj = nn.Linear(d_model, vocab) <span class="comment">#å…¨è¿æ¥ï¼Œä½œä¸ºsoftmaxçš„è¾“å…¥ã€‚</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(self.proj(x), dim=<span class="number">-1</span>) <span class="comment">#softmaxçš„logå€¼</span></span><br></pre></td></tr></tbody></table></figure><p>æ³¨ï¼š<code>Generatorè¿”å›çš„æ˜¯softmaxçš„logå€¼</code>ã€‚åœ¨PyTorché‡Œä¸ºäº†è®¡ç®—äº¤å‰ç†µæŸå¤±ï¼Œæœ‰ä¸¤ç§æ–¹æ³•ã€‚ç¬¬ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨<strong>nn.CrossEntropyLoss()</strong>ï¼Œä¸€ç§æ˜¯ä½¿ç”¨<strong>NLLLoss()</strong>ã€‚å¾ˆå¤šå¼€æºä»£ç é‡Œç¬¬äºŒç§æ›´å¸¸è§ï¼Œ</p><p>æˆ‘ä»¬å…ˆçœ‹CrossEntropyLossï¼Œå®ƒå°±æ˜¯è®¡ç®—äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œæ¯”å¦‚ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">y = torch.empty(<span class="number">1</span>, dtype=torch.long).random_(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">loss = criterion(x, y)</span><br></pre></td></tr></tbody></table></figure><p>æ¯”å¦‚ä¸Šé¢çš„ä»£ç ï¼Œå‡è®¾æ˜¯5åˆ†ç±»é—®é¢˜ï¼Œxè¡¨ç¤ºæ¨¡å‹çš„è¾“å‡ºlogits(batch=1)ï¼Œè€Œyæ˜¯çœŸå®åˆ†ç±»çš„ä¸‹æ ‡(0-4)ã€‚å®é™…çš„è®¡ç®—è¿‡ç¨‹ä¸ºï¼š<img src="https://i.loli.net/2020/08/06/KyPspa4Cqef6m8Q.png" alt="image-20200806000621448" style="zoom: 67%;"></p><p>æ¯”å¦‚logitsæ˜¯[0,1,2,3,4]ï¼ŒçœŸå®åˆ†ç±»æ˜¯3ï¼Œé‚£ä¹ˆä¸Šå¼å°±æ˜¯ï¼š</p><p><img src="https://i.loli.net/2020/08/06/i7mfUWAeHE5P1zd.png" alt="image-20200806000641945" style="zoom:67%;"></p><p>å› æ­¤æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨NLLLoss()é…åˆF.log_softmaxå‡½æ•°(æˆ–è€…nn.LogSoftmaxï¼Œè¿™ä¸æ˜¯ä¸€ä¸ªå‡½æ•°è€Œæ˜¯ä¸€ä¸ªModuleäº†)æ¥å®ç°ä¸€æ ·çš„æ•ˆæœï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">m = nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">criterion = nn.NLLLoss()</span><br><span class="line">x = torch.randn(<span class="number">1</span>, <span class="number">5</span>)</span><br><span class="line">y = torch.empty(<span class="number">1</span>, dtype=torch.long).random_(<span class="number">5</span>)</span><br><span class="line">loss = criterion(m(x), y)</span><br></pre></td></tr></tbody></table></figure><p>NLLLoss(Negative Log Likelihood Loss)æ˜¯è®¡ç®—è´Ÿlogä¼¼ç„¶æŸå¤±ã€‚å®ƒè¾“å…¥çš„xæ˜¯log_softmaxä¹‹åçš„ç»“æœ(é•¿åº¦ä¸º5çš„æ•°ç»„)ï¼Œyæ˜¯çœŸå®åˆ†ç±»(0-4)ï¼Œè¾“å‡ºå°±æ˜¯x[y]ã€‚å› æ­¤ä¸Šé¢çš„ä»£ç ä¸ºï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">criterion(m(x), y)=m(x)[y]</span><br></pre></td></tr></tbody></table></figure><p>The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1, respectively.</p><figure><img src="https://i.loli.net/2020/07/28/P3fSgRhrmFtlpxY.png" alt="png"><figcaption>png</figcaption></figure><h3 id="encoder-and-decoder-stacks">Encoder and Decoder Stacks</h3><h4 id="encoder">Encoder</h4><p>Encoderå’ŒDecoderéƒ½æ˜¯ç”±Nä¸ªç›¸åŒç»“æ„çš„Layerå †ç§¯(stack)è€Œæˆã€‚<strong>å› æ­¤æˆ‘ä»¬é¦–å…ˆå®šä¹‰cloneså‡½æ•°ï¼Œç”¨äºå…‹éš†ç›¸åŒçš„SubLayerã€‚</strong></p><p>è¿™é‡Œä½¿ç”¨äº†<strong>nn.ModuleList</strong>ï¼ŒModuleListå°±åƒä¸€ä¸ªæ™®é€šçš„Pythonçš„Listï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸‹æ ‡æ¥è®¿é—®å®ƒï¼Œå®ƒçš„å¥½å¤„æ˜¯ä¼ å…¥çš„ModuleListçš„æ‰€æœ‰Moduleéƒ½ä¼šæ³¨å†Œçš„PyTorché‡Œï¼Œè¿™æ ·Optimizerå°±èƒ½æ‰¾åˆ°è¿™é‡Œé¢çš„å‚æ•°ï¼Œä»è€Œèƒ½å¤Ÿç”¨æ¢¯åº¦ä¸‹é™æ›´æ–°è¿™äº›å‚æ•°ã€‚ä½†æ˜¯nn.ModuleListå¹¶ä¸æ˜¯Module(çš„å­ç±»)ï¼Œå› æ­¤å®ƒæ²¡æœ‰forwardç­‰æ–¹æ³•ï¼Œæˆ‘ä»¬é€šå¸¸æŠŠå®ƒæ”¾åˆ°æŸä¸ªModuleé‡Œã€‚</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clones</span><span class="params">(module, N)</span>:</span>  <span class="comment">#å…‹éš†Nå±‚ï¼Œæ˜¯ä¸ªå±‚æ•°çš„åˆ—è¡¨ã€‚ copy.deepcopyæ˜¯æ·±å¤åˆ¶ï¼Œ ä¸€ä¸ªæ”¹å˜ä¸ä¼šå½±å“å¦ä¸€ä¸ª</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> nn.ModuleList([copy.deepcopy(module) <span class="keyword">for</span> _ <span class="keyword">in</span> range(N)]) <span class="comment">#å¤åˆ¶N=6å±‚</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Encoder</span><span class="params">(nn.Module)</span>:</span>  <span class="comment">#å®šä¹‰ç¼–ç å™¨ </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Encoderæ˜¯Nä¸ªEncoderLayerçš„stack</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, layer, N)</span>:</span> <span class="comment"># æ ¹æ®make_modelå®šä¹‰ï¼Œlayer = encoderlayer ï¼ˆsublayerï¼‰</span></span><br><span class="line">        super(Encoder, self).__init__()</span><br><span class="line">        self.layers = clones(layer, N) <span class="comment">#ç¼–ç å™¨æœ‰6å±‚ç¼–ç å±‚ï¼Œæ ¹æ®ä¸Šè¿°å‡½æ•°çš„å®šä¹‰ï¼Œmodule=layer</span></span><br><span class="line">        self.norm = LayerNorm(layer.size) <span class="comment">#è°ƒç”¨ä¸‹é¢çš„LayerNormã€‚ åˆ†å¼€å®šä¹‰æ˜¯å› ä¸º LayerNorm = 2* layer</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, mask)</span>:</span> </span><br><span class="line">       <span class="comment">#é€å±‚è¿›è¡Œå¤„ç†</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers: <span class="comment"># x åœ¨æ¯ä¸€å±‚ä¸­ä¼ é€’</span></span><br><span class="line">            x = layer(x, mask)</span><br><span class="line">        <span class="keyword">return</span> self.norm(x) <span class="comment">#æœ€ç»ˆencoderçš„è¿”å›å€¼</span></span><br></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LayerNorm</span><span class="params">(nn.Module)</span>:</span> <span class="comment">#add &amp; norméƒ¨åˆ†  ä½œä¸ºæ¯ä¸€ä¸ªå­å±‚çš„è¾“å‡º</span></span><br><span class="line">    <span class="string">"Construct a layernorm module (See citation for details)."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, features, eps=<span class="number">1e-6</span>)</span>:</span> <span class="comment">#feature = layer.size layerçš„å½¢çŠ¶</span></span><br><span class="line">        super(LayerNorm, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.a_2 = nn.Parameter(torch.ones(features))  <span class="comment">#å°†åé¢çš„tensorè½¬æ¢ä¸ºå¯ä¼˜åŒ–çš„å‚æ•°</span></span><br><span class="line">        self.b_2 = nn.Parameter(torch.zeros(features))</span><br><span class="line">        self.eps = eps <span class="comment">#å¾ˆå°çš„å€¼</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span> <span class="comment"># å¹³å‡å€¼å’Œæ ‡å‡†å·®</span></span><br><span class="line">        mean = x.mean(<span class="number">-1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        std = x.std(<span class="number">-1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> self.a_2 * (x - mean) / (std + self.eps) + self.b_2 <span class="comment">#è¾“å‡º</span></span><br></pre></td></tr></tbody></table></figure><p><strong>ä¸ç®¡æ˜¯Self-Attentionè¿˜æ˜¯å…¨è¿æ¥å±‚ï¼Œéƒ½é¦–å…ˆæ˜¯LayerNormï¼Œç„¶åæ˜¯Self-Attention/Denseï¼Œç„¶åæ˜¯Dropoutï¼Œæœ€å¥½æ˜¯æ®‹å·®è¿æ¥ã€‚è¿™é‡Œé¢æœ‰å¾ˆå¤šå¯ä»¥é‡ç”¨çš„ä»£ç ï¼Œæˆ‘ä»¬æŠŠå®ƒå°è£…æˆSublayerConnectionã€‚</strong></p><hr><p>That is, <code>the output of each sub-layer is LayerNorm(x+Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer itself.</code> We apply dropout <a href="http://jmlr.org/papers/v15/srivastava14a.html" target="_blank" rel="noopener">(cite)</a> to the output of each sub-layer, before it is added to the sub-layer input and normalized.</p><p>To facilitate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of dimension <code>dmodel=512</code>.</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SublayerConnection</span><span class="params">(nn.Module)</span>:</span> <span class="comment">#æ¯ä¸€ä¸ªç¼–ç å±‚ä¸­çš„ä¸¤ä¸ªå­å±‚ä¹‹é—´çš„è¿æ¥</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">LayerNorm + sublayer(Self-Attenion/Dense) + dropout + æ®‹å·®è¿æ¥</span></span><br><span class="line"><span class="string">ä¸ºäº†ç®€å•ï¼ŒæŠŠLayerNormæ”¾åˆ°äº†å‰é¢ï¼Œè¿™å’ŒåŸå§‹è®ºæ–‡ç¨æœ‰ä¸åŒï¼ŒåŸå§‹è®ºæ–‡LayerNormåœ¨æœ€åã€‚</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, dropout)</span>:</span></span><br><span class="line">        super(SublayerConnection, self).__init__()</span><br><span class="line">        self.norm = LayerNorm(size)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, sublayer)</span>:</span></span><br><span class="line">       <span class="comment">#sublayeræ˜¯ä¼ å…¥çš„å‚æ•°ï¼Œå‚è€ƒDecoderLayerï¼Œå®ƒå¯ä»¥å½“æˆå‡½æ•°è°ƒç”¨ï¼Œè¿™ä¸ªå‡½æ•°çš„æœ‰ä¸€ä¸ªè¾“å…¥å‚æ•°</span></span><br><span class="line">        <span class="keyword">return</span> x + self.dropout(sublayer(self.norm(x))) <span class="comment">#è°ƒç”¨layernorm ï¼Œæ­£åˆ™åŒ–ä¹‹åå†ç›¸åŠ </span></span><br></pre></td></tr></tbody></table></figure><p>è¿™ä¸ªç±»ä¼šæ„é€ LayerNormå’ŒDropoutï¼Œä½†æ˜¯Self-Attentionæˆ–è€…Denseå¹¶ä¸åœ¨è¿™é‡Œæ„é€ ï¼Œè¿˜æ˜¯æ”¾åœ¨äº†EncoderLayeré‡Œï¼Œåœ¨forwardçš„æ—¶å€™ç”±EncoderLayerä¼ å…¥ã€‚è¿™æ ·çš„å¥½å¤„æ˜¯æ›´åŠ é€šç”¨ï¼Œæ¯”å¦‚Decoderä¹Ÿæ˜¯ç±»ä¼¼çš„éœ€è¦åœ¨Self-Attentionã€Attentionæˆ–è€…Denseå‰é¢ååŠ ä¸ŠLayerNormå’ŒDropoutä»¥åŠæ®‹å·®è¿æ¥ï¼Œæˆ‘ä»¬å°±å¯ä»¥å¤ç”¨ä»£ç ã€‚ä½†æ˜¯è¿™é‡Œè¦æ±‚ä¼ å…¥çš„sublayerå¯ä»¥ä½¿ç”¨ä¸€ä¸ªå‚æ•°æ¥è°ƒç”¨çš„å‡½æ•°(æˆ–è€…æœ‰__call__)ã€‚</p><hr><p>forwardè°ƒç”¨sublayer[0] (è¿™æ˜¯SublayerConnectionå¯¹è±¡)çš„__call__æ–¹æ³•ï¼Œæœ€ç»ˆä¼šè°ƒåˆ°å®ƒçš„forwardæ–¹æ³•ï¼Œè€Œè¿™ä¸ªæ–¹æ³•éœ€è¦ä¸¤ä¸ªå‚æ•°ï¼Œ<strong>ä¸€ä¸ªæ˜¯è¾“å…¥Tensorï¼Œä¸€ä¸ªæ˜¯ä¸€ä¸ªcallableï¼Œå¹¶ä¸”è¿™ä¸ªcallableå¯ä»¥ç”¨ä¸€ä¸ªå‚æ•°æ¥è°ƒç”¨</strong>ã€‚è€Œ<strong>self_attnå‡½æ•°éœ€è¦4ä¸ªå‚æ•°(Queryçš„è¾“å…¥,Keyçš„è¾“å…¥,Valueçš„è¾“å…¥å’ŒMask)</strong>ï¼Œå› æ­¤è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨lambdaçš„æŠ€å·§æŠŠå®ƒå˜æˆä¸€ä¸ªå‚æ•°xçš„å‡½æ•°(maskå¯ä»¥çœ‹æˆå·²çŸ¥çš„æ•°)ã€‚</p><p>Callable ç±»å‹æ˜¯å¯ä»¥è¢«æ‰§è¡Œè°ƒç”¨æ“ä½œçš„ç±»å‹ã€‚åŒ…å«è‡ªå®šä¹‰å‡½æ•°ç­‰ã€‚è‡ªå®šä¹‰çš„å‡½æ•°æ¯”å¦‚ä½¿ç”¨defã€lambdaæ‰€å®šä¹‰çš„å‡½æ•°</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncoderLayer</span><span class="params">(nn.Module)</span>:</span> <span class="comment">#æ¯ä¸€ä¸ªç¼–ç å±‚</span></span><br><span class="line">    <span class="string">"Encoder is made up of self-attn and feed forward (defined below)"</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, self_attn, feed_forward, dropout)</span>:</span></span><br><span class="line">        super(EncoderLayer, self).__init__()</span><br><span class="line">        self.self_attn = self_attn</span><br><span class="line">        self.feed_forward = feed_forward</span><br><span class="line">        self.sublayer = clones(SublayerConnection(size, dropout), <span class="number">2</span>) <span class="comment">#æ¯ä¸€å±‚æœ‰2å­å±‚</span></span><br><span class="line">        self.size = size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, mask)</span>:</span></span><br><span class="line">      <span class="comment">#attentionå±‚ï¼Œæ‹¬å·é‡Œé¢æ˜¯å‚æ•°ã€‚æ¥æ”¶æ¥è‡ªattentionçš„è¾“å‡º</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">     lambda : atten()SublayerConnectioné‡Œæ˜¯ä½œä¸ºsublayerå‡ºç°çš„ï¼Œè€Œå®ƒçš„å‚æ•°æ˜¯norm(x),norm(x)çš„è¾“å‡ºæ˜¯ä¸€ä¸ªå‘é‡xï¼Œ</span></span><br><span class="line"><span class="string">   æ‰€ä»¥attençš„å‚æ•°æ˜¯åªæœ‰ä¸€ä¸ªxï¼Œ è€Œåœ¨muitiheadé‡Œé¢ï¼Œkã€qã€våœ¨å‡½æ•°é‡Œæ˜¯è¦è¢«é‡æ–°æ ¹æ®xè®¡ç®—çš„</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">        x = self.sublayer[<span class="number">0</span>](x, <span class="keyword">lambda</span> x: self.self_attn(x, x, x, mask)) </span><br><span class="line">        <span class="keyword">return</span> self.sublayer[<span class="number">1</span>](x, self.feed_forward) <span class="comment">#xæ˜¯atten+normä¹‹åçš„è¾“å‡ºï¼Œå†ffè¾“å‡º</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    å¯ä»¥ç†è§£ä¸º</span></span><br><span class="line"><span class="string">    z = lambda y: self.self_attn(y, y, y, mask)</span></span><br><span class="line"><span class="string">x = self.sublayer[0](x, z)</span></span><br><span class="line"><span class="string">    """</span></span><br></pre></td></tr></tbody></table></figure><h4 id="decoder">Decoder</h4><p>The decoder is also composed of a stack of <code>N=6</code> identical layers.</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Decoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Generic N layer decoder with masking."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, layer, N)</span>:</span></span><br><span class="line">        super(Decoder, self).__init__()</span><br><span class="line">        self.layers = clones(layer, N)</span><br><span class="line">        self.norm = LayerNorm(layer.size)</span><br><span class="line">     <span class="comment">#memory: ç¼–ç å™¨çš„è¾“å‡º xæ˜¯è¾“å…¥</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, memory, src_mask, tgt_mask)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            x = layer(x, memory, src_mask, tgt_mask)</span><br><span class="line">        <span class="keyword">return</span> self.norm(x)</span><br></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DecoderLayer</span><span class="params">(nn.Module)</span>:</span> <span class="comment">#æ¯ä¸€å±‚è§£ç å±‚</span></span><br><span class="line">    <span class="string">"Decoder is made of self-attn, src-attn, and feed forward (defined below)"</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, self_attn, src_attn, feed_forward, dropout)</span>:</span></span><br><span class="line">        super(DecoderLayer, self).__init__()</span><br><span class="line">        self.size = size</span><br><span class="line">        self.self_attn = self_attn</span><br><span class="line">        self.src_attn = src_attn</span><br><span class="line">        self.feed_forward = feed_forward</span><br><span class="line">        self.sublayer = clones(SublayerConnection(size, dropout), <span class="number">3</span>) <span class="comment">#æ¯ä¸€å±‚æœ‰3ä¸ªå­å±‚</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, memory, src_mask, tgt_mask)</span>:</span></span><br><span class="line">        <span class="string">"Follow Figure 1 (right) for connections."</span></span><br><span class="line">        m = memory</span><br><span class="line">        x = self.sublayer[<span class="number">0</span>](x, <span class="keyword">lambda</span> x: self.self_attn(x, x, x, tgt_mask)) <span class="comment">#ç¬¬ä¸€å­å±‚</span></span><br><span class="line">        x = self.sublayer[<span class="number">1</span>](x, <span class="keyword">lambda</span> x: self.src_attn(x, m, m, src_mask)) <span class="comment">#ç¬¬äºŒå­å±‚ </span></span><br><span class="line">        <span class="keyword">return</span> self.sublayer[<span class="number">2</span>](x, self.feed_forward) <span class="comment">#ç¬¬ä¸‰å­å±‚</span></span><br></pre></td></tr></tbody></table></figure><p><strong>src-attnå’Œself-attnçš„å®ç°æ˜¯ä¸€æ ·çš„ï¼Œåªä¸è¿‡ä½¿ç”¨çš„Queryï¼ŒKeyå’ŒValueçš„è¾“å…¥ä¸åŒã€‚</strong>æ™®é€šçš„Attention(src-attn)çš„Queryæ˜¯ä¸‹å±‚è¾“å…¥è¿›æ¥çš„(æ¥è‡ªself-attnçš„è¾“å‡º)ï¼ŒKeyå’ŒValueæ˜¯Encoderæœ€åä¸€å±‚çš„è¾“å‡ºmemoryï¼›è€ŒSelf-Attentionçš„Queryï¼ŒKeyå’ŒValueéƒ½æ˜¯æ¥è‡ªä¸‹å±‚è¾“å…¥è¿›æ¥çš„ã€‚</p><hr><p>Decoderå’ŒEncoderæœ‰ä¸€ä¸ªå…³é”®çš„ä¸åŒï¼šDecoderåœ¨è§£ç ç¬¬tä¸ªæ—¶åˆ»çš„æ—¶å€™åªèƒ½ä½¿ç”¨<strong>1â€¦tæ—¶åˆ»</strong>çš„è¾“å…¥ï¼Œè€Œä¸èƒ½ä½¿ç”¨t+1æ—¶åˆ»åŠå…¶ä¹‹åçš„è¾“å…¥ã€‚å› æ­¤æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå‡½æ•°æ¥äº§ç”Ÿä¸€ä¸ªMaskçŸ©é˜µï¼Œæ‰€ä»¥ä»£ç å¦‚ä¸‹ï¼š</p><p>æ³¨æ„ï¼š tæ—¶åˆ»åŒ…æ‹¬tæ—¶åˆ»çš„è¾“å…¥</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">subsequent_mask</span><span class="params">(size)</span>:</span>  <span class="comment">#å°†iåé¢çš„maskæ‰</span></span><br><span class="line">    <span class="string">"Mask out subsequent positions."</span></span><br><span class="line">    attn_shape = (<span class="number">1</span>, size, size)</span><br><span class="line">    subsequent_mask = np.triu(np.ones(attn_shape), k=<span class="number">1</span>).astype(<span class="string">'uint8'</span>) <span class="comment">#triu ä¸Šä¸‰è§’</span></span><br><span class="line">    <span class="keyword">return</span> torch.from_numpy(subsequent_mask) == <span class="number">0</span> <span class="comment">#å°†numpyæ ¼å¼è½¬æ¢ä¸ºtensoræ ¼å¼ï¼Œåˆ¤æ–­æ˜¯å¦ä¸º0ï¼Œ è¾“å‡ºå¸ƒå°”å€¼</span></span><br></pre></td></tr></tbody></table></figure><figure><img src="https://i.loli.net/2020/08/08/7brnPfDJxsLBtvh.png" alt="png"><figcaption>png</figcaption></figure><p>å®ƒçš„è¾“å‡ºï¼š</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">print(subsequent_mask(5))</span><br><span class="line"># è¾“å‡º</span><br><span class="line">  1  0  0  0  0</span><br><span class="line">  1  1  0  0  0</span><br><span class="line">  1  1  1  0  0</span><br><span class="line">  1  1  1  1  0</span><br><span class="line">  1  1  1  1  1</span><br></pre></td></tr></tbody></table></figure><p>æˆ‘ä»¬å‘ç°å®ƒè¾“å‡ºçš„æ˜¯ä¸€ä¸ªæ–¹é˜µï¼Œå¯¹è§’çº¿å’Œä¸‹é¢éƒ½æ˜¯1ã€‚<strong>ç¬¬ä¸€è¡Œåªæœ‰ç¬¬ä¸€åˆ—æ˜¯1ï¼Œå®ƒçš„æ„æ€æ˜¯æ—¶åˆ»1åªèƒ½attend toè¾“å…¥1</strong>ï¼Œç¬¬ä¸‰è¡Œè¯´æ˜æ—¶åˆ»3å¯ä»¥attend to {1,2,3}è€Œä¸èƒ½attend to{4,5}çš„è¾“å…¥ï¼Œå› ä¸ºåœ¨çœŸæ­£Decoderçš„æ—¶å€™è¿™æ˜¯å±äºFutureçš„ä¿¡æ¯ã€‚ä»£ç é¦–å…ˆä½¿ç”¨triuäº§ç”Ÿä¸€ä¸ªä¸Šä¸‰è§’é˜µï¼š</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">0 1 1 1 1</span><br><span class="line">0 0 1 1 1</span><br><span class="line">0 0 0 1 1</span><br><span class="line">0 0 0 0 1</span><br><span class="line">0 0 0 0 0</span><br></pre></td></tr></tbody></table></figure><p>ç„¶åéœ€è¦æŠŠ0å˜æˆ1ï¼ŒæŠŠ1å˜æˆ0ï¼Œè¿™å¯ä»¥ä½¿ç”¨ matrix == 0æ¥å®ç°ã€‚</p><p>å› ä¸ºï¼šå¸ƒå°”å€¼Trueè¢«ç´¢å¼•æ±‚å€¼ä¸º1ï¼Œè€ŒFalseå°±ç­‰äº0ã€‚</p><h4 id="attention">Attention</h4><p>An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.</p><p>We call our particular attention â€œ<code>Scaled Dot-Product Attention</code>â€. The input consists of queries and keys of dimension <code>dk</code>, and values of dimension <code>dv</code>. We compute the dot products of the query with all keys, divide each by <code>âˆšdk</code>, and apply a softmax function to obtain the weights on the values.</p><figure><img src="https://i.loli.net/2020/08/06/O3UNSGF7Poa1w4Q.png" alt="image-20200806015122441"><figcaption>image-20200806015122441</figcaption></figure><p><strong>Attentionå¯ä»¥çœ‹æˆä¸€ä¸ªå‡½æ•°ï¼Œå®ƒçš„è¾“å…¥æ˜¯Query,Key,Valueå’ŒMaskï¼Œè¾“å‡ºæ˜¯ä¸€ä¸ªTensor</strong>ã€‚å…¶ä¸­è¾“å‡ºæ˜¯Valueçš„åŠ æƒå¹³å‡ï¼Œè€Œæƒé‡æ¥è‡ªQueryå’ŒKeyçš„è®¡ç®—ã€‚å…·ä½“çš„è®¡ç®—å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè®¡ç®—å…¬å¼ä¸ºï¼š</p><p><img src="https://i.loli.net/2020/07/28/WaSfHnNdt2L1AXU.png" alt="image-20200728212241453" style="zoom:50%;"></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention</span><span class="params">(query, key, value, mask=None, dropout=None)</span>:</span></span><br><span class="line">    <span class="string">"Compute 'Scaled Dot Product Attention'"</span></span><br><span class="line">    d_k = query.size(<span class="number">-1</span>) <span class="comment"># query.sizeçš„æœ€åä¸€ç»´</span></span><br><span class="line">    scores = torch.matmul(query, key.transpose(<span class="number">-2</span>, <span class="number">-1</span>)) / math.sqrt(d_k)</span><br><span class="line">    <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:<span class="comment"># å¦‚æœæœ‰mask</span></span><br><span class="line">        scores = scores.masked_fill(mask == <span class="number">0</span>, <span class="number">-1e9</span>)</span><br><span class="line">    p_attn = F.softmax(scores, dim = <span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">if</span> dropout <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: <span class="comment">#å¯¹p_attnè¿›è¡Œdropout</span></span><br><span class="line">        p_attn = dropout(p_attn)</span><br><span class="line">    <span class="keyword">return</span> torch.matmul(p_attn, value), p_attn</span><br></pre></td></tr></tbody></table></figure><p>æˆ‘ä»¬çŸ¥é“, åœ¨è®­ç»ƒçš„æ—¶å€™, æˆ‘ä»¬æ˜¯ä»¥ batch_size ä¸ºå•ä½çš„, é‚£ä¹ˆå°±ä¼šæœ‰ padding, ä¸€èˆ¬æˆ‘ä»¬å– pad == 0, é‚£ä¹ˆå°±ä¼šé€ æˆåœ¨ Attention çš„æ—¶å€™, query çš„å€¼ä¸º 0, query çš„å€¼ä¸º 0, æ‰€ä»¥æˆ‘ä»¬è®¡ç®—çš„å¯¹åº”çš„ scores çš„å€¼ä¹Ÿæ˜¯ 0, é‚£ä¹ˆå°±ä¼šå¯¼è‡´ softmax å¾ˆå¯èƒ½åˆ†é…ç»™è¯¥å•è¯ä¸€ä¸ªç›¸å¯¹ä¸æ˜¯å¾ˆå°çš„æ¯”ä¾‹, å› æ­¤, æˆ‘ä»¬å°† pad å¯¹åº”çš„ score å–å€¼ä¸º<strong>è´Ÿæ— ç©·</strong>ï¼ˆæ™®é€šçš„è®¡ç®—ï¼Œscoreå¯ä»¥ä¸ºè´Ÿæ•°ï¼Ÿï¼‰, ä»¥æ­¤æ¥å‡å° pad çš„å½±å“.</p><p>å¾ˆå®¹æ˜“æƒ³åˆ°, åœ¨ decoder, <strong>æœªé¢„æµ‹çš„å•è¯</strong>ä¹Ÿæ˜¯ç”¨ padding çš„æ–¹å¼åŠ å…¥åˆ° batch çš„, æ‰€ä»¥ä½¿ç”¨çš„mask æœºåˆ¶ä¸ padding æ—¶mask çš„æœºåˆ¶æ˜¯ç›¸åŒçš„, æœ¬è´¨ä¸Šéƒ½æ˜¯query çš„å€¼ä¸º0, åªæ˜¯ mask çŸ©é˜µä¸åŒ, æˆ‘ä»¬å¯ä»¥æ ¹æ® decoder éƒ¨åˆ†çš„ä»£ç å‘ç°è¿™ä¸€ç‚¹.</p><hr><p>æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ª<strong>å®é™…çš„ä¾‹å­è·Ÿè¸ªä¸€äº›ä¸åŒTensorçš„shape</strong>ï¼Œç„¶åå¯¹ç…§å…¬å¼å°±å¾ˆå®¹æ˜“ç†è§£ã€‚æ¯”å¦‚<strong>Qæ˜¯(30,8,33,64)ï¼Œå…¶ä¸­30æ˜¯batchï¼Œ8æ˜¯headä¸ªæ•°ï¼Œ33æ˜¯åºåˆ—é•¿åº¦ï¼Œ64æ˜¯æ¯ä¸ªæ—¶åˆ»çš„ç‰¹å¾æ•°ï¼ˆsizeï¼‰ã€‚Kå’ŒQçš„shapeå¿…é¡»ç›¸åŒçš„ï¼Œè€ŒVå¯ä»¥ä¸åŒï¼Œä½†æ˜¯è¿™é‡Œçš„å®ç°shapeä¹Ÿæ˜¯ç›¸åŒçš„ã€‚</strong></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scores = torch.matmul(query, key.transpose(<span class="number">-2</span>, <span class="number">-1</span>)) \</span><br><span class="line">/ math.sqrt(d_k)</span><br></pre></td></tr></tbody></table></figure><p>ä¸Šé¢çš„ä»£ç å®ç°<img src="https://i.loli.net/2020/08/06/rLCJ7VFBAsmQb4x.png" alt="image-20200806014945713" style="zoom:50%;">ï¼Œå’Œå…¬å¼é‡Œç¨å¾®ä¸åŒçš„æ˜¯ï¼Œè¿™é‡Œçš„Qå’ŒKéƒ½æ˜¯4dçš„Tensorï¼ŒåŒ…æ‹¬batchå’Œheadç»´åº¦ã€‚<strong>matmulä¼šæŠŠqueryå’Œkeyçš„æœ€åä¸¤ç»´è¿›è¡ŒçŸ©é˜µä¹˜æ³•</strong>ï¼Œè¿™æ ·æ•ˆç‡æ›´é«˜ï¼Œå¦‚æœæˆ‘ä»¬è¦ç”¨æ ‡å‡†çš„çŸ©é˜µ(äºŒç»´Tensor)ä¹˜æ³•æ¥å®ç°ï¼Œé‚£ä¹ˆéœ€è¦éå†batchç»´å’Œheadç»´ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">batch_num = query.size(<span class="number">0</span>) <span class="comment"># query.size(0)è¿”å›çš„æ˜¯0ç»´çš„æ•°</span></span><br><span class="line">head_num = query.size(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(batch_num):</span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(head_num):</span><br><span class="line">scores[i,j] = torch.matmul(query[i,j], key[i,j].transpose())</span><br></pre></td></tr></tbody></table></figure><p>è€Œä¸Šé¢çš„å†™æ³•ä¸€æ¬¡å®Œæˆæ‰€æœ‰è¿™äº›å¾ªç¯ï¼Œæ•ˆç‡æ›´é«˜ã€‚<strong>è¾“å‡ºçš„scoreæ˜¯(30, 8, 33, 33)</strong>ï¼Œå‰é¢ä¸¤ç»´ä¸çœ‹ï¼Œé‚£<strong>ä¹ˆæ˜¯ä¸€ä¸ª(33, 33)çš„attentionçŸ©é˜µaï¼Œaijè¡¨ç¤ºæ—¶åˆ» iå…³æ³¨ j çš„å¾—åˆ†</strong>(è¿˜æ²¡æœ‰ç»è¿‡softmaxå˜æˆæ¦‚ç‡)ã€‚</p><p><strong>åœ¨ç¼–ç å™¨çš„attentionä¸­src_maskçš„ä½œç”¨ï¼ï¼ï¼</strong></p><p>æ¥ä¸‹æ¥æ˜¯<code>scores.masked_fill(mask == 0, -1e9)</code>ï¼Œç”¨äº<strong>æŠŠmaskæ˜¯0çš„å˜æˆä¸€ä¸ªå¾ˆå°çš„æ•°</strong>ï¼Œè¿™æ ·åé¢ç»è¿‡softmaxä¹‹åçš„æ¦‚ç‡å°±å¾ˆæ¥è¿‘é›¶(ä½†æ˜¯ç†è®ºä¸Šè¿˜æ˜¯ç”¨æ¥å¾ˆå°‘ä¸€ç‚¹ç‚¹æœªæ¥çš„ä¿¡æ¯)ã€‚</p><blockquote><p>masked_fill_(mask, value)ï¼šæ©ç æ“ä½œ masked_fillæ–¹æ³•æœ‰ä¸¤ä¸ªå‚æ•°ï¼Œmaskeå’Œvalueï¼Œmaskæ˜¯ä¸€ä¸ªpytorchå¼ é‡ï¼ˆTensorï¼‰ï¼Œ<strong>å…ƒç´ æ˜¯å¸ƒå°”å€¼ï¼Œvalueæ˜¯è¦å¡«å……çš„å€¼</strong>ï¼Œå¡«å……è§„åˆ™æ˜¯maskä¸­å–å€¼ä¸ºTrueä½ç½®å¯¹åº”äºselfçš„ç›¸åº”ä½ç½®ç”¨valueå¡«å……ã€‚</p><p>æ³¨ï¼šå‚æ•°maskå¿…é¡»ä¸scoreçš„sizeç›¸åŒæˆ–è€…ä¸¤è€…æ˜¯å¯å¹¿æ’­(broadcasting-semantics)çš„</p><p>pytorch masked_fillæ–¹æ³•ç®€å•ç†è§£</p><p>https://blog.csdn.net/jianyingyao7658/article/details/103382654</p><p>pytorch å¹¿æ’­è¯­ä¹‰(Broadcasting semantics)</p><p>https://blog.csdn.net/qq_35012749/article/details/88308657</p></blockquote><p>è¿™é‡Œ<strong>maskæ˜¯(30, 1, 1, 33)çš„tensor</strong>ï¼Œå› ä¸º8ä¸ªheadçš„maskéƒ½æ˜¯ä¸€æ ·çš„ï¼Œæ‰€æœ‰ç¬¬äºŒç»´æ˜¯1ï¼Œmasked_fillæ—¶ä½¿ç”¨broadcastingå°±å¯ä»¥äº†ã€‚è¿™é‡Œæ˜¯self-attentionçš„maskï¼Œæ‰€ä»¥æ¯ä¸ªæ—¶åˆ»éƒ½å¯ä»¥attendåˆ°æ‰€æœ‰å…¶å®ƒæ—¶åˆ»ï¼Œæ‰€æœ‰ç¬¬ä¸‰ç»´ä¹Ÿæ˜¯1ï¼Œä¹Ÿä½¿ç”¨broadcastingã€‚å¦‚æœæ˜¯æ™®é€šçš„maskï¼Œé‚£ä¹ˆmaskçš„shapeæ˜¯(30, 1, 33, 33)ã€‚</p><p>è¿™æ ·è®²æœ‰ç‚¹æŠ½è±¡ï¼Œæˆ‘ä»¬å¯ä»¥ä¸¾ä¸€ä¸ªä¾‹å­ï¼Œä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬å‡è®¾batch=2, head=8ã€‚ç¬¬ä¸€ä¸ªåºåˆ—é•¿åº¦ä¸º3ï¼Œç¬¬äºŒä¸ªä¸º4ï¼Œé‚£ä¹ˆself-attentionçš„maskä¸º(2, 1, 1, 4)ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸¤ä¸ªå‘é‡è¡¨ç¤ºï¼š</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1 1 1 0</span><br><span class="line">1 1 1 1</span><br></pre></td></tr></tbody></table></figure><p>å®ƒçš„æ„æ€æ˜¯åœ¨self-attentioné‡Œï¼Œç¬¬ä¸€ä¸ªåºåˆ—çš„ä»»ä¸€æ—¶åˆ»å¯ä»¥attend to å‰3ä¸ªæ—¶åˆ»(å› ä¸ºç¬¬4ä¸ªæ—¶åˆ»æ˜¯paddingçš„)ï¼›è€Œç¬¬äºŒä¸ªåºåˆ—çš„å¯ä»¥attend toæ‰€æœ‰æ—¶åˆ»çš„è¾“å…¥ã€‚è€ŒDecoderçš„src-attentionçš„maskä¸º(2, 1, 4, 4)ï¼Œæˆ‘ä»¬éœ€è¦ç”¨2ä¸ªçŸ©é˜µè¡¨ç¤ºï¼š(ä¸€ä¸ªåºåˆ—å¯¹åº”ä¸€ä¸ªä¸€ç»´src_maskï¼ˆ1Ã—4ï¼‰ï¼Œ ä¸€ä¸ªåºåˆ—å¯¹åº”ä¸€ä¸ªäºŒç»´çš„tgt_maskï¼ˆ4Ã—4ï¼‰)</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ç¬¬ä¸€ä¸ªåºåˆ—çš„maskçŸ©é˜µ</span><br><span class="line">1 0 0 0</span><br><span class="line">1 1 0 0</span><br><span class="line">1 1 1 0</span><br><span class="line">1 1 1 0</span><br><span class="line"></span><br><span class="line">ç¬¬äºŒä¸ªåºåˆ—çš„maskçŸ©é˜µ</span><br><span class="line">1 0 0 0</span><br><span class="line">1 1 0 0 </span><br><span class="line">1 1 1 0</span><br><span class="line">1 1 1 1</span><br></pre></td></tr></tbody></table></figure><p>æ¥ä¸‹æ¥å¯¹scoreæ±‚softmaxï¼ŒæŠŠå¾—åˆ†å˜æˆæ¦‚ç‡p_attnï¼Œå¦‚æœæœ‰dropoutè¿˜å¯¹p_attnè¿›è¡ŒDropout(è¿™ä¹Ÿæ˜¯åŸå§‹è®ºæ–‡æ²¡æœ‰çš„)ã€‚æœ€åæŠŠp_attnå’Œvalueç›¸ä¹˜ã€‚p_attnæ˜¯(30, 8, 33, 33)ï¼Œvalueæ˜¯(30, 8, 33, 64)ï¼Œæˆ‘ä»¬<strong>åªçœ‹åä¸¤ç»´ï¼Œ(33x33) x (33x64)æœ€ç»ˆå¾—åˆ°33x64ã€‚</strong></p><hr><p>æ¥ä¸‹æ¥å°±æ˜¯è¾“å…¥æ€ä¹ˆå˜æˆQ,Kå’ŒVäº†ï¼Œ<strong>å¯¹äºæ¯ä¸€ä¸ªHeadï¼Œéƒ½ä½¿ç”¨ä¸‰ä¸ªçŸ©é˜µWQ,WK,WVæŠŠè¾“å…¥è½¬æ¢æˆQï¼ŒKå’ŒVã€‚</strong>ç„¶å<strong>åˆ†åˆ«ç”¨æ¯ä¸€ä¸ªHeadè¿›è¡ŒSelf-Attentionçš„è®¡ç®—ï¼Œæœ€åæŠŠNä¸ªHeadçš„è¾“å‡ºæ‹¼æ¥èµ·æ¥ï¼Œæœ€åç”¨ä¸€ä¸ªçŸ©é˜µWOæŠŠè¾“å‡ºå‹ç¼©ä¸€ä¸‹ã€‚</strong>å…·ä½“è®¡ç®—è¿‡ç¨‹ä¸ºï¼š</p><p><img src="https://i.loli.net/2020/08/06/1IbPcFJeK8tsHqN.png" alt="image-20200806023820900" style="zoom: 67%;"></p><p>è¯¦ç»†ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè¾“å…¥Qï¼ŒKå’ŒVç»è¿‡å¤šä¸ªçº¿æ€§å˜æ¢åå¾—åˆ°N(8)ç»„Queryï¼ŒKeyå’ŒValueï¼Œç„¶åä½¿ç”¨Self-Attentionè®¡ç®—å¾—åˆ°Nä¸ªå‘é‡ï¼Œç„¶åæ‹¼æ¥èµ·æ¥ï¼Œ<strong>æœ€åä½¿ç”¨ä¸€ä¸ªçº¿æ€§å˜æ¢è¿›è¡Œé™ç»´ã€‚</strong></p><p><img src="https://i.loli.net/2020/08/08/a2gozSYGn8NOkpH.png" alt="png" style="zoom:67%;"></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiHeadedAttention</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, h, d_model, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        <span class="string">"Take in model size and number of heads."</span></span><br><span class="line">        super(MultiHeadedAttention, self).__init__()</span><br><span class="line">        <span class="keyword">assert</span> d_model % h == <span class="number">0</span>  <span class="comment"># ä¸èƒ½æ•´é™¤å°±æŠ¥é”™</span></span><br><span class="line">        <span class="comment"># We assume d_v always equals d_k</span></span><br><span class="line">        self.d_k = d_model // h</span><br><span class="line">        self.h = h</span><br><span class="line">        self.linears = clones(nn.Linear(d_model, d_model), <span class="number">4</span>)</span><br><span class="line">        self.attn = <span class="literal">None</span></span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, query, key, value, mask=None)</span>:</span></span><br><span class="line">        <span class="string">"Implements Figure 2"</span></span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># # æ‰€æœ‰hä¸ªheadçš„maskéƒ½æ˜¯ç›¸åŒçš„ </span></span><br><span class="line">            mask = mask.unsqueeze(<span class="number">1</span>) <span class="comment">#åœ¨ç»´åº¦ä¸º1çš„ä½ç½®æ·»åŠ ä¸€ä¸ªç»´åº¦ï¼Œæ•°å­—ä¸º1</span></span><br><span class="line">        nbatches = query.size(<span class="number">0</span>) <span class="comment">#å°±æ˜¯æœ‰å¤šå°‘batchçš„å€¼</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 1) é¦–å…ˆä½¿ç”¨çº¿æ€§å˜æ¢ï¼Œç„¶åæŠŠd_modelåˆ†é…ç»™hä¸ªHeadï¼Œæ¯ä¸ªheadä¸ºd_k=d_model/h </span></span><br><span class="line">        query, key, value = \</span><br><span class="line">            [l(x).view(nbatches, <span class="number">-1</span>, self.h, self.d_k).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">             <span class="keyword">for</span> l, x <span class="keyword">in</span> zip(self.linears, (query, key, value))]</span><br><span class="line">           <span class="comment">#.view()è¡¨ç¤ºé‡æ„å¼ é‡çš„ç»´åº¦</span></span><br><span class="line">         <span class="comment">#æ³¨ï¼šå› ä¸ºæ¯ä¸ªLinearå­¦ä¹ åˆ°çš„å‚æ•°æ˜¯ä¸ä¸€æ ·çš„ã€‚æ‰€ä»¥qkvä¸‰ä¸ªä¹Ÿæ˜¯ä¸ä¸€æ ·çš„</span></span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 2)ä½¿ç”¨attentionå‡½æ•°è®¡ç®— </span></span><br><span class="line">        x, self.attn = attention(query, key, value, mask=mask, </span><br><span class="line">                                 dropout=self.dropout)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3) æŠŠ8ä¸ªheadçš„64ç»´å‘é‡æ‹¼æ¥æˆä¸€ä¸ª512çš„å‘é‡ã€‚ç„¶åå†ä½¿ç”¨ä¸€ä¸ªçº¿æ€§å˜æ¢(512,521)ï¼Œshapeä¸å˜ã€‚ </span></span><br><span class="line">        x = x.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous() \</span><br><span class="line">             .view(nbatches, <span class="number">-1</span>, self.h * self.d_k)</span><br><span class="line">        <span class="keyword">return</span> self.linears[<span class="number">-1</span>](x)</span><br></pre></td></tr></tbody></table></figure><p>æˆ‘ä»¬å…ˆçœ‹æ„é€ å‡½æ•°ï¼Œè¿™é‡Œ<strong>d_model(512)æ˜¯Multi-Headçš„è¾“å‡ºå¤§å°</strong>ï¼Œå› ä¸ºæœ‰h(8)ä¸ªheadï¼Œå› æ­¤æ¯ä¸ªheadçš„d_k=512/8=64ã€‚æ¥ç€æˆ‘ä»¬æ„é€ 4ä¸ª(d_model ï¼Œ d_model)çš„çŸ©é˜µï¼Œåé¢æˆ‘ä»¬ä¼šçœ‹åˆ°å®ƒçš„ç”¨å¤„ã€‚æœ€åæ˜¯æ„é€ ä¸€ä¸ªDropoutå±‚ã€‚</p><p>ç„¶åæˆ‘ä»¬æ¥çœ‹forwardæ–¹æ³•ã€‚<strong>è¾“å…¥çš„maskæ˜¯(batch, 1, time)çš„ï¼Œå› ä¸ºæ¯ä¸ªheadçš„maskéƒ½æ˜¯ä¸€æ ·çš„ï¼Œæ‰€ä»¥å…ˆç”¨unsqueeze(1)å˜æˆ(batch, 1, 1, time)</strong>ï¼Œmaskæˆ‘ä»¬å‰é¢å·²ç»è¯¦ç»†åˆ†æè¿‡äº†ã€‚</p><p>æ¥ä¸‹æ¥æ˜¯<strong>æ ¹æ®è¾“å…¥queryï¼Œkeyå’Œvalueè®¡ç®—å˜æ¢åçš„Multi-Headçš„queryï¼Œkeyå’Œvalue</strong>ã€‚è¿™æ˜¯é€šè¿‡ä¸‹é¢çš„è¯­å¥æ¥å®ç°çš„ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">query, key, value = \</span><br><span class="line">[l(x).view(nbatches, <span class="number">-1</span>, self.h, self.d_k).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">for</span> l, x <span class="keyword">in</span> zip(self.linears, (query, key, value))] <span class="comment"># l(x): è°ƒç”¨nn.Linearå‡½æ•°</span></span><br></pre></td></tr></tbody></table></figure><p><strong>zip(self.linears, (query, key, value))æ˜¯æŠŠ(self.linears[0],self.linears[1],self.linears[2])å’Œ(query, key, value)æ”¾åˆ°ä¸€èµ·ç„¶åéå†ã€‚æˆ‘ä»¬åªçœ‹ä¸€ä¸ªself.linears[0] (query)ã€‚æ ¹æ®æ„é€ å‡½æ•°çš„å®šä¹‰ï¼Œself.linears[0]æ˜¯ä¸€ä¸ª(512, 512)çš„çŸ©é˜µï¼Œè€Œqueryæ˜¯(batch, time, 512)ï¼Œç›¸ä¹˜ä¹‹åå¾—åˆ°çš„æ–°queryè¿˜æ˜¯512(d_model)ç»´çš„å‘é‡ï¼Œç„¶åç”¨viewæŠŠå®ƒå˜æˆ(batch, time, 8, 64)ã€‚ç„¶åtransponseæˆ(batch, 8,time,64)ï¼Œè¿™æ˜¯attentionå‡½æ•°è¦æ±‚çš„shapeã€‚åˆ†åˆ«å¯¹åº”8ä¸ªHeadï¼Œæ¯ä¸ªHeadçš„Queryéƒ½æ˜¯64ç»´ã€‚</strong></p><blockquote><p>1.ä¸€èˆ¬æ¥è¯´ï¼ŒçŸ©é˜µç›¸ä¹˜ï¼Œ[a,b] x [b,c] = [a,c]</p><p>æ‰€ä»¥ä¸åŒç»´åº¦è¦è¿›è¡Œå¤„ç†ï¼Œå¿…é¡»é™ç»´ã€‚ä¾‹å¦‚ A çŸ©é˜µ [a,b,c], B çŸ©é˜µæ˜¯[c,d]</p><p>è¿™ä¸ªæ—¶å€™å°±éœ€è¦å°† A çŸ©é˜µçœ‹æˆæ˜¯ [axb, c] ä¸ [c,d] è¿›è¡Œç›¸ä¹˜ï¼Œå¾—åˆ°ç»“æœã€‚</p><ol start="2" type="1"><li>Linearå‡½æ•°l(x)ï¼Œåº”è¯¥å°±æ˜¯ (batch*time,512)**(512,512)</li></ol></blockquote><p>Keyå’ŒValueçš„è¿ç®—å®Œå…¨ç›¸åŒï¼Œå› æ­¤æˆ‘ä»¬ä¹Ÿåˆ†åˆ«å¾—åˆ°8ä¸ªHeadçš„64ç»´çš„Keyå’Œ64ç»´çš„Valueã€‚æ¥ä¸‹æ¥<strong>è°ƒç”¨attentionå‡½æ•°ï¼Œå¾—åˆ°xå’Œself.attnã€‚å…¶ä¸­xçš„shapeæ˜¯(batch, 8, time, 64)ï¼Œè€Œattnæ˜¯(batch, 8, time, time)ã€‚</strong></p><p><strong>x.transpose(1, 2)æŠŠxå˜æˆ(batch, time, 8, 64)ï¼Œç„¶åæŠŠå®ƒviewæˆ(batch, time, 512)ï¼Œå…¶å®å°±æ˜¯æŠŠæœ€å8ä¸ª64ç»´çš„å‘é‡æ‹¼æ¥æˆ512çš„å‘é‡ã€‚æœ€åä½¿ç”¨self.linears[-1]å¯¹xè¿›è¡Œçº¿æ€§å˜æ¢ï¼Œself.linears[-1]æ˜¯(512, 512)çš„ï¼Œå› æ­¤æœ€ç»ˆçš„è¾“å‡ºè¿˜æ˜¯(batch, time, 512)ã€‚æˆ‘ä»¬æœ€åˆæ„é€ äº†4ä¸ª(512, 512)çš„çŸ©é˜µï¼Œå‰3ä¸ªç”¨äºå¯¹queryï¼Œkeyå’Œvalueè¿›è¡Œå˜æ¢ï¼Œè€Œæœ€åä¸€ä¸ªå¯¹8ä¸ªheadæ‹¼æ¥åçš„å‘é‡å†åšä¸€æ¬¡å˜æ¢ã€‚</strong></p><h4 id="a0ttentionåœ¨æ¨¡å‹ä¸­çš„åº”ç”¨">A0ttentionåœ¨æ¨¡å‹ä¸­çš„åº”ç”¨</h4><p>åœ¨Transformeré‡Œï¼Œæœ‰3ä¸ªåœ°æ–¹ç”¨åˆ°äº†MultiHeadedAttentionï¼š</p><ul><li><p>Encoderçš„Self-Attentionå±‚</p><p><strong>queryï¼Œkeyå’Œvalueéƒ½æ˜¯ç›¸åŒçš„å€¼</strong>ï¼Œæ¥è‡ªä¸‹å±‚çš„è¾“å…¥ã€‚Maskéƒ½æ˜¯1(å½“ç„¶paddingçš„ä¸ç®—)ã€‚</p></li><li><p>Decoderçš„Self-Attentionå±‚</p><p><strong>queryï¼Œkeyå’Œvalueéƒ½æ˜¯ç›¸åŒçš„å€¼</strong>ï¼Œæ¥è‡ªä¸‹å±‚çš„è¾“å…¥ã€‚ä½†æ˜¯Maskä½¿å¾—å®ƒä¸èƒ½è®¿é—®æœªæ¥çš„è¾“å…¥ã€‚</p></li><li><p>Encoder-Decoderçš„æ™®é€šAttention</p><p><strong>queryæ¥è‡ªä¸‹å±‚çš„è¾“å…¥ï¼Œè€Œkeyå’Œvalueç›¸åŒ</strong>ï¼Œæ˜¯Encoderæœ€åä¸€å±‚çš„è¾“å‡ºï¼Œè€ŒMaskéƒ½æ˜¯1ã€‚</p></li></ul><h3 id="position-wise-å‰é¦ˆç½‘ç»œ">Position-wise å‰é¦ˆç½‘ç»œ</h3><p>In addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully connected feed-forward network, which is applied to each position separately and identically. <code>This consists of two linear transformations with a ReLU activation in between.</code></p><p>å…¨è¿æ¥å±‚æœ‰ä¸¤ä¸ªçº¿æ€§å˜æ¢ä»¥åŠå®ƒä»¬ä¹‹é—´çš„ReLUæ¿€æ´»ç»„æˆï¼š</p><p><img src="https://i.loli.net/2020/08/08/PU96rciRsWxOCKp.png" alt="image-20200728231445307" style="zoom:50%;"></p><p>å…¨è¿æ¥å±‚çš„è¾“å…¥å’Œè¾“å‡ºéƒ½æ˜¯d_model(512)ç»´çš„ï¼Œä¸­é—´éšå•å…ƒçš„ä¸ªæ•°æ˜¯d_ff(2048)ç»´</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionwiseFeedForward</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Implements FFN equation."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, d_ff, dropout=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">        super(PositionwiseFeedForward, self).__init__()</span><br><span class="line">        self.w_1 = nn.Linear(d_model, d_ff)</span><br><span class="line">        self.w_2 = nn.Linear(d_ff, d_model)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.w_2(self.dropout(F.relu(self.w_1(x))))</span><br></pre></td></tr></tbody></table></figure><h3 id="embeddings-å’Œ-softmax">Embeddings å’Œ Softmax</h3><p><strong>è¾“å…¥çš„è¯åºåˆ—éƒ½æ˜¯IDåºåˆ—ï¼Œæˆ‘ä»¬éœ€è¦Embedding</strong>ã€‚æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€éƒ½éœ€è¦Embeddingï¼Œæ­¤å¤–æˆ‘ä»¬éœ€è¦ä¸€ä¸ªçº¿æ€§å˜æ¢æŠŠéšå˜é‡å˜æˆè¾“å‡ºæ¦‚ç‡ï¼Œè¿™å¯ä»¥é€šè¿‡å‰é¢çš„ç±»Generatoræ¥å®ç°ã€‚æˆ‘ä»¬è¿™é‡Œå®ç°Embeddingï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Embeddings</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, vocab)</span>:</span></span><br><span class="line">        super(Embeddings, self).__init__()</span><br><span class="line">        self.lut = nn.Embedding(vocab, d_model) <span class="comment">#å°†å­—å…¸vocabå¤§å°æ˜ å°„åˆ°d_modelå¤§å°</span></span><br><span class="line">        self.d_model = d_model</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.lut(x) * math.sqrt(self.d_model)</span><br></pre></td></tr></tbody></table></figure><p>æ³¨æ„çš„å°±æ˜¯forwardå¤„ç†ä½¿ç”¨nn.Embeddingå¯¹è¾“å…¥xè¿›è¡ŒEmbeddingä¹‹å¤–ï¼Œè¿˜é™¤ä»¥äº†sqrt(d_model) ï¼ˆå¼€æ–¹ï¼‰</p><h3 id="ä½ç½®ç¼–ç ">ä½ç½®ç¼–ç </h3><p>ä½ç½®ç¼–ç çš„å…¬å¼ä¸ºï¼š</p><p><img src="https://i.loli.net/2020/08/08/WUpXhHsK3S1jCqn.png" alt="image-20200728232133981" style="zoom:50%;"></p><p><img src="https://i.loli.net/2020/08/08/XOZPy89KVi1xjTh.png" alt="image-20200728232255029" style="zoom:50%;"></p><p>where <code>pos</code> is the position and <code>i</code> is the dimension. That is, each dimension of the positional encoding corresponds to a sinusoid.</p><p>å‡è®¾è¾“å…¥æ˜¯IDåºåˆ—é•¿åº¦ä¸º10ï¼Œ<strong>å¦‚æœè¾“å…¥Embeddingä¹‹åæ˜¯(10, 512)ï¼Œé‚£ä¹ˆä½ç½®ç¼–ç çš„è¾“å‡ºä¹Ÿæ˜¯(10, 512)ã€‚</strong>ä¸Šå¼ä¸­poså°±æ˜¯ä½ç½®(0-9)ï¼Œ512ç»´çš„å¶æ•°ç»´ä½¿ç”¨sinå‡½æ•°ï¼Œè€Œå¥‡æ•°ç»´ä½¿ç”¨coså‡½æ•°ã€‚è¿™ç§ä½ç½®ç¼–ç çš„å¥½å¤„æ˜¯ï¼šPE_pos+kå¯ä»¥è¡¨ç¤ºæˆ PE_posçš„çº¿æ€§å‡½æ•°ï¼Œè¿™æ ·ç½‘ç»œå°±èƒ½å®¹æ˜“çš„å­¦åˆ°ç›¸å¯¹ä½ç½®çš„å…³ç³»ã€‚</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">5</span>))</span><br><span class="line">pe = PositionalEncoding(<span class="number">20</span>, <span class="number">0</span>)</span><br><span class="line">y = pe.forward(Variable(torch.zeros(<span class="number">1</span>, <span class="number">100</span>, <span class="number">20</span>)))</span><br><span class="line">plt.plot(np.arange(<span class="number">100</span>), y[<span class="number">0</span>, :, <span class="number">4</span>:<span class="number">8</span>].data.numpy())</span><br><span class="line">plt.legend([<span class="string">"dim %d"</span>%p <span class="keyword">for</span> p <span class="keyword">in</span> [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>]])</span><br></pre></td></tr></tbody></table></figure><p>å›¾æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œå‘é‡çš„å¤§å°d_model=20ï¼Œæˆ‘ä»¬è¿™é‡Œç”»å‡ºæ¥ç¬¬4ã€5ã€6å’Œ7ç»´(ä¸‹æ ‡ä»é›¶å¼€å§‹)ç»´çš„å›¾åƒï¼Œæœ€å¤§çš„ä½ç½®æ˜¯100ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒä»¬éƒ½æ˜¯æ­£å¼¦(ä½™å¼¦)å‡½æ•°ï¼Œè€Œä¸”å‘¨æœŸè¶Šæ¥è¶Šé•¿ã€‚</p><figure><img src="https://i.loli.net/2020/08/08/TfDHKvnM3emYysL.png" alt="png"><figcaption>png</figcaption></figure><p>å‰é¢æˆ‘ä»¬æåˆ°ä½ç½®ç¼–ç çš„å¥½å¤„æ˜¯PE_pos+kå¯ä»¥è¡¨ç¤ºæˆ P_Eposçš„çº¿æ€§å‡½æ•°ï¼Œæˆ‘ä»¬ä¸‹é¢ç®€å•çš„éªŒè¯ä¸€ä¸‹ã€‚æˆ‘ä»¬ä»¥ç¬¬iç»´ä¸ºä¾‹ï¼Œä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬æŠŠ<img src="https://i.loli.net/2020/08/06/iEoDOvKzB42N6Xe.png" alt="image-20200806104700979" style="zoom: 67%;">è®°ä½œWiï¼Œè¿™æ˜¯ä¸€ä¸ªå¸¸é‡ã€‚</p><p><img src="https://i.loli.net/2020/08/06/E9h2vXIDK1MAjUg.png" alt="image-20200806104725624" style="zoom:67%;"></p><p>æˆ‘ä»¬å‘ç°PE_pos+k ç¡®å®å¯ä»¥è¡¨ç¤ºæˆ PE_posçš„çº¿æ€§å‡½æ•°ã€‚</p><p>In addition, we apply dropout to the sums of the embeddings and the positional encodings in both the encoder and decoder stacks. For the base model, we use a rate of <code>Pdrop=0.1</code>.</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PositionalEncoding</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Implement the PE function."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_model, dropout, max_len=<span class="number">5000</span>)</span>:</span></span><br><span class="line">        super(PositionalEncoding, self).__init__()</span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Compute the positional encodings once in log space.</span></span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        <span class="comment">#ä¹‹æ‰€ä»¥ç”¨logå†exp,å¯èƒ½æ˜¯è€ƒè™‘åˆ°æ•°å€¼è¿‡å¤§æº¢å‡ºçš„é—®é¢˜</span></span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>) *</span><br><span class="line">                             -(math.log(<span class="number">10000.0</span>) / d_model))</span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        self.register_buffer(<span class="string">'pe'</span>, pe)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = x + Variable(self.pe[:, :x.size(<span class="number">1</span>)], </span><br><span class="line">                         requires_grad=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">return</span> self.dropout(x)</span><br></pre></td></tr></tbody></table></figure><p>ä»£ç å¯ä»¥å‚è€ƒå…¬å¼ï¼Œè°ƒç”¨äº†<code>Module.register_bufferå‡½æ•°</code>ã€‚è¿™ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯åˆ›å»ºä¸€ä¸ªbufferï¼Œæ¯”å¦‚è¿™é‡ŒæŠŠpeä¿å­˜ä¸‹æ¥ã€‚register_bufferé€šå¸¸ç”¨äºä¿å­˜ä¸€äº›æ¨¡å‹å‚æ•°ä¹‹å¤–çš„å€¼ï¼Œæ¯”å¦‚åœ¨BatchNormä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¿å­˜running_mean(Moving Average)ï¼Œå®ƒä¸æ˜¯æ¨¡å‹çš„å‚æ•°(ä¸ç”¨æ¢¯åº¦ä¸‹é™)ï¼Œä½†æ˜¯æ¨¡å‹ä¼šä¿®æ”¹å®ƒï¼Œè€Œä¸”åœ¨é¢„æµ‹çš„æ—¶å€™ä¹Ÿè¦ä½¿ç”¨å®ƒã€‚è¿™é‡Œä¹Ÿæ˜¯ç±»ä¼¼çš„ï¼Œpeæ˜¯ä¸€ä¸ªæå‰è®¡ç®—å¥½çš„å¸¸é‡ï¼Œæˆ‘ä»¬åœ¨forwardè¦ç”¨åˆ°å®ƒã€‚æˆ‘ä»¬åœ¨æ„é€ å‡½æ•°é‡Œå¹¶æ²¡æœ‰æŠŠpeä¿å­˜åˆ°selfé‡Œï¼Œä½†æ˜¯åœ¨forwardçš„æ—¶å€™æˆ‘ä»¬å´å¯ä»¥ç›´æ¥ä½¿ç”¨å®ƒ(self.pe)ã€‚å¦‚æœæˆ‘ä»¬ä¿å­˜(åºåˆ—åŒ–)æ¨¡å‹åˆ°ç£ç›˜çš„è¯ï¼ŒPyTorchæ¡†æ¶ä¹Ÿä¼šå¸®æˆ‘ä»¬ä¿å­˜bufferé‡Œçš„æ•°æ®åˆ°ç£ç›˜ï¼Œè¿™æ ·ååºåˆ—åŒ–çš„æ—¶å€™èƒ½æ¢å¤å®ƒä»¬</p><h3 id="å®Œæ•´æ¨¡å‹">å®Œæ•´æ¨¡å‹</h3><blockquote><p>Here we <code>define a function that takes in hyperparameters and produces a full model.</code></p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_model</span><span class="params">(src_vocab, tgt_vocab, N=<span class="number">6</span>, </span></span></span><br><span class="line"><span class="function"><span class="params">               d_model=<span class="number">512</span>, d_ff=<span class="number">2048</span>, h=<span class="number">8</span>, dropout=<span class="number">0.1</span>)</span>:</span> <span class="comment">#d_ffï¼š feedforwardçš„ç»´åº¦</span></span><br><span class="line">    <span class="string">"Helper: Construct a model from hyperparameters."</span></span><br><span class="line">    c = copy.deepcopy</span><br><span class="line">    attn = MultiHeadedAttention(h, d_model)</span><br><span class="line">    ff = PositionwiseFeedForward(d_model, d_ff, dropout)</span><br><span class="line">    position = PositionalEncoding(d_model, dropout)</span><br><span class="line">    model = EncoderDecoder(</span><br><span class="line">        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),</span><br><span class="line">        Decoder(DecoderLayer(d_model, c(attn), c(attn), </span><br><span class="line">                             c(ff), dropout), N),</span><br><span class="line">        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),</span><br><span class="line">        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),</span><br><span class="line">        Generator(d_model, tgt_vocab))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># This was important from their code. </span></span><br><span class="line">    <span class="comment"># Initialize parameters with Glorot / fan_avg. éšæœºåˆå§‹åŒ–å‚æ•°ï¼Œè¿™éå¸¸é‡è¦</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters():</span><br><span class="line">        <span class="keyword">if</span> p.dim() &gt; <span class="number">1</span>:</span><br><span class="line">            nn.init.xavier_uniform(p)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¤ºä¾‹: å¯¹modelç®€å•è¾“å…¥å‚æ•°</span></span><br><span class="line">tmp_model = make_model(<span class="number">10</span>, <span class="number">10</span>, <span class="number">2</span>)</span><br></pre></td></tr></tbody></table></figure><p>é¦–å…ˆæŠŠcopy.deepcopyå‘½åä¸ºcï¼Œè¿™æ ·ä½¿ä¸‹é¢çš„ä»£ç ç®€æ´ä¸€ç‚¹ã€‚ç„¶åæ„é€ MultiHeadedAttentionï¼ŒPositionwiseFeedForwardå’ŒPositionalEncodingå¯¹è±¡ã€‚æ¥ç€å°±æ˜¯æ„é€ EncoderDecoderå¯¹è±¡ã€‚å®ƒéœ€è¦5ä¸ªå‚æ•°ï¼šEncoderã€Decoderã€src-embedã€tgt-embedå’ŒGeneratorã€‚</p><p>æˆ‘ä»¬å…ˆçœ‹åé¢ä¸‰ä¸ªç®€å•çš„å‚æ•°ï¼ŒGeneratorç›´æ¥æ„é€ å°±è¡Œäº†ï¼Œå®ƒçš„ä½œç”¨æ˜¯æŠŠæ¨¡å‹çš„éšå•å…ƒå˜æˆè¾“å‡ºè¯çš„æ¦‚ç‡ã€‚è€Œsrc-embedæ˜¯ä¸€ä¸ªEmbeddingså±‚å’Œä¸€ä¸ªä½ç½®ç¼–ç å±‚c(position)ï¼Œtgt-embedä¹Ÿæ˜¯ç±»ä¼¼çš„ã€‚</p><p>æœ€åæˆ‘ä»¬æ¥çœ‹Decoder(Encoderå’ŒDecoderç±»ä¼¼çš„)ã€‚Decoderç”±Nä¸ªDecoderLayerç»„æˆï¼Œè€ŒDecoderLayeréœ€è¦ä¼ å…¥self-attn, src-attnï¼Œå…¨è¿æ¥å±‚å’ŒDropoutã€‚å› ä¸ºæ‰€æœ‰çš„MultiHeadedAttentionéƒ½æ˜¯ä¸€æ ·çš„ï¼Œå› æ­¤æˆ‘ä»¬ç›´æ¥deepcopyå°±è¡Œï¼›åŒç†æ‰€æœ‰çš„PositionwiseFeedForwardä¹Ÿæ˜¯ä¸€æ ·çš„ç½‘ç»œç»“æœï¼Œæˆ‘ä»¬å¯ä»¥deepcopyè€Œä¸è¦å†æ„é€ ä¸€ä¸ªã€‚</p><h3 id="è®­ç»ƒ">è®­ç»ƒ</h3><p>This section describes the training regime for our models.</p><blockquote><p>We stop for a quick interlude to introduce some of the tools needed to train a standard encoder decoder model. First <code>we define a batch object that holds the src and target sentences for training, as well as constructing the masks.</code></p></blockquote><h4 id="batches-å’Œ-masking">Batches å’Œ Masking</h4><p><code>mask çŸ©é˜µæ¥è‡ª batch</code></p><p><code>self.src_mask = (src != pad).unsqueeze(-2)</code> ä¹Ÿå°±æ˜¯è¯´, æºè¯­è¨€çš„ <strong>mask çŸ©é˜µçš„ç»´åº¦æ˜¯ (batch_size, 1, length)</strong>, é‚£ä¹ˆä¸ºä»€ä¹ˆ <code>attn_shape = (batch_size, size, size)</code> å‘¢? å¯ä»¥è¿™ä¹ˆè§£é‡Š, <strong>åœ¨ encoder é˜¶æ®µçš„ Self_Attention é˜¶æ®µ, æ‰€æœ‰çš„ Attention æ˜¯å¯ä»¥åŒæ—¶è¿›è¡Œçš„, æŠŠæ‰€æœ‰çš„ Attention_result ç®—å‡ºæ¥, ç„¶åç”¨åŒä¸€ä¸ª mask vector * Attention_result å°±å¯ä»¥äº†</strong>, ä½†æ˜¯åœ¨ decoder é˜¶æ®µå´ä¸èƒ½è¿™ä¹ˆåš, æˆ‘ä»¬éœ€è¦å…³æ³¨çš„é—®é¢˜æ˜¯:</p><blockquote><p>æ ¹æ®å·²ç»é¢„æµ‹å‡ºæ¥çš„å•è¯é¢„æµ‹ä¸‹é¢çš„å•è¯, è¿™ä¸€è¿‡ç¨‹<strong>æ˜¯åºåˆ—çš„</strong>,</p><p>è€Œæˆ‘ä»¬çš„è®¡ç®—æ˜¯<strong>å¹¶è¡Œ</strong>çš„, æ‰€ä»¥è¿™ä¸€è¿‡ç¨‹ä¸­, å¿…é¡»è¦å¼•å…¥çŸ©é˜µ. ä¹Ÿå°±æ˜¯ä¸Šé¢çš„ subsequent_mask() å‡½æ•°è·å¾—çš„çŸ©é˜µ.</p></blockquote><p>è¿™ä¸ªçŸ©é˜µä¹Ÿå¾ˆå½¢è±¡, åˆ†åˆ«è¡¨ç¤ºå·²ç»é¢„æµ‹çš„å•è¯çš„ä¸ªæ•°ä¸º, 1, 2, 3, 4, 5.</p><p>ç„¶åæˆ‘ä»¬å°†ä»¥ä¸Šè¿‡ç¨‹åè¿‡æ¥è¿‡ä¸€ç¯‡, å°±å¾ˆæ˜æ˜¾äº†, åœ¨ batché˜¶æ®µè·å¾— mask çŸ©é˜µ, ç„¶åå’Œ batch ä¸€èµ·è®­ç»ƒ, åœ¨ encoder ä¸ deocder é˜¶æ®µå®ç° mask æœºåˆ¶.</p><blockquote><ul><li><p>maskåœ¨Batchä¸­å®šä¹‰ï¼Œsrc_mask.size (30,1,10) , trg_mask.size(30,10,10)</p></li><li><p>ç„¶ååœ¨MultiHeadedAttentionä¸­<code>mask = mask.unsqueeze(1)</code>åˆæ‰©ç»´äº†ï¼Œ</p><p>å…¶ä¸­src_mask.size(30,1,1,10) ,trg_mask.size(30,1,10,10)</p></li><li><p>src_mask.sizeæ»¡è¶³attentionä¸­çš„ç»´åº¦ï¼Œæ‰€ä»¥å¯ä»¥å¯¹scoreè¿›è¡Œmask</p><p>src_maskè¿˜åœ¨è§£ç å™¨çš„ç¬¬1å­å±‚ç”¨åˆ°ï¼Œç›¸åŒçš„åŸç†</p></li><li><p>trg_maskåœ¨è§£ç å™¨çš„ç¬¬0å­å±‚ç”¨åˆ°ï¼Œæ»¡è¶³è¦æ±‚</p></li></ul></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Batch</span>:</span> <span class="comment">#å®šä¹‰æ¯ä¸€ä¸ªbatchä¸­çš„srcã€tgtã€mask</span></span><br><span class="line">    <span class="comment">#trg = tgt: çœŸå®çš„æ ‡ç­¾åºåˆ—  out ï¼š é¢„æµ‹çš„å•è¯  </span></span><br><span class="line">    <span class="string">"Object for holding a batch of data with mask during training."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, src, trg=None, pad=<span class="number">0</span>)</span>:</span> </span><br><span class="line">        self.src = src</span><br><span class="line">        self.src_mask = (src != pad).unsqueeze(<span class="number">-2</span>) <span class="comment">#æ‰©å……ç»´åº¦ å€’æ•°ç¬¬äºŒç»´å¢åŠ å€¼ä¸º1 size=(30,1,10)</span></span><br><span class="line">        <span class="comment">#å¹¶ä¸”éé›¶å€¼å…¨éƒ¨èµ‹å€¼ä¸º1</span></span><br><span class="line">        </span><br><span class="line">         <span class="comment"># åœ¨é¢„æµ‹çš„æ—¶å€™æ˜¯æ²¡æœ‰ tgt çš„,æ­¤æ—¶ä¸º None æ­¤æ—¶trgæ˜¯tgtçš„å½¢å‚</span></span><br><span class="line">        <span class="keyword">if</span> trg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.trg = trg[:, :<span class="number">-1</span>] <span class="comment">#trg.size(30,9) ï¼Œåœ¨é¢„æµ‹ä¸­ï¼Œä¼šæå‰è¾“å…¥èµ·å§‹ç¬¦åˆ°ysä¸­</span></span><br><span class="line">            <span class="string">"""</span></span><br><span class="line"><span class="string">              trg.size(30,9) è¿™é‡Œå»æ‰çš„æœ€åä¸€ä¸ªå•è¯, ä¸æ˜¯çœŸæ­£çš„å•è¯, è€Œæ˜¯æ ‡å¿— '&lt;eos&gt;' , è¾“å…¥ä¸è¾“å‡ºéƒ½è¿˜æœ‰ä¸€ä¸ª '&lt;sos&gt;' åœ¨å¥å­çš„å¼€å¤´,  æ˜¯decoderçš„è¾“å…¥ï¼Œ</span></span><br><span class="line"><span class="string">            éœ€è¦è¿›è¡Œmaskï¼Œä½¿å¾—Self-Attentionä¸èƒ½è®¿é—®æœªæ¥çš„è¾“å…¥ã€‚æœ€åä¸€ä¸ªè¯ä¸éœ€è¦ç”¨åˆ°trg</span></span><br><span class="line"><span class="string">            """</span></span><br><span class="line">        self.trg_y = trg[:, <span class="number">1</span>:] <span class="comment"># trg_y.size(30,9) </span></span><br><span class="line">            <span class="comment">#trg_y: æœ€åçš„ç»“æœã€‚ç”¨äºlossä¸­çš„æ¯”è¾ƒã€‚ å»æ‰å¼€å¤´çš„'&lt;sos&gt;'ï¼Œæ˜¯decoderçš„è¾“å‡º</span></span><br><span class="line">            self.trg_mask = \</span><br><span class="line">                self.make_std_mask(self.trg, pad)</span><br><span class="line">            self.ntokens = (self.trg_y != pad).data.sum() <span class="comment">#ä¸ä¸º0çš„æ€»æ•° 30*9 = 270</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_std_mask</span><span class="params">(tgt, pad)</span>:</span> <span class="comment">#tgt_mask.size(30,9,9)ï¼Œæ¯ä¸€ä¸ªåºåˆ—éƒ½æ˜¯ä¸€ä¸ª9*9çš„çŸ©é˜µ</span></span><br><span class="line">        <span class="string">"Create a mask to hide padding and future words."</span></span><br><span class="line">        <span class="comment">#"åˆ›å»ºMaskï¼Œä½¿å¾—æˆ‘ä»¬ä¸èƒ½attend toæœªæ¥çš„è¯"</span></span><br><span class="line">        tgt_mask = (tgt != pad).unsqueeze(<span class="number">-2</span>)</span><br><span class="line">        tgt_mask = tgt_mask &amp; Variable(</span><br><span class="line">            subsequent_mask(tgt.size(<span class="number">-1</span>)).type_as(tgt_mask.data))</span><br><span class="line">        <span class="keyword">return</span> tgt_mask</span><br></pre></td></tr></tbody></table></figure><p>Batchæ„é€ å‡½æ•°çš„è¾“å…¥æ˜¯srcå’Œtrgï¼Œåè€…å¯ä»¥ä¸ºNoneï¼Œå› ä¸ºå†é¢„æµ‹çš„æ—¶å€™æ˜¯æ²¡æœ‰tgtçš„ã€‚</p><p>æˆ‘ä»¬ç”¨ä¸€ä¸ªä¾‹å­æ¥è¯´æ˜Batchçš„ä»£ç ï¼Œè¿™æ˜¯è®­ç»ƒé˜¶æ®µçš„ä¸€ä¸ªBatchï¼Œ<strong>srcæ˜¯(48, 20)</strong>ï¼Œ48æ˜¯batchå¤§å°ï¼Œè€Œ20æ˜¯æœ€é•¿çš„å¥å­é•¿åº¦ï¼Œå…¶å®ƒçš„ä¸å¤Ÿé•¿çš„éƒ½paddingæˆ20äº†ã€‚è€Œ<strong>trgæ˜¯(48, 25)</strong>ï¼Œè¡¨ç¤ºç¿»è¯‘åçš„æœ€é•¿å¥å­æ˜¯25ä¸ªè¯ï¼Œä¸è¶³çš„ä¹Ÿpaddingè¿‡äº†ã€‚</p><p>æˆ‘ä»¬é¦–å…ˆçœ‹src_maskæ€ä¹ˆå¾—åˆ°ï¼Œ(src != pad)æŠŠsrcä¸­å¤§äº0çš„æ—¶åˆ»ç½®ä¸º1ï¼Œè¿™æ ·è¡¨ç¤ºå®ƒå¯ä»¥attend toçš„èŒƒå›´ã€‚ç„¶åunsqueeze(-2)æŠŠsrc_maskå˜æˆ(48/batch, 1, 20/time)ã€‚å®ƒçš„ç”¨æ³•å‚è€ƒå‰é¢çš„attentionå‡½æ•°ã€‚</p><p>å¯¹äºè®­ç»ƒæ¥è¯´(Teaching Forcingæ¨¡å¼)ï¼ŒDecoderæœ‰ä¸€ä¸ªè¾“å…¥å’Œä¸€ä¸ªè¾“å‡ºã€‚<strong>æ¯”å¦‚å¥å­â€<sos> it is a good day <eos>â€ï¼Œè¾“å…¥ä¼šå˜æˆâ€<sos> it is a good dayâ€ï¼Œè€Œè¾“å‡ºä¸ºâ€it is a good day <eos>â€ã€‚å¯¹åº”åˆ°ä»£ç é‡Œï¼Œself.trgå°±æ˜¯è¾“å…¥ï¼Œè€Œself.trg_yå°±æ˜¯è¾“å‡ºã€‚</eos></sos></eos></sos></strong>æ¥ç€å¯¹è¾“å…¥self.trgè¿›è¡Œmaskï¼Œä½¿å¾—Self-Attentionä¸èƒ½è®¿é—®æœªæ¥çš„è¾“å…¥ã€‚è¿™æ˜¯é€šè¿‡make_std_maskå‡½æ•°å®ç°çš„ï¼Œè¿™ä¸ªå‡½æ•°ä¼šè°ƒç”¨æˆ‘ä»¬ä¹‹å‰è¯¦ç»†ä»‹ç»è¿‡çš„subsequent_maskå‡½æ•°ã€‚æœ€ç»ˆå¾—åˆ°çš„<strong>trg_maskçš„shapeæ˜¯(48/batch, 24, 24)</strong>ï¼Œè¡¨ç¤º24ä¸ªæ—¶åˆ»çš„MaskçŸ©é˜µï¼Œè¿™æ˜¯ä¸€ä¸ªå¯¹è§’çº¿ä»¥åŠä¹‹ä¸‹éƒ½æ˜¯1çš„çŸ©é˜µï¼Œå‰é¢å·²ç»ä»‹ç»è¿‡äº†ã€‚</p><p>æ³¨æ„<strong>src_maskçš„shapeæ˜¯(batch, 1, time)</strong>ï¼Œè€Œ<strong>trg_maskæ˜¯(batch, time, time)</strong>ã€‚å› ä¸ºsrc_maskçš„æ¯ä¸€ä¸ªæ—¶åˆ»éƒ½èƒ½attend toæ‰€æœ‰æ—¶åˆ»(paddingçš„é™¤å¤–)ï¼Œä¸€æ¬¡åªéœ€è¦ä¸€ä¸ªå‘é‡å°±è¡Œäº†ï¼Œè€Œtrg_maskéœ€è¦ä¸€ä¸ªçŸ©é˜µã€‚</p><h4 id="training-loop">Training Loop</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_epoch</span><span class="params">(data_iter, model, loss_compute)</span>:</span> <span class="comment">#è¿”å›total_loss / total_tokens ã€‚æ˜¯ä¸€ä¸ªæ•°å€¼ï¼ŒæŸå¤±è®¡ç®—</span></span><br><span class="line">    <span class="comment">#éå†ä¸€ä¸ªepochçš„æ•°æ®</span></span><br><span class="line">    <span class="string">"Standard Training and Logging Function"</span></span><br><span class="line">    start = time.time() <span class="comment">#å¼€å§‹æ—¶é—´ï¼Œè®¡ç®—ç”¨æ—¶</span></span><br><span class="line">    total_tokens = <span class="number">0</span> </span><br><span class="line">    total_loss = <span class="number">0</span> </span><br><span class="line">    tokens = <span class="number">0</span> </span><br><span class="line">    <span class="keyword">for</span> i, batch <span class="keyword">in</span> enumerate(data_iter): <span class="comment">#æ¯ä¸€æ­¥data_iterï¼ˆgen_dataï¼‰ï¼Œå®ä¾‹åŒ–batchæ•°æ®ç”¨äºå­¦ä¹ .è¿›è¡Œ20æ¬¡</span></span><br><span class="line">        <span class="comment">#gen_dataè¿”å›çš„æ˜¯20ä¸ªBatchï¼Œé€šè¿‡enumerateå®ä¾‹åŒ–20ä¸ªbatch </span></span><br><span class="line">        out = model.forward(batch.src, batch.trg, </span><br><span class="line">                            batch.src_mask, batch.trg_mask) <span class="comment">#è°ƒç”¨EncoderDecoderçš„å®ä¾‹åŒ–modelï¼Œè§£ç å™¨ä½œä¸ºè¾“å‡º</span></span><br><span class="line">        loss = loss_compute(out, batch.trg_y, batch.ntokens) <span class="comment">#è®¡ç®—å‡ºä¸€ä¸ªbatchä¸­çš„lossã€‚ trg_yæ˜¯æ ‡å‡†å€¼ã€‚ntokensä½œä¸ºnorm</span></span><br><span class="line">        total_loss += loss <span class="comment">#losså åŠ ã€‚è¿›è¡Œ20æ¬¡</span></span><br><span class="line">        total_tokens += batch.ntokens </span><br><span class="line">        tokens += batch.ntokens</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">1</span>: <span class="comment">#iä»0å¼€å§‹çš„ï¼Œå½“i=1çš„æ—¶å€™ï¼Œè¿›è¡Œäº†ä¸€æ¬¡batchï¼Œæ‰€ä»¥è¿™é‡Œè®¡ç®—çš„å°±æ˜¯ä¸€æ¬¡batchæ‰€ç”¨çš„æ—¶é—´ã€‚è€Œè¦è¿›è¡Œ20æ¬¡ã€‚  50æ˜¯éšæœºè®¾ç½®</span></span><br><span class="line">            elapsed = time.time() - start <span class="comment">#è®¡ç®—ä¸€å…±ç”¨æ—¶</span></span><br><span class="line">            print(<span class="string">"Epoch Step: %d Loss: %f Tokens per Sec: %f"</span> % </span><br><span class="line">                    (i, loss / batch.ntokens, tokens / elapsed)) <span class="comment">#æ‰€æœ‰batchä¸­çš„losså’Œntoken,å³ä¸€ä¸ªepochä¸­</span></span><br><span class="line">            start = time.time() <span class="comment"># é‡ç½®æ—¶é—´</span></span><br><span class="line">            tokens = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> total_loss / total_tokens</span><br></pre></td></tr></tbody></table></figure><p>å®ƒéå†ä¸€ä¸ªepochçš„æ•°æ®ï¼Œç„¶åè°ƒç”¨forwardï¼Œæ¥ç€ç”¨loss_computeå‡½æ•°è®¡ç®—æ¢¯åº¦ï¼Œæ›´æ–°å‚æ•°å¹¶ä¸”è¿”å›lossã€‚è¿™é‡Œçš„loss_computeæ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œå®ƒçš„è¾“å…¥æ˜¯æ¨¡å‹çš„é¢„æµ‹outï¼ŒçœŸå®çš„æ ‡ç­¾åºåˆ—batch.trg_yå’Œbatchçš„è¯ä¸ªæ•°ã€‚å®é™…çš„å®ç°æ˜¯MultiGPULossComputeç±»ï¼Œè¿™æ˜¯ä¸€ä¸ªcallableã€‚æœ¬æ¥è®¡ç®—æŸå¤±å’Œæ›´æ–°å‚æ•°æ¯”è¾ƒç®€å•ï¼Œä½†æ˜¯è¿™é‡Œä¸ºäº†å®ç°å¤šGPUçš„è®­ç»ƒï¼Œè¿™ä¸ªç±»å°±æ¯”è¾ƒå¤æ‚äº†ã€‚</p><h4 id="training-data-å’Œ-batching">Training Data å’Œ Batching</h4><p>We trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million sentence pairs. Sentences were encoded using byte-pair encoding, which has a shared source-target vocabulary of about 37000 tokens. For English- French, we used the significantly larger WMT 2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece vocabulary.</p><p>Sentence pairs were batched together by approximate sequence length. Each training batch contained a set of sentence pairs containing approximately 25000 source tokens and 25000 target tokens.</p><blockquote><p>We will use torch text for batching. This is discussed in more detail below. Here we create batches in a torchtext function that ensures our batch size padded to the maximum batchsize does not surpass a threshold (25000 if we have 8 gpus).</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">global</span> max_src_in_batch, max_tgt_in_batch</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_size_fn</span><span class="params">(new, count, sofar)</span>:</span></span><br><span class="line">    <span class="string">"Keep augmenting batch and calculate total number of tokens + padding."</span></span><br><span class="line">    <span class="keyword">global</span> max_src_in_batch, max_tgt_in_batch</span><br><span class="line">    <span class="keyword">if</span> count == <span class="number">1</span>:</span><br><span class="line">        max_src_in_batch = <span class="number">0</span></span><br><span class="line">        max_tgt_in_batch = <span class="number">0</span></span><br><span class="line">    max_src_in_batch = max(max_src_in_batch,  len(new.src))</span><br><span class="line">    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + <span class="number">2</span>)</span><br><span class="line">    src_elements = count * max_src_in_batch</span><br><span class="line">    tgt_elements = count * max_tgt_in_batch</span><br><span class="line">    <span class="keyword">return</span> max(src_elements, tgt_elements)</span><br></pre></td></tr></tbody></table></figure><h4 id="ç¡¬ä»¶-å’Œ-è®­ç»ƒè¿›åº¦">ç¡¬ä»¶ å’Œ è®­ç»ƒè¿›åº¦</h4><p>We trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using the hyperparameters described throughout the paper, each training step took about 0.4 seconds. We trained the base models for a total of 100,000 steps or 12 hours. For our big models, step time was 1.0 seconds. The big models were trained for 300,000 steps (3.5 days).</p><h4 id="optimizer">Optimizer</h4><p>We used the <code>Adam optimizer</code> <a href="https://arxiv.org/abs/1412.6980" target="_blank" rel="noopener">(cite)</a> with Î²1=0.9Î²1=0.9, Î²2=0.98Î²2=0.98 and Ïµ=10âˆ’9Ïµ=10âˆ’9. We varied the learning rate over the course of training, according to the formula: lrate=dâˆ’0.5modelâ‹…min(step_numâˆ’0.5,step_numâ‹…warmup_stepsâˆ’1.5)lrate=dmodelâˆ’0.5â‹…min(step_numâˆ’0.5,step_numâ‹…warmup_stepsâˆ’1.5) This corresponds to increasing the learning rate linearly for the first warmupstepswarmupsteps training steps, and decreasing it thereafter proportionally to the inverse square root of the step number. We used warmupsteps=4000warmupsteps=4000.</p><blockquote><p>Note: This part is very important. Need to train with this setup of the model.</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NoamOpt</span>:</span></span><br><span class="line">    <span class="string">"Optim wrapper that implements rate."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, model_size, factor, warmup, optimizer)</span>:</span></span><br><span class="line">        self.optimizer = optimizer</span><br><span class="line">        self._step = <span class="number">0</span></span><br><span class="line">        self.warmup = warmup</span><br><span class="line">        self.factor = factor</span><br><span class="line">        self.model_size = model_size</span><br><span class="line">        self._rate = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"Update parameters and rate"</span></span><br><span class="line">        self._step += <span class="number">1</span></span><br><span class="line">        rate = self.rate()</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> self.optimizer.param_groups:</span><br><span class="line">            p[<span class="string">'lr'</span>] = rate</span><br><span class="line">        self._rate = rate</span><br><span class="line">        self.optimizer.step()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rate</span><span class="params">(self, step = None)</span>:</span></span><br><span class="line">        <span class="string">"Implement `lrate` above"</span></span><br><span class="line">        <span class="keyword">if</span> step <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            step = self._step</span><br><span class="line">        <span class="keyword">return</span> self.factor * \</span><br><span class="line">            (self.model_size ** (<span class="number">-0.5</span>) *</span><br><span class="line">            min(step ** (<span class="number">-0.5</span>), step * self.warmup ** (<span class="number">-1.5</span>)))</span><br><span class="line">        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_std_opt</span><span class="params">(model)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> NoamOpt(model.src_embed[<span class="number">0</span>].d_model, <span class="number">2</span>, <span class="number">4000</span>,</span><br><span class="line">            torch.optim.Adam(model.parameters(), lr=<span class="number">0</span>, betas=(<span class="number">0.9</span>, <span class="number">0.98</span>), eps=<span class="number">1e-9</span>))</span><br></pre></td></tr></tbody></table></figure><blockquote><p>Example of the curves of this model for different model sizes and for optimization hyperparameters.</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Three settings of the lrate hyperparameters.</span></span><br><span class="line">opts = [NoamOpt(<span class="number">512</span>, <span class="number">1</span>, <span class="number">4000</span>, <span class="literal">None</span>), </span><br><span class="line">        NoamOpt(<span class="number">512</span>, <span class="number">1</span>, <span class="number">8000</span>, <span class="literal">None</span>),</span><br><span class="line">        NoamOpt(<span class="number">256</span>, <span class="number">1</span>, <span class="number">4000</span>, <span class="literal">None</span>)]</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, <span class="number">20000</span>), [[opt.rate(i) <span class="keyword">for</span> opt <span class="keyword">in</span> opts] <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">20000</span>)])</span><br><span class="line">plt.legend([<span class="string">"512:4000"</span>, <span class="string">"512:8000"</span>, <span class="string">"256:4000"</span>])</span><br><span class="line"><span class="literal">None</span></span><br></pre></td></tr></tbody></table></figure><figure><img src="http://nlp.seas.harvard.edu/images/the-annotated-transformer_69_0.png" alt="png"><figcaption>png</figcaption></figure><h4 id="regularization">Regularization</h4><h5 id="label-smoothing">Label Smoothing</h5><p>During training, we employed label smoothing of value Ïµls=0.1Ïµls=0.1 <a href="https://arxiv.org/abs/1512.00567" target="_blank" rel="noopener">(cite)</a>. This hurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.</p><blockquote><p>We implement label smoothing using the KL div loss. Instead of using a one-hot target distribution, we create a distribution that has <code>confidence</code> of the correct word and the rest of the <code>smoothing</code> mass distributed throughout the vocabulary.</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LabelSmoothing</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"Implement label smoothing."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, size, padding_idx, smoothing=<span class="number">0.0</span>)</span>:</span></span><br><span class="line">        super(LabelSmoothing, self).__init__()</span><br><span class="line">        self.criterion = nn.KLDivLoss(size_average=<span class="literal">False</span>)  <span class="comment">#KLæ•£åº¦</span></span><br><span class="line">        self.padding_idx = padding_idx</span><br><span class="line">        self.confidence = <span class="number">1.0</span> - smoothing</span><br><span class="line">        self.smoothing = smoothing</span><br><span class="line">        self.size = size</span><br><span class="line">        self.true_dist = <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x, target)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> x.size(<span class="number">1</span>) == self.size</span><br><span class="line">        true_dist = x.data.clone()</span><br><span class="line">        true_dist.fill_(self.smoothing / (self.size - <span class="number">2</span>))</span><br><span class="line">        true_dist.scatter_(<span class="number">1</span>, target.data.unsqueeze(<span class="number">1</span>), self.confidence)</span><br><span class="line">        true_dist[:, self.padding_idx] = <span class="number">0</span></span><br><span class="line">        mask = torch.nonzero(target.data == self.padding_idx)</span><br><span class="line">        <span class="keyword">if</span> mask.dim() &gt; <span class="number">0</span>:</span><br><span class="line">            true_dist.index_fill_(<span class="number">0</span>, mask.squeeze(), <span class="number">0.0</span>)</span><br><span class="line">        self.true_dist = true_dist</span><br><span class="line">        <span class="keyword">return</span> self.criterion(x, Variable(true_dist, requires_grad=<span class="literal">False</span>))</span><br></pre></td></tr></tbody></table></figure><blockquote><p>Here we can see an example of how the mass is distributed to the words based on confidence.</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Example of label smoothing.</span></span><br><span class="line">crit = LabelSmoothing(<span class="number">5</span>, <span class="number">0</span>, <span class="number">0.4</span>)</span><br><span class="line">predict = torch.FloatTensor([[<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>],</span><br><span class="line">                             [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>], </span><br><span class="line">                             [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>]])</span><br><span class="line">v = crit(Variable(predict.log()), </span><br><span class="line">         Variable(torch.LongTensor([<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>])))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show the target distributions expected by the system.</span></span><br><span class="line">plt.imshow(crit.true_dist)</span><br><span class="line"><span class="literal">None</span></span><br></pre></td></tr></tbody></table></figure><figure><img src="http://nlp.seas.harvard.edu/images/the-annotated-transformer_74_0.png" alt="png"><figcaption>png</figcaption></figure><blockquote><p>Label smoothing actually starts to penalize the model if it gets very confident about a given choice.</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">crit = LabelSmoothing(<span class="number">5</span>, <span class="number">0</span>, <span class="number">0.1</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span><span class="params">(x)</span>:</span></span><br><span class="line">    d = x + <span class="number">3</span> * <span class="number">1</span></span><br><span class="line">    predict = torch.FloatTensor([[<span class="number">0</span>, x / d, <span class="number">1</span> / d, <span class="number">1</span> / d, <span class="number">1</span> / d],</span><br><span class="line">                                 ])</span><br><span class="line">    <span class="comment">#print(predict)</span></span><br><span class="line">    <span class="keyword">return</span> crit(Variable(predict.log()),</span><br><span class="line">                 Variable(torch.LongTensor([<span class="number">1</span>]))).data[<span class="number">0</span>]</span><br><span class="line">plt.plot(np.arange(<span class="number">1</span>, <span class="number">100</span>), [loss(x) <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">100</span>)])</span><br><span class="line"><span class="literal">None</span></span><br></pre></td></tr></tbody></table></figure><figure><img src="http://nlp.seas.harvard.edu/images/the-annotated-transformer_76_0.png" alt="png"><figcaption>png</figcaption></figure><h3 id="æ€»ç»“"><strong>æ€»ç»“</strong></h3><p>transformeræ¨¡å‹ä¸»è¦åˆ†ä¸ºä¸¤å¤§éƒ¨åˆ†, åˆ†åˆ«æ˜¯ç¼–ç å™¨å’Œè§£ç å™¨, ç¼–ç å™¨è´Ÿè´£æŠŠè‡ªç„¶è¯­è¨€åºåˆ—æ˜ å°„æˆä¸ºéšè—å±‚(ä¸‹å›¾ä¸­ç¬¬2æ­¥ç”¨ä¹å®«æ ¼æ¯”å–»çš„éƒ¨åˆ†), å«æœ‰è‡ªç„¶è¯­è¨€åºåˆ—çš„æ•°å­¦è¡¨è¾¾. ç„¶åè§£ç å™¨æŠŠéšè—å±‚å†æ˜ å°„ä¸ºè‡ªç„¶è¯­è¨€åºåˆ—, ä»è€Œä½¿æˆ‘ä»¬å¯ä»¥è§£å†³å„ç§é—®é¢˜, å¦‚æƒ…æ„Ÿåˆ†ç±», å‘½åå®ä½“è¯†åˆ«, è¯­ä¹‰å…³ç³»æŠ½å–, æ‘˜è¦ç”Ÿæˆ, æœº å™¨ç¿»è¯‘ç­‰ç­‰, ä¸‹é¢æˆ‘ä»¬ç®€å•è¯´ä¸€ä¸‹ä¸‹å›¾çš„æ¯ä¸€æ­¥éƒ½åšäº†ä»€ä¹ˆ:</p><blockquote><p>1.è¾“å…¥è‡ªç„¶è¯­è¨€åºåˆ—åˆ°ç¼–ç å™¨: Why do we work?(ä¸ºä»€ä¹ˆè¦å·¥ä½œ);</p><p>2.ç¼–ç å™¨è¾“å‡ºçš„éšè—å±‚, å†è¾“å…¥åˆ°è§£ç å™¨;</p><p>3.è¾“å…¥&lt;ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡&gt;<start>(èµ·å§‹)ç¬¦å·åˆ°è§£ç å™¨;</start></p><p>4.å¾—åˆ°ç¬¬ä¸€ä¸ªå­—"ä¸º";</p><p>5.å°†å¾—åˆ°çš„ç¬¬ä¸€ä¸ªå­—"ä¸º"è½ä¸‹æ¥å†è¾“å…¥åˆ°è§£ç å™¨;</p><p>6.å¾—åˆ°ç¬¬äºŒä¸ªå­—"ä»€";</p><p>7.å°†å¾—åˆ°çš„ç¬¬äºŒå­—å†è½ä¸‹æ¥, ç›´åˆ°è§£ç å™¨è¾“å‡º&lt;ğ‘’ğ‘›ğ‘‘&gt;<end>(ç»ˆæ­¢ç¬¦), å³åºåˆ—ç”Ÿæˆå®Œæˆ.</end></p></blockquote><p><img src="https://i.loli.net/2020/08/06/1pea3WSThisHBql.png" alt="image-20200806233205808" style="zoom:67%;"></p><figure><img src="https://i.loli.net/2020/08/07/ZGa1snNULJtjFWS.png" alt="transformer"><figcaption>transformer</figcaption></figure><p>åŸå§‹dataæ•°æ®æ˜¯ï¼š(30,10)</p><p>src: (30,10) trg:(30,10)</p><p>åœ¨encoderä¸­ï¼Œ</p><p>embeddingï¼š å‚æ•°xå°±æ˜¯ src ï¼ˆ30,10ï¼‰ ç»è¿‡å¤„ç†ä¹‹åï¼Œ x:ï¼ˆ30,10,512ï¼‰ -&gt; å³è¾“å…¥ç»™encoderçš„xï¼š(30,10,512)</p><p>ç»è¿‡encoderå„ä¸ªå±‚å¤„ç†ä¹‹åï¼Œè¾“å‡ºçš„ï¼ˆ30ï¼Œ10,512ï¼‰ memoryæ˜¯encoderçš„è¾“å‡ºï¼Œä½†æ˜¯ä¸ºä»€ä¹ˆmemoryï¼šï¼ˆ1,10,512ï¼‰ ??? å› ä¸ºåœ¨é¢„æµ‹æ—¶ ï¼Œsrcæ˜¯ï¼ˆ1,10ï¼‰ï¼Œä¸æ˜¯ï¼ˆ30,10ï¼‰æ‰€ä»¥memoryæ˜¯ï¼ˆ1,10,512ï¼‰</p><p>decoderä¸­ï¼šè¾“å…¥æ¥è‡ª memory å’Œ trg_emd</p><p>embedding ï¼š å‚æ•°xæ˜¯trgï¼ˆ30,9ï¼‰ï¼Œç»è¿‡å¤„ç†ä¹‹åï¼Œxï¼šï¼ˆ30,9,512)</p><p>ç»è¿‡decoderå„ä¸ªå±‚å¤„ç†ä¹‹åï¼Œè¾“å‡ºçš„ï¼ˆ30ï¼Œ9 , 512ï¼‰</p><p>å†ç»è¿‡generatorå±‚ä¹‹åï¼Œxï¼šï¼ˆ30,9,11ï¼‰</p><p>åœ¨é¢„æµ‹çš„æ—¶å€™æ˜¯ï¼ˆ1ï¼Œ1,512ï¼‰ï¼Œä¸æ˜¯ï¼ˆ1,9,512ï¼‰ï¼Œåœ¨é¢„æµ‹å®Œgeneratorä¹‹åï¼Œï¼ˆ1,11ï¼‰ï¼Œé€‰ä¸€ä¸ªæœ€å¤§çš„ã€‚</p><p>å› ä¸ºæ˜¯ä¸€ä¸ªæ•°å­—ä¸€ä¸ªæ•°å­—é¢„æµ‹è¾“å‡ºçš„ï¼Œæ‰€ä»¥æ˜¯1ï¼Œä¸æ˜¯9</p><h3 id="ç¬¬ä¸€ä¸ªä¾‹å­">ç¬¬ä¸€ä¸ªä¾‹å­</h3><blockquote><p>We can begin by trying out a simple copy-task. Given a random set of input symbols from a small vocabulary, the goal is to generate back those same symbols.</p></blockquote><h4 id="synthetic-data">Synthetic Data</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_gen</span><span class="params">(V, batch, nbatches)</span>:</span> <span class="comment"># batch=30:ä¸€æ¬¡è¾“å…¥å¤šå°‘ï¼Œ nbatch=20ï¼šè¾“å…¥å¤šå°‘æ¬¡</span></span><br><span class="line">    <span class="string">"Generate random data for a src-tgt copy task."</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(nbatches): <span class="comment">#ä¸€å…±å¾ªç¯nbatchesä¸ªï¼Œåœ¨æ¯ä¸€ä¸ªæ˜¯ä¸€ä¸ªbatch</span></span><br><span class="line"><span class="comment">#from_numpy ï¼š å°†numpyæ•°æ®è½¬æ¢ä¸ºtensor</span></span><br><span class="line"><span class="comment">#æ³¨ï¼šç”Ÿæˆè¿”å›çš„tensorä¼šå’Œndarryå…±äº«æ•°æ®ï¼Œä»»ä½•å¯¹tensorçš„æ“ä½œéƒ½ä¼šå½±å“åˆ°ndarry</span></span><br><span class="line">        data = torch.from_numpy(np.random.randint(<span class="number">1</span>, V, size=(batch, <span class="number">10</span>))) <span class="comment">#1æ˜¯äº§ç”Ÿçš„æœ€å°å€¼ï¼ŒV=11æ˜¯æœ€å¤§å€¼ï¼Œsizeæ˜¯å½¢çŠ¶ï¼ˆbatchï¼Œ10ï¼‰ã€‚ç”Ÿæˆï¼ˆbatchï¼Œ10ï¼‰çš„çŸ©é˜µï¼ŒçŸ©é˜µçš„æ¯ä¸€ä¸ªå…ƒç´ éƒ½æ˜¯1~V-1ä¹‹é—´  ï¼ˆå–ä¸åˆ°Vï¼‰</span></span><br><span class="line">        data[:, <span class="number">0</span>] = <span class="number">1</span> <span class="comment">#å°†ç¬¬0åˆ—çš„å€¼èµ‹å€¼ä¸º1</span></span><br><span class="line">        <span class="comment"># Variable å°±æ˜¯ä¸€ä¸ªå­˜æ”¾å€¼ï¼Œ é‡Œé¢çš„å€¼ä¼šä¸åœçš„å˜åŒ–.  å­˜æ”¾çš„æ˜¯Torch çš„ Tensor . å¦‚æœç”¨ä¸€ä¸ª Variable è¿›è¡Œè®¡ç®—, é‚£è¿”å›çš„ä¹Ÿæ˜¯ä¸€ä¸ªåŒç±»å‹çš„ Variable.  </span></span><br><span class="line">        <span class="comment">#requires_gradï¼š æ˜¯å¦å‚ä¸è¯¯å·®åå‘ä¼ æ’­, è¦ä¸è¦è®¡ç®—æ¢¯åº¦</span></span><br><span class="line">        src = Variable(data, requires_grad=<span class="literal">False</span>) <span class="comment">#size(batch,10) å’Œdataçš„å€¼å®Œå…¨ä¸€æ ·</span></span><br><span class="line">        tgt = Variable(data, requires_grad=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">yield</span> Batch(src, tgt, <span class="number">0</span>)<span class="comment">#yieldå°±æ˜¯returnä¸€ä¸ªå€¼ï¼Œå¹¶ä¸”è®°ä½è¿™ä¸ªè¿”å›çš„ä½ç½®ï¼Œä¸‹æ¬¡è¿­ä»£å°±ä»è¿™ä¸ªä½ç½®å(ä¸‹ä¸€è¡Œ)å¼€å§‹</span></span><br><span class="line">        <span class="comment">#batchè¿”å›çš„æ˜¯trg_mask</span></span><br></pre></td></tr></tbody></table></figure><h4 id="loss-computation">Loss Computation</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleLossCompute</span>:</span> <span class="comment">#lossè®¡ç®—ä»¥åŠæ›´æ–°ã€‚è°ƒç”¨LabelSmoothingï¼Œä½¿ç”¨KLæ•£åº¦</span></span><br><span class="line">    <span class="string">"A simple loss compute and train function."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, generator, criterion, opt=None)</span>:</span></span><br><span class="line">        self.generator = generator <span class="comment">#è§£ç å™¨åçš„ç”Ÿæˆå‡½æ•°</span></span><br><span class="line">        self.criterion = criterion <span class="comment"># LabelSmoothingï¼ˆè®¡ç®—loss KLDivLoss KLæ•£åº¦ï¼‰çš„å®ä¾‹åŒ–</span></span><br><span class="line">        self.opt = opt <span class="comment"># NoamOptï¼ˆä¼˜åŒ–ï¼‰çš„å®ä¾‹åŒ–</span></span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, x, y, norm)</span>:</span></span><br><span class="line">        x = self.generator(x) <span class="comment">#è§£ç å™¨çš„è¾“å‡º</span></span><br><span class="line">        loss = self.criterion(x.contiguous().view(<span class="number">-1</span>, x.size(<span class="number">-1</span>)), </span><br><span class="line">                              y.contiguous().view(<span class="number">-1</span>)) / norm  <span class="comment">#è®¡ç®—loss</span></span><br><span class="line">        loss.backward() <span class="comment">#å°†lossåå‘ä¼ æ’­ã€‚lossæ˜¯æ ‡é‡ï¼Œæ ¹æ®é“¾å¼æ³•åˆ™è‡ªåŠ¨è®¡ç®—å‡ºå¶å­èŠ‚ç‚¹çš„æ¢¯åº¦å€¼</span></span><br><span class="line">        <span class="keyword">if</span> self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: <span class="comment">#å­˜åœ¨ä¼˜åŒ–</span></span><br><span class="line">            self.opt.step() <span class="comment">#è°ƒç”¨optçš„stepå‡½æ•°ã€‚ adamä¼˜åŒ–ï¼Œï¼Œæ›´æ–°å‚æ•°</span></span><br><span class="line">            self.opt.optimizer.zero_grad() <span class="comment">#æŠŠæ¢¯åº¦ç½®é›¶ï¼Œä¹Ÿå°±æ˜¯æŠŠlosså…³äºweightçš„å¯¼æ•°å˜æˆ0.</span></span><br><span class="line">        <span class="keyword">return</span> loss.data[<span class="number">0</span>] * norm</span><br></pre></td></tr></tbody></table></figure><h4 id="greedy-decoding">Greedy Decoding</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train the simple copy task.</span></span><br><span class="line">V = <span class="number">11</span></span><br><span class="line">criterion = LabelSmoothing(size=V, padding_idx=<span class="number">0</span>, smoothing=<span class="number">0.0</span>) <span class="comment">#LabelSmoothingæ˜¯KLæ•£åº¦å®ç°çš„</span></span><br><span class="line">model = make_model(V, V, N=<span class="number">2</span>) <span class="comment">#src_vocab=11, tgt_vocab=11ï¼Œè¦†ç›–N=2</span></span><br><span class="line"><span class="comment"># å¯¹æ¨¡å‹å‚æ•°è¿›è¡Œæ›´æ–°ä¼˜åŒ–ï¼Œä½¿ç”¨Adamä¼˜åŒ–</span></span><br><span class="line">model_opt = NoamOpt(model.src_embed[<span class="number">0</span>].d_model, <span class="number">1</span>, <span class="number">400</span>,</span><br><span class="line">        torch.optim.Adam(model.parameters(), lr=<span class="number">0</span>, betas=(<span class="number">0.9</span>, <span class="number">0.98</span>), eps=<span class="number">1e-9</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#model.eval()ï¼Œpytorchä¼šè‡ªåŠ¨æŠŠBNå’ŒDropOutå›ºå®šä½ï¼Œä¸ä¼šå–å¹³å‡ï¼Œè€Œæ˜¯ç”¨è®­ç»ƒå¥½çš„å€¼ã€‚</span></span><br><span class="line"><span class="comment">#model.train() è®©modelå˜æˆè®­ç»ƒæ¨¡å¼ï¼Œæ­¤æ—¶dropoutå’Œbatch normalizationçš„æ“ä½œåœ¨è®­ç»ƒèµ·åˆ°é˜²æ­¢ç½‘ç»œè¿‡æ‹Ÿåˆçš„é—®é¢˜</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>): <span class="comment">#ä¸€å…±10å¤§ä»½ï¼Œ model.train()æ‰“å°1è¡Œï¼Œmodel.eval()æ‰“å°1è¡Œ</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="comment">#è°ƒç”¨run_epoch(data_iter, model, loss_compute)å‡½æ•°</span></span><br><span class="line">    <span class="comment">#è¿”å›total_loss / total_tokens ã€‚è¿”å›å€¼å¯ä»¥æ²¡æœ‰æ¥æ”¶ï¼Œä¸ä¼šæŠ¥é”™</span></span><br><span class="line">    run_epoch(data_gen(V, <span class="number">30</span>, <span class="number">20</span>), model, </span><br><span class="line">              SimpleLossCompute(model.generator, criterion, model_opt))</span><br><span class="line">    model.eval()</span><br><span class="line">    <span class="comment">#printæ¥æ”¶run_epochçš„è¿”å›å€¼ åœ¨è¾“å‡ºçš„ç¬¬ä¸‰è¡Œ</span></span><br><span class="line">    print(run_epoch(data_gen(V, <span class="number">30</span>, <span class="number">5</span>), model, </span><br><span class="line">                    SimpleLossCompute(model.generator, criterion, <span class="literal">None</span>)))</span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">3.023465</span> Tokens per Sec: <span class="number">403.074173</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.920030</span> Tokens per Sec: <span class="number">641.689380</span></span><br><span class="line"><span class="number">1.9274832487106324</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.940011</span> Tokens per Sec: <span class="number">432.003378</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.699767</span> Tokens per Sec: <span class="number">641.979665</span></span><br><span class="line"><span class="number">1.657595729827881</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.860276</span> Tokens per Sec: <span class="number">433.320240</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.546011</span> Tokens per Sec: <span class="number">640.537198</span></span><br><span class="line"><span class="number">1.4888023376464843</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.682198</span> Tokens per Sec: <span class="number">432.092305</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.313169</span> Tokens per Sec: <span class="number">639.441857</span></span><br><span class="line"><span class="number">1.3485562801361084</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.278768</span> Tokens per Sec: <span class="number">433.568756</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.062384</span> Tokens per Sec: <span class="number">642.542067</span></span><br><span class="line"><span class="number">0.9853351473808288</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.269471</span> Tokens per Sec: <span class="number">433.388727</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.590709</span> Tokens per Sec: <span class="number">642.862135</span></span><br><span class="line"><span class="number">0.5686767101287842</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.997076</span> Tokens per Sec: <span class="number">433.009746</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.343118</span> Tokens per Sec: <span class="number">642.288427</span></span><br><span class="line"><span class="number">0.34273059368133546</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.459483</span> Tokens per Sec: <span class="number">434.594030</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.290385</span> Tokens per Sec: <span class="number">642.519464</span></span><br><span class="line"><span class="number">0.2612409472465515</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">1.031042</span> Tokens per Sec: <span class="number">434.557008</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.437069</span> Tokens per Sec: <span class="number">643.630322</span></span><br><span class="line"><span class="number">0.4323212027549744</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.617165</span> Tokens per Sec: <span class="number">436.652626</span></span><br><span class="line">Epoch Step: <span class="number">1</span> Loss: <span class="number">0.258793</span> Tokens per Sec: <span class="number">644.372296</span></span><br><span class="line"><span class="number">0.27331129014492034</span></span><br></pre></td></tr></tbody></table></figure><blockquote><p>This code predicts a translation using greedy decoding for simplicity.</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#é¢„æµ‹è¿‡ç¨‹</span></span><br><span class="line"><span class="comment">#é¢„æµ‹çš„æ—¶å€™æ²¡æœ‰ç”¨tgtï¼ˆæ ‡å‡†å€¼ï¼‰ï¼Œè€Œæ˜¯æ¯æ¬¡è§£ç å™¨çš„è¾“å…¥éƒ½æ˜¯ysï¼Œæ˜¯é¢„æµ‹çš„å€¼</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greedy_decode</span><span class="params">(model, src, src_mask, max_len, start_symbol)</span>:</span></span><br><span class="line">    memory = model.encode(src, src_mask) <span class="comment">#memoryæ˜¯ç¼–ç å™¨çš„è¾“å‡º ã€‚æ˜¯ä¸€ä¸ªçŸ©é˜µ</span></span><br><span class="line">    ys = torch.ones(<span class="number">1</span>, <span class="number">1</span>).fill_(start_symbol).type_as(src.data) <span class="comment">#å¡«å……è¾“å‡ºå¼€å§‹ç¬¦ï¼Œå’Œsrcçš„ç±»å‹ä¸€æ ·ã€‚å¯¹é¢„æµ‹çš„å¥å­è¿›è¡Œåˆå§‹åŒ– ys =1 ï¼ˆ1,1ï¼‰</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(max_len<span class="number">-1</span>): <span class="comment">#0~8 å¯¹æ¯ä¸€ä¸ªè¯éƒ½è¿›è¡Œé¢„æµ‹</span></span><br><span class="line">        out = model.decode(memory, src_mask, </span><br><span class="line">                           Variable(ys), </span><br><span class="line">                           Variable(subsequent_mask(ys.size(<span class="number">1</span>))</span><br><span class="line">                                    .type_as(src.data)))</span><br><span class="line">         <span class="comment"># ys çš„ç»´åº¦æ˜¯ batch_size * times ï¼ˆå›ºå®šçš„ï¼‰,   æ‰€ä»¥target_mask çŸ©é˜µå¿…é¡»æ˜¯ys.size(1),æ‰€ä»¥æ˜¯ times * times</span></span><br><span class="line">        <span class="comment"># æ ¹æ® decoder çš„è®­ç»ƒæ­¥éª¤, è¿™é‡Œçš„ out è¾“å‡ºå°±åº”è¯¥æ˜¯ batch_size * (times+1) çš„çŸ©é˜µ</span></span><br><span class="line">        </span><br><span class="line">        prob = model.generator(out[:, <span class="number">-1</span>]) <span class="comment">#generatorè¿”å›çš„æ˜¯softmax</span></span><br><span class="line">          <span class="comment"># out[:, -1] è¿™é‡Œæ˜¯æœ€æ–°çš„ä¸€ä¸ªå•è¯çš„ embedding å‘é‡</span></span><br><span class="line">        <span class="comment"># generator å°±æ˜¯äº§ç”Ÿæœ€åçš„ vocabulary çš„æ¦‚ç‡, æ˜¯ä¸€ä¸ªå…¨è¿æ¥å±‚</span></span><br><span class="line">        </span><br><span class="line">        _, next_word = torch.max(prob, dim = <span class="number">1</span>) <span class="comment"># torch.max:æŒ‰ç»´åº¦dim è¿”å›æœ€å¤§å€¼ï¼Œå¹¶ä¸”ä¼šè¿”å›ç´¢å¼•ã€‚next_dataæ¥æ”¶#ç´¢å¼•</span></span><br><span class="line">        next_word = next_word.data[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># å°†å¥å­æ‹¼æ¥èµ·æ¥  .type_as: å°†tensorå¼ºåˆ¶è½¬æ¢ä¸ºsrc.data æ ¼å¼çš„</span></span><br><span class="line">        ys = torch.cat([ys, </span><br><span class="line">                        torch.ones(<span class="number">1</span>, <span class="number">1</span>).type_as(src.data).fill_(next_word)], dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> ys</span><br><span class="line"></span><br><span class="line">model.eval()</span><br><span class="line">src = Variable(torch.LongTensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>]]) )</span><br><span class="line">src_mask = Variable(torch.ones(<span class="number">1</span>, <span class="number">1</span>, <span class="number">10</span>) )</span><br><span class="line">print(greedy_decode(model, src, src_mask, max_len=<span class="number">10</span>, start_symbol=<span class="number">1</span>))</span><br><span class="line">    <span class="number">1</span>     <span class="number">2</span>     <span class="number">3</span>     <span class="number">4</span>     <span class="number">5</span>     <span class="number">6</span>     <span class="number">7</span>     <span class="number">8</span>     <span class="number">9</span>    <span class="number">10</span></span><br><span class="line">[torch.LongTensor of size <span class="number">1</span>x10]</span><br></pre></td></tr></tbody></table></figure><h3 id="çœŸå®ä¾‹å­">çœŸå®ä¾‹å­</h3><blockquote><p>Now we consider a real-world example using the IWSLT German-English Translation task. This task is much smaller than the WMT task considered in the paper, but it illustrates the whole system. We also show how to use multi-gpu processing to make it really fast.</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!pip install torchtext spacy</span></span><br><span class="line"><span class="comment">#!python -m spacy download en</span></span><br><span class="line"><span class="comment">#!python -m spacy download de</span></span><br></pre></td></tr></tbody></table></figure><h4 id="data-loading">Data Loading</h4><blockquote><p>We will load the dataset using torchtext and spacy for tokenization.</p><p>ç”¨torchtextæ¥åŠ è½½æ•°æ®é›† ï¼Œ ç”¨spacyæ¥åˆ†è¯</p></blockquote><p><img src="https://i.loli.net/2020/08/07/teSG1hufEjF4Zkv.png" alt="image-20200807001353729" style="zoom: 67%;"></p><p>torchtextç»„ä»¶æµç¨‹ï¼š</p><blockquote><ul><li>å®šä¹‰Fieldï¼šå£°æ˜å¦‚ä½•å¤„ç†æ•°æ®ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹æ•°æ®é¢„å¤„ç†çš„é…ç½®ä¿¡æ¯ï¼Œæ¯”å¦‚æŒ‡å®šåˆ†è¯æ–¹æ³•ï¼Œæ˜¯å¦è½¬æˆå°å†™ï¼Œèµ·å§‹å­—ç¬¦ï¼Œç»“æŸå­—ç¬¦ï¼Œè¡¥å…¨å­—ç¬¦ä»¥åŠè¯å…¸ç­‰ç­‰</li><li>å®šä¹‰Datasetï¼šç”¨äºå¾—åˆ°æ•°æ®é›†ï¼Œç»§æ‰¿è‡ªpytorchçš„Datasetã€‚æ­¤æ—¶æ•°æ®é›†é‡Œæ¯ä¸€ä¸ªæ ·æœ¬æ˜¯ä¸€ä¸ª ç»è¿‡ Fieldå£°æ˜çš„é¢„å¤„ç† é¢„å¤„ç†åçš„ wordlist</li><li>å»ºç«‹vocabï¼šåœ¨è¿™ä¸€æ­¥å»ºç«‹è¯æ±‡è¡¨ï¼Œè¯å‘é‡(word embeddings)</li><li>æ„é€ è¿­ä»£å™¨Iteratorï¼š: ä¸»è¦æ˜¯æ•°æ®è¾“å‡ºçš„æ¨¡å‹çš„è¿­ä»£å™¨ã€‚æ„é€ è¿­ä»£å™¨ï¼Œæ”¯æŒbatchå®šåˆ¶ç”¨æ¥åˆ†æ‰¹æ¬¡è®­ç»ƒæ¨¡å‹ã€‚</li></ul></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># For data loading.</span></span><br><span class="line"><span class="keyword">from</span> torchtext <span class="keyword">import</span> data, datasets</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">import</span> spacy</span><br><span class="line">    spacy_de = spacy.load(<span class="string">'de'</span>) <span class="comment">#åŠ è½½å¾·è¯­è¯­è¨€æ¨¡å‹</span></span><br><span class="line">    spacy_en = spacy.load(<span class="string">'en'</span>) <span class="comment">#åŠ è½½è‹±è¯­è¯­è¨€æ¨¡å‹</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">   åœ¨æ–‡æœ¬å¤„ç†çš„è¿‡ç¨‹ä¸­ï¼ŒspaCyé¦–å…ˆå¯¹æ–‡æœ¬åˆ†è¯ï¼ŒåŸå§‹æ–‡æœ¬åœ¨ç©ºæ ¼å¤„åˆ†å‰²ï¼Œç±»ä¼¼äºtext.split(' ')ï¼Œç„¶ååˆ†è¯å™¨ï¼ˆTokenizerï¼‰ä»å·¦å‘å³ä¾æ¬¡å¤„ç†token</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenize_de</span><span class="params">(text)</span>:</span> <span class="comment">#Tokenizer:åˆ†è¯å™¨  è¿›è¡Œå¾·è¯­åˆ†è¯  </span></span><br><span class="line">        <span class="comment">#textï¼šè¾“å…¥çš„æ®µè½å¥å­  tok.textï¼šåˆ†åçš„tokenè¯</span></span><br><span class="line">        <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> spacy_de.tokenizer(text)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tokenize_en</span><span class="params">(text)</span>:</span> <span class="comment"># è¿›è¡Œè‹±è¯­åˆ†è¯</span></span><br><span class="line">        <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> spacy_en.tokenizer(text)]</span><br><span class="line"></span><br><span class="line">    BOS_WORD = <span class="string">'&lt;s&gt;'</span>  <span class="comment">#å¼€å§‹ç¬¦</span></span><br><span class="line">    EOS_WORD = <span class="string">'&lt;/s&gt;'</span> <span class="comment">#ç»ˆæ­¢ç¬¦</span></span><br><span class="line">    BLANK_WORD = <span class="string">"&lt;blank&gt;"</span> <span class="comment">#ç©ºæ ¼</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># æ„å»ºFiledå¯¹è±¡ï¼Œå£°æ˜å¦‚ä½•å¤„ç†æ•°æ®ã€‚ä¸»è¦åŒ…å«ä»¥ä¸‹æ•°æ®é¢„å¤„ç†çš„é…ç½®ä¿¡æ¯ï¼Œæ¯”å¦‚æŒ‡å®šåˆ†è¯æ–¹æ³•ï¼Œæ˜¯å¦è½¬æˆå°å†™ï¼Œ#èµ·å§‹å­—ç¬¦ï¼Œç»“æŸå­—ç¬¦ï¼Œè¡¥å…¨å­—ç¬¦ä»¥åŠè¯å…¸ç­‰ç­‰</span></span><br><span class="line">    SRC = data.Field(tokenize=tokenize_de, pad_token=BLANK_WORD) <span class="comment">#å¾—åˆ°æºå¥å­</span></span><br><span class="line">    TGT = data.Field(tokenize=tokenize_en, init_token = BOS_WORD,  </span><br><span class="line">                     eos_token = EOS_WORD, pad_token=BLANK_WORD)</span><br><span class="line"></span><br><span class="line">    MAX_LEN = <span class="number">100</span> <span class="comment">#æœ€å¤§é•¿åº¦</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># https://s3.amazonaws.com/opennmt-models/iwslt.pt æ•°æ®é›†</span></span><br><span class="line">    <span class="comment">#åŒæ—¶å¯¹è®­ç»ƒé›†å’ŒéªŒè¯é›†è¿˜æœ‰æµ‹è¯•é›†çš„æ„å»ºï¼Œæ­¤æ—¶æ•°æ®é›†é‡Œæ¯ä¸€ä¸ªæ ·æœ¬æ˜¯ä¸€ä¸ª ç»è¿‡ Fieldå£°æ˜çš„é¢„å¤„ç† é¢„å¤„ç†åçš„ #wordlist</span></span><br><span class="line">    train, val, test = datasets.IWSLT.splits(</span><br><span class="line">        exts=(<span class="string">'.de'</span>, <span class="string">'.en'</span>)   <span class="comment"># æ„å»ºæ•°æ®é›†æ‰€éœ€çš„æ•°æ®é›†</span></span><br><span class="line">        , fields=(SRC, TGT),  <span class="comment">#å¦‚ä½•èµ‹å€¼ç»™trainé‚£ä¸‰ä¸ªçš„ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ</span></span><br><span class="line">        filter_pred=<span class="keyword">lambda</span> x: len(vars(x)[<span class="string">'src'</span>]) &lt;= MAX_LEN <span class="keyword">and</span> </span><br><span class="line">            len(vars(x)[<span class="string">'trg'</span>]) &lt;= MAX_LEN)  <span class="comment">#æºå¥å­å’Œç›®æ ‡å¥å­é•¿åº¦å°äº100çš„ç­›é€‰å‡ºæ¥</span></span><br><span class="line">    </span><br><span class="line">    MIN_FREQ = <span class="number">2</span> <span class="comment">#å®šä¹‰æœ€å°é¢‘ç‡</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#å»ºç«‹è¯æ±‡è¡¨ï¼Œè¯å‘é‡(word embeddings)ã€‚å³éœ€è¦ç»™æ¯ä¸ªå•è¯ç¼–ç ï¼Œç„¶åè¾“å…¥æ¨¡å‹</span></span><br><span class="line">    <span class="comment">#bulid_vocab()æ–¹æ³•ä¸­ä¼ å…¥ç”¨äºæ„å»ºè¯è¡¨çš„æ•°æ®é›†</span></span><br><span class="line">    SRC.build_vocab(train.src, min_freq=MIN_FREQ) </span><br><span class="line">    TGT.build_vocab(train.trg, min_freq=MIN_FREQ)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#ä¸€æ—¦è¿è¡Œäº†è¿™äº›ä»£ç è¡Œï¼ŒSRC.vocab.stoiå°†æ˜¯ä¸€ä¸ªè¯å…¸ï¼Œå…¶è¯æ±‡è¡¨ä¸­çš„æ ‡è®°ä½œä¸ºé”®ï¼Œè€Œå…¶å¯¹åº”çš„ç´¢å¼•ä½œä¸ºå€¼ï¼› #SRC.vocab.itoså°†æ˜¯ç›¸åŒçš„å­—å…¸ï¼Œå…¶ä¸­çš„é”®å’Œå€¼è¢«äº¤æ¢ã€‚</span></span><br></pre></td></tr></tbody></table></figure><blockquote><p>æ‰¹è®­ç»ƒå¯¹äºé€Ÿåº¦æ¥è¯´å¾ˆé‡è¦ã€‚å¸Œæœ›æ‰¹æ¬¡åˆ†å‰²éå¸¸å‡åŒ€å¹¶ä¸”å¡«å……æœ€å°‘ã€‚ è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬<strong>å¿…é¡»ä¿®æ”¹torchtexté»˜è®¤çš„æ‰¹å¤„ç†å‡½æ•°</strong>ã€‚ è¿™éƒ¨åˆ†ä»£ç ä¿®è¡¥å…¶é»˜è®¤æ‰¹å¤„ç†å‡½æ•°ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬æœç´¢è¶³å¤Ÿå¤šçš„å¥å­ä»¥æ„å»ºç´§å¯†æ‰¹å¤„ç†ã€‚ ä¸€èˆ¬æ¥è¯´ç›´æ¥è°ƒç”¨<code>BucketIterator</code> ï¼ˆè®­ç»ƒç”¨ï¼‰å’Œ <code>Iterator</code>ï¼ˆæµ‹è¯•ç”¨ï¼‰ å³å¯</p><p><code>BucketIterator</code>å’Œ<code>Iterator</code>çš„åŒºåˆ«æ˜¯ï¼ŒBucketIteratorå°½å¯èƒ½çš„æŠŠé•¿åº¦ç›¸ä¼¼çš„å¥å­æ”¾åœ¨ä¸€ä¸ªbatché‡Œé¢ã€‚</p></blockquote><h4 id="iterators">Iterators</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">å®šä¹‰ä¸€ä¸ªè¿­ä»£å™¨ï¼Œè¯¥è¿­ä»£å™¨å°†ç›¸ä¼¼é•¿åº¦çš„ç¤ºä¾‹æ‰¹å¤„ç†åœ¨ä¸€èµ·ã€‚ åœ¨ä¸ºæ¯ä¸ªæ–°çºªå…ƒ(epoch)ç”Ÿäº§æ–°é²œæ”¹ç»„çš„æ‰¹æ¬¡æ—¶ï¼Œæœ€å¤§ç¨‹åº¦åœ°å‡å°‘æ‰€éœ€çš„å¡«å……é‡ã€‚</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyIterator</span><span class="params">(data.Iterator)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">create_batches</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#åœ¨trainçš„æ—¶å€™ï¼Œè¦è¿›è¡Œsortï¼Œå°½é‡å‡å°‘padding</span></span><br><span class="line">        <span class="comment">#ç›®çš„æ˜¯è‡ªåŠ¨è¿›è¡Œshuffleå’Œpaddingï¼Œå¹¶ä¸”ä¸ºäº†è®­ç»ƒæ•ˆç‡æœŸé—´ï¼Œå°½é‡æŠŠå¥å­é•¿åº¦ç›¸ä¼¼çš„shuffleåœ¨ä¸€èµ·ã€‚</span></span><br><span class="line">        <span class="keyword">if</span> self.train:</span><br><span class="line">            <span class="function"><span class="keyword">def</span> <span class="title">pool</span><span class="params">(d, random_shuffler)</span>:</span></span><br><span class="line">                <span class="keyword">for</span> p <span class="keyword">in</span> data.batch(d, self.batch_size * <span class="number">100</span>):</span><br><span class="line">                    p_batch = data.batch(</span><br><span class="line">                        sorted(p, key=self.sort_key), <span class="comment">#æŒ‰ç…§è¯çš„æ•°å¤§å°æ’åº</span></span><br><span class="line">                        self.batch_size, self.batch_size_fn)</span><br><span class="line">                    <span class="keyword">for</span> b <span class="keyword">in</span> random_shuffler(list(p_batch)):</span><br><span class="line">                        <span class="keyword">yield</span> b <span class="comment">#bå°±æ˜¯batchï¼Œ ç±»æ¯”ä¸Šè¿°çš„gen_dataå‡½æ•°</span></span><br><span class="line">            self.batches = pool(self.data(), self.random_shuffler) <span class="comment">#è°ƒç”¨pool</span></span><br><span class="line">            </span><br><span class="line">         <span class="comment">#åœ¨valid+test(éªŒè¯é›†å’Œæµ‹è¯•é›†)çš„æ—¶å€™  å’Œä¸Šé¢å…·ä½“åŒºåˆ«åœ¨å“ªï¼Ÿï¼Ÿï¼Ÿï¼Ÿ</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.batches = []</span><br><span class="line">            <span class="keyword">for</span> b <span class="keyword">in</span> data.batch(self.data(), self.batch_size,</span><br><span class="line">                                          self.batch_size_fn):</span><br><span class="line">                self.batches.append(sorted(b, key=self.sort_key))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rebatch</span><span class="params">(pad_idx, batch)</span>:</span>  <span class="comment">#pad_idxï¼šç©ºæ ¼é”®</span></span><br><span class="line">    <span class="string">"Fix order in torchtext to match ours"</span></span><br><span class="line">    src, trg = batch.src.transpose(<span class="number">0</span>, <span class="number">1</span>), batch.trg.transpose(<span class="number">0</span>, <span class="number">1</span>)<span class="comment">#ä¸ºä»€ä¹ˆè¦è¿›è¡Œ</span></span><br><span class="line">    <span class="keyword">return</span> Batch(src, trg, pad_idx) <span class="comment">#è°ƒç”¨ä¸Šè¿°çš„Batchç±»   pad_idxå°±æ˜¯pad</span></span><br></pre></td></tr></tbody></table></figure><h4 id="multi-gpu-training">Multi-GPU Training</h4><blockquote><p>æœ€åä¸ºäº†çœŸæ­£åœ°å¿«é€Ÿè®­ç»ƒï¼Œå°†ä½¿ç”¨å¤šä¸ªGPUã€‚ è¿™éƒ¨åˆ†ä»£ç å®ç°äº†å¤šGPUå­—ç”Ÿæˆï¼Œå®ƒä¸æ˜¯Transformerç‰¹æœ‰çš„ã€‚ å…¶<strong>æ€æƒ³æ˜¯å°†è®­ç»ƒæ—¶çš„å•è¯ç”Ÿæˆåˆ†æˆå—ï¼Œä»¥ä¾¿åœ¨è®¸å¤šä¸åŒçš„GPUä¸Šå¹¶è¡Œå¤„ç†ã€‚</strong> æˆ‘ä»¬ä½¿ç”¨PyTorchå¹¶è¡ŒåŸè¯­æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼š</p><ul><li>replicate -å¤åˆ¶ - å°†æ¨¡å—æ‹†åˆ†åˆ°ä¸åŒçš„GPUä¸Š</li><li>scatter -åˆ†æ•£ - å°†æ‰¹æ¬¡æ‹†åˆ†åˆ°ä¸åŒçš„GPUä¸Š</li><li>parallel_apply -å¹¶è¡Œåº”ç”¨ - åœ¨ä¸åŒGPUä¸Šå°†æ¨¡å—åº”ç”¨äºæ‰¹å¤„ç†</li><li>gather - èšé›† - å°†åˆ†æ•£çš„æ•°æ®èšé›†åˆ°ä¸€ä¸ªGPUä¸Š</li><li>nn.DataParallel - ä¸€ä¸ªç‰¹æ®Šçš„æ¨¡å—åŒ…è£…å™¨ï¼Œåœ¨è¯„ä¼°ä¹‹å‰è°ƒç”¨å®ƒä»¬ã€‚</li></ul></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Skip if not interested in multigpu.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiGPULossCompute</span>:</span></span><br><span class="line">    <span class="string">"A multi-gpu loss compute and train function."</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, generator, criterion, devices, opt=None, chunk_size=<span class="number">5</span>)</span>:</span></span><br><span class="line">        <span class="comment"># Send out to different gpus.</span></span><br><span class="line">        self.generator = generator</span><br><span class="line">        self.criterion = nn.parallel.replicate(criterion, </span><br><span class="line">                                               devices=devices)</span><br><span class="line">        self.opt = opt</span><br><span class="line">        self.devices = devices</span><br><span class="line">        self.chunk_size = chunk_size</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, out, targets, normalize)</span>:</span></span><br><span class="line">        total = <span class="number">0.0</span></span><br><span class="line">        generator = nn.parallel.replicate(self.generator, </span><br><span class="line">                                                devices=self.devices)</span><br><span class="line">        out_scatter = nn.parallel.scatter(out, </span><br><span class="line">                                          target_gpus=self.devices)</span><br><span class="line">        out_grad = [[] <span class="keyword">for</span> _ <span class="keyword">in</span> out_scatter]</span><br><span class="line">        targets = nn.parallel.scatter(targets, </span><br><span class="line">                                      target_gpus=self.devices)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Divide generating into chunks.</span></span><br><span class="line">        chunk_size = self.chunk_size</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, out_scatter[<span class="number">0</span>].size(<span class="number">1</span>), chunk_size):</span><br><span class="line">            <span class="comment"># Predict distributions</span></span><br><span class="line">            out_column = [[Variable(o[:, i:i+chunk_size].data, </span><br><span class="line">                                    requires_grad=self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>)] </span><br><span class="line">                           <span class="keyword">for</span> o <span class="keyword">in</span> out_scatter]</span><br><span class="line">            gen = nn.parallel.parallel_apply(generator, out_column)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Compute loss. </span></span><br><span class="line">            y = [(g.contiguous().view(<span class="number">-1</span>, g.size(<span class="number">-1</span>)), </span><br><span class="line">                  t[:, i:i+chunk_size].contiguous().view(<span class="number">-1</span>)) </span><br><span class="line">                 <span class="keyword">for</span> g, t <span class="keyword">in</span> zip(gen, targets)]</span><br><span class="line">            loss = nn.parallel.parallel_apply(self.criterion, y)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Sum and normalize loss</span></span><br><span class="line">            l = nn.parallel.gather(loss, </span><br><span class="line">                                   target_device=self.devices[<span class="number">0</span>])</span><br><span class="line">            l = l.sum()[<span class="number">0</span>] / normalize</span><br><span class="line">            total += l.data[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Backprop loss to output of transformer</span></span><br><span class="line">            <span class="keyword">if</span> self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                l.backward()</span><br><span class="line">                <span class="keyword">for</span> j, l <span class="keyword">in</span> enumerate(loss):</span><br><span class="line">                    out_grad[j].append(out_column[j][<span class="number">0</span>].grad.data.clone())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Backprop all loss through transformer.            </span></span><br><span class="line">        <span class="keyword">if</span> self.opt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            out_grad = [Variable(torch.cat(og, dim=<span class="number">1</span>)) <span class="keyword">for</span> og <span class="keyword">in</span> out_grad]</span><br><span class="line">            o1 = out</span><br><span class="line">            o2 = nn.parallel.gather(out_grad, </span><br><span class="line">                                    target_device=self.devices[<span class="number">0</span>])</span><br><span class="line">            o1.backward(gradient=o2)</span><br><span class="line">            self.opt.step()</span><br><span class="line">            self.opt.optimizer.zero_grad()</span><br><span class="line">        <span class="keyword">return</span> total * normalize</span><br></pre></td></tr></tbody></table></figure><blockquote><p>Now we create our model, criterion, optimizer, data iterators, and paralelization</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GPUs to use</span></span><br><span class="line">devices = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"><span class="keyword">if</span> <span class="literal">True</span>:</span><br><span class="line">    pad_idx = TGT.vocab.stoi[<span class="string">"&lt;blank&gt;"</span>]</span><br><span class="line">    model = make_model(len(SRC.vocab), len(TGT.vocab), N=<span class="number">6</span>)</span><br><span class="line">    model.cuda()</span><br><span class="line">    criterion = LabelSmoothing(size=len(TGT.vocab), padding_idx=pad_idx, smoothing=<span class="number">0.1</span>)</span><br><span class="line">    criterion.cuda()</span><br><span class="line">    BATCH_SIZE = <span class="number">12000</span></span><br><span class="line">    train_iter = MyIterator(train, batch_size=BATCH_SIZE, device=<span class="number">0</span>,</span><br><span class="line">                            repeat=<span class="literal">False</span>, sort_key=<span class="keyword">lambda</span> x: (len(x.src), len(x.trg)),</span><br><span class="line">                            batch_size_fn=batch_size_fn, train=<span class="literal">True</span>)</span><br><span class="line">    valid_iter = MyIterator(val, batch_size=BATCH_SIZE, device=<span class="number">0</span>,</span><br><span class="line">                            repeat=<span class="literal">False</span>, sort_key=<span class="keyword">lambda</span> x: (len(x.src), len(x.trg)),</span><br><span class="line">                            batch_size_fn=batch_size_fn, train=<span class="literal">False</span>)</span><br><span class="line">    model_par = nn.DataParallel(model, device_ids=devices)</span><br><span class="line"><span class="literal">None</span></span><br></pre></td></tr></tbody></table></figure><blockquote><p>Now we <strong>train the model</strong>. I will play with the warmup steps a bit, but everything else uses the default parameters. On an AWS p3.8xlarge with 4 Tesla V100s, this runs at ~27,000 tokens per second with a batch size of 12,000</p><p>åœ¨å…·æœ‰4ä¸ªTesla V100 GPUçš„AWS p3.8xlargeæœºå™¨ä¸Šï¼Œæ¯ç§’è¿è¡Œçº¦27,000ä¸ªè¯ï¼Œæ‰¹è®­ç»ƒå¤§å°ä¸º12,000ã€‚</p></blockquote><h4 id="training-the-system">Training the System</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!wget https://s3.amazonaws.com/opennmt-models/iwslt.pt</span></span><br><span class="line"><span class="comment">#è¿›è¡Œtrainå’Œeval</span></span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: <span class="comment"># falseå­˜åœ¨çš„æ„ä¹‰åœ¨å“ªï¼Ÿï¼Ÿï¼Ÿ ä½¿ç”¨GPUï¼Ÿ</span></span><br><span class="line">    model_opt = NoamOpt(model.src_embed[<span class="number">0</span>].d_model, <span class="number">1</span>, <span class="number">2000</span>,</span><br><span class="line">            torch.optim.Adam(model.parameters(), lr=<span class="number">0</span>, betas=(<span class="number">0.9</span>, <span class="number">0.98</span>), eps=<span class="number">1e-9</span>))</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        model_par.train()</span><br><span class="line">        run_epoch((rebatch(pad_idx, b) <span class="keyword">for</span> b <span class="keyword">in</span> train_iter), </span><br><span class="line">                  model_par, </span><br><span class="line">                  MultiGPULossCompute(model.generator, criterion, </span><br><span class="line">                                      devices=devices, opt=model_opt))</span><br><span class="line">        model_par.eval()</span><br><span class="line">        loss = run_epoch((rebatch(pad_idx, b) <span class="keyword">for</span> b <span class="keyword">in</span> valid_iter), </span><br><span class="line">                          model_par, </span><br><span class="line">                          MultiGPULossCompute(model.generator, criterion, </span><br><span class="line">                          devices=devices, opt=<span class="literal">None</span>))</span><br><span class="line">        print(loss)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    model = torch.load(<span class="string">"iwslt.pt"</span>) <span class="comment">#åŠ è½½æ‰€æœ‰çš„tensoråˆ°CPU</span></span><br></pre></td></tr></tbody></table></figure><blockquote><p>Once trained we can decode the model to produce a set of translations. Here we simply translate the first sentence in the validation set. This dataset is pretty small so the translations with greedy search are reasonably accurate.</p></blockquote><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ç±»æ¯”äºrun_epochå‡½æ•°  </span></span><br><span class="line"><span class="keyword">for</span> i, batch <span class="keyword">in</span> enumerate(valid_iter):</span><br><span class="line">    src = batch.src.transpose(<span class="number">0</span>, <span class="number">1</span>)[:<span class="number">1</span>]</span><br><span class="line">    src_mask = (src != SRC.vocab.stoi[<span class="string">"&lt;blank&gt;"</span>]).unsqueeze(<span class="number">-2</span>)</span><br><span class="line">    out = greedy_decode(model, src, src_mask, </span><br><span class="line">                        max_len=<span class="number">60</span>, start_symbol=TGT.vocab.stoi[<span class="string">"&lt;s&gt;"</span>])</span><br><span class="line">    print(<span class="string">"Translation:"</span>, end=<span class="string">"\t"</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, out.size(<span class="number">1</span>)):</span><br><span class="line">        sym = TGT.vocab.itos[out[<span class="number">0</span>, i]]</span><br><span class="line">        <span class="keyword">if</span> sym == <span class="string">"&lt;/s&gt;"</span>: <span class="keyword">break</span></span><br><span class="line">        print(sym, end =<span class="string">" "</span>)</span><br><span class="line">    print()</span><br><span class="line">    print(<span class="string">"Target:"</span>, end=<span class="string">"\t"</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, batch.trg.size(<span class="number">0</span>)):</span><br><span class="line">        sym = TGT.vocab.itos[batch.trg.data[i, <span class="number">0</span>]]</span><br><span class="line">        <span class="keyword">if</span> sym == <span class="string">"&lt;/s&gt;"</span>: <span class="keyword">break</span></span><br><span class="line">        print(sym, end =<span class="string">" "</span>)</span><br><span class="line">    print()</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">Translation:&lt;unk&gt; &lt;unk&gt; . In my language , that means , thank you very much . </span><br><span class="line">Gold:&lt;unk&gt; &lt;unk&gt; . It means <span class="keyword">in</span> my language , thank you very much .</span><br></pre></td></tr></tbody></table></figure><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      transformer-pytorch
    
    </summary>
    
    
      <category term="transformer" scheme="http://yoursite.com/categories/transformer/"/>
    
    
      <category term="transformer" scheme="http://yoursite.com/tags/transformer/"/>
    
  </entry>
  
  <entry>
    <title>2020-07-28-pytorchå®‰è£…</title>
    <link href="http://yoursite.com/2020/07/28/2020-07-28-pytorch%E5%AE%89%E8%A3%85/"/>
    <id>http://yoursite.com/2020/07/28/2020-07-28-pytorch%E5%AE%89%E8%A3%85/</id>
    <published>2020-07-27T17:21:43.000Z</published>
    <updated>2020-07-28T01:36:02.720Z</updated>
    
    <content type="html"><![CDATA[<h3 id="anacondaå®‰è£…é…ç½®">Anacondaå®‰è£…é…ç½®</h3><p>ç”±äºå¢™çš„é—®é¢˜ï¼Œç”¨condaå®‰è£…Pytorchè¿‡ç¨‹ä¸­ä¼šè¿æ¥å¤±è´¥ï¼Œè¿™æ˜¯å› ä¸ºAnaconda.orgçš„æœåŠ¡å™¨åœ¨å›½å¤–ã€‚åœ¨è¿™é‡Œå¯ä»¥ç”¨æ¸…åTUNAé•œåƒæºï¼ŒåŒ…å«Anacondaä»“åº“çš„é•œåƒï¼Œå°†å…¶åŠ å…¥condaçš„é…ç½®ï¼Œé…ç½®å¦‚ä¸‹ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#æ·»åŠ Anacondaçš„TUNAé•œåƒ</span></span><br><span class="line"></span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line"></span><br><span class="line"><span class="comment">#TUNAçš„helpä¸­é•œåƒåœ°å€åŠ æœ‰å¼•å·ï¼Œéœ€è¦å»æ‰</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#è®¾ç½®æœç´¢æ—¶æ˜¾ç¤ºé€šé“åœ°å€</span></span><br><span class="line"></span><br><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></tbody></table></figure><p>æ‰§è¡Œå®Œä¸Šè¿°å‘½ä»¤åï¼Œä¼šç”Ÿæˆ~/.condarcæ–‡ä»¶ï¼Œè®°å½•ç€å¯¹condaçš„é…ç½®ï¼Œç›´æ¥æ‰‹åŠ¨åˆ›å»ºã€ç¼–è¾‘è¯¥æ–‡ä»¶æ˜¯ç›¸åŒçš„æ•ˆæœã€‚</p><h3 id="pytorchå®‰è£…">Pytorchå®‰è£…</h3><p>åœ¨è¿™é‡Œçš„å®‰è£…ï¼Œæˆ‘é‡‡ç”¨condaå®‰è£…ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision -c soumith</span><br></pre></td></tr></tbody></table></figure><h3 id="æµ‹è¯•">æµ‹è¯•</h3><p>è¿›å…¥pythonæ¨¡å¼ä¸‹ï¼Œçœ‹èƒ½å¦å¯¼å…¥torchæˆåŠŸï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br></pre></td></tr></tbody></table></figure><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      pytorchçš„å®‰è£…ç¬”è®°
    
    </summary>
    
    
      <category term="pytorch" scheme="http://yoursite.com/categories/pytorch/"/>
    
    
      <category term="pytorch" scheme="http://yoursite.com/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>2020-07-27-linuxçš„sessionè§£æ</title>
    <link href="http://yoursite.com/2020/07/27/2020-07-27-linux%E7%9A%84session%E8%A7%A3%E6%9E%90/"/>
    <id>http://yoursite.com/2020/07/27/2020-07-27-linux%E7%9A%84session%E8%A7%A3%E6%9E%90/</id>
    <published>2020-07-27T12:43:11.000Z</published>
    <updated>2020-07-27T16:31:07.271Z</updated>
    
    <content type="html"><![CDATA[<h3 id="å‰è¨€">å‰è¨€</h3><p>æˆ‘ä»¬ä½¿ç”¨sshè¿æ¥æœåŠ¡å™¨æ—¶ï¼Œsshçš„çª—å£çªç„¶æ–­å¼€äº†è¿æ¥ï¼Œé‚£ä¹ˆåœ¨æœåŠ¡å™¨ä¸Šè·‘çš„ç¨‹åºå°±ä¹Ÿè·Ÿç€æ–­æ‰äº†ï¼Œä¹‹å‰æ‰€æœ‰è·‘çš„æ•°æ®ä¹Ÿå°†ä¸¢å¤±ï¼Œè¿™æ ·å°†ä¼šæµªè´¹æˆ‘ä»¬å¤§é‡çš„æ—¶é—´ã€‚</p><h3 id="ä¸ºä»€ä¹ˆsshä¸€æ—¦æ–­å¼€æˆ‘ä»¬çš„è¿›ç¨‹ä¹Ÿå°†ä¼šè¢«æ€æ‰">ä¸ºä»€ä¹ˆsshä¸€æ—¦æ–­å¼€æˆ‘ä»¬çš„è¿›ç¨‹ä¹Ÿå°†ä¼šè¢«æ€æ‰ï¼Ÿ</h3><p>å…ƒå‡¶ï¼šSIGHUP ä¿¡å·</p><p>è®©æˆ‘ä»¬æ¥çœ‹çœ‹ä¸ºä»€ä¹ˆå…³æ‰çª—å£/æ–­å¼€è¿æ¥ä¼šä½¿å¾—æ­£åœ¨è¿è¡Œçš„ç¨‹åºæ­»æ‰ã€‚</p><p>åœ¨Linux/Unixä¸­ï¼Œæœ‰è¿™æ ·å‡ ä¸ªæ¦‚å¿µï¼š</p><p>è¿›ç¨‹ç»„ï¼ˆprocess groupï¼‰ï¼šä¸€ä¸ªæˆ–å¤šä¸ªè¿›ç¨‹çš„é›†åˆï¼Œæ¯ä¸€ä¸ªè¿›ç¨‹ç»„æœ‰å”¯ä¸€ä¸€ä¸ªè¿›ç¨‹ç»„IDï¼Œå³è¿›ç¨‹ç»„é•¿è¿›ç¨‹çš„IDã€‚</p><p>ä¼šè¯æœŸï¼ˆsessionï¼‰ï¼šä¸€ä¸ªæˆ–å¤šä¸ªè¿›ç¨‹ç»„çš„é›†åˆï¼Œæœ‰å”¯ä¸€ä¸€ä¸ªä¼šè¯æœŸé¦–è¿›ç¨‹ï¼ˆsession leaderï¼‰ã€‚ä¼šè¯æœŸIDä¸ºé¦–è¿›ç¨‹çš„IDã€‚</p><p>ä¼šè¯æœŸå¯ä»¥æœ‰ä¸€ä¸ªå•ç‹¬çš„æ§åˆ¶ç»ˆç«¯ï¼ˆcontrolling terminalï¼‰ã€‚ä¸æ§åˆ¶ç»ˆç«¯è¿æ¥çš„ä¼šè¯æœŸé¦–è¿›ç¨‹å«åšæ§åˆ¶è¿›ç¨‹ï¼ˆcontrolling processï¼‰ã€‚å½“å‰ä¸ç»ˆç«¯äº¤äº’çš„è¿›ç¨‹ç§°ä¸ºå‰å°è¿›ç¨‹ç»„ã€‚å…¶ä½™è¿›ç¨‹ç»„ç§°ä¸ºåå°è¿›ç¨‹ç»„ã€‚</p><p>æ ¹æ®POSIX.1å®šä¹‰ï¼š</p><p>æŒ‚æ–­ä¿¡å·ï¼ˆSIGHUPï¼‰é»˜è®¤çš„åŠ¨ä½œæ˜¯ç»ˆæ­¢ç¨‹åºã€‚</p><p>å½“ç»ˆç«¯æ¥å£æ£€æµ‹åˆ°ç½‘ç»œè¿æ¥æ–­å¼€ï¼Œå°†æŒ‚æ–­ä¿¡å·å‘é€ç»™æ§åˆ¶è¿›ç¨‹ï¼ˆä¼šè¯æœŸé¦–è¿›ç¨‹ï¼‰ã€‚</p><p>å¦‚æœä¼šè¯æœŸé¦–è¿›ç¨‹ç»ˆæ­¢ï¼Œåˆ™è¯¥ä¿¡å·å‘é€åˆ°è¯¥ä¼šè¯æœŸå‰å°è¿›ç¨‹ç»„ã€‚</p><p>ä¸€ä¸ªè¿›ç¨‹é€€å‡ºå¯¼è‡´ä¸€ä¸ªå­¤å„¿è¿›ç¨‹ç»„ä¸­äº§ç”Ÿæ—¶ï¼Œå¦‚æœä»»æ„ä¸€ä¸ªå­¤å„¿è¿›ç¨‹ç»„è¿›ç¨‹å¤„äºSTOPçŠ¶æ€ï¼Œå‘é€SIGHUPå’ŒSIGCONTä¿¡å·åˆ°è¯¥è¿›ç¨‹ç»„ä¸­æ‰€æœ‰è¿›ç¨‹ã€‚</p><p>å› æ­¤å½“ç½‘ç»œæ–­å¼€æˆ–ç»ˆç«¯çª—å£å…³é—­åï¼Œæ§åˆ¶è¿›ç¨‹æ”¶åˆ°SIGHUPä¿¡å·é€€å‡ºï¼Œä¼šå¯¼è‡´è¯¥ä¼šè¯æœŸå†…å…¶ä»–è¿›ç¨‹é€€å‡ºã€‚</p><p><strong>è¿™é‡Œæˆ‘è®¤ä¸ºæˆ‘ä»¬çš„è¿›ç¨‹è¢«æ€æ‰ä¹Ÿå°±æ˜¯å› ä¸ºsshä¸æœåŠ¡å™¨ä¹‹é—´çš„é€šä¿¡æ–­æ‰äº†ï¼Œè¿™ä¸ªé€šä¿¡æ–­æ‰ä¹‹ålinuxç¨‹åºå°±é»˜è®¤å°†è¯¥è¿æ¥ä¸‹çš„æ‰€æœ‰è¿›ç¨‹éƒ½æ€æ‰</strong></p><h3 id="session-æ˜¯ä»€ä¹ˆ">session æ˜¯ä»€ä¹ˆï¼Ÿ</h3><p>æˆ‘ä»¬å¸¸è§çš„ Linux session ä¸€èˆ¬æ˜¯æŒ‡ shell sessionã€‚Shell session æ˜¯ç»ˆç«¯ä¸­å½“å‰çš„çŠ¶æ€ï¼Œåœ¨ç»ˆç«¯ä¸­åªèƒ½æœ‰ä¸€ä¸ª sessionã€‚<code>å½“æˆ‘ä»¬æ‰“å¼€ä¸€ä¸ªæ–°çš„ç»ˆç«¯æ—¶ï¼Œæ€»ä¼šåˆ›å»ºä¸€ä¸ªæ–°çš„ shell sessionã€‚</code></p><p>å°±è¿›ç¨‹é—´çš„å…³ç³»æ¥è¯´ï¼Œsession ç”±ä¸€ä¸ªæˆ–å¤šä¸ªè¿›ç¨‹ç»„ç»„æˆã€‚ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œæ¥è‡ªå•ä¸ªç™»å½•çš„æ‰€æœ‰è¿›ç¨‹éƒ½å±äºåŒä¸€ä¸ª sessionã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹å›¾æ¥ç†è§£è¿›ç¨‹ã€è¿›ç¨‹ç»„å’Œ session ä¹‹é—´çš„å…³ç³»ï¼š</p><figure><img src="https://img2018.cnblogs.com/blog/952033/202001/952033-20200103182042686-2100862807.png" alt="img"><figcaption>img</figcaption></figure><p><code>ä¼šè¯æ˜¯ç”±ä¼šè¯ä¸­çš„ç¬¬ä¸€ä¸ªè¿›ç¨‹åˆ›å»ºçš„ï¼Œä¸€èˆ¬æƒ…å†µä¸‹æ˜¯æ‰“å¼€ç»ˆç«¯æ—¶åˆ›å»ºçš„ shell è¿›ç¨‹ã€‚</code>è¯¥è¿›ç¨‹ä¹Ÿå« session çš„é¢†å¤´è¿›ç¨‹ã€‚Session ä¸­é¢†å¤´è¿›ç¨‹çš„ PID ä¹Ÿå°±æ˜¯ session çš„ SIDã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤æŸ¥çœ‹ SIDï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ps -o pid,ppid,pgid,sid,tty,comm</span><br></pre></td></tr></tbody></table></figure><figure><img src="https://img2018.cnblogs.com/blog/952033/202001/952033-20200103182117962-99639442.png" alt="img"><figcaption>img</figcaption></figure><p>Session ä¸­çš„æ¯ä¸ªè¿›ç¨‹ç»„è¢«ç§°ä¸ºä¸€ä¸ª jobï¼Œæœ‰ä¸€ä¸ª job ä¼šæˆä¸º session çš„å‰å° job(foreground)ï¼Œå…¶å®ƒçš„ job åˆ™æ˜¯åå° job(background)ã€‚æ¯ä¸ª session è¿æ¥ä¸€ä¸ªæ§åˆ¶ç»ˆç«¯(control terminal)ï¼Œæ§åˆ¶ç»ˆç«¯ä¸­çš„è¾“å…¥è¢«å‘é€ç»™å‰å° jobï¼Œä»å‰å° job äº§ç”Ÿçš„è¾“å‡ºä¹Ÿè¢«å‘é€åˆ°æ§åˆ¶ç»ˆç«¯ä¸Šã€‚åŒæ—¶ç”±æ§åˆ¶ç»ˆç«¯äº§ç”Ÿçš„ä¿¡å·ï¼Œæ¯”å¦‚ ctrl + z ç­‰éƒ½ä¼šä¼ é€’ç»™å‰å° jobã€‚</p><p>ä¸€èˆ¬æƒ…å†µä¸‹ session å’Œç»ˆç«¯æ˜¯ä¸€å¯¹ä¸€çš„å…³ç³»ï¼Œå½“æˆ‘ä»¬æ‰“å¼€å¤šä¸ªç»ˆç«¯çª—å£æ—¶ï¼Œå®é™…ä¸Šå°±åˆ›å»ºäº†å¤šä¸ª sessionã€‚</p><p><code>Session çš„æ„ä¹‰åœ¨äºå¤šä¸ªå·¥ä½œ(job)åœ¨ä¸€ä¸ªç»ˆç«¯ä¸­è¿è¡Œï¼Œå…¶ä¸­çš„ä¸€ä¸ªä¸ºå‰å° jobï¼Œå®ƒç›´æ¥æ¥æ”¶è¯¥ç»ˆç«¯çš„è¾“å…¥å¹¶æŠŠç»“æœè¾“å‡ºåˆ°è¯¥ç»ˆç«¯ã€‚å…¶å®ƒçš„ job åˆ™åœ¨åå°è¿è¡Œã€‚</code></p><h3 id="session-çš„è¯ç”Ÿä¸æ¶ˆäº¡">session çš„è¯ç”Ÿä¸æ¶ˆäº¡</h3><p>é€šå¸¸ï¼Œæ–°çš„ session ç”±ç³»ç»Ÿç™»å½•ç¨‹åºåˆ›å»ºï¼Œsession ä¸­çš„é¢†å¤´è¿›ç¨‹æ˜¯è¿è¡Œç”¨æˆ·ç™»å½• shell çš„è¿›ç¨‹ã€‚<code>æ–°åˆ›å»ºçš„æ¯ä¸ªè¿›ç¨‹éƒ½ä¼šå±äºä¸€ä¸ªè¿›ç¨‹ç»„ï¼Œå½“åˆ›å»ºä¸€ä¸ªè¿›ç¨‹æ—¶ï¼Œå®ƒå’Œçˆ¶è¿›ç¨‹åœ¨åŒä¸€ä¸ªè¿›ç¨‹ç»„ã€session ä¸­ã€‚</code></p><p>å°†è¿›ç¨‹æ”¾å…¥ä¸åŒ session çš„æƒŸä¸€æ–¹æ³•æ˜¯ä½¿ç”¨ setsid å‡½æ•°ä½¿å…¶æˆä¸ºæ–° session çš„é¢†å¤´è¿›ç¨‹ã€‚è¿™è¿˜ä¼šå°† session é¢†å¤´è¿›ç¨‹æ”¾å…¥ä¸€ä¸ªæ–°çš„è¿›ç¨‹ç»„ä¸­ã€‚</p><p><code>å½“ session ä¸­çš„æ‰€æœ‰è¿›ç¨‹éƒ½ç»“æŸæ—¶ session ä¹Ÿå°±æ¶ˆäº¡äº†</code>ã€‚å¦‚ä¸‹ä¸¤ç§ï¼š</p><p>1.å®é™…ä½¿ç”¨ä¸­æ¯”å¦‚ç½‘ç»œæ–­å¼€äº†ï¼Œsession è‚¯å®šæ˜¯è¦æ¶ˆäº¡çš„ã€‚</p><p>2.æ­£å¸¸çš„æ¶ˆäº¡ï¼Œæ¯”å¦‚è®© session çš„é¢†å¤´è¿›ç¨‹é€€å‡ºã€‚</p><p>ä¸€èˆ¬æƒ…å†µä¸‹ session çš„é¢†å¤´è¿›ç¨‹æ˜¯ shell è¿›ç¨‹ï¼Œå¦‚æœå®ƒå¤„äºå‰å°ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ <code>exit å‘½ä»¤æˆ–è€…æ˜¯ ctrl + d</code> è®©å®ƒé€€å‡ºã€‚æˆ–è€…æˆ‘ä»¬å¯ä»¥ç›´æ¥é€šè¿‡ kill å‘½ä»¤æ€æ­» session çš„é¢†å¤´è¿›ç¨‹ã€‚è¿™é‡Œé¢çš„åŸç†æ˜¯ï¼šå½“ç³»ç»Ÿæ£€æµ‹åˆ°æŒ‚æ–­(hangup)æ¡ä»¶æ—¶ï¼Œå†…æ ¸ä¸­çš„é©±åŠ¨ä¼šå°† SIGHUP ä¿¡å·å‘é€åˆ°æ•´ä¸ª sessionã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œè¿™ä¼šæ€æ­» session ä¸­çš„æ‰€æœ‰è¿›ç¨‹ã€‚</p><p>session ä¸ç»ˆç«¯çš„å…³ç³» å¦‚æœ session å…³è”çš„æ˜¯ä¼ªç»ˆç«¯ï¼Œè¿™ä¸ªä¼ªç»ˆç«¯æœ¬èº«å°±æ˜¯éšç€ session çš„å»ºç«‹è€Œåˆ›å»ºçš„ï¼Œsession ç»“æŸï¼Œé‚£ä¹ˆè¿™ä¸ªä¼ªç»ˆç«¯ä¹Ÿä¼šè¢«é”€æ¯ã€‚ å¦‚æœ session å…³è”çš„æ˜¯ tty1-6ï¼Œtty åˆ™ä¸ä¼šè¢«é”€æ¯ã€‚å› ä¸ºè¯¥ç»ˆç«¯è®¾å¤‡æ˜¯åœ¨ç³»ç»Ÿåˆå§‹åŒ–çš„æ—¶å€™åˆ›å»ºçš„ï¼Œå¹¶ä¸æ˜¯ä¾èµ–è¯¥ä¼šè¯å»ºç«‹çš„ï¼Œæ‰€ä»¥å½“ session é€€å‡ºï¼Œtty ä»ç„¶å­˜åœ¨ã€‚åªæ˜¯ init ç³»ç»Ÿåœ¨ session ç»“æŸåï¼Œä¼šé‡å¯ getty æ¥ç›‘å¬è¿™ä¸ª ttyã€‚</p><h3 id="nohup">nohup</h3><p><code>å¦‚æœæˆ‘ä»¬åœ¨ session ä¸­æ‰§è¡Œäº† nohup ç­‰ç±»ä¼¼çš„å‘½ä»¤ï¼Œå½“ session æ¶ˆäº¡æ—¶ï¼Œç›¸å…³çš„è¿›ç¨‹å¹¶ä¸ä¼šéšç€ session ç»“æŸï¼ŒåŸå› æ˜¯è¿™äº›è¿›ç¨‹ä¸å†å— SIGHUP ä¿¡å·çš„å½±å“ã€‚</code>æ¯”å¦‚æˆ‘ä»¬æ‰§è¡Œä¸‹é¢çš„å‘½ä»¤ï¼š</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nohup sleep <span class="number">1000</span> &gt;/dev/null <span class="number">2</span>&gt;&amp;<span class="number">1</span> &amp;</span><br></pre></td></tr></tbody></table></figure><figure><img src="https://img2018.cnblogs.com/blog/952033/202001/952033-20200103182343352-1366915632.png" alt="img"><figcaption>img</figcaption></figure><p>æ­¤æ—¶ sleep è¿›ç¨‹çš„ sid å’Œå…¶å®ƒè¿›ç¨‹æ˜¯ç›¸åŒçš„ï¼Œè¿˜å¯ä»¥é€šè¿‡ pstree å‘½ä»¤çœ‹åˆ°è¿›ç¨‹é—´çš„çˆ¶å­å…³ç³»ï¼š</p><figure><img src="https://img2018.cnblogs.com/blog/952033/202001/952033-20200103182417115-817556079.png" alt="img"><figcaption>img</figcaption></figure><p><code>å¦‚æœæˆ‘ä»¬é€€å‡ºå½“å‰ session çš„é¢†å¤´è¿›ç¨‹(bash)ï¼Œsleep è¿›ç¨‹å¹¶ä¸ä¼šé€€å‡ºï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥æ”¾å¿ƒçš„ç­‰å¾…è¯¥è¿›ç¨‹è¿è¡Œç»“æœäº†ã€‚</code> nohup å¹¶ä¸æ”¹å˜è¿›ç¨‹çš„ sidï¼ŒåŒæ—¶ä¹Ÿè¯´æ˜åœ¨è¿™ç§æƒ…å†µä¸­ï¼Œè™½ç„¶ session çš„é¢†å¤´è¿›ç¨‹é€€å‡ºäº†ï¼Œä½†æ˜¯ session ä¾ç„¶æ²¡æœ‰è¢«é”€æ¯(è‡³å°‘ sid è¿˜åœ¨è¢«å¼•ç”¨)ã€‚é‡æ–°å»ºç«‹è¿æ¥ï¼Œé€šè¿‡ä¸‹é¢çš„å‘½ä»¤æŸ¥çœ‹ sleep è¿›ç¨‹çš„ä¿¡æ¯ï¼Œå‘ç°è¿›ç¨‹çš„ sid ä¾ç„¶æ˜¯ 7837ï¼š</p><figure><img src="https://img2018.cnblogs.com/blog/952033/202001/952033-20200103182448160-376880623.png" alt="img"><figcaption>img</figcaption></figure><p>ä½†æ˜¯<code>æ­¤æ—¶çš„ sleep å·²ç»è¢«ç³»ç»Ÿçš„ 1 å·è¿›ç¨‹ systemd æ”¶å…»äº†</code>ï¼š</p><figure><img src="https://img2018.cnblogs.com/blog/952033/202001/952033-20200103182521953-1574746082.png" alt="img"><figcaption>img</figcaption></figure><h3 id="å‚è€ƒ">å‚è€ƒ</h3><blockquote><p>https://www.cnblogs.com/sparkdev/p/12146305.html</p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      å…³äºsshè¿æ¥ç»ˆç«¯å’Œsession
    
    </summary>
    
    
      <category term="linux" scheme="http://yoursite.com/categories/linux/"/>
    
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
  </entry>
  
</feed>
