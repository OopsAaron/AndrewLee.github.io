<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>思建的NLP之旅</title>
  
  <subtitle>沉淀自己</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-09-19T07:01:37.149Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>李思建</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>2020-09-19-一周论文分享（第2期）</title>
    <link href="http://yoursite.com/2020/09/19/2020-09-19-%E4%B8%80%E5%91%A8%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%EF%BC%88%E7%AC%AC2%E6%9C%9F%EF%BC%89/"/>
    <id>http://yoursite.com/2020/09/19/2020-09-19-%E4%B8%80%E5%91%A8%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%EF%BC%88%E7%AC%AC2%E6%9C%9F%EF%BC%89/</id>
    <published>2020-09-19T02:58:48.000Z</published>
    <updated>2020-09-19T07:01:37.149Z</updated>
    
    <content type="html"><![CDATA[<h4 id="联邦学习">联邦学习</h4><p>参考 <a href="https://zhuanlan.zhihu.com/p/79284686" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/79284686</a></p><p>背景</p><p>1.现实生活中，除了少数巨头公司能够满足，绝大多数企业都存在数据量少，数据质量差的问题，不足以支撑人工智能技术的实现；</p><p>2.同时国内外监管环境也在逐步加强数据保护，因此数据在安全合规的前提下自由流动，成了大势所趋，所以不能获取很多涉及用户隐私的信息。</p><p>3.数据的不充分交流，同时也导致即使在同一个公司内，数据也往往以孤岛形式出现。</p><p>基于以上不足以支撑实现、不允许粗暴交换、不愿意贡献价值三点，</p><p>现在大量存在的<strong>数据孤岛</strong>，以及隐私保护问题，联邦学习被提出。</p><p>概念</p><p>本质：联邦学习本质上是一种<strong>分布式</strong>机器学习技术，或机器学习<strong>框架</strong>。</p><p>目标：联邦学习的目标是在保证数据隐私安全及合法合规的基础上，实现共同建模，提升AI模型的效果。</p><p>前身：联邦学习最早在 2016 年由谷歌提出，原本用于解决安卓手机终端用户在本地更新模型的问题；</p><p><img src="E:\myBlog\source_posts\v2-657a9f63512351691e60af9d88a34605_720w.jpg" alt="img"></p><h2 id="横向联邦学习">3.1 横向联邦学习</h2><p><strong>适用场景：</strong></p><p>横向联邦学习的本质是<strong>样本的联合</strong>，适用于参与者间业态相同但触达客户不同，即特征重叠多，用户重叠少时的场景，比如不同地区的银行间，他们的业务相似（特征相似），但用户不同（样本不同）</p><p><strong>学习过程：</strong></p><p><img src="E:\myBlog\source_posts\v2-23616816b92a6d62be206b0aa28ba393_720w.jpg" alt="img"></p><p>step1：参与方各自从服务器A下载最新模型；</p><p>step2：每个参与方利用本地数据训练模型，加密梯度上传给服务器A，服务器A聚合各用户的梯度更新模型参数；</p><p>step3：服务器A返回更新后的模型给各参与方；</p><p>step4：各参与方更新各自模型。</p><p><strong>步骤解读：</strong>在传统的机器学习建模中，通常是把模型训练需要的数据集合到一个数据中心然后再训练模型，之后预测。在横向联邦学习中，可以看作是<strong>基于样本的分布式模型训练</strong>，分发全部数据到不同的机器，每台机器从服务器下载模型，然后利用本地数据训练模型，之后返回给服务器需要更新的参数；服务器聚合各机器上的返回的参数，更新模型，再把最新的模型反馈到每台机器。</p><p>在这个过程中，每台机器下都是<strong>相同且完整的模型</strong>，且机器之间不交流不依赖，在预测时每台机器也可以<strong>独立预测</strong>，可以把这个过程看作成基于样本的分布式模型训练。谷歌最初就是采用横向联邦的方式解决安卓手机终端用户在本地更新模型的问题的。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录每周值得分享的论文，周一发布、
《reformer-the eficient transformer》、
《Transformer-XL-Attentive Language Models Beyond a Fixed-Length Context》

    
    </summary>
    
    
      <category term="论文分享" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"/>
    
    
      <category term="论文" scheme="http://yoursite.com/tags/%E8%AE%BA%E6%96%87/"/>
    
      <category term="论文分享" scheme="http://yoursite.com/tags/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"/>
    
  </entry>
  
  <entry>
    <title>2020-09-14-修改pytorch版transformer代码</title>
    <link href="http://yoursite.com/2020/09/14/2020-09-14-%E4%BF%AE%E6%94%B9pytorch%E7%89%88transformer%E4%BB%A3%E7%A0%81/"/>
    <id>http://yoursite.com/2020/09/14/2020-09-14-%E4%BF%AE%E6%94%B9pytorch%E7%89%88transformer%E4%BB%A3%E7%A0%81/</id>
    <published>2020-09-14T08:26:17.000Z</published>
    <updated>2020-09-14T09:14:07.600Z</updated>
    
    <content type="html"><![CDATA[<p><del>源代码是<code>main3.py</code> ,在此基础上进行修改，修改后文件为<code>main3-2.py</code></del></p><p>740中<code>annotated-transformer</code>中<code>main.py</code>和哈佛的一样</p><p>复制到了本地<code>main.py</code> ,再复制到<code>annotated-transformer1</code>中的main.py</p><p><strong>所以改前的代码是<code>main.py</code> ，改后的代码是<code>main-1.py</code></strong></p><p>注：</p><p><strong><code>python main.py &gt;main.txt 2&gt;&amp;1</code>，在将结果重定向到main.txt中，会覆盖main.txt之前的内容</strong></p><p><strong>每次跑实验的预测都是不一样的，但是都是和输入差不多</strong></p><ol type="1"><li>将<code>attention</code>函数去掉，合并到<code>MultiHeadedAttention</code>中，服务器上测试<strong>可行</strong></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录修改过程
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-09-11-gpu实验加速</title>
    <link href="http://yoursite.com/2020/09/11/2020-09-11-gpu%E5%AE%9E%E9%AA%8C%E5%8A%A0%E9%80%9F/"/>
    <id>http://yoursite.com/2020/09/11/2020-09-11-gpu%E5%AE%9E%E9%AA%8C%E5%8A%A0%E9%80%9F/</id>
    <published>2020-09-11T00:48:00.000Z</published>
    <updated>2020-09-13T06:49:02.999Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言">前言</h3><p>将深度学习应用到实际问题中，一个非常大的问题在于训练深度学习模型需要的计算量太大。为了加速训练过程，本文将介绍如何如何在TensorFlow中使用单个GPU进行计算加速</p><h3 id="简介">简介</h3><h4 id="cuda">CUDA</h4><p><a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">CUDA</a>（Compute Unified Device Architecture,点击进入安装网站），是显卡厂商NVIDIA推出的运算平台。 CUDA™是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。安装GPU版tensorflow,必须有这个环境。</p><p>CUDA是NVIDIA推出的用于自家GPU的并行计算框架，也就是说CUDA只能在NVIDIA的GPU上运行，而且只有当要解决的计算问题是可以大量并行计算的时候才能发挥CUDA的作用。</p><h4 id="cudnn">cuDNN</h4><p>NVIDIA <a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">cuDNN</a>是用于深度神经网络的GPU加速库。它强调性能、易用性和低内存开销。</p><h3 id="安装">安装</h3><p>必须要安装对应版本的CUDA、cuDNN和tensorflow</p><p>我在实验室服务器R740上的安装版本如下，是可以运行的</p><blockquote><p>CUDA： V10.1 # nvcc --version</p><p>cuDNN：V7</p><p>tensorflow-gpu：1.14.0</p></blockquote><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda install python==3.6.10  <span class="comment">#这样可以 ，但是为什么 python==3.6.1 和  python==3.6.0 是不可以的呢？？</span></span><br><span class="line">pip install tensorflow-gpu==1.14.0  <span class="comment">#安装成功gpu版本</span></span><br><span class="line"><span class="comment">#用conda装tensorflow时候，会自动下载cuda和cudnn，所以推荐用pip安装</span></span><br><span class="line"></span><br><span class="line">pip install tensorflow-gpu==1.2 <span class="comment">#如果安装错误，可以用pip卸载，没测试过。 或者直接再新建一个虚拟环境也可以</span></span><br></pre></td></tr></tbody></table></figure><h3 id="测试tensorflow-gpu">测试tensorflow-gpu</h3><p>测试安装的tensorflow是否可用GPU，测试如下：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pyhton <span class="comment">#进入python操作环境</span></span><br><span class="line"></span><br><span class="line">import tensorflow as tf </span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))</span><br></pre></td></tr></tbody></table></figure><p>显示如下则表示tensorflow支持的，输出如下：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">2020-09-11 08:30:54.735834: Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA</span><br><span class="line">2020-09-11 08:30:54.821023:  Successfully opened dynamic library libcuda.so.1</span><br><span class="line">2020-09-11 08:30:55.698894:  XLA service 0x5654b4f86600 executing computations on platform CUDA. Devices:</span><br><span class="line">2020-09-11 08:30:55.699000:   StreamExecutor device (0): Tesla M60, Compute Capability 5.2</span><br><span class="line">2020-09-11 08:30:55.699022:   StreamExecutor device (1): Tesla M60, Compute Capability 5.2</span><br><span class="line">2020-09-11 08:30:55.699042:   StreamExecutor device (2): Tesla M60, Compute Capability 5.2</span><br><span class="line">2020-09-11 08:30:55.699062:   StreamExecutor device (3): Tesla M60, Compute Capability 5.2</span><br><span class="line">2020-09-11 08:30:55.732911:   CPU Frequency: 2100000000 Hz</span><br><span class="line">2020-09-11 08:30:55.738953: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5654b54aa810 executing computations on platform Host. Devices:</span><br><span class="line">2020-09-11 08:30:55.739001: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): &lt;undefined&gt;, &lt;undefined&gt;</span><br><span class="line">2020-09-11 08:30:55.741878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: </span><br><span class="line">name: Tesla M60 major: 5 minor: 2 memoryClockRate(GHz): 1.1775</span><br><span class="line">pciBusID: 0000:b1:00.0</span><br><span class="line">2020-09-11 08:30:55.742665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: </span><br><span class="line">name: Tesla M60 major: 5 minor: 2 memoryClockRate(GHz): 1.1775</span><br><span class="line">pciBusID: 0000:b2:00.0</span><br><span class="line">2020-09-11 08:30:55.743420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: </span><br><span class="line">name: Tesla M60 major: 5 minor: 2 memoryClockRate(GHz): 1.1775</span><br><span class="line">pciBusID: 0000:da:00.0</span><br><span class="line">2020-09-11 08:30:55.744263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: </span><br><span class="line">name: Tesla M60 major: 5 minor: 2 memoryClockRate(GHz): 1.1775</span><br><span class="line">pciBusID: 0000:db:00.0</span><br><span class="line">2020-09-11 08:30:55.744692: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library <span class="string">'libcudart.so.10.0'</span>; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dell2/.mujoco/mjpro150/bin:/usr/<span class="built_in">local</span>/cuda-10.1/lib64:</span><br><span class="line">2020-09-11 08:30:55.744798: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library <span class="string">'libcublas.so.10.0'</span>; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dell2/.mujoco/mjpro150/bin:/usr/<span class="built_in">local</span>/cuda-10.1/lib64:</span><br><span class="line">2020-09-11 08:30:55.744891: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library <span class="string">'libcufft.so.10.0'</span>; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dell2/.mujoco/mjpro150/bin:/usr/<span class="built_in">local</span>/cuda-10.1/lib64:</span><br><span class="line">2020-09-11 08:30:55.744980: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library <span class="string">'libcurand.so.10.0'</span>; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dell2/.mujoco/mjpro150/bin:/usr/<span class="built_in">local</span>/cuda-10.1/lib64:</span><br><span class="line">2020-09-11 08:30:55.745070: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library <span class="string">'libcusolver.so.10.0'</span>; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dell2/.mujoco/mjpro150/bin:/usr/<span class="built_in">local</span>/cuda-10.1/lib64:</span><br><span class="line">2020-09-11 08:30:55.745166: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library <span class="string">'libcusparse.so.10.0'</span>; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dell2/.mujoco/mjpro150/bin:/usr/<span class="built_in">local</span>/cuda-10.1/lib64:</span><br><span class="line">2020-09-11 08:30:55.750141: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7</span><br><span class="line">2020-09-11 08:30:55.750170: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1663] Cannot dlopen some GPU libraries. Skipping registering GPU devices...</span><br><span class="line">2020-09-11 08:30:55.750542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:</span><br><span class="line">2020-09-11 08:30:55.750706:       0 1 2 3 </span><br><span class="line">2020-09-11 08:30:55.750797:  0:   N Y Y Y </span><br><span class="line">2020-09-11 08:30:55.750887:  1:   Y N Y Y </span><br><span class="line">2020-09-11 08:30:55.750974:  2:   Y Y N Y </span><br><span class="line">2020-09-11 08:30:55.751059:  3:   Y Y Y N </span><br><span class="line">Device mapping:</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_GPU:0 -&gt; device: XLA_GPU device</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_GPU:1 -&gt; device: XLA_GPU device</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_GPU:2 -&gt; device: XLA_GPU device</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_GPU:3 -&gt; device: XLA_GPU device</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_CPU:0 -&gt; device: XLA_CPU device</span><br><span class="line">2020-09-11 08:30:55.757190: I tensorflow/core/common_runtime/direct_session.cc:296] Device mapping:</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_GPU:0 -&gt; device: XLA_GPU device</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_GPU:1 -&gt; device: XLA_GPU device</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_GPU:2 -&gt; device: XLA_GPU device</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_GPU:3 -&gt; device: XLA_GPU device</span><br><span class="line">/job:localhost/replica:0/task:0/device:XLA_CPU:0 -&gt; device: XLA_CPU device</span><br></pre></td></tr></tbody></table></figure><p>表示tensorflow支持device：CPU：0 ，支持device：<code>GPU：0,1,2,3</code>，共4块GPU</p><p>比如CPU在TensorFlow中的名称为/cpu:0。<strong>在默认情况下，即使机器有多个CPU，TensorFlow也不会区分它们，所有的CPU都使用/cpu:0作为名称。</strong></p><p>而一台机器上不同GPU的名称是不同的，第n个GPU在TensorFlow中的名称为/gpu:n。比如第一个GPU的名称为/gpu:0，第二个GPU名称为/gpu:1，以此类推。</p><p>作者：博文视点 链接：https://www.jianshu.com/p/26ac409dfb38 来源：简书 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p><h3 id="ubuntu中查看显卡信息">Ubuntu中查看显卡信息</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lspci | grep -i vga <span class="comment">#显卡</span></span><br></pre></td></tr></tbody></table></figure><p>显示结果如下：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">03:00.0 VGA compatible controller: Matrox Electronics Systems Ltd. Integrated Matrox G200eW3 Graphics Controller (rev 04)</span><br><span class="line">b1:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br><span class="line">b2:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br><span class="line">da:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br><span class="line">db:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br></pre></td></tr></tbody></table></figure><h3 id="ubuntu中查看nvidia-gpu">Ubuntu中查看nvidia GPU</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lspci | grep -i nvidia <span class="comment">#查看gpu信息</span></span><br></pre></td></tr></tbody></table></figure><p>显示结果如下：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">b1:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br><span class="line">b2:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br><span class="line">da:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br><span class="line">db:00.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br></pre></td></tr></tbody></table></figure><h3 id="查看nvidia的显卡信息和使用情况">查看Nvidia的显卡信息和使用情况</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></tbody></table></figure><p>显示如下：</p><p><img src="https://i.loli.net/2020/09/11/OQZjHpocke5S9FE.png" alt="image-20200910221947824"></p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps aux | grep train.py #我的实验名称为train.py</span><br></pre></td></tr></tbody></table></figure><p><img src="https://i.loli.net/2020/09/11/7lujWDbiqnV6zwG.png" alt="image-20200910222011793"></p><p>可以看到，我的实验进程号是<code>21195</code>，在<code>processes</code>中可以看到使用了<code>GPU1,2</code></p><h3 id="指定gpu实验加速">指定GPU实验加速</h3><p>如果电脑有多个GPU，tensorflow默认全部使用。</p><p>如果想只使用部分GPU，可以设置<code>CUDA_VISIBLE_DEVICES</code>。</p><h4 id="命令行指定">命令行指定</h4><p>在执行python程序时，可以通过：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=1 python train.py <span class="comment">#只使用GPU1</span></span><br></pre></td></tr></tbody></table></figure><p>以下为一些使用指导：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Environment Variable Syntax      Results</span><br><span class="line"></span><br><span class="line">CUDA_VISIBLE_DEVICES=1           Only device 1 will be seen</span><br><span class="line">CUDA_VISIBLE_DEVICES=0,1         Devices 0 and 1 will be visible</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="string">"0,1"</span>       Same as above, quotation marks are optional</span><br><span class="line">CUDA_VISIBLE_DEVICES=0,2,3       Devices 0, 2, 3 will be visible; device 1 is masked</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="string">""</span>          No GPU will be visible1234567</span><br></pre></td></tr></tbody></table></figure><h4 id="代码中指定">代码中指定</h4><p>在Python代码中添加以下内容：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"1"</span> <span class="comment">#只使用GPU1</span></span><br></pre></td></tr></tbody></table></figure><h3 id="设置tensorflow使用的显存大小">设置tensorflow使用的显存大小</h3><h4 id="定量设置显存">定量设置显存</h4><p>默认tensorflow是使用GPU尽可能多的显存（内存）。</p><p>用Tensorflow创建session的时候要注意设置内存使用情况，特别是内存资源不够而且要和别人共享一块GPU的时候（留一点给别人用）</p><p>可以通过下面的方式，来设置使用的GPU显存：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=<span class="number">0.7</span>)</span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))</span><br></pre></td></tr></tbody></table></figure><p>上面分配给tensorflow的GPU显存大小为：GPU实际显存*0.7。 可以按照需要，设置不同的值，来分配显存。</p><h4 id="按需设置显存">按需设置显存</h4><p>上面的只能设置固定的大小。如果想按需分配，可以使用allow_growth参数</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gpu_options = tf.GPUOptions(allow_growth=<span class="literal">True</span>)</span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))  </span><br><span class="line"><span class="comment"># 使用allow_growth option，刚一开始分配少量的GPU容量，然后按需慢慢的增加，由于不会释放内存，所以会导致碎片</span></span><br></pre></td></tr></tbody></table></figure><p>如果一个 TensorFlow 的 operation 中兼有 CPU 和 GPU 的实现, 当这个算子被指派设备时, GPU 有优先权. 比如<code>matmul</code>中 CPU 和 GPU kernel 函数都存在. 那么在 <code>cpu:0</code> 和 <code>gpu:0</code> 中, <code>matmul</code> operation 会被指派给 <code>gpu:0</code> .</p><h4 id="记录设备指派情况">记录设备指派情况</h4><p>为了获取你的 operations 和 Tensor 被指派到哪个设备上运行, 用 <code>log_device_placement</code> 新建一个 <code>session</code>, 并设置为 <code>True</code>.</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建一个 graph.</span></span><br><span class="line">a = tf.constant([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>], shape=[<span class="number">2</span>, <span class="number">3</span>], name=<span class="string">'a'</span>)</span><br><span class="line">b = tf.constant([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>], shape=[<span class="number">3</span>, <span class="number">2</span>], name=<span class="string">'b'</span>)</span><br><span class="line">c = tf.matmul(a, b)</span><br><span class="line"><span class="comment"># 新建session with log_device_placement并设置为True.</span></span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(log_device_placement=<span class="literal">True</span>))</span><br><span class="line"><span class="comment"># 运行这个 op.</span></span><br><span class="line"><span class="keyword">print</span> sess.run(c)</span><br></pre></td></tr></tbody></table></figure><p>你应该能看见以下输出:</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Device mapping:</span><br><span class="line">/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: Tesla K40c, pci bus</span><br><span class="line">id: <span class="number">0000</span>:<span class="number">05</span>:<span class="number">00.0</span></span><br><span class="line">b: /job:localhost/replica:<span class="number">0</span>/task:<span class="number">0</span>/gpu:<span class="number">0</span></span><br><span class="line">a: /job:localhost/replica:<span class="number">0</span>/task:<span class="number">0</span>/gpu:<span class="number">0</span></span><br><span class="line">MatMul: /job:localhost/replica:<span class="number">0</span>/task:<span class="number">0</span>/gpu:<span class="number">0</span></span><br><span class="line">[[ <span class="number">22.</span>  <span class="number">28.</span>]</span><br><span class="line"> [ <span class="number">49.</span>  <span class="number">64.</span>]]</span><br></pre></td></tr></tbody></table></figure><h4 id="section"></h4><h3 id="gpu和cpu">GPU和CPU</h3><p>一个GPU被多个实验使用，但是如果实验超过显存大小，就会都被挂掉，会显示<code>stopped</code>字样</p><p>一个实验可以用多个GPU，但是需要更改部分代码，让其支持多GPU</p><p>不要tensorflow-gpu和tensorflow(cpu版)一起装，因为这样装有个先后顺序问题，先安装tensorflow-gpu再安装tensorflow，gpu版本直接不能用了。</p><p>如果想测试cpu和gpu版本性能的，最好创建两个python的虚拟环境，一个装tensorflow-gpu，另一个装tensorflow。</p><hr><p>在Tensorflow中使用gpu和cpu是有很大的差别的。在小数据集的情况下，cpu和gpu的性能差别不大。不过在大数据集的情况下，cpu的时间显著增加，而gpu变化并不明显。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> timeit</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cpu_run</span><span class="params">(num)</span>:</span></span><br><span class="line">  <span class="keyword">with</span> tf.device(<span class="string">'/cpu:0'</span>):</span><br><span class="line">    cpu_a=tf.random.normal([<span class="number">1</span>,num])</span><br><span class="line">    cpu_b=tf.random.normal([num,<span class="number">1</span>])</span><br><span class="line">    c=tf.matmul(cpu_a,cpu_b)</span><br><span class="line">  <span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gpu_run</span><span class="params">(num)</span>:</span></span><br><span class="line">  <span class="keyword">with</span> tf.device(<span class="string">'/gpu:0'</span>):</span><br><span class="line">    gpu_a=tf.random.normal([<span class="number">1</span>,num])</span><br><span class="line">    gpu_b=tf.random.normal([num,<span class="number">1</span>])</span><br><span class="line">    c=tf.matmul(gpu_a,gpu_b)</span><br><span class="line">  <span class="keyword">return</span> c</span><br><span class="line">k=<span class="number">10</span></span><br><span class="line">m=<span class="number">7</span></span><br><span class="line">cpu_result=np.arange(m,dtype=np.float32)</span><br><span class="line">gpu_result=np.arange(m,dtype=np.float32)</span><br><span class="line">x_time=np.arange(m)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">  k=k*<span class="number">10</span></span><br><span class="line">  x_time[i]=k</span><br><span class="line">  cpu_str=<span class="string">'cpu_run('</span>+str(k)+<span class="string">')'</span></span><br><span class="line">  gpu_str=<span class="string">'gpu_run('</span>+str(k)+<span class="string">')'</span></span><br><span class="line">  <span class="comment">#print(cpu_str)</span></span><br><span class="line">  cpu_time=timeit.timeit(cpu_str,<span class="string">'from __main__ import cpu_run'</span>,number=<span class="number">10</span>)</span><br><span class="line">  gpu_time=timeit.timeit(gpu_str,<span class="string">'from __main__ import gpu_run'</span>,number=<span class="number">10</span>)</span><br><span class="line">  <span class="comment"># 正式计算10次，取平均时间</span></span><br><span class="line">  cpu_time=timeit.timeit(cpu_str,<span class="string">'from __main__ import cpu_run'</span>,number=<span class="number">10</span>)</span><br><span class="line">  gpu_time=timeit.timeit(gpu_str,<span class="string">'from __main__ import gpu_run'</span>,number=<span class="number">10</span>)</span><br><span class="line">  cpu_result[i]=cpu_time</span><br><span class="line">  gpu_result[i]=gpu_time</span><br><span class="line"></span><br><span class="line">print(cpu_result)</span><br><span class="line">print(gpu_result)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.set_xscale(<span class="string">"log"</span>)</span><br><span class="line">ax.set_adjustable(<span class="string">"datalim"</span>)</span><br><span class="line">ax.plot(x_time,cpu_result)</span><br><span class="line">ax.plot(x_time,gpu_result)</span><br><span class="line">ax.grid()</span><br><span class="line">plt.draw()</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure><p><img src="https://i.loli.net/2020/09/11/tRxAb2wY5qKGF4D.png" alt="在这里插入图片描述"> 蓝线是cpu的耗时，而红线是gpu的耗时。</p><p>更多gpu内容可参考</p><blockquote><p><a href="https://docs.pythontab.com/tensorflow/how_tos/using_gpu/" target="_blank" rel="noopener">tensorflow官方文档，使用 GPUs</a></p><p><a href="https://www.cnblogs.com/nxf-rabbit75/p/10639833.html" target="_blank" rel="noopener">Tensorflow检验GPU是否安装成功 及 使用GPU训练注意事项</a></p><p><a href="https://www.jianshu.com/p/26ac409dfb38" target="_blank" rel="noopener">TensorFlow：实战Google深度学习框架（第2版）:GPU加速</a></p></blockquote><h3 id="tensorflow匹配的关系">tensorflow匹配的关系</h3><p><img src="https://i.loli.net/2020/09/13/FqJ1cXThMzKHvA5.png" alt="image-20200913144848843"></p><p><img src="E:\myBlog\source_posts\FqJ1cXThMzKHvA5.png"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录加速过程以及知识点
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-09-07-实验日志</title>
    <link href="http://yoursite.com/2020/09/07/2020-09-07-%E5%AE%9E%E9%AA%8C%E6%97%A5%E5%BF%97/"/>
    <id>http://yoursite.com/2020/09/07/2020-09-07-%E5%AE%9E%E9%AA%8C%E6%97%A5%E5%BF%97/</id>
    <published>2020-09-07T12:44:43.000Z</published>
    <updated>2020-09-18T14:46:15.108Z</updated>
    
    <content type="html"><![CDATA[<h3 id="虚拟环境配置">虚拟环境配置</h3><h4 id="笔记本">笔记本</h4><table><thead><tr class="header"><th>名称</th><th>配置</th><th>用处</th></tr></thead><tbody><tr class="odd"><td>sijian36</td><td>tf 1.9.0</td><td>普通跑实验</td></tr><tr class="even"><td>python714</td><td>tf 1.14.0</td><td>RKN</td></tr><tr class="odd"><td>ronghe</td><td>tf 1.14.0</td><td>transformer和RKN</td></tr></tbody></table><h4 id="r740服务器">R740服务器</h4><p>cuda-10.2</p><table><thead><tr class="header"><th>名称</th><th>配置</th><th>用处</th></tr></thead><tbody><tr class="odd"><td>sijian1</td><td>tf 1.13.0</td><td>一般实验</td></tr><tr class="even"><td>pytorth030</td><td>torch 0.3</td><td>哈佛torch版transformer</td></tr><tr class="odd"><td>lsjRKN</td><td>tf 1.14.0</td><td>RKN</td></tr><tr class="even"><td>ronghe</td><td>tf 1.14.0</td><td>transformer和RKN</td></tr><tr class="odd"><td>ronghe6</td><td>tf-gpu1.14.0</td><td>gpu加速融合</td></tr></tbody></table><h3 id="日志">日志</h3><h4 id="section"><strong>2020-09-06</strong></h4><h5 id="主要内容">主要内容</h5><p>笔记本的RKN实验</p><p>跑通是在RKNmaster文件跑</p><hr><p>哈佛torch版transformer实验</p><p>R740中 LSJ/annotated-transformer1/main5.py(pytorch030)</p><p>是之前上传到R740跑的实验</p><p>LSJ/annotated-transformer是前一阵为了将函数改成直通型流程而从笔记本上上传的</p><h5 id="出现问题">出现问题</h5><p>在R740跑RKN实验</p><p><code>attributeerror: module 'tensorflow.keras.initializers'  has no attribute 'normal'</code> 解决</p><p>将RKN.py 77行 normal 改为 <strong>RandomNormal</strong> 还是出错</p><p>再次出错 keep.dim出错</p><p>修改 将keep.dim=True参数去掉 再运行</p><p>​ <img src="https://i.loli.net/2020/09/08/h7Ma3lm82eFSuWX.png" alt="img"></p><ul><li>运行结果是没有tf.matrix_band_part 这个参数，于是百度发现，</li><li>新版本：tf.matrix_band_part变成tf.linalg.band_part 于是修改再运行</li></ul><p>运行结果显示</p><p>​ <img src="https://i.loli.net/2020/09/08/h7Ma3lm82eFSuWX.png" alt="img"></p><p>于是百度，原因是</p><p>The image from your input pipeline is of type 'uint8', you need to type cast it to 'float32', You can do this after the image jpeg decoder:</p><p>以下更改，在RKN.py中插入h = tf.cast(h, tf.float32)</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">def _prop_through_layers(inputs, layers):</span><br><span class="line"></span><br><span class="line">​    """propagates inputs through layers"""</span><br><span class="line"></span><br><span class="line">​    h = inputs</span><br><span class="line"></span><br><span class="line">h = tf.cast(h, tf.float32)</span><br><span class="line"></span><br><span class="line">​    for layer in layers:</span><br><span class="line"></span><br><span class="line">​        h = layer(h)</span><br><span class="line"></span><br><span class="line">​    return h</span><br></pre></td></tr></tbody></table></figure><p>还是报错</p><p><strong>放弃使用sijian1 以及刚刚对RKNmaser的修改</strong></p><p>将笔记本中的RKNmaster 复制为rknmas上传到R740 名字为<strong>rknmas</strong></p><p>参考了笔记本中的虚拟环境，在R740新建lsjRKN的虚拟环境，<strong>tf版本为1.14 python：3.6</strong></p><p>可以跑通实验</p><p>实验可以在R740跑起来，但是为什么论文作者的github代码上tensorflow版本是1.13 不好使，但是在tensorflow1.14就可以跑起来？？？？</p><p>在笔记本上跑的 设置epoch=5</p><p>​ <img src="https://i.loli.net/2020/09/08/h7Ma3lm82eFSuWX.png" alt="img"></p><h4 id="section-1"><strong>2020-09-07</strong></h4><h5 id="主要内容-1">主要内容</h5><p>配置transformer和RKN融合的实验虚拟环境 测试代码</p><p>下载的是<a href="https://github.com/Kyubyong/transformer" target="_blank" rel="noopener">Kyubyong/transformer</a> 代码，准备融合RKN</p><p>具体的配置如下：</p><hr><p><strong>Requirements</strong></p><ul><li>python==3.x (Let's move on to python 3 if you still use python 2)</li><li>tensorflow==1.12.0</li><li>numpy&gt;=1.15.4</li><li>sentencepiece==0.1.8</li><li>tqdm&gt;=4.28.1 #显示进度条的包</li></ul><hr><p>github下载代码，放到<code>C:\Users\Administrator\PycharmProjects</code>目录下，文件名为 <code>transformer-master</code></p><p><code>python714</code>是可以运行RKN的，在笔记本上，根据<code>python714</code> clone了<code>ronghe</code> ，并添加所需要的包</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda install tqdm</span><br><span class="line"></span><br><span class="line">pip install  sentencepiece==0.1.8 <span class="comment"># conda 安装出错 ，于是用pip安装</span></span><br></pre></td></tr></tbody></table></figure><h5 id="出现问题-1"><strong>出现问题</strong></h5><p>此代码不是官方代码，虽然可以实现transformer，但是使用的数据集是小型的<code>IWSLT 2016 de-en</code>，而不是transformer论文中使用的大型数据集WMT，但是官方代码又很难读，而且有很多用不到的接口</p><p>在纠结，要用目前的代码进行融合，还是用官方的代码呢？</p><p>问过师兄，现在还是不用官方的transformer代码，就用目前的代码，只是验证，不用管实验数据集，先将现在的代码结合RKN再说</p><h4 id="section-2"><strong>2020-09-08</strong></h4><h5 id="主要内容-2">主要内容</h5><p>阅读整理RKN的代码</p><p>将昨天的transformer数据集无法读取的问题解决</p><p>将RKN在R740上跑，并保存在<code>test1.txt</code>文件中，可以用<code>less</code> 查看</p><h5 id="遇到问题">遇到问题</h5><p>RKN代码读的一脸懵</p><p>transformer代码bug还未修复 <span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f62d.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f62d.png?v8">😭</span></p><h4 id="section-3"><strong>2020-09-09</strong></h4><h5 id="主要内容-3">主要内容</h5><p>在R740新建环境<code>ronghe</code>，根据虚拟环境<code>lsjRKN</code>来建的</p><p>第三方包也安装成功</p><h5 id="遇到问题-1"><strong>遇到问题</strong></h5><ol type="1"><li></li><li>添加上encoding='ascii',error='ignore'就可以解决</li></ol><p><img src="https://i.loli.net/2020/09/11/vCfMGWJ975VEiRl.png" alt="image-20200909094144959"></p><h6 id="注">注</h6><p>在解决完之后，一定要看报错的位置，可能这个已解决，但是其它相同的问题不同位置也会报错，同样解决就可以了</p><ol start="2" type="1"><li>在笔记本上跑此实验，发现内存不够，超出内容超过10%</li></ol><p><code>Allocation of 1196032000 exceeds 10% of system memory</code></p><p><strong>解决</strong></p><p>减少<code>banch_size</code> ， 但是还是超出，但是应该是在现有环境下实验可以跑通的，于是想着在R740上跑</p><p>在R740跑<code>prepro.py</code>实验，如下输出，并<code>INFO：done</code> （表示完成）</p><p><img src="https://i.loli.net/2020/09/11/BAb9krnJ8dCYKTX.png" alt="image-20200909132740936"></p><p>开始跑<code>train.py</code> 并将输出保存在train99.txt中（9月9日）</p><p><img src="https://i.loli.net/2020/09/11/7UpXhTBcnGNILtH.png" alt="image-20200909134011883"></p><p>这个WARNING是什么意思呢？</p><p>猜想：源代码需要的是<code>tf1.12</code>版本 我配置的是<code>tf 1.14</code>版本，不知道是不是这个原因 。晚上回寝百度一下</p><ol start="3" type="1"><li>在740中跑的太慢了，不知道具体原因。在看源代码进行修改</li></ol><h4 id="section-4">2020-09-10</h4><h5 id="主要内容-4">主要内容</h5><p>更改虚拟环境，可以使用GPU对实验进行加速</p><p>阅读transformer的代码，明天融合</p><p>对跑实验的一些warning都已经修改了，复制项目名字为<code>transformer-mas</code></p><p>上传到R740中，命名<code>transformer-mas</code></p><h5 id="遇到问题-2">遇到问题</h5><p><img src="https://i.loli.net/2020/09/11/HUMOjGrYSiZlPo5.png" alt="image-20200910200948426" style="zoom:200%;"></p><p>新建<code>ronghe3</code>虚拟环境</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda install python==3.6.10  <span class="comment">#这样可以 ，但是为什么 python==3.6.1 和  python==3.6.0 是不可以的呢？？</span></span><br><span class="line">pip install tensorflow-gpu==1.13.1</span><br></pre></td></tr></tbody></table></figure><p>在已经安装了tensorflow-gpu的<code>ronghe3</code>基础上，克隆了<code>ronghe4</code>，进行接下来的操作</p><h6 id="注-1">注</h6><p>如果执行<code>conda install tensorflow==1.13.1</code></p><p>安装错误 ，导入不了tensorflow-gpu，应该是和CUDA版本不匹配</p><p><img src="https://i.loli.net/2020/09/11/CgXZf5vQzdODpyU.png" alt="image-20200910211644840"></p><h5 id="参考">参考</h5><p><a href="https://www.tensorflow.org/install/gpu?hl=zh-cn" target="_blank" rel="noopener">tensorflow官方，GPU 支持</a></p><p><code>ronghe5</code></p><p><code>pip install tensorflow-gpu==1.12.0</code></p><p>还是跑不通</p><p><code>ronghe6</code></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda install python==3.6.10  <span class="comment">#这样可以 ，但是为什么 python==3.6.1 和  python==3.6.0 是不可以的呢？？</span></span><br><span class="line">pip install tensorflow-gpu==1.14.0</span><br></pre></td></tr></tbody></table></figure><p>终于可以跑通了，不会报错了！！！</p><p>测试安装的tensorflow是否可用GPU，可以使用。测试如下：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pyhton <span class="comment">#进入python操作环境</span></span><br><span class="line"></span><br><span class="line">import tensorflow as tf </span><br><span class="line">sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))</span><br></pre></td></tr></tbody></table></figure><p>RKN实验跑完了，保存在test2.txt中</p><blockquote><p>tensorflow-gpu 1.5版本及以上要求CUDA版本为9.0</p><p>tensorflow-gpu 1.3及以上版本要求cudnn版本为V6及以上</p></blockquote><h4 id="section-5">2020-09-11</h4><h5 id="主要内容-5">主要内容</h5><p>解决在linux显示图形的问题</p><p>解决transformer实验报错</p><h5 id="遇到问题-3">遇到问题</h5><ol type="1"><li>用xshell在服务器linux端只能显示控制台输出，如果想要显示图像，比如<code>matplotlib</code>包，则要下载<code>xmanage</code></li></ol><p>由于需要收费，没有下载</p><p><img src="https://i.loli.net/2020/09/11/zkqMvhElw2ubg9U.png" alt="image-20200911212759446"></p><p>解决方法： 可以用<code>plt.savafig</code>保存到服务器，再保存在本地笔记本</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">'Agg'</span>)</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.font_manager <span class="keyword">import</span> FontProperties</span><br><span class="line">X = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</span><br><span class="line">dataY = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>]</span><br><span class="line">plt.xlabel(<span class="string">"x轴"</span>);</span><br><span class="line">plt.ylabel(<span class="string">"y轴"</span>);</span><br><span class="line">plt.savefig(<span class="string">"./lisijian.png"</span>,dpi=<span class="number">100</span>) <span class="comment">#保存在本文件夹下的lisijian.png</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure><p>报错<code>_tkinter.TclError: couldn't connect to display "localhost:32.0"</code></p><p>原因： 问题在于，您使用的是一个交互式后端，它试图为您创建图形窗口，但由于您断开了启动模拟时可用的x服务器，所以失败了。</p><p>解决方法：使用非交互式后端(请参见<a href="https://matplotlib.org/faq/usage_faq.html#what-is-a-backend" target="_blank" rel="noopener">后端</a>？)比如：Agg(用于Png格式，PDF, SVG或PS。在生成图形的脚本中，只需在import matplotlib.pyplot as plt之前调用matplotlib.use(）即可</p><p>比如<code>matplotlib.use('Agg')</code></p><ol start="2" type="1"><li><p>在transformer实验中，才开始没注意，今天才发现有一个错误，如下:</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AssertionError: Bad argument number <span class="keyword">for</span> Name: 3, expecting 4</span><br></pre></td></tr></tbody></table></figure></li></ol><p>解决方法：因为对结果的影响不可观,所以就没去在意 ,后面发现用其他docker并没有多少问题,而且每次都出现一堆warning很影响美观性,于是百度准备解决这个问题</p><p><strong>后来发现是有个gast的库版本太高,导致不兼容的问题,降级gast即可解决</strong></p><p>使用pip进行降级</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --user gast==0.2.2</span><br></pre></td></tr></tbody></table></figure><p><strong>待解决：</strong></p><p><strong>tensorflow的兼容性问题 cuda的兼容性问题 ？？</strong></p><p><strong>一般如果要对服务器上的实验进行更改的话，怎能会简单一些？？</strong></p><h4 id="section-6">2020-09-13</h4><h5 id="主要内容-6">主要内容</h5><p>解决transformer报错的问题</p><p>解决tensorflow目前不支持CUDA10.1的问题</p><p>修改：</p><p>将batch 由 128 改为 32</p><p>将maxlen1 和maxlen2 由100改为101</p><h5 id="遇到问题-4">遇到问题</h5><ol type="1"><li><p>在运行transformer代码的时候，程序报错如下（部分内容，具体参考<code>train911.txt</code>）：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"train.py"</span>, line 81, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    hypotheses = get_hypotheses(num_eval_batches, num_eval_samples, sess, y_hat, m.idx2token)</span><br><span class="line">  File <span class="string">"/home/dell2/LSJ/transformer-master/utils.py"</span>, line 144, <span class="keyword">in</span> get_hypotheses</span><br><span class="line">    h = sess.run(tensor)</span><br><span class="line">  File <span class="string">"/home/dell2/anaconda3/envs/ronghe6/lib/python3.6/site-packages/tensorflow/python/client/session.py"</span>, line 950, <span class="keyword">in</span> run</span><br><span class="line">    run_metadata_ptr)</span><br><span class="line">  File <span class="string">"/home/dell2/anaconda3/envs/ronghe6/lib/python3.6/site-packages/tensorflow/python/client/session.py"</span>, line 1173, <span class="keyword">in</span> _run</span><br><span class="line">    feed_dict_tensor, options, run_metadata)</span><br><span class="line">  File <span class="string">"/home/dell2/anaconda3/envs/ronghe6/lib/python3.6/site-packages/tensorflow/python/client/session.py"</span>, line 1350, <span class="keyword">in</span> _do_run</span><br><span class="line">    run_metadata)</span><br><span class="line">  File <span class="string">"/home/dell2/anaconda3/envs/ronghe6/lib/python3.6/site-packages/tensorflow/python/client/session.py"</span>, line 1370, <span class="keyword">in</span> _do_call</span><br><span class="line">    raise <span class="built_in">type</span>(e)(node_def, op, message)</span><br><span class="line">tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[111,100] = 100 is not <span class="keyword">in</span> [0, 100)</span><br><span class="line"> [[node encoder_1/positional_encoding/embedding_lookup (defined at /home/dell2/LSJ/transformer-master/modules.py:290) ]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Original stack trace <span class="keyword">for</span> <span class="string">'encoder_1/positional_encoding/embedding_lookup'</span>:</span><br><span class="line">  File <span class="string">"train.py"</span>, line 48, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    y_hat, eval_summaries = m.eval(xs, ys)</span><br><span class="line">  File <span class="string">"/home/dell2/LSJ/transformer-master/model.py"</span>, line 176, <span class="keyword">in</span> <span class="built_in">eval</span></span><br><span class="line">    memory, sents1, src_masks = self.encode(xs, False)</span><br><span class="line">  File <span class="string">"/home/dell2/LSJ/transformer-master/model.py"</span>, line 53, <span class="keyword">in</span> encode</span><br><span class="line">    enc += positional_encoding(enc, self.hp.maxlen1)</span><br><span class="line"></span><br><span class="line">  File <span class="string">"/home/dell2/LSJ/transformer-master/modules.py"</span>, line 290, <span class="keyword">in</span> positional_encoding</span><br><span class="line">     outputs = tf.nn.embedding_lookup(position_enc, position_ind)</span><br></pre></td></tr></tbody></table></figure><p>可以追溯到位置编码部分，出现了<code>InvalidArgumentError: indices[111,100] = 100 is not in [0, 100)</code>的错误</p><p>于是在我将超参数maxlen由100改为101，可以正常运行</p><h4 id="参考-1">参考</h4></li><li><p>在rognhe6中安装的tensorflow-gpu：1.14是不支持CUDA10.1版本的，只支持到CUDA10.0版本。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">tf.test.is_gpu_available()</span><br></pre></td></tr></tbody></table></figure><p>输出如下：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pciBusID: 0000:db:00.0</span><br><span class="line">2020-09-13 09:32:43.541828: Could not dlopen library <span class="string">'libcudart.so.10.0'</span>; </span><br><span class="line">dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory;</span><br><span class="line"></span><br><span class="line">False</span><br></pre></td></tr></tbody></table></figure></li></ol><p>可见是不支持目前ubuntu中的CUDA环境，参考了博客，修改如下：</p><p>将<code>cudatoolkit=10.0</code>安装到当前环境下</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install cudatoolkit=10.0</span><br></pre></td></tr></tbody></table></figure><p>问题解决</p><h5 id="参考-2">参考</h5><blockquote><p><a href="https://blog.csdn.net/qq_28193019/article/details/103146116" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/qq_28193019/article/details/103146116</a></p><p><a href="https://zhuanlan.zhihu.com/p/115611908" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/115611908</a></p></blockquote><ol start="3" type="1"><li>可以继续跑实验，可以用GPU，但是还是出现了一些问题</li></ol><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Resource exhausted: OOM when allocating tensor with shape[1024,98,64] and <span class="built_in">type</span> <span class="built_in">float</span> on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc</span><br></pre></td></tr></tbody></table></figure><p>显示内存不够，于是我将batch_size从128改为32 ，可以正常运行了</p><p>或者可以考虑使用多个GPU呢？</p><h5 id="参考-3">参考</h5><blockquote><p><a href="https://blog.csdn.net/Will_Ye/article/details/89878588" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/Will_Ye/article/details/89878588</a></p><p><a href="https://blog.csdn.net/Will_Ye/article/details/89878588" target="_blank" rel="noopener">OOM ResourceExhaustedError 的完美解决方法</a></p></blockquote><h3 id="section-7">2020-09-13</h3><p>transformer-mas训练部分已经跑了8个epoch，只用了一个GPU，跑的有点慢，于是暂停，以后再跑。</p><p>开始跑test.py文件，但是在跑的时候，<code>TypeError: stat: path should be string, bytes, os.PathLike or integer, &gt; not NoneType</code></p><p>路径写的不对，在ckpt中添加路径即可</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录在跑实验的一些配置以及遇到的问题解决，保持更新
    
    </summary>
    
    
    
      <category term="故障排除" scheme="http://yoursite.com/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4/"/>
    
  </entry>
  
  <entry>
    <title>2020-09-06-学习工作杂记</title>
    <link href="http://yoursite.com/2020/09/06/2020-09-06-%E5%AD%A6%E4%B9%A0%E5%B7%A5%E4%BD%9C%E6%9D%82%E8%AE%B0/"/>
    <id>http://yoursite.com/2020/09/06/2020-09-06-%E5%AD%A6%E4%B9%A0%E5%B7%A5%E4%BD%9C%E6%9D%82%E8%AE%B0/</id>
    <published>2020-09-06T06:38:39.000Z</published>
    <updated>2020-09-19T14:02:42.167Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言">前言</h3><p>多做总结，提高效率，不要拖延</p><h3 id="怎样从熬夜中恢复过来">怎样从熬夜中恢复过来</h3><p>1． 不要打盹，5min不能够得到休息</p><p>2． 吃早餐 一个小时内吃早餐（全谷物和蛋白质） ，可以充满活力，认知能力可以提高，最好不摄入糖，会让人发困</p><p>3． 出去走。自然光可以让身体发热</p><p>4． 开始办公时候，喝一杯咖啡</p><p>5． 工作：首先完成最困难的部分，最开始的几个小时是一天中效率最高的时候</p><p>6． 会议之前可以喝一杯咖啡，有效时间是半小时</p><p>7． 午饭不吃过多的糖，会犯困</p><p>8． 下午可以喝一杯咖啡这时候是最困的时候。三点之后不能摄入咖啡，有效时间7 小时</p><p>9． 下午可以做一下简单的事情</p><h3 id="在家寝室学习">在家&amp;寝室学习</h3><ol type="1"><li><p>行为影响态度。换掉睡衣，接近类似学校的状态。希望自己成为什么样子， 就穿成什么样子</p></li><li></li></ol><p><img src="https://i.loli.net/2020/09/06/QDutkAwlLGgKTBo.png"></p><ol start="3" type="1"><li>先做一道题再说。（计划太多，无从下手。过分犹豫）不要想太多，直接动手</li></ol><p><img src="https://i.loli.net/2020/09/06/CerZI164jAU85qO.png"></p><ol start="4" type="1"><li>拒绝含糖食物</li></ol><p>自控力需要能量的供给，学习前可以吃块糖，可以补充能量。但是减少高gi食物，如酸奶果汁薯片，或者碳水类食物（米饭面条土豆）。多吃瘦肉、蔬菜、水果，能够增强自控力，还能瘦</p><ol start="5" type="1"><li><p>不要用时间做计划，用学习量做计划。（因为会拖延）拒绝整点学习、计划学习时间，采用今天背多少单词等，一个清晰明确的目标会事半功倍</p></li><li><p>保持工作区的整洁，不放无关的物品。使手机飞行模式、黑白模式</p></li></ol><p><img src="https://i.loli.net/2020/09/06/UO5JydTCmLIKa12.png"></p><h3 id="戒掉手机避免用意志力来克制">戒掉手机（避免用意志力来克制）</h3><p>1． 替代法 并不是真正想做，而是习惯了某种行为。可以买一个手机模型，终止大脑的无意识行为，给大脑一个选择的机会</p><p>2． 心理暗示。‘我不玩手机‘ 而不是’我不能玩手机‘</p><p>3． 优化环境。环境的影响很大。搭建一个良好的环境。睡觉前把手机放在客厅，学习时增加获得手机的难度</p><p>4． 负面反馈。人们对于损失和负面事件的敏感度高于正面事件的敏感</p><p>5． 看实时学习视频，看到别人学习 自己也不好意思玩</p><p>休息放空自己，会使得注意力更集中</p><p>把社交软件放在小文件夹里再放到手指不容易碰到的地方，如果一段时间又习惯了点这个位置的社交软件，就再更换桌面排布</p><h3 id="自己习惯">自己习惯</h3><p>对于我自己来说，习惯睡觉前进行一些文字记录的工作，比如写博客做总结，就是不会再去接触一些新知识。把第二天要做的事情列好，或者直接找好第二天最难工作内容的参考资料，对第二天工作内容有一个大概的印象，这样第二天一早就可以直攻克艰难的部分，避免其它琐碎的事情</p><p>起床的时候，提前找好第二天要穿的衣服，同时可以适量补充水分</p><p>在进行学习的时候，先设置5分钟，休息5分钟，再逐渐增加时间，进入状态，多学习时间不休息</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      之前看的一个b站up主关于如何高效学习的视频，觉得受到了启发，于是记录了下来，以此找到更适合自己的学习习惯
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-09-06-不确定性研究</title>
    <link href="http://yoursite.com/2020/09/06/2020-09-06-%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%A0%94%E7%A9%B6/"/>
    <id>http://yoursite.com/2020/09/06/2020-09-06-%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%A0%94%E7%A9%B6/</id>
    <published>2020-09-05T16:06:55.000Z</published>
    <updated>2020-09-07T09:05:00.433Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言">前言</h3><p>近日，旷视上海研究院长危夷晨在将门技术社群做了一次题为《Uncertainty Learning for Visual Recognition》(不确定性学习在视觉计算中的应用) Online Talk，共分为4个部分：</p><ol type="1"><li>Preliminary（基础知识）</li><li>Uncertainty in Deep Learning（深度学习中的不确定性问题）</li><li>Uncertainty in Computer Vision（不确定性的计算机视觉应用）</li><li>Summary（总结）</li></ol><p>我主要参考了前三部分的内容</p><h3 id="基础知识">基础知识</h3><h4 id="何为不确定性估计">何为不确定性估计</h4><p>要理解何为不确定性估计，我们可以先从<strong>确定性预测（deterministic prediction）</strong>开始。假设要对两张人脸进行对比，验证是否是同一个人的照片，那么可以使用人脸识别系统分别对这两张人脸图片提取特征，并使用某种度量指标衡量所提取的两个特征的相似程度，根据所预测出的相似程度来判断两张人脸图像是否从属同一个人。如果相似度很高（比如95%），则可以判断这两张人脸属于同一个人。这种通过预测一个确定性的人脸特征用来判断的方式被称为确定性预测（deterministic prediction）。</p><p>然而这个<strong>相似度分数并不总是有效</strong>，以下图中第二个例子为例，可以看到在输入图像中，一张非常清晰，另一张十分模糊，然而这个时候人脸识别系统依然给二者打出很高的相似度分数，那么面对这种情况，我们是否要相信系统给出的答案，我们是否有办法来判断系统给出这个分数的可靠程度？</p><p>为此，人们提出了另一个<strong>辅助判断的指标</strong>，即判断机器给出的答案是否可信，可信程度多少的分数被称为<strong>confidence score（置信度分数）</strong>。如下图第二行中，系统给出相似度95%，然而confidence score却只有10%，表明<strong>系统给出的相似度分数的可信度很低，因此我们在采纳系统给出的这个判断答案的时候需要十分谨慎。</strong></p><p>从这个案例可以知道，<strong>在confidence score分数背后存在一个核心思想，即很多时候机器学习系统给出的判断不一定是靠谱的，即，系统对于给出的判断具有一定程度的“不确定性”。</strong>那么此时人们就需要知道系统给出这个判断到底有几成把握，因此我们需要诸如置信度分数或者“不确定性”分数这样的额外信息来帮助我们做出更好的决策。</p><p><img src="https://i.loli.net/2020/09/06/xBqNOnrsRiM7o85.jpg" alt="img"></p><h4 id="为何不确定性重要">为何不确定性重要</h4><p>上面介绍完之后，我们再来谈谈它为什么重要。简单来讲，不确定性估计在深度学习之中有着广泛的应用场景，为其落地发挥着不可替代的重要作用，下面讲一些比较要代表性的场景：</p><ol type="1"><li><strong>高风险应用场景</strong>。这类场景<strong>需要非常精确的估计</strong>，因为一旦估计错误，可能出现严重的后果，例如医疗图像诊断、自动驾驶。</li><li><strong>大量机器学习场景</strong>。比如，在主动学习（Active Learning）这种技术框架中，模型需要确定哪些样本更值得被打标签。这也涉及到系统对于估计样本“价值程度”不确定性。同时，研究人员往往也会发现单纯使用机器学习系统进行判断时，会存在少量样本系统无法做出很好的判断，因此这时人们会邀请专家来标记这部分困难样本，以训练模型。</li><li><strong>强化学习</strong>。强化学习由于经常要权衡exploration和exploitation操作，因此如何确定每一台机器的概率分布是否被准确估计，就是对这台机器模型参数的不确定性估计。</li><li><strong>对处于训练数据分布之外情况的检测</strong>。由于很多时候测试数据并不在训练数据中，因此如果测试数据超出了训练数据的数据分布，那这样的预测是没有准确度可言的，这时候就需要一个额外的不确定性估计来确认对当前的预测有多大把握。</li></ol><h4 id="两种不确定性">两种不确定性</h4><p>接下来，我们界定一下不确定性的分类问题。一般来讲，不确定性可以分为两类：</p><ol type="1"><li><strong>数据的不确定性</strong>：也被称为偶然（Aleatoric）不确定性，它描述的是<strong>数据中内在的噪声，即无法避免的误差，这个现象不能通过增加采样数据来削弱。</strong>例如有时候拍照的手稍微颤抖画面便会模糊，这种数据是不能通过增加拍照次数来消除的。因此解决这个问题的方法一般是提升数据采集时候的稳定性，或者提升衡量指标的精度以囊括各类客观影响因素。</li><li><strong>模型的不确定性</strong>：也被称为认知（Epistemic）不确定性。它指出，<strong>模型自身对输入数据的估计可能因为训练不佳、训练数据不够等原因而不准确，与某一单独的数据无关</strong>。因此，认知不确定性测量的，是训练过程本身所估计的模型参数的不确定性。这种不确定性是可以通过有针对性的调整（增加训练数据等方式）来缓解甚至解决的。</li></ol><h3 id="深度学习中的不确定性问题">深度学习中的不确定性问题</h3><p><strong>如果单看深度学习网络本身，它是确定性的，例如简单的多层前馈网络，在训练好以后，其结构、权重以及对某一个样本所输出类别的概率都是确定的。因此，在深度神经网络中引入不确定性的一个方法就是引入贝叶斯法则，从而得到贝叶斯神经网络（BNN）。</strong></p><p>简单而言，如下图，贝叶斯神经网络的<strong>权重不像普通神经网络是一个具体数值，而是一个概率分布，表示每一个权重w遵循一个分布，而非之前是一个确定的数值</strong>。因此在训练和推理中，网络的权重会变化，<strong>根据分布来随机采样</strong>。通过这种方法可以建模各个参数本身存在的不确定性。</p><p><img src="https://i.loli.net/2020/09/06/6IRjbGw4cfT8mSB.jpg" alt="img"></p><p>然而，由于在实际应用中参数量十分巨大，要严格根据贝叶斯公式计算后验概率几乎不现实，因此为了将网络应用于大型数据集，就<strong>需要高效的近似计算方法</strong>。早期比较有名的方法是通过马尔科夫链蒙特卡洛采样法（MCMC-sampling）来逼近假定的参数分布，但是由于这种方法很慢，因此发展出了一系列更好的<strong>近似计算后验概率</strong>的方法，如下：</p><h4 id="变分推断">变分推断</h4><p>变分推断的基本方法就是<strong>引入变分分布对BNN优化过程中涉及到的后验概率进行近似估计，这种方法较为高效。</strong></p><p><img src="https://i.loli.net/2020/09/06/nQzKO2i1PYNkvuU.jpg"></p><h4 id="dropoutbnnvi">Dropout=BNN+VI</h4><p><img src="https://i.loli.net/2020/09/06/aQRWjzwDKIJl6eL.jpg" alt="img"></p><p>这种<strong>dropout方法</strong>也称为蒙特卡洛dropout，进一步简化了对后验概率分布的近似计算，它认为常见的dropout技术实际上等于在贝叶斯网络中进行变分推断。通过上图的对比，我们可以直观理解标准神经网络经过dropout之后，在每一层随机取消一些神经元，把连接变稀疏的网络是什么样子。</p><p>可以证明，<strong>在假设每一个神经元都服从一个离散的伯努利分布的情况下，经dropout方法处理的神经网络的优化过程实际上等价于在一个贝叶斯网络中进行变分推断。</strong>由于这种结构中每个节点的权重是被多个子网络共享的，因此它的训练和推理相对高效。这项理论成果近年来得到了较多的应用。</p><p>我们在前向传播的时候，让某个神经元的激活值以<strong>一定的概率p停止工作</strong>（每一个批次都是随机），这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征。</p><p><strong>dropout掉不同的隐藏神经元就类似在训练不同的网络，随机删掉一半隐藏神经元导致网络结构已经不同，整个dropout过程就相当于对很多个不同的神经网络取平均。而不同的网络产生不同的过拟合，一些互为“反向”的拟合相互抵消就可以达到整体上减少过拟合。</strong></p><h5 id="dropout具体工作流程">Dropout具体工作流程</h5><p>假设我们要训练这样一个神经网络，如图所示。</p><p><img src="https://i.loli.net/2020/09/06/SetbpsjYxEX1yQZ.jpg" alt="标准的神经网络"></p><p>输入是x输出是y，正常的流程是：我们首先把x通过网络前向传播，然后把误差反向传播以决定如何更新参数让网络进行学习。使用Dropout之后，过程变成如下：</p><p>（1）首先<strong>随机（临时）</strong>删掉网络中一半（dropout=0.5时）的隐藏神经元，输入输出神经元保持不变（图中虚线为部分临时被删除的神经元）</p><p><img src="https://i.loli.net/2020/09/06/GnirX4u39lSmyUg.jpg" alt="部分临时被删除的神经元"></p><p>（2） 然后把输入x通过修改后的网络前向传播，然后把得到的损失结果通过修改的网络反向传播。一小批训练样本执行完这个过程后，在<strong>没有被删除的神经元上</strong>按照随机梯度下降法更新对应的参数（w，b）。</p><p>（3）然后继续重复这一过程：</p><ul><li><strong>恢复被删掉的神经元</strong>（此时被删除的神经元保持原样，而没有被删除的神经元已经有所更新）</li><li>从隐藏层神经元中<strong>随机选择</strong>一个一半大小的子集临时删除掉（备份被删除神经元的参数）。</li><li>对一小批训练样本，先前向传播然后反向传播损失并根据随机梯度下降法更新参数（w，b） （没有被删除的那一部分参数得到更新，删除的神经元参数保持被删除前的结果）。</li></ul><p>不断重复这一过程。</p><h5 id="参考">参考</h5><blockquote><p><a href="https://zhuanlan.zhihu.com/p/38200980" target="_blank" rel="noopener">深度学习中Dropout原理解析</a></p></blockquote><h4 id="模型融合">模型融合</h4><p>这也是一种进行不确定性估计的基本方法，其大致思路是，<strong>从一个数据集中进行多次随机采样，分别训练模型，然后再将这些模型的推理结果综合，其均值作为预测结果，方差作为预测的不确定性。</strong>另外需要强调的是，蒙特卡洛dropout可以认为是一种特殊的模型融合方法。</p><p><img src="https://i.loli.net/2020/09/06/noXFIR2ACtwpmk1.jpg" alt="img"></p><h3 id="回归问题中的数据不确定性">回归问题中的数据不确定性</h3><p>这是一种数据估计的标准做法。<strong>给定输入x_i，解一个函数f(x_i)，使得它逼近ground truth y_i。假设这个函数f(x_i)遵循一个高斯分布，那么其均值就是y_i，方差就是σ（也依赖于x_i）。</strong></p><p><strong>这时，如果对这个高斯分布取似然度，再取负的log值，那么就可以得到下图中的损失函数L。因此在优化的时候，除了希望优化f(x_i)逼近y_i，同时也需要优化σ(x_i)，它表示这个高斯分布的不确定性，σ越大越不确定。</strong></p><p>因此当f很容易逼近y的时候，那么公式中第一项L2范数就会很小，这时即便σ也小，但结果依然不会很大；当f很难逼近y，即f很难学习的时候，第一项中的L2范数就会很大，这时优化过程就会使得σ也变大，从而使得整个第一项减小，因此学到的σ会随着数据学习的难度做自我调整。</p><p><img src="https://i.loli.net/2020/09/06/nlD62kW1pXygAV4.jpg" alt="img"></p><h4 id="简单例子">简单例子</h4><p>我们借助一个直观例子来理解模型不确定性与数据不确定性。首先这里的<strong>ground truth函数为一个正弦函数</strong>，即图中橙色的点是测试数据，而<strong>训练数据是从[-5，+5]区间采样的蓝色点，研究人员对每一个蓝色点都添加了高斯噪声，因此可以看到这些蓝色点明显偏离ground truth。</strong></p><p>下方左图是用贝叶斯网络加dropout进行的<strong>模型不确定性估计</strong>。<strong>红色曲线为估计出来的预测值，延其上下分布的黄色面积则为每一个点对应的方差</strong>。在进行模型不确定性估计时，系统会对每个输入点估计多次，每次会随机采样模型的权重，以求出对每个输入点多次预测所得到的均值和方差。可以发现，蓝色点区域之外的部分预测的方差很大，这是因为模型没有见过这样的数据。（<strong>因为蓝色是训练数据</strong>，其它是测试数据，没见过的，所以方差就会较大，也就是不确定性较高）</p><p>下方右图中红色曲线为估计出来的预测值，是<strong>数据不确定性估计</strong>，曲线上下的黄色跨度就是每一个点通过数据不确定性估计方法所学出的方差。可以发现，原本输入数据中有噪声的部分，其预测出的方差比较大，反映出模型对这样的输出拥有较大的不确定性。</p><p><img src="https://i.loli.net/2020/09/06/EjFQnPko6pVhYH5.jpg" alt="img"></p><h3 id="不确定性的计算机视觉应用">不确定性的计算机视觉应用</h3><p><img src="https://i.loli.net/2020/09/06/Gw6pNAvuisDe18a.png" alt="img"></p><p>尽管不确定性在机器学习中已经有很长历史，但是直到2017年（就我所知）随着NeurlPS论文<em>What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision</em>的提出，它才开始真正应用在基于深度学习的视觉预测任务中。这篇论文本身没有太多方法创新，通过将已知的方法 用于语义分割与深度回归任务，取得了不错的结果。<strong>通过在模型中引入不确定性估计的已有理论成果，使得原本任务的精度得到了显著提升。</strong></p><p>通过论文给出的定性结果可以较为直观的理解模型不确定性和数据不确定性。如下图，系统估计出来的不确定性是有明确含义即很容易理解的，图中上半部分做语义分割，下半部分做深度估计。</p><p><img src="https://picb.zhimg.com/80/v2-cf9cf0d7715af33b38dc8fa8b71b8aa0_1440w.jpg" alt="img"></p><p><strong>整张图的第4、5列分别是数据不确定性和模型不确定性的结果。红色部分表示不确定程度较大，蓝色部分表示较为确定。从数据不确定性结果（第4列）可以看到，红色部分往往出现在物体边界处，表示这些区域的像素更加具有二义性，系统不太清楚这部分像素究竟属于前景还是背景，另外这部分信息在训练数据中（即ground truth）往往也较模糊。可以发现，系统给出的数据不确定结果符合人类直观理解。</strong></p><p><strong>从模型不确定性结果（第5列）可以看到，模型对出现人的部分给出了很高的不确定性，这是因为模型在训练中很少遇到人的数据，因此模型很难估计出人所处位置的深度，将该区域标记为高度不确定。</strong></p><h4 id="物体检测中的数据不确定性">物体检测中的数据不确定性</h4><p><img src="https://i.loli.net/2020/09/06/RrKDqx7kFG8mJyl.jpg" alt="img"></p><p>在物体检测任务中，很大一部分不确定性来源于标注数据的不确定。上图给出了几个典型例子，可以看到，在标注边界框的时候，由于存在各种物体角度、遮挡，所以往往很难评价一个边界框标注的好坏。由于标注规则不一、数据本身存在的各种不确定性，因此具有二义性的数据标注会导致具有二义性的学习结果，从而将不确定性引入了模型，进一步输出结果也是不确定的。</p><p>针对这个问题，有研究人员在CVPR 2019、ICCV 2019提出了两篇颇有价值的论文，其核心思想类似，将每一个边界框的4个坐标均认为呈高斯分布，然后分别估计其均值和方差。用上述介绍的数据不确定性回归公式来替代传统的L1损失，将原来所需要预测的4个变量扩充为8个变量。</p><p>因此，这种方法除了可以估计边界框每一个坐标之外，还让它们都带有了一个不确定性参数。利用这些不确定性数据，可以进一步做很多事情（比如在NMS中作为权重来对边界框位置进行投票）。</p><h4 id="人脸识别中的模型不确定性">人脸识别中的模型不确定性</h4><p><img src="https://i.loli.net/2020/09/06/nWDBsXI2dNfaHTV.jpg" alt="img"></p><p>对于在人脸识别任务中如何估计模型不确定性，推荐大家上图中的论文工作，其核心思想是，将BNN+dropout用到人脸识别任务中，如图所示，dropout层（红色）被加在每一个卷积block之后，从而构建了一个蒙特卡洛Dropout网络。在训练过程中，每当流程到达这些层的时候，就会随机丢掉一些神经元，从而实现模拟参数分布的效果。在测试过程中，每一个图像都会经过该网络多次，进而可以多这些结果估计均值与方差，将方差作为预测结果的不确定性。</p><h4 id="人脸识别中的数据不确定性pfe方法">人脸识别中的数据不确定性：PFE方法</h4><p><img src="https://i.loli.net/2020/09/06/qPMvAkWN1UHK2e9.jpg" alt="img"></p><p>PFE方法全称为Probabilistic Face Embeddings，其核心思想是用概率分布来替代传统确定的人脸嵌入特征。传统的方法会将输入图像映射到一个高维空间中，得到一个表示特征的向量，然而对于这些方法而言，输出的向量都是确定的，因此被称为deterministic embedding。PFE引入了不确定性，将输出向量认为是一个概率分布，而不再是一个确定的向量，它有一个均值μ、方差σ。</p><p>均值代表对图像的嵌入，方差描述了模型对输入数据的不确定性。该方法希望同时估计μ和σ，并且σ能够根据输入图像的质量、包含噪声的程度进行自适应的学习。在上图右方的示例中可以看到，每一个输出的特征z不再是一个点，而是一个高斯形状的概率分布（椭圆），椭圆的大小就描述了估计的不确定性。</p><p><img src="https://i.loli.net/2020/09/06/O8mvS1VTIHodxZ5.png" alt="img"></p><p>从具体实现方法来看，PFE的创新值得借鉴，它并不直接去估计每一个均值μ，而是通过一个事先已经训练好的人脸识别模型来抽取每个样本的特征μ_i，然后研究人员再在网络中加入一个小分支，来对每个样本输出一个方差（比如假设μ_i是一个512维的向量，那么此时也会输出一个对μ_i的每一维度单独估计方差的512维方差向量）。</p><p>进一步，论文提出了一种新的metric——mutual likelihood score（MLS），来衡量两个分布间的距离。上图公式中x_i和x_j是两个样本在特定空间中的高斯分布，两个分布所得到的MLS数值就代表了其相似度。在训练过程中，针对所有positive 样本，计算负的MLS数值作为损失，并最小化该损失目标函数，进而可以估计新增加分支（估计方差的分支）的参数。</p><p><img src="https://picb.zhimg.com/80/v2-b2a72843a1b2199fb213df0e93e9d570_1440w.jpg" alt="img"></p><p>上图是论文对方差的解释，较为直观。可以发现红框标注出来的（方差超过一定阈值）图片都是姿态有较大变化、模糊、或者有遮挡的图片，系统都认为它们识别起来有较大不确定性；而正面、高清的图片不确定性普遍较小。为了进一步验证学习出来的不确定性是否能够有效解释图像质量，PFE在下方左图中进行了有关在低质量图像之间使用传统cosine相似度计算是否可靠的研究。</p><p>研究人员对清晰图片添加了不同程度的噪声，蓝色线代表原图与模糊图之间的相似度分数，而红色代表两张来自不同ID的图随模糊程度的增加所计算的相似度。可以发现对于同一ID（蓝线），随着模糊程度增加，相似度也逐渐降低；而对于不同ID，随着模糊程度增加相似度却在增加。这说明依据该相似度可能会将两张来自不同ID的模糊图像错认为是同一张图。这一现象在其它很多论文中也同样被观测到。</p><p><img src="https://picb.zhimg.com/80/v2-e38487eb964f4dc56b7ba89689ea5158_1440w.jpg" alt="img"></p><p>然而在经过PFE论文提出的MLS相似度修正之后，情况得到了很大改善。如右图，当图片模糊度增加时，对同样ID的图来说，其相似度没有变得太小，而不同ID图像的相似度也没有变得太大。这个实验证明这种计算图像相似度的新metric在面对低质量图片时更加鲁棒。</p><h4 id="pfe方法的缺陷">PFE方法的缺陷</h4><p>虽然PFE方法取得了重要进展，但是缺点也很明显，因为它并没有学习身份特征（identity-feature），每一个identity的特征嵌入是确定的，PFE只是增加了一个估计方差的小网络分支，这导致必须用一个新的metric（即MLS）来计算所有样本对的距离。而使用MLS这个度量函数带来的缺陷在实际工业应用中是代价较高的：第一，我们需要额外存储方差向量；第二，相比传统的余弦相似度，MLS相似度的计算资源消耗也更大。</p><p>受此启发，我们团队在投递给CVPR 2020的新论文中不仅做到了估计方差，同时也能更新每个样本的特征。下图为传统方法、PFE与我们团队方法的对比。</p><p><img src="https://i.loli.net/2020/09/06/pYSInMZ9R64euEC.jpg" alt="img"></p><p>可以发现，在图（a）中，虚线框出的蓝色椭圆代表一个类别，圈外存在一个正样本和负样本，而对于传统相似度计算方法来说，很难将负样本和正样本区分开来；而（b）中PFE方法对每个样本估计了一个分布，在带有分布的特征表示下，利用MLS就能够有效将正样本和负样本区分开来，但是PFE中正负样本本身是确定的；在（c）中，我们团队方法能够在估计正负样本方差的同时，也让特征本身修正得更好。</p><p><img src="https://i.loli.net/2020/09/06/ayVXfSxm1DYk5dG.png" alt="img"></p><p>上图是三种方法的对比，可以看到在最后计算相似度的时候，由于特征本身经过了调整，只需要使用cosine相似度来计算两个均值向量就可以得出答案。具体而言，我们团队提出了两种实现方法，如下：</p><h3 id="法1从头学习一个分类模型"><strong>法1：从头学习一个分类模型</strong></h3><p><img src="https://i.loli.net/2020/09/06/yZWVciHGd8bwK74.jpg" alt="img"></p><p>这种方法的主要部分与通用识别模型的结构一致，区别在于，在输出特征的位置，我们让模型输出一个有关每个样本特征的均值μ，以及一个方差σ。进一步，对于每个样本的每一次迭代而言，都随机采样一个ε（如上图最下方）。</p><p>通过这种方式得到的新样本特征s_i就是遵从均值μ、方差为σ的高斯分布采出的值，它可以模拟一个服从高斯分布的特征。通过这种简单的重新采样的技巧，就可以很好进行模型训练。在测试的时候不再需要采样，仅需要将已经得到的均值μ作为特征来计算相似度即可。</p><p><img src="https://i.loli.net/2020/09/06/8PcKyqBlErgUQAm.png" alt="img"></p><p>该方法的损失函数除了包含softmax以及其一切合理变种之外，还有一个KL损失，它使得每一个学出来特征的分布尽可能逼近单位高斯分布。这个损失项的引入来自于2016年一篇名为<em>Deep variational information bottleneck</em>的论文。进一步整个损失函数就可以用标准SGD方法来优化。下图解释了整个损失函数中softmax与kl损失是如何起到平衡的作用的。</p><p><img src="https://i.loli.net/2020/09/06/9wxoyQuj8M2AWem.jpg" alt="img"></p><h3 id="法2从现有模型出发学习回归模型"><strong>法2：从现有模型出发学习回归模型</strong></h3><p><img src="https://i.loli.net/2020/09/06/k8rDhcJY5ZaMQnU.jpg" alt="img"></p><p>这种方法假设输出的特征μ遵循高斯分布，目的是让它逼近期望的特征w。与PFE类似，假设输入的模型已经固定，且输出的特征μ属于类别c，则让μ逼近这个类别c的特征中心w_c（w_c来自事先训练好的人脸分类模型）。这种方法适用于当已经有一个训练好的模型，但依然希望做不确定性估计的情况。相对于PFE而言，它多做了样本特征的学习。下图解释了该损失函数中σ起到的平衡作用。</p><p><img src="https://i.loli.net/2020/09/06/3qWYVXC4QIx1vh8.png" alt="img"></p><p><strong>实验结果：</strong>在三种损失函数上的对比测试结果显示，我们团队提出的分类方法（HUM_cls）在最困难的数据集IJB-C（具有大量模糊、噪声图像）上效果最佳；在LFW、CFP-FP、YTF这些较成熟的数据集上我们提出的两种方法同其他方法区别不大；在较困难的MegFace(R1)数据集上我们团队的分类方法效果最佳。</p><p><img src="https://i.loli.net/2020/09/06/9e3k4ImOhET5Wgo.jpg" alt="img"></p><p>下图展示了在三种数据集上学习出来的方差分布情况，展示了位于不同方差位置的图像的样子。</p><p><img src="https://i.loli.net/2020/09/06/81X3Pk4o9IHZTxE.jpg" alt="img"></p><p>进一步，我们团队使用了ResNet-64作为backbone（与PFE的SOTA模型backbone深度一致），来将本文方法同SOTA方法在最困难的数据集IJB-C上进行性能对比，结果显示在每一个指标上我们团队方法均实现了领先。为了测试本文方法对噪声信息干扰的鲁棒性，团队对图片人工施加了高斯噪声（从0到40%），可以发现，当噪声越明显的时候，本文引入的不确定估计方法的优越性也约高。</p><p><img src="https://i.loli.net/2020/09/06/4VLqFkPgIvaYSm2.jpg" alt="img"></p><h4 id="section"></h4><h3 id="参考-1">🚀参考</h3><blockquote><p><a href="https://zhuanlan.zhihu.com/p/95774787" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/95774787</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      深度学习模型的不确定性估计，摘自几篇不错的博客
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-09-05-知识点杂</title>
    <link href="http://yoursite.com/2020/09/05/2020-09-05-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%9D%82/"/>
    <id>http://yoursite.com/2020/09/05/2020-09-05-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%9D%82/</id>
    <published>2020-09-05T11:56:22.000Z</published>
    <updated>2020-09-13T01:04:19.992Z</updated>
    
    <content type="html"><![CDATA[<h3 id="对数似然">对数似然</h3><p>最大化对数似然，因此值越大越好。例如，对数似然值 -3 比 -7 好。</p><p>对数为负值是完全可能的，如下图log函数</p><p><img src="https://i.loli.net/2020/09/12/UFihCbxJk9gBfuz.png" alt="对数- 维基百科，自由的百科全书" style="zoom: 33%;"></p><h3 id="高斯分布中考虑对数似然而不是似然">高斯分布中考虑对数似然而不是似然</h3><p>通过最大似然函数来确定高斯分布中未知参数的值，实际上，<strong>最大化似然函数的对数更方便</strong>。因为对数是其论证的单调递增函数，函数的对数的最大化等价于函数本身的最大化。logaithm不仅简化了后续的数学分析，而且还有助于数学计算，<strong>因为大量小概率的乘积很容易使计算机的数值精度下降，但是log就可以通过计算总和来解决</strong>。</p><ol type="1"><li>当要计算随机变量的joint likelihood时很有用，他们之间独立，并且分布相同。</li></ol><p><img src="https://i.loli.net/2020/09/12/jAqSrXz7v39mE2p.png" alt="image-20200905213103449"></p><p>联合概率是所有点的概率的乘积：</p><p><img src="https://i.loli.net/2020/09/12/2sf4RyCm7IVxFpt.png" alt="image-20200905213136550"></p><p><strong>如果是log，则只需要求和即可</strong></p><ol start="2" type="1"><li>由于是<strong>高斯分布</strong>，使用log避免了计算指数</li></ol><p><img src="https://i.loli.net/2020/09/12/pbN4OgBAyoEWv2Y.png" alt="image-20200905213239871"></p><p>可以写成：</p><p><img src="https://i.loli.net/2020/09/12/YHpEnC951eJfvkj.png" alt="image-20200905213249229"></p><ol start="3" type="1"><li>ln x是单调递增的函数，因此log-likelihood和likelihood有相同的关系</li></ol><p><img src="https://i.loli.net/2020/09/12/1NHzhmdvcIZEkQl.png" alt="image-20200905213303446"></p><p><strong>负对数似然</strong>是一种用于解决分类问题的 损失函数 ，它是似然函数得一种自然对数形式，可用于测量两种概率分布之间的相似性，其取负号是为了让最大似然值和最小损失相对应，是最大似然估计及相关领域的常见函数形式。</p><p>机器学习中，习惯用优化 算法 求最小值，因此会用到负对数似然，这是分类问题中的常见的损失函数，且能拓展到 多分类 问题。</p><h3 id="负对数似然和似然估计">负对数似然和似然估计</h3><p><strong>负对数似然</strong>是一种用于解决分类问题的 损失函数 ，它是似然函数的一种自然对数形式，可用于测量两种概率分布之间的相似性，其取负号是为了让最大似然值和最小损失相对应，是最大似然估计及相关领域的常见函数形式。</p><p>机器学习中，习惯用优化 算法 求最小值，因此会用到负对数似然，这是分类问题中的常见的损失函数，且能拓展到 多分类 问题。</p><h3 id="最大似然估计">最大似然估计</h3><blockquote><p><a href="https://zhuanlan.zhihu.com/p/32803109" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/32803109</a></p></blockquote><h3 id="epochiterationbatch_size">Epoch、Iteration、Batch_size</h3><p><a href="https://blog.csdn.net/program_developer/article/details/78597738" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/program_developer/article/details/78597738</a></p><h3 id="tf.tile用法">tf.tile()用法</h3><p><a href="https://blog.csdn.net/tsyccnh/article/details/82459859" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/tsyccnh/article/details/82459859</a></p><h3 id="dataset-api-和-iterator">Dataset API 和 Iterator</h3><p>Dataset API 和 Iterator</p><p><a href="https://blog.csdn.net/briblue/article/details/80962728" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/briblue/article/details/80962728</a></p><p>TensorFlow中的Dataset API</p><p><a href="https://blog.csdn.net/dqcfkyqdxym3f8rb0/article/details/79342369" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/dqcfkyqdxym3f8rb0/article/details/79342369</a></p><p>TensorFlow data模块详解</p><p><a href="https://www.weaf.top/posts/cd5ba0c4/" target="_blank" rel="noopener" class="uri">https://www.weaf.top/posts/cd5ba0c4/</a></p><p>使用Tensorflow的DataSet和Iterator读取数据</p><p><a href="https://www.jianshu.com/p/bcff8a99b15b" target="_blank" rel="noopener" class="uri">https://www.jianshu.com/p/bcff8a99b15b</a></p><p>tensorflow数据读取机制（附代码）</p><p><a href="https://zhuanlan.zhihu.com/p/27238630" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/27238630</a></p><p>Dataset API入门教程</p><p><a href="https://zhuanlan.zhihu.com/p/30751039" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/30751039</a></p><p>Dataset.from_generator</p><p><a href="https://blog.csdn.net/foreseerwang/article/details/80572182" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/foreseerwang/article/details/80572182</a></p><p>看个简单的示例：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#创建一个Dataset对象</span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices([1,2,3,4,5,6,7,8,9])</span><br><span class="line"></span><br><span class="line">#创建一个迭代器</span><br><span class="line">iterator = dataset.make_one_shot_iterator()</span><br><span class="line"></span><br><span class="line">#get_next()函数可以帮助我们从迭代器中获取元素</span><br><span class="line">element = iterator.get_next()</span><br><span class="line"></span><br><span class="line">#遍历迭代器，获取所有元素</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">   for i in range(9):</span><br><span class="line">       print(sess.run(element))</span><br></pre></td></tr></tbody></table></figure><p>以上打印结果为：1 2 3 4 5 6 7 8 9</p><p>from_generator</p><p>创建Dataset由其生成元素的元素generator。</p><p>函数形式：from_generator(generator,output_types,output_shapes=None,args=None)</p><p>参数generator:一个可调用对象，它返回支持该iter()协议的对象 。如果args未指定，generator则不得参数; 否则它必须采取与有值一样多的参数args。 参数output_types：tf.DType对应于由元素生成的元素的每个组件的对象的嵌套结构generator。 参数output_shapes:tf.TensorShape 对应于由元素生成的元素的每个组件的对象 的嵌套结构generator 参数args:tf.Tensor将被计算并将generator作为NumPy数组参数传递的对象元组。</p><p>具体例子</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#定义一个生成器</span><br><span class="line">def data_generator():</span><br><span class="line">    dataset = np.array(range(9))</span><br><span class="line">    for i in dataset:</span><br><span class="line">        yield i</span><br><span class="line"></span><br><span class="line">#接收生成器，并生产dataset数据结构</span><br><span class="line">dataset = tf.data.Dataset.from_generator(data_generator, (tf.int32))</span><br><span class="line"></span><br><span class="line">iterator = concat_dataset.make_one_shot_iterator()</span><br><span class="line"></span><br><span class="line">element = iterator.get_next()</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">   for i in range(3):</span><br><span class="line">       print(sess.run(element))</span><br></pre></td></tr></tbody></table></figure><p>以上代码运行结果：0 1 2</p><h3 id="strip-和-split">strip() 和 split()</h3><p><a href="https://blog.csdn.net/hjxu2016/article/details/78676859" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/hjxu2016/article/details/78676859</a></p><h3 id="summary用法--tensorborad可视化">Summary用法 -tensorborad可视化</h3><p><a href="https://www.cnblogs.com/lyc-seu/p/8647792.html" target="_blank" rel="noopener" class="uri">https://www.cnblogs.com/lyc-seu/p/8647792.html</a></p><h3 id="math.ceil">math.ceil()</h3><p><a href="https://www.runoob.com/python/func-number-ceil.html" target="_blank" rel="noopener" class="uri">https://www.runoob.com/python/func-number-ceil.html</a></p><h3 id="format-格式化函数">.format() 格式化函数</h3><p><a href="https://www.runoob.com/python/att-string-format.html" target="_blank" rel="noopener" class="uri">https://www.runoob.com/python/att-string-format.html</a></p><h3 id="tf.shapea-和-a.get_shape.as_list-和-tf.split">tf.shape(A) 和 A.get_shape().as_list() 和 tf.split()</h3><p><a href="https://www.itread01.com/content/1544436557.html" target="_blank" rel="noopener" class="uri">https://www.itread01.com/content/1544436557.html</a></p><p><a href="https://blog.csdn.net/xc_zhou/article/details/85632109" target="_blank" rel="noopener" class="uri">https://blog.csdn.net/xc_zhou/article/details/85632109</a></p><ul><li>tf.shape(A) # 獲取張量A（陣列，list, tensor張量）的大小，返回的是一個list</li><li>x.get_shape()，只有<strong>tensor</strong>才可以使用這種方法，返回的是一個元組</li><li>tf.split(dimension, num_split, input)：dimension的意思就是輸入張量的哪一個維度，如果是0就表示對第0維度進行切割。num_split就是切割的數量，如果是2就表示輸入張量被切成2份，每一份是一個列表。</li></ul><h3 id="tf.range">tf.range()</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w=tf.range(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">print</span> (sess.run(w))<span class="comment">#输出[0 1 2]</span></span><br></pre></td></tr></tbody></table></figure><h3 id="embedding_lookup">embedding_lookup()</h3><p><a href="https://www.jianshu.com/p/7bb87873f89e" target="_blank" rel="noopener" class="uri">https://www.jianshu.com/p/7bb87873f89e</a></p><p><a href="https://www.zhihu.com/question/52250059" target="_blank" rel="noopener" class="uri">https://www.zhihu.com/question/52250059</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录杂乱的知识点
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-09-05-讨论总结</title>
    <link href="http://yoursite.com/2020/09/05/2020-09-05-%E8%AE%A8%E8%AE%BA%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2020/09/05/2020-09-05-%E8%AE%A8%E8%AE%BA%E6%80%BB%E7%BB%93/</id>
    <published>2020-09-05T07:33:34.000Z</published>
    <updated>2020-09-05T07:40:45.081Z</updated>
    
    <content type="html"><![CDATA[<p>研究生阶段想要重点去研究透彻某个知识点，还是要去系统学习。不要只是依赖博客</p><p>博客缺点</p><ol type="1"><li>一般不成体系，比较片面</li><li>不管是翻译外国博客还是自己的总结，由于博主本身的能力，导致在写的时候，都会出现一定的误差，可信度不抵论文和书籍</li><li>讲的不深入</li></ol><p>和师兄讨论了卡尔曼滤波的内容，师兄针对我的问题也给了很好的建议，让我有方向去继续。发现一直以来我对卡尔曼滤波理解的太浅显，不深刻，理解只是停留结合例子理解卡尔曼滤波那五个公式，知道计算过程，但是没有去深入理解来源以及公式的意义，变量的含义等等，没有真正转化为自己的东西 因为卡尔曼滤波是RKN的核心基础，所以必须要深入理解，这样才能更好地运用卡尔曼滤波，也更好地理解模型。 因为融合到transformer中，也要讲清楚为什么融合之后效果好，或者为什么不好，只有将本质讲清楚，去理论分析的时候才有信服力。避免只是简单的拼接。</p><p>为什么这么做，这么做的好处。公式间的逻辑关系， 买了本卡尔曼滤波的书，意义和含义，背景和理论公式一步一步推导</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录讨论后的一些研究方法感想
    
    </summary>
    
    
    
      <category term="研究方法" scheme="http://yoursite.com/tags/%E7%A0%94%E7%A9%B6%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>2020-09-04-transformer直观理解</title>
    <link href="http://yoursite.com/2020/09/04/2020-09-04-transformer%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/"/>
    <id>http://yoursite.com/2020/09/04/2020-09-04-transformer%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/</id>
    <published>2020-09-04T13:16:46.000Z</published>
    <updated>2020-09-05T06:29:00.518Z</updated>
    
    <content type="html"><![CDATA[<h3 id="直观attention-模型">直观“Attention 模型”</h3><p>本文试着从直观的角度解析“Attention模型”，应用场景：原文--译文，具体选择 中文--英文，即在<strong>将中文翻译为英文</strong>这一场景中，直观解析“Attention模型”。</p><h4 id="概括">概括</h4><p>一句中文A翻译为一句英文B主要是完成以下“<strong>两项任务</strong>”：</p><ol type="1"><li><p>理解中文A的意思为X；</p></li><li><p>将意思X用英文表达出来，即英文B；</p></li></ol><p>在用计算机完成以上任务前，需要以下三点“<strong>准备工作</strong>”：</p><ol type="i"><li><p>需要将中文的字和英文的单词转换为计算机可以理解（计算）的数（即一个字/单词对应转换为一个向量，称为字向量/单词向量），然后计算机才有可能完成以上两项任务，实现翻译； <code>单词-&gt;单词向量</code></p></li><li><p>另外针对一句中文翻译为一句英文，每个字在句子中的位置也对意思的表达会产生很大的影响，所以每个字在句子中的位置也要定义一个向量来表达（即一个位置对应转换为一个向量，称为位置向量）； <code>位置向量</code></p></li><li><p>将字向量/单词向量加上位置向量（定义两种向量的维度相同，如都是512维，便于此处元素相加），能更好更全面的代表这句话，为更好的翻译做好准备；<code>单词向量+位置向量</code></p></li></ol><p>“Attention模型”实现以上内容，具体情况如下图所示：</p><p><img src="https://i.loli.net/2020/09/05/bEpK5wcj9rkAGCU.jpg" alt="img"></p><p>以下针对“准备工作”、任务1和任务2展开讨论；</p><h4 id="准备工作">准备工作</h4><p>包括字向量/单词向量、位置向量；此处也称为<strong>词嵌入，位置编码</strong>；</p><ol type="a"><li>字向量/单词向量分别是<code>随机产生产生的一组512维向量</code>，如字向量，假设选用了3000个常用汉字，每个字对应一个512维的随机向量，则整个字向量就是一个3000 X 512 的二维矩阵，每一行代表一个字；</li></ol><p><strong>之所以用随机且选择较大维度（如512维），是为了让生成的各个向量间尽可能的独立，即没有相关性</strong>，就像“你、我、他、拿、和、中”指代的具体意思在最初定义时是可以随机互换的，之间也无关系，他们之间的相关性/关系是在该语系语境中根据语义、语法、文化等因素形成的，即上述任务1需要完成的。</p><p>（词嵌入，每个词之间没有关系）</p><p><img src="https://i.loli.net/2020/09/05/9tSTwmsdnfuW7Ol.jpg" alt="img"></p><ol start="2" type="a"><li>位置向量是代表一个字在句子中的位置信息，也定义为一个512维的向量，但并不是随机产生的，而是根据位置确切计算得来，即<strong>一个位置对应转化为一个512维向量；</strong></li></ol><p><img src="https://i.loli.net/2020/09/05/FAR6vuDZgBoJwTX.jpg" alt="img"></p><ol start="3" type="a"><li>假设翻译时定义一句话最大长度是10个字，则该句话对应的字向量是一个10 X 512的二维矩阵（每一行代表一个字），位置向量也是一个10 X 512的二维矩阵（每一行代表对应字的位置信息）；<strong>两个矩阵相加得新的二维矩阵能更好更全面的表达这句话；</strong></li></ol><h4 id="任务1编码">任务1：编码</h4><p><strong>理解</strong>一句中文A的意思为X；此处也称为“编码”</p><ol type="i"><li><p>翻译时中文中的“你”、“我”大多时候对应着英文的“you”、“me”，如果都是这样的简单一一对应关系，那翻译是很简单的；而实际情况是<strong>绝大多数都是一对多的关系，即同一个中文字在不同的语境中对应的英文是不一样的单词</strong>，如“和”字在不同语境中翻译为英文可能是“and”、“sum”、“peace”等。</p></li><li><p>一个字从多个可能的意思中选择一个是根据语境来确定的，即根据这个字与句子中所有字的相关关系来确定；<strong>一句话需要计算该句话中每个字与该句子中所有字的相关关系来确定这句话中每个字在该语境中的意思，即确认中文语境</strong>；</p></li><li><p>在计算相关性之前，对每一个<strong>字对应的向量进行相应的线性变换</strong>以便于更好的计算相关性确认最终意思；计算完相关性（确认中文语境）并以此更新向量矩阵后（即self-attention，确认每个字在当前这句话的语境下的“确切意思”），再<strong>进行一次线性变换</strong>，对这个“确切意思”进行再次拟合校准；</p></li></ol><p>具体情况，如下图所示；</p><p><img src="https://i.loli.net/2020/09/05/ZT4OvczK3tyCdGX.jpg" alt="img"></p><p>Notes：i~iii是一个处理单元，<strong>输入“向量矩阵”和输出“新向量矩阵X”的维度是一样的</strong>；完成任务1是以上处理单元循环N次（<strong>强化上述效果</strong>），设定义N=3（论文中N=8）；即由3个处理单元依次链接完成任务1，如下图所示：</p><p><img src="https://i.loli.net/2020/09/05/ZS4YMITXOWyr8kf.jpg" alt="img"></p><h4 id="任务2解码">任务2：解码</h4><p>将意思X用英文表达出来，即英文B；此处也称为“解码”</p><p>和任务1类似，<strong>差异</strong>在于：</p><p>I. 任务1仅考虑中文语境即可，任务2<strong>既考虑中文语境（vanilla-attention），也考虑英文语境（self-attention）；</strong></p><ol start="2" type="i"><li>和任务1类似，经过N个处理单元后获得的向量矩阵，经过“最后一次线性变换”转换为对应英文语系中各个单词的值，然后由softmax转换为是各个英文单词的概率，完成翻译；</li></ol><p>图示如下：</p><p><img src="https://i.loli.net/2020/09/05/yKDA2Fs3Xc4HkIo.jpg" alt="img"></p><p>整体简化图示如下：</p><p><img src="https://i.loli.net/2020/09/05/6epU1uboH2AGP7k.jpg" alt="img"></p><h3 id="attention注意力">Attention注意力</h3><p><img src="https://i.loli.net/2020/09/05/R2XINUW16u4anTs.jpg" alt="img"></p><p>上图是attention模型的总体结构，包含了模型所有节点及流程（因为有循环结构，流程不是特别清楚，下文会详细解释）；模型总体分为两个部分：编码部分和解码部分，分别是上图的左边和右边图示；以下选取翻译情景，以<strong>模型训练</strong>为例解释整个过程；</p><p><strong>训练样本：原文译文(一一对应)</strong></p><h4 id="编码部分inputs">编码部分（inputs）</h4><h5 id="input-embedding">Input embedding:</h5><p>1.1 将原文的所有单词汇总统计频率，删除低频词汇（比如出现次数小于20次的统一</p><p>定义为’<unk>’）；</unk></p><p>此时总共选出了假设10000个单词，则用数字编号为0~9999，一一对应，定义该对应表为word2num；</p><p>然后用<code>xaviers方法</code>生成随机矩阵Matrix ：<strong>10000行N列</strong>（10000行是确定的，对应10000个单词，N列自定义）；这样就可以将10000个不同的单词通过word2num映射成10000个不同的数字（int），然后将10000个不同的数字通过Matrix映射成10000个不同的N维向量（如何映射？比如数字0，3，经过 Matrix映射分别变为向量Matrix[0],Matrix[3]，维度为N维）；</p><p>这样，<strong>任何一个单词，都可以被映射成为唯一的一个N维向量</strong>；</p><p><img src="https://i.loli.net/2020/09/05/86ByVmtDIGfd2bx.png" alt="img"></p><p>*<strong>Note：此处N自定义为512*</strong></p><p>1.2 翻译的时候是<strong>一个句子一个句子的翻译</strong>，所以需要定义一个句子的标准长度，比如10个单词；如果一句话不足10个单词则用0填充（<strong>对应的word即word2num表中的<pad></pad></strong>），如果多了，删掉；</p><p>这样一句话就是标准的10个单词；比如句子 “中国人有中国梦。”，这句话共有八个字（最后一个是结束符），<strong>经过word2num变为一列X：<a href="注：100代表的word是结束符">1,7,3,2,1,7,6,100,0,0</a>,X经过Matrix映射为10行N列的矩阵matX</strong>= [Matrix[1], Matrix[7], Matrix[3], Matrix[2] , Matrix[1] , Matrix[7] , Matrix[6], Matrix[100] , Matrix[0] , Matrix[0]]; embedding 到此基本结束，即完成了将一句话变为 一个矩阵，矩阵的每一行代表一个特定的单词；此处还可以scale一下，即<code>matX*N**(1/2)</code>; （<code>**代表次方，即matX中的每一个元素都乘以N的1/2次方，此时N=512，以此来缩放</code>）</p><p><img src="https://i.loli.net/2020/09/05/xOJBLyNruSIX9s2.png" alt="img"></p><h5 id="positional-encoding">Positional encoding:</h5><p>2.1 单词在句子中的不同位置体现了不同信息，所以需要对位置进行编码，体现不同的信息情况，此处是对绝对位置进行编码，即位置数字0，1，2，3，…N等，进行运算编码，具体编码如下：</p><p>2.1.1 对于句子中的每一个字，其位置pos∈<a href="每句话10个字">0,1,2,…,9</a>,每个字是N（512）维向量，维度 i （i∈[ 0,1,2,3,4,..N]）带入<strong>函数计算</strong>，</p><p><img src="https://i.loli.net/2020/09/05/dR4rAa9DkZJKNQC.png" alt="img"></p><blockquote><p>用sin和cos是因为在后面运算过程中会近似出现sin(a)sin(b)+cos(a)cos(b)的形式，根据三角函数公式上式恰好等于cos(a-b)，当a和b差小时（即两个字离得近）值大，反之小。这在一定程度上可以表达两个字的距离。</p></blockquote><p>2.1.2 经过如上函数运行一次后，获得了一个<strong>10行N列的矩阵matP</strong>；每一行代表一个绝对位置信息，此时matP的shape和matX的shape相同；</p><p><img src="https://i.loli.net/2020/09/05/xFKDaYu1pSNZ7lo.png" alt="img"></p><p>2.1.3 <strong>对于矩阵matP的每一行，第0，2，4，6,...等偶数列上的值用sin()函数激 活，第1，3，5，。。。等奇数列的值用cos()函数激活，以此更新matP</strong>；即 matP[:,0::2]=sin(matP[:,0::2]), matP[:,1::2]=cos(matP[:,1::2])；</p><p><img src="https://i.loli.net/2020/09/05/w1FJXfzq5IRrPCS.png" alt="img"></p><p>2.2 至此positional encoding结束，最后通常也会scale一次，即对更新后的matP进行<code>matP*N**(1/2)</code>运算，得到再次更新的matP，此时的matP的shape还是和matX相同；<strong>然后将matP和matX相加即matEnc=matP+matX，矩阵matEnc其shape=[10，512]；</strong></p><h5 id="multi-head-attention循环单元">Multi-head attention循环单元</h5><p>3.1 然后matEnc进入模型编码部分的循环，即Figure1中左边红色框内部分，每个循环 单元又分为4个小部分：multi-head attention, add&amp;norm, feedForward, add&amp;norm；</p><p>3.2 Multi-head attention</p><p><img src="https://i.loli.net/2020/09/05/np9H73tSVYogJG4.jpg" alt="img"></p><p>3.2.1 Multi-head attention 由三个输入，分别为V，K，Q，此处<strong>V=K=Q=matEnc</strong>（在解码部分multi-head attention中的VKQ三者不是这种关系）;</p><p>3.2.2 首先分别对V，K，Q三者分别进行线性变换，即将三者分别输入到三个单层神经网络层，激活函数选择relu，输出新的V，K，Q（三者shape都和原来shape相同，即<strong>经过线性变换时输出维度和输入维度相同</strong>）；</p><p>3.2.3 然后将Q在最后一维上进行切分为num_heads(假设为8)段，然后对切分完的矩阵在axis=0维上进行concat链接起来(纵向连接)；对V和K都进行和Q一样的操作；操作后的矩阵记为Q_,K_,V_；</p><p><img src="https://i.loli.net/2020/09/05/PqJYGOb4fvTmsFw.png" alt="img"></p><p><img src="https://i.loli.net/2020/09/05/2npJkGobFc4RXwu.png" alt="img"></p><p>3.2.4 <strong>Q_矩阵相乘 K_的转置（对最后2维）</strong>，生成结果记为outputs，然后对outputs 进行scale一次更新为outputs；<strong>此次矩阵相乘是计算词与词的相关性，切成多个num_heads进行计算是为了实现对词与词之间深层次相关性进行计算；</strong></p><p><img src="https://i.loli.net/2020/09/05/imn5tKIUxzyfwLW.png" alt="img"></p><p><code>shape（outputs） = （8,10,10）</code></p><p>3.2.5 对outputs进行softmax运算，更新outputs，即outputs=softmax(outputs);</p><p>3.2.6 最新的outputs（即K和Q的相关性） 矩阵相乘 V_， 其值更新为outputs；</p><p><img src="https://i.loli.net/2020/09/05/oZalMTkQeRVqsUy.png" alt="img"></p><p><code>shape（outputs）= (8,10,64)</code></p><p>3.2.7 最后将outputs在axis=0维上切分为num_heads段，然后在axis=2维上合并， <strong>恢复原来Q的维度</strong>；</p><p><img src="https://i.loli.net/2020/09/05/JrFbIdWauXxA4nK.png" alt="img"></p><p>3.3 Add&amp;norm</p><p>3.3.1 类似ResNet，将<strong>最初的输入与其对应的输出叠加一次</strong>，即outputs=outputs+Q， 使网络有效叠加，<strong>避免梯度消失</strong>；</p><p><img src="https://i.loli.net/2020/09/05/falSI79c3xD2Ey8.png" alt="img"></p><p>3.3.2 标准化矫正一次，在outputs对最后一维计算均值和方差，用outputs减去均值除以方差+spsilon得值更新为outputs，然后变量gamma*outputs+变量beta；（Norm操作）</p><p>3.4 feed Forward （就是dense layer 全连接层）</p><p>3.4.1 对outputs进行第一次卷积操作，结果更新为outputs（卷积核为1*1，每一次卷积操作的计算发生在一个词对应的向量元素上，卷积核数目即最后一维向量长度，也就是一个词对应的向量维数）；</p><p>3.4.2 对最新outputs进行第二次卷积操作，卷积核仍然为1*1，卷积核数目为N；</p><p><img src="https://i.loli.net/2020/09/05/esShU1Nx32AYt8Z.png" alt="img"></p><p>3.5 Add&amp;norm : 和3.3相同，经过以上操作后，此时最新的output和matEnc的shape相同；</p><p>3.6 <strong>令matEnc=outputs, 完成一次循环，然后返回到3.2开始第二次循环</strong>；共循环Nx（自定义；每一次循环其结构相同，但对应的参数是不同的，即是独立训练的）；完成Nx次后，模型的编码部分完成，仍然令matEnc=outputs，准备进入解码部分；</p><p>解码部分：</p><p>​ <strong>此时的outputs指的是上一时间点解码器的输出</strong></p><ol type="1"><li><p>Outputs：<strong>shifted right右移一位</strong>？？？？，是为了解码区最初初始化时第一次输入，并将其统一定义为特定值（在word2num中提前定义）；</p></li><li><p>Outputs embedding: 同编码部分；更新outputs；</p></li><li><p>Positional embedding：同编码部分；更新outputs； （前三步是准备工作）</p></li><li><p>进入解码区循环体； （以下是解码器的顺序操作）</p></li></ol><p>4.1 Masked multi-head attention: 和编码部分的multi-head attention类似，但是多了一 次<strong>masked</strong>，因为在解码部分，解码的时候时从左到右依次解码的，当解出第一个字的时候，第一个字只能与第一个字计算相关性，当解出第二个字的时候，只能计算出第二个字与第一个字和第二个字的相关性，...；所以需要进行一次mask；</p><p><img src="https://i.loli.net/2020/09/05/54eVnEgmh7CdqKH.jpg" alt="img"></p><p>4.2 Add&amp;norm：同编码部分，更新outputs；</p><p>4.3 Multi-head attention：同编码部分，但是Q和K，V不再相同，Q=outputs，K=V=matEnc；(outputs是上层的输出，k,v是来自编码器的输出)</p><p>4.4 Add&amp;norm:同编码部分，更新outputs；</p><p>4.5 Feed-Forward：同编码部分，更新outputs；</p><p>4.6 Add&amp;norm: 同编码部分，更新outputs；</p><p>4.7 最新outputs和最开始进入该循环时候的outputs的shape相同；回到4.1，开始第 二次循环。。。；直到完成Nx次循环（自定义；<strong>每一次循环layer结构相同，但对应的参数是不同的，即独立训练的</strong>）；</p><ol start="5" type="1"><li><p>Linear: 将最新的outputs，输入到单层神经网络中，输出层维度为“译文”有效单词总数；更新outputs；</p></li><li><p>Softmax: 对outputs进行softmax运算，确定模型译文和原译文比较计算loss，进行网络优化（参数更新）；</p></li></ol><h4 id="注">注</h4><p>1.解码器的<code>outputs embedding</code> ：在训练的时候就是对应原文的译文，其中第一字统一定义为0,作为输入；在预测时第一次输入也是全是0,然后每循环一次，预测一个字直到出现终止符。</p><p>2.对于matEnc=matP+matX，这里为什么要用add,而不是contact ?</p><p>matX是一个10行512列的矩阵，每一行代表一个字；</p><p>matP是一个10行512列的矩阵，每一行代表一个位置；</p><p>对于不一样的句子，matX是不一样的，matP是完全一样的；</p><p>则对于不一样的句子，add后是不一样的，contact后至少一半是一样的，从直观上，add似乎更好；</p><p>对于一个字，其出现的位置不同，可能表达的意思完全不一样，比如“和”，如果其在句首或者句中出现更可能是“and”的意思，如果在句末出现，更可能是“sum”的意思，而这两个意思几乎完全不一样，即他们的向量完全不一样似乎更合理，而非contact的至少一半一样；</p><p>matP矩阵的特点从上到下对应各元素是递增的，matX是随机产生的（比如均值为0的随机数），即大约在0附近波动的数，与matP做add运算后，相当于均值被依次提高，以此代表融入每个字位置信息；因为每次训练的时候均值被提高的量是一定的，所以可以期望模型训练后能“意识”到这一点；</p><p>add产生“信息混淆”，比如两个字在两个不同的位置上分别add后，结果相近，从直观上这可能会造成问题；这个问题可以通过加大向量维度来降低其出现概率，比如选择512维是很长的维度了，出现这种概率的问题还是很小的；</p><p>如果用contact实际就是在每个字向量后面追加一个位置信息以示区别，做这种区别无需太多维，也许一两维即可；</p><p>深度学习算法的可解释性差，分析大多属于理论上的“纸上谈兵”，最可靠的方式，仍是分别以add和contact两种方式建模，大量测试后的结果更为可靠。</p><ol start="3" type="1"><li><p>待探究</p><p>你文章中的逻辑是，对原始Q/K/V做不同线性变换（三个权重矩阵）得到新的Q/K/V→对新的Q/K/V在最后一个维度做切分得到多头（8组Q/K/V）→各组Q/K/V计算attetion值→8组Q/K/V的attetion值concat得到最终的attention值。</p><p>而原论文的逻辑是，对原始的Q/K/V做不同的线性变换（8（组）×3个权重矩阵）得到新的8组Q/K/V值→各组Q/K/V计算attention值→8组Q/K/V的attention值concat→concat结果经过一个线性变换（为了还原到最初的维度）得到最终的attention值。</p><p>论文提到multi-head attention是为了从不同表征子空间提取信息。个人理解实现这种差异化的提取，是通过多组权重矩阵来实现的，而不是通过embedding值不同分段获取。</p></li><li><p>在<strong>预测阶段</strong>，每次预测后底部decoder的输入是可变的，首先是[<bos>]，然后是[<bos>, word1 ]，再输入[<bos>, word1, word2 ]……，那么decoder内部如何保证它送入linear层的输出是(1, N)的向量呢？</bos></bos></bos></p><p><strong>答</strong>：[<bos>]时，经过解码区的循环部分后 是一个[1, 512]的矩阵， 经过linear层是准备预测1个字的；</bos></p><p>[<bos>, word1 ]时，经过解码区的循环部分 是一个[2, 512]的矩阵；经过linear层是准备预测2个字的；以此类推。</bos></p><p>也就是说，输入bos，输出word1；然后将bos word1输入，再输出word1 word2；再输入bos word1 word2......每次都把输出的最后一个字加到下一轮输入。</p></li><li><p>假设target是<bos>我爱中国<eos>，这算6个字，训练时decoder是不是也输出6个vocab-size长度的向量，那么第一个vocab-size长度的向量预测的是<bos>还是"我"呢？</bos></eos></bos></p><p><strong>答</strong>：预测的第一个是“我”,<bos>作为一个起始引导使用。</bos></p></li><li><p>第一个问题是训练和预测时解码端如何运行，我理解训练时使用mask一次性对所有时间步并行进行解码，预测时则需要先预测出上一步的词，再输入预测下一步，所以不能并行。如果我上面说的没错的话，第一个问题是为什么训练时mask没有掩盖自身，也就是对角线不mask，这样的话不就泄露了要预测那个词吗？第二个问题是预测时该如何进行，因为训练时，输入多少个时间步的词就会输出多少个时间步的预测值，但是在预测解码阶段，假设为t，要预测t + 1该如何操作？难道是先将t + 1随便加一个pad上去然后看预测值softmax吗？</p><p><strong>答</strong>：在训练时，用mask是一次性的解码，因为训练时所有label是已知的，用mask实现同时并行运算；预测时label是未知的，需要一个一个词预测，当预测第一个词时只能知道第一个词和第一个词的相关性，然后再运行模型一遍，预测出第一个词和第二词，依次循环直到出现终止符，这个过程不是并行的。</p><p>个人理解： 在训练时，把一整句话都作为解码器的输入，这样可以实现并行运算，因为每一个label都是已知的。而在预测时，需要一步一步来</p></li></ol><h3 id="参考">🚀参考</h3><blockquote><p><a href="https://zhuanlan.zhihu.com/p/62397974" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/62397974</a></p><p><a href="https://zhuanlan.zhihu.com/p/44731789" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/44731789</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      摘自一篇不错的博客
    
    </summary>
    
    
      <category term="transformer" scheme="http://yoursite.com/categories/transformer/"/>
    
    
      <category term="transformer" scheme="http://yoursite.com/tags/transformer/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-31-一周论文分享（第1期）</title>
    <link href="http://yoursite.com/2020/08/31/2020-08-31-%E4%B8%80%E5%91%A8%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%EF%BC%88%E7%AC%AC1%E6%9C%9F%EF%BC%89/"/>
    <id>http://yoursite.com/2020/08/31/2020-08-31-%E4%B8%80%E5%91%A8%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%EF%BC%88%E7%AC%AC1%E6%9C%9F%EF%BC%89/</id>
    <published>2020-08-31T12:43:16.000Z</published>
    <updated>2020-09-04T08:00:41.608Z</updated>
    
    <content type="html"><![CDATA[<h3 id="reformerthe-eficient-transformer">reformer：the eficient transformer</h3><h4 id="论文概况">论文概况</h4><ul><li>来源：ICLR 2020</li><li>arXiv: 1901.02860</li><li>作者：Nikita Kitaev ，Anselm Levskaya</li><li>论文地址：<a href="https://openreview.net/forum?id=rkgNKkHtvB" target="_blank" rel="noopener" class="uri">https://openreview.net/forum?id=rkgNKkHtvB</a></li><li>Code url：<a href="https://github.com/google/trax/tree/master/trax/models/reformer" target="_blank" rel="noopener" class="uri">https://github.com/google/trax/tree/master/trax/models/reformer</a></li><li>论文组会报告于<code>2020.08.30</code></li></ul><h4 id="背景">背景</h4><p>Transformer架构被广泛用于自然语言处理中，并在许多任务上产生了最新的结果</p><h5 id="问题">问题</h5><ol type="1"><li>大型的 Transformer 可以在许多任务上实现 sota，但是面临着参数过多的问题，导致所占内存过大，造成资源紧张.</li></ol><p>在最大的配置中，参数数量已经超过了 5亿/层，层数多达 64。</p><ol start="2" type="1"><li><p>具有 <em>N</em> 层的模型要消耗 <em>N</em> 倍于单层模型的内存，因为每一层中的激活都需要存储以进行反向传播。</p></li><li><p>由于点乘注意力本身的局限性，导致不能处理长序列数据，否则会导致效率不高</p></li></ol><p>也就是说transformer的上下文窗口有限制范围。最多也就几千个单词。</p><blockquote><p>Transformer 的强大来源于注意力机制 ，通过这一机制，Transformer 将上下文窗口内所有可能的单词对纳入考虑，以理解它们之间的联系。因此，如果文本包含 10 万个单词，Transformer 将需要评估 100 亿单词对（10 万 x 10 万），这显然不切实际。</p><p>另一个问题是如何保存每个模型层的输出 。对于使用大型上下文窗口的应用来说，存储多个模型层输出的内存需求会迅速变得过大。这意味着，实际使用大量层的 Transformer 模型只能用于生成几小段落的文本或一小段的音乐。</p></blockquote><h5 id="解决方案">解决方案</h5><ol type="1"><li><p>使用可逆残差（reversible residual layers）代替标准残差（standard residuals），这使得存储在训练过程中仅激活一次，而不是 n 次（此处 n 指层数），更有效地使用可用内存</p></li><li><p>将点乘注意力（dot-product attention）替换为一个使用局部敏感哈希（locality-sensitive hashing）的点乘注意力，将复杂度从 O(L2 ) 变为 O(L log L)，此处 L 指序列的长度，来降低长序列的处理复杂度</p></li></ol><p><strong>Reformer与使用完全Transformer所获得的结果相匹配，但运行速度要快得多，尤其是在文本任务上，并且内存效率要高几个数量级。</strong></p><h4 id="注意力问题">注意力问题</h4><h5 id="原始注意力">原始注意力</h5><p>公式如下：<span class="math inline">\(Attention (Q, K, V)=\operatorname{softmax}\left(\frac{Q K^{T}}{\sqrt{d_{k}}}\right) V\)</span></p><p>self-attention操作的核心 ——<span class="math inline">\(QK^T\)</span> 表示key和query之间的相似度得分</p><p>计算带有所有k的q的点积，并用√dk进行缩放，然后应用softmax函数来获得v的权重。用来消除hidden size这个参数对注意力分布的影响。对于每个query，我们在所有keys上计算一个softmax，以确保矩阵的每一行和为1—— 确保新的隐藏状态的大小不依赖于序列长度。</p><p>最后，我们用我们的注意力矩阵乘以我们的values矩阵，为每个token生成一个新的隐藏表示。</p><hr><blockquote><h5 id="例子">例子</h5><p>Key:(batch, length,d_model)</p><p>Query:(batch, length,d_model)</p><p>-&gt; <span class="math inline">\(QK^T\)</span>　:(batch, length,length)</p><p>-&gt; 复杂度： O(<span class="math inline">\(L^2\)</span> )</p><p>-&gt;原始的transformer结构难以处理过长的序列长度</p></blockquote><p><img src="https://i.loli.net/2020/09/03/9mdzrXcGKZ5FPi3.png" alt="image-20200903163000933"></p><p><img src="https://i.loli.net/2020/09/03/6QvMn1qxGXzwKmC.png" alt="image-20200903161441529"></p><p>其实，在softmax中，对于每个查询 <em>q</em>，我们只需要注意最接近 <em>q</em> 的键 <em>k</em>。<strong>并不一定需要那些注意力权重很小的token。</strong></p><p>例如，如果序列长度是 64K，对于每个 <em>q</em>，我们可以只考虑 32 或 64 个最近的键的一个小子集。因为这些是和<em>q</em>最需要注意的</p><h5 id="局部敏感哈希lsh">局部敏感哈希(LSH)</h5><p><img src="https://i.loli.net/2020/09/03/zQI9n2ubZYDV7SL.png" alt="image-20200903163152560"></p><p>局部敏感哈希使用<code>球形投影点的随机旋转</code>，通过argmax在有符号轴投影上<code>建立桶（bucket）</code>。 在此高度简化的2D描绘中，对于三个不同的角度hash，两个点x和y不太可能共享相同的哈希桶（上方），除非它们的球面投影彼此靠近（下方）。</p><p>该图演示了一个用<code>4个桶进行3轮哈希的设置</code>。下面的图中的向量映射到了同一个bucket，因为它们的输入很接近，而上一张图中的向量映射到第一个和最后一个bucket。</p><p>LSH是一组将高维向量映射到一组离散值(桶/集群)的方法。是解决在高维空间中快速找到最近邻居（最相似）的问题。</p><p><code>基本思想</code>：选择 <em>hash</em> 函数，对于两个点 p 和 q，如果 q 接近 p，那么很有可能我们有 hash(q) == hash(p)</p><h5 id="lsh注意力">LSH注意力</h5><p><img src="https://i.loli.net/2020/09/03/KgnJ7iB2kImcshX.png" alt="image-20200903163641310"></p><p>完全不同的方法来处理序列长度问题，丢弃了<code>query投影</code>（Q=K）（实验结果发现，学习不同的keys和queries的投影并不是严格必要的），<code>并将注意力权重替换为key的函数（hash函数）</code>，以此降低复杂度</p><p>步骤如下：</p><p>1.使用LSH为每个token计算一个桶</p><p>2.根据相同的桶进行归类排序</p><p>3.分块并将标准的点乘注意力应用到桶中的token的块上，从而大大降低计算负载</p><h4 id="内存问题">内存问题</h4><p>单层能够执行长序列的单模型。但是，当使用梯度下降训练多层模型时，由于需要保存每一层的激活（函数），以用于执行逆推。一个传统的 Transformer 模型具有十几个或更多的层，通过缓存这些层的值，内存将会很快用完。</p><p>可逆层：在反向传播时，按需重新计算每个层的输入，而不是将其保存在内存中。其中来自网络最后一层的激活用于还原来自任何中间层的激活。</p><p>原始的残差网络：<span class="math inline">\(Y=F(x)\)</span></p><p>可逆层的残差网络： 注意我们如何从它的输出(Y ₁, Y ₂)计算物体的输入(X ₁, X ₂)。</p><p><span class="math inline">\(\begin{array}{ll}y_{1}=x_{1}+F\left(x_{2}\right) &amp; y_{2}=x_{2}+G\left(y_{1}\right) \\ x_{2}=y_{2}-G\left(y_{1}\right) &amp; x_{1}=y_{1}-F\left(x_{2}\right) \\ Y_{1}=X_{1}+\text { Attention }\left(X_{2}\right) &amp; Y_{2}=X_{2}+\text { FeedForward }\left(Y_{1}\right)\end{array}\)</span></p><p>示意图如下</p><p><img src="https://i.loli.net/2020/09/03/WX3lcQrmB16pI2Y.png" alt="image-20200903164816966"></p><p><img src="https://i.loli.net/2020/09/03/FgHKa4QNrsjlzMh.png" alt="image-20200903164907447"></p><h4 id="实验">实验</h4><p>作者分别对图像生成任务 <em>imagenet64</em>(长度为 12K)和文本任务 <em>enwik8</em>(长度为 64K)进行了实验，评价了可逆 Transformer 和 LSH 哈希对内存、精度和速度的影响。</p><p>🎉可逆 Transformer 匹配基准：他们的实验结果表明，可逆的 Transformer 可以节省内存不牺牲精度：</p><p><img src="https://i.loli.net/2020/09/03/LwSPM5qFuBfQhaZ.png" alt="null"></p><p>在 enwik8 和 imagenet64 训练中，可逆性对性能的影响</p><p>🎉LSH 注意力匹配基准：注意 LSH 注意力是一个近似的全注意力，其准确性随着散列值的增加而提高。当哈希值为 8 时，LSH 的注意力几乎等于完全注意力：</p><p><img src="https://i.loli.net/2020/09/03/t4zNAXOf6iEZ7cH.jpg" alt="null"></p><p>LSH 注意力作为散列循环对 imagenet64 的影响</p><p>🎉他们也证明了传统注意力的速度随着序列长度的增加而变慢，而 LSH 注意力速度保持稳定，它运行在序列长度~ 100k 在 8GB 的 GPU 上的正常速度：</p><p><img src="https://i.loli.net/2020/09/03/aGRcA42EiNSBz8v.jpg" alt="null"></p><p>注意力评估的速度作为全注意力和 LSH 注意力的输入长度的函数</p><blockquote><p>与 Transformer 模型相比，最终的 Reformer 模型具有更高的存储效率和更快的存储速度。</p></blockquote><h4 id="参考">🚀参考</h4><blockquote><p><a href="https://www.6aiq.com/article/1583729200869" target="_blank" rel="noopener" class="uri">https://www.6aiq.com/article/1583729200869</a></p><p><a href="https://thinkwee.top/2020/02/07/reformer/" target="_blank" rel="noopener" class="uri">https://thinkwee.top/2020/02/07/reformer/</a></p><p><a href="https://aijishu.com/a/1060000000100293" target="_blank" rel="noopener" class="uri">https://aijishu.com/a/1060000000100293</a></p></blockquote><h3 id="transformer-xl-attentive-language-models-beyond-a-fixed-length-context">Transformer-XL : Attentive Language Models Beyond a Fixed-Length Context</h3><h4 id="论文概况-1">论文概况</h4><ul><li>来源：ACL 2019</li><li>arXiv: 1901.02860</li><li>作者：ZihangDai , ZhilinYang , YimingYang</li><li>论文地址： <a href="https://arxiv.org/abs/1901.02860" target="_blank" rel="noopener" class="uri">https://arxiv.org/abs/1901.02860</a></li><li>Code url：<a href="https://github.com/kimiyoung/transformer-xl" target="_blank" rel="noopener" class="uri">https://github.com/kimiyoung/transformer-xl</a></li><li>论文组会报告于<code>2020.08.15</code></li></ul><h4 id="背景-1">背景</h4><h5 id="问题-1">问题</h5><p>Transformer存在局限性：</p><p>1.在语言建模时的设置受到固定长度（segment）的限制。对长距离依赖的建模能力仍然不足</p><p>2.因为transformer将文本等分为相同的片段，导致了上下文碎片</p><h5 id="解决方案-1">解决方案</h5><p>使学习不再仅仅依赖于定长，且不破坏时间的相关性。</p><ol type="1"><li>提出<strong>片段级递归机制(segment-level recurrence mechanism)</strong>，引入一个<strong>记忆(memory)</strong>模块（类似于cache或cell） 之前计算过了不需要重复计算，直接为后面片段使用。</li></ol><ul><li>使得<code>长距离依赖的建模</code>成为可能；</li><li>使得片段之间产生交互，解决上下文碎片化问题</li></ul><p>2.提出<strong>相对位置编码机制</strong>，代替绝对位置编码。 Transformer的绝对位置编码指的是一个片段中，为1 为2 。如果是多个片段同时考虑的话，那么这种1，2就会重复，所以使用了相对位置编码的方法。这样可以在多个片段（segment）中使用相对编码。具体内容见论文</p><p>注：两者是一起使用的，共同解决transformer存在的局限性</p><h4 id="模型-transformer-xl">模型 transformer-XL</h4><h5 id="原始transformer">原始transformer</h5><p><img src="https://i.loli.net/2020/09/04/YU3mC2hIOA9ncrj.gif" alt="v2-732805e00feb35e41f1d00f8df516950_b"></p><h5 id="片段注意力机制">片段注意力机制</h5><p>为了解决长距离依赖，文章引入一个memory状态。</p><p>在训练过程中，每个片段的表示为最后的隐层状态，表示片段的序号，表示片段的长度，表示隐层维度。</p><p>在计算片段的表示时，用memory缓存片段层的隐层状态，用来更新，这样就给下一个片段同了上文，长距离依赖也通过memory保存了下来。并且，最大可能的依赖长度线性增长，达到**N*L**</p><p><img src="https://i.loli.net/2020/09/04/IjUWo7DahsNPAkv.gif" alt="v2-a8210cd2f9bfb9307ba81d694dc4e4b4_b"></p><h5 id="评估阶段">评估阶段</h5><h6 id="原始transformer-1">原始transformer</h6><p><img src="https://i.loli.net/2020/09/04/epOcXjYTy835dJv.gif" alt="v2-13a38126e684b838e5ed207fd5cae944_b"></p><h6 id="transformer-xl">Transformer-XL</h6><p><img src="https://i.loli.net/2020/09/04/qdYL5RsQEOFS8nG.gif" alt="v2-502e1e1fec12b326ace579e059b3b3df_b"></p><h4 id="实验-1">实验</h4><p>实验部分是对基于Transformer-XL的语言模型进行评估，分为字符级和词级。评价指标分别是bpc(每字符位数)和PPL(困惑度)，越小越好。enwiki8和text8用的是bpc。Transformer-XL在多个语言模型基准测试中实现了最先进的结果。 Transformer-XL第一个在char级语言模型基准enwiki8上突破1.0。</p><p><strong>去除实验：</strong></p><p><img src="https://i.loli.net/2020/09/04/ZV1lpewdtanoWi9.png" alt="image-20200904153950861"></p><p>重点是本文设计的相对位置编码<strong>优于</strong>其他工作，memory的设计也有很大的提升。</p><p>最后，Transformer-XL在评估阶段的速度也明显快于 vanilla Transformer，特别是对于较长的上下文。例如，对于 800 个字符的上下文长度，Transformer-XL 比Vanilla Transformer 快 363 倍；而对于 3800 字符的上下文，Transformer-XL 快了 1874 倍。</p><h4 id="创新点">创新点</h4><ul><li>提出了片段级递归机制和相对位置编码机制</li><li>依赖关系比原始Transformer长450％，并且在评估过程中，其速度比原始Transformer快1800倍以上</li></ul><h4 id="参考-1">🚀参考</h4><blockquote><p><a href="https://www.cnblogs.com/shona/p/12041055.html" target="_blank" rel="noopener" class="uri">https://www.cnblogs.com/shona/p/12041055.html</a></p><p><a href="https://zhuanlan.zhihu.com/p/83062195" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/83062195</a></p><p><a href="https://www.cnblogs.com/mj-selina/p/12373636.html" target="_blank" rel="noopener" class="uri">https://www.cnblogs.com/mj-selina/p/12373636.html</a></p><p><a href="https://zhuanlan.zhihu.com/p/70745925" target="_blank" rel="noopener" class="uri">https://zhuanlan.zhihu.com/p/70745925</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录每周值得分享的论文，周一发布、
《reformer-the eficient transformer》、
《Transformer-XL-Attentive Language Models Beyond a Fixed-Length Context》

    
    </summary>
    
    
      <category term="论文分享" scheme="http://yoursite.com/categories/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"/>
    
    
      <category term="论文" scheme="http://yoursite.com/tags/%E8%AE%BA%E6%96%87/"/>
    
      <category term="论文分享" scheme="http://yoursite.com/tags/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"/>
    
      <category term="transformer" scheme="http://yoursite.com/tags/transformer/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-31-git进阶</title>
    <link href="http://yoursite.com/2020/08/31/2020-08-31-git%E8%BF%9B%E9%98%B6/"/>
    <id>http://yoursite.com/2020/08/31/2020-08-31-git%E8%BF%9B%E9%98%B6/</id>
    <published>2020-08-31T08:41:49.000Z</published>
    <updated>2020-09-05T08:34:47.989Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言">前言</h3><p>之前总结过git的一些基本命令，后来使用了更多git，写博客用于记录。不断更新 ，在实践中总结git知识点。</p><p>回顾下之前的git基本操作</p><ul><li>将现有的项目添加提交并上传到远程仓库</li></ul><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">git add . #添加当前文件夹下的所有文件</span><br><span class="line"></span><br><span class="line">git commit -m "first commit " # 引号内是本次的提交说明 </span><br><span class="line"></span><br><span class="line">git push -u origin master # 提交本地分支到远程分支</span><br><span class="line">(若出现failed to push som refs to， 则执行git pull origin master，</span><br><span class="line">将远程服务器github上的master拉下来，再重新push)</span><br></pre></td></tr></tbody></table></figure><ul><li>clone代码</li></ul><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone   https://github.com/raymond-zhao/cat-mall.git   ../Github/cat-mall </span><br><span class="line">#将cat-mall代码克隆到  ../Github/cat-mall 中</span><br></pre></td></tr></tbody></table></figure><h3 id="git-status-和-git-diff">git status 和 git diff</h3><p>在对文件进行修改之后，可以用 <code>git status</code> 查看结果，可以让我们时刻掌握仓库当前的状态</p><p><img src="https://i.loli.net/2020/08/31/fTmxaAeZG1iSCLd.png" alt="image-20200831180231338" style="zoom:67%;"></p><p>可以看到在<code>modified</code>部分，可以看到有四个文件被修改了，<strong>但是还没有进行提交（<code>commit</code>）修改</strong></p><p>而下半部分的<code>untracked files</code>表示的是<strong>之前从未提交到仓库分支</strong>的文件（一个markd文件，一个照片）</p><p>上述只是看到被修改的文件，但如果能看看具体修改了什么内容就好了，<code>git diff</code> 可以实现这个功能</p><p><img src="https://i.loli.net/2020/08/31/nVd3hGKLJy6f7zH.png" alt="image-20200831194816455"></p><p>可以看到修改的详细细节（红色为修改前的内容，绿色为修改后的内容）。向下箭头可以下拉文本，<code>q</code>退出查看 （quit）</p><p>这样就可以放心的添加（add）到仓库的暂存区，并提交（commit）到仓库分支</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m 20/8/31/commit1</span><br></pre></td></tr></tbody></table></figure><h4 id="小结">小结</h4><ul><li>要随时掌握工作区的状态，使用<code>git status</code>命令。</li><li>如果<code>git status</code>告诉你有文件被修改过，用<code>git diff</code>可以查看修改内容。</li></ul><h3 id="版本回退">版本回退</h3><p>每当文件修改到一定程度的时候，就可以“保存一个快照”，这个快照在Git中被称为<code>commit</code>。一旦你把文件改乱了，或者误删了文件，还可以从最近的一个<code>commit</code>恢复，然后继续工作，而不是把几个月的工作成果全部丢失。</p><p>在Git中，我们用<code>git log</code>命令查看：</p><p><img src="https://i.loli.net/2020/08/31/4lC7ufP6ZmbUvWT.png" alt="image-20200831233324006" style="zoom:80%;"></p><p><code>git log</code>命令显示从最近到最远的提交日志，每一次<code>commit</code>很详细</p><p>可以加上<code>--pretty=oneline</code>参数，来简化显示。推荐使用</p><p><img src="https://i.loli.net/2020/08/31/xNXAn7Pt8rT2mcE.png" alt="image-20200831233340202" style="zoom:80%;"></p><p>其中前面编号类似<code>012214236e...</code>的是<code>commit id</code>（版本号），是一个<code>SHA1</code>计算出来的一个非常大的数字，用十六进制表示</p><p>每个人的编号不一样，因为Git是分布式的版本控制系统，多人在同一个版本库里工作，如果大家都用1，2，3……作为版本号，那肯定就冲突了。</p><blockquote><p><a href="https://1024tools.com/hash" target="_blank" rel="noopener">Hash在线计算、md5计算、sha1计算、sha256计算、sha512计算</a></p></blockquote><h4 id="回退到历史版本">回退到历史版本</h4><p>这样我们就可以进行回退操作</p><p>首先，Git必须知道当前版本是哪个版本。</p><p>在Git中，用<code>HEAD</code>表示当前版本，也就是最新的提交<code>012214236e...</code>，上一个版本就是<code>HEAD^</code>，上上一个版本就是<code>HEAD^^</code>，当然往上100个版本写100个<code>^</code>比较容易数不过来，所以写成<code>HEAD~100</code>。</p><p>我们可以使用<code>git reset</code>命令：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard HEAD^ <span class="comment">#回退到上一版本</span></span><br></pre></td></tr></tbody></table></figure><p><img src="https://i.loli.net/2020/08/31/k37ptdoMJxGcufR.png" alt="image-20200831233416378"></p><p>结果显示出现在是<code>ca41b0a</code>，也就是上一次<code>commit</code>的版本。我们成功回退版本！</p><p>当我们再查看日志的时候，发现已经没有<code>20/8/31/commit1</code>版本了</p><p><img src="https://i.loli.net/2020/08/31/xWIlbtTwazUJNdO.png" alt="image-20200831233446124"></p><hr><h4 id="还原到最新版本">还原到最新版本</h4><p>如果想要再还原到<code>20/8/31/commit1</code>版本呢？</p><p>也是可以的，只要<strong><code>上面的命令行窗口还没有被关掉</code></strong>，就可以顺着往上找，找到那个<code>20/8/31/commit1</code>版本的<code>commit id</code>是<code>012214236e...</code>，于是就可以指定回到未来的某个版本：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset --hard 0221423</span><br></pre></td></tr></tbody></table></figure><p><img src="https://i.loli.net/2020/08/31/9pK7UsnRrv1loSD.png" alt="image-20200831233507305"></p><p>版本号没必要写全，前几位就可以了，Git会自动去找。当然也不能只写前一两位，因为Git可能会找到多个版本号，就无法确定是哪一个了。</p><p>这样就实现了还原到最后<code>commit</code>版本</p><p>Git的版本回退速度非常快，因为Git在内部有个指向当前版本的<code>HEAD</code>指针，当你回退版本的时候，Git仅仅是把HEAD从指向历史版本，再将工作区的文件更新即可</p><p>如果回退到了某个版本，关掉了命令行窗口，后悔想恢复到新版本但是找不到新版本的<code>commit id</code>怎么办？</p><p>在Git中，总是有后悔药可以吃的。Git提供了一个命令<code>git reflog</code>用来记录你的每一次命令：</p><p><img src="https://i.loli.net/2020/09/01/Ly4MDnv6WAEwQlV.png" alt="image-20200901000008019"></p><p>知道<code>commit_id</code>，还原版本就十分滴完美！</p><blockquote><p><strong>注！！！</strong></p><p>如果从历史版本回到最后的版本，也只能还原到最后<code>commit</code>后的版本。</p><p>我才开始<code>commit</code>了版本A，之后又写了一部分内容 B(未<code>commit</code>)。还原到了A-1版本，之后又想还原到A+B版本，操作完之后发现还原后的没有B部分，也就是我只能还原到A。</p><p>原因就是我在最后一次<code>commit</code>就是A，而写完B之后，没有<code>commit</code> ，于是无法还原。 （多多<code>commit</code>，</p><p>，还原需谨慎。我是真的折腾）<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f62d.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f62d.png?v8">😭</span></p></blockquote><h4 id="小结-1">小结</h4><ul><li><code>HEAD</code>指向的版本就是当前版本，因此，Git允许我们在版本的历史之间穿梭，使用命令<code>git reset --hard commit_id</code>。 （commit_id也写成HEAD^）</li><li>穿梭前，用<code>git log</code>可以查看提交历史，以便确定要回退到哪个版本。</li><li>要重返未来，用<code>git reflog</code>查看命令历史，以便确定要回到未来的哪个版本。</li></ul><h4 id="参考">参考</h4><blockquote><p><a href="http://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html" target="_blank" rel="noopener">常用git命令清单-阮一峰</a></p><p><a href="http://www.ruanyifeng.com/blog/2012/08/how_to_read_diff.html" target="_blank" rel="noopener">读懂diff-阮一峰</a></p><p><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="noopener">git教程-廖雪峰</a></p><p><a href="http://www.runoob.com/git/git-install-setup.html" target="_blank" rel="noopener">git教程-菜鸟教程</a></p><p><a href="https://git-scm.com/book/zh/v2" target="_blank" rel="noopener">gitbook</a></p><p><a href="http://gitbook.liuhui998.com/index." target="_blank" rel="noopener">Git Community Book</a></p><p><a href="https://juejin.im/post/6844903586023866375" target="_blank" rel="noopener">从只会git add .的菜鸟到掌握git基本功能</a></p></blockquote><h3 id="工作区和暂存区">工作区和暂存区</h3><h4 id="工作区working-directory">工作区（Working Directory）</h4><p>就是在电脑里能看到的目录，比如我的<code>mynlog</code>文件夹就是一个工作区：</p><p><img src="https://i.loli.net/2020/09/01/lp9hvTzLtVuMPG5.png" alt="image-20200901000937480" style="zoom:80%;"></p><h4 id="版本库repository">版本库（Repository）</h4><p>也就是本地仓库</p><p>工作区有一个隐藏目录<code>.git</code>，这个不算工作区，而是Git的版本库。（选择<code>隐藏文件可见</code>就可以看到）</p><p>Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫<code>index</code>）的暂存区，还有Git为我们自动创建的第一个分支<code>master</code>，以及指向<code>master</code>的一个指针叫<code>HEAD</code>。</p><p><img src="https://i.loli.net/2020/09/01/wBe5iWuajDJKxdV.png" alt="image-20200901001300425" style="zoom:80%;"></p><p><img src="https://i.loli.net/2020/09/01/KywEFn2dtMJeBkq.png" alt="image-20200901001406385" style="zoom:80%;"></p><p>前面讲了我们把文件往Git版本库里添加的时候，是分两步执行的：</p><p>第一步是用<code>git add</code>把文件添加进去，实际上就是把文件修改添加到暂存区(<code>index</code>)；</p><p>第二步是用<code>git commit</code>提交更改，实际上就是把暂存区的所有内容提交到当前分支(<code>master</code>)。</p><p>因为我们创建Git版本库时，Git自动为我们创建了唯一一个<code>master</code>分支，所以，现在，<code>git commit</code>就是往<code>master</code>分支上提交更改。</p><p>你可以简单理解为，<strong>需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。</strong> 也就是可以多次<code>git add .</code> ,之后再一次性<code>git commit</code></p><p>我对文件进行修改之后，<code>git status</code> 显示如下：</p><p><img src="https://i.loli.net/2020/09/01/qZ4JcAzCrBOQng5.png" alt="image-20200901003431025"></p><p>这是对文件进行了修改，但是未添加（add）到暂存区和提交（commit）到仓库分支。 并且出现了之前从未提交的文件（四张png图片）</p><p>然后<code>git add .</code>,再查看目前的状态 <code>git status</code></p><p><img src="https://i.loli.net/2020/09/01/leMQO9F83N5DxUq.png" alt="image-20200901003844459"></p><p>出现了绿色的<code>new file</code>字样和<code>modified</code>，代表已添加到缓存区。</p><p>现在，暂存区的状态就变成这样了（原文是添加的readme和LICENSE文件）：</p><p><img src="https://i.loli.net/2020/09/01/MHQiJkB674jcAE5.png" alt="image-20200901003951252"></p><p>所以，<code>git add</code>命令实际上就是把要提交的所有修改放到暂存区（index），然后，执行<code>git commit</code>就可以一次性把暂存区的所有修改提交到分支。</p><p><img src="https://i.loli.net/2020/09/01/1uzidT9knarwNMU.png" alt="image-20200901004202394"></p><p>这时候再 <code>git status</code>，则是干净的</p><p>现在版本库变成了这样，暂存区就没有任何内容了：</p><p><img src="https://i.loli.net/2020/09/01/kCXlv3FiurZNbIO.jpg" alt="git-stage-after-commit"></p><h4 id="小结-2">小结</h4><p>了解工作区和暂存区的概念，并通过例子加强<code>git status</code> 、<code>git add</code>、<code>git commit</code>的理解</p><p>如果不用<code>git add</code>到暂存区，那就不会加入到<code>commit</code>中。也就是说<code>commit</code>只会提交暂存区里的内容</p><h3 id="撤销修改">撤销修改</h3><h4 id="在工作区撤销修改">在工作区撤销修改</h4><p>在工作区写的内容想要撤销，当然可以手动删除。同时还有另外的一种方法</p><p><code>git status</code> 查看一下状态</p><p><img src="https://i.loli.net/2020/09/01/qT7BN95PkQeSumd.jpg" alt="img"></p><p>根据git提示，可以知道如下信息：</p><ol type="1"><li><code>changes not staged for commit</code>：表示没有更改添加到暂存区，也就是对于当前的修改还没有进行<code>add</code>操作</li></ol><p><img src="https://i.loli.net/2020/09/01/NfZ2vXuB4etLHxF.jpg" alt="img"></p><ol start="2" type="1"><li><p>可以看到修改的部分是<code>2020-08-31-git 进阶.md</code>文件，不能显示中文，所以用编码表示</p></li><li><p>同时<code>next</code>文件也做了修改。这个每次都有提示，猜想应该是因为next是我<code>clone</code>下来的文件，所以存在<code>.git</code>文件，将<code>.git</code>文件删除就ok了</p></li><li><p>提示显示，<code>git checkout -- file</code>可以丢弃工作区（work directory）的修改</p></li></ol><h5 id="git-checkout----file">git checkout -- file</h5><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git checkout -- <span class="built_in">source</span>/_posts/2020-08-31-git进阶.md （注意--不要遗漏，同时后面有一个空格）</span><br><span class="line"><span class="comment"># git checkout -- .  这种写法也是可以的，表示全部撤销</span></span><br></pre></td></tr></tbody></table></figure><p>命令<code>git checkout -- filename</code>意思就是，把<code>filename</code>文件在工作区的修改全部撤销，这里有两种情况：</p><ul><li>一种是文件自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态；</li><li>一种是文件已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。</li></ul><p>总之，就是让这个文件回到最近一次<code>git commit</code>或<code>git add</code>时的状态。</p><p><code>git checkout</code>其实是<strong>用版本库里的版本替换工作区的版本</strong>，无论工作区是修改还是删除，都可以“一键还原”。</p><h5 id="注">注</h5><ul><li>文件必须写当前git bash 下的完整路径，可以参考<code>git status</code>下的modified部分路径名称，如上的<code>source/_posts/</code></li><li>文件名必须写中文（就是正常的文件名），不能按照modified部分的编码后的名称</li></ul><p><img src="https://i.loli.net/2020/09/01/2l6Nxsh14bdpAY8.jpg" alt="img"></p><p>这是错误过程，可以看到最后一次没有提示，表示成功撤销修改</p><p>打开git进阶文件可以看到内容已经撤销</p><h4 id="添加到暂存区后的撤销">添加到暂存区后的撤销</h4><p>如果在工作区已经修改，并且添加到暂存区了，在<code>commit</code>之前，发现了这个问题。用<code>git status</code>查看一下，修改只是添加到了暂存区，还没有提交：</p><p><img src="https://i.loli.net/2020/09/01/CIASBwaTMEY3Gh1.png" alt="添加到暂存区前"></p><p><img src="https://i.loli.net/2020/09/01/T8jefu37XvFnZMJ.png" alt="添加到暂存区后"></p><ul><li>在添加到暂存区后，可以看到在<code>changes to be committed</code> 部分，添加的部分已经变成绿色，等待被<code>commit</code>提交</li><li>根据git提示，用命令<code>git reset HEAD &lt;file&gt;</code>可以把暂存区的修改撤销掉（<code>unstage</code>），重新放回工作区：</li></ul><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset HEAD .</span><br></pre></td></tr></tbody></table></figure><blockquote><p><code>git reset</code>命令既可以回退版本，也可以把暂存区的修改回退到工作区。当我们用<code>HEAD</code>时，表示最新的版本。</p></blockquote><p>撤销到工作区的内容可以根据上述内容撤销其修改</p><h4 id="提交到版本库后的撤销">提交到版本库后的撤销</h4><p>前提是<strong>还没有把自己的本地版本库推送到远程</strong>。</p><p>可以利用上述的<code>版本回退</code>功能</p><h4 id="小结-3">小结</h4><ul><li>场景1：当你改乱了<code>工作区</code>某个文件的内容，想直接丢弃工作区的修改时，用命令<code>git checkout -- file</code>。</li><li>场景2：当你不但改乱了工作区某个文件的内容，还<code>添加到了暂存区</code>时，想丢弃修改，分两步，第一步用命令<code>git reset HEAD &lt;file&gt;</code>，就回到了场景1，第二步按场景1操作，用命令<code>git checkout -- file</code>。</li><li>场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，参考<code>版本回退</code>，不过前提是没有推送到远程库。</li></ul><h3 id="远程仓库">远程仓库</h3><h4 id="section"></h4><p>已经在本地创建了一个Git仓库后，又想在GitHub创建一个Git仓库，并且让这两个仓库进行远程同步，这样，GitHub上的仓库既可以作为备份，又可以让其他人通过该仓库来协作。</p><p>首先，登陆GitHub，然后，在右上角找到“Create a new repo”按钮，创建一个新的仓库</p><p>在Repository name填入<code>shijian</code>，其他保持默认设置，点击“Create repository”按钮，就成功地创建了一个新的Git仓库。出现以下界面：</p><p><img src="https://i.loli.net/2020/09/01/vMnFmb9aQU6xuXp.png" alt="image-20200901142716798"></p><p>复制仓库的SSH链接</p><p>根据提示，可以返回到需要上传的文件夹目录下，右键选择<code>git bash</code></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git init  <span class="comment">#创建.git隐藏文件，用于本地仓库</span></span><br><span class="line"></span><br><span class="line">git remote add origin git@github.com:OopsAaron/shijian.git <span class="comment">#关联本地仓库和github远程仓库</span></span><br></pre></td></tr></tbody></table></figure><p>添加后，<strong>远程库的名字就是<code>origin</code></strong>，这是Git默认的叫法，也可以改成别的，但是<code>origin</code>这个名字一看就知道是远程库。</p><p>接下来就是git的基本三样操作，添加提交并推送</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">git add . <span class="comment">#添加当前文件夹下的所有文件</span></span><br><span class="line"></span><br><span class="line">git commit -m <span class="string">"first commit "</span> <span class="comment"># 引号内是本次的提交说明 </span></span><br><span class="line"></span><br><span class="line">git push -u origin master <span class="comment"># 提交本地分支到远程分支</span></span><br><span class="line">(若出现failed to push som refs to， 则执行git pull origin master，</span><br><span class="line">将远程服务器github上的master拉下来，再重新push)</span><br></pre></td></tr></tbody></table></figure><p>把本地库的内容推送到远程，用<code>git push</code>命令，实际上是把当前分支<code>master</code>推送到远程。这时候在github界面就可以看到推送的文件</p><blockquote><p>第一次push的时候可以添加参数 <code>-u</code> ，之后可以不添加</p><p>由于远程库是空的，我们第一次推送<code>master</code>分支时，加上了<code>-u</code>参数，Git不但会把本地的<code>master</code>分支内容推送的远程新的<code>master</code>分支，还会把本地的<code>master</code>分支和远程的<code>master</code>分支关联起来，在以后的推送或者拉取时就可以简化命令。</p></blockquote><h4 id="section-1"></h4><h3 id="分支">分支</h3><p>分支暂时用不到，就没有学习</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      不断更新 ，在实践中总结git知识点。
    
    </summary>
    
    
      <category term="git" scheme="http://yoursite.com/categories/git/"/>
    
    
      <category term="git" scheme="http://yoursite.com/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-30-阅读论文</title>
    <link href="http://yoursite.com/2020/08/30/2020-08-30-%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87/"/>
    <id>http://yoursite.com/2020/08/30/2020-08-30-%E9%98%85%E8%AF%BB%E8%AE%BA%E6%96%87/</id>
    <published>2020-08-30T07:11:28.000Z</published>
    <updated>2020-09-05T06:42:17.124Z</updated>
    
    <content type="html"><![CDATA[<p>一篇论文至少要看三遍。 第一遍，仔细阅读论文中的标题、摘要和关键词。 第二遍，阅读文中的导言、结论以及图表，快速扫描一下论文剩下的内容。 这一步主要是要把握论文中的关键信息，不光是导言和结论，还包括文章中任何小结论的总 结，文中涉及的补充信息都跳过。 第三遍，阅读论文的整个部分，但是要跳过任何可能陌生看不懂的数学公式，技术术语。</p><p>不过，如果你需要对这个专业领域有一个「深入」的理解，那就必须要搞懂那些公式术语 了。</p><blockquote><p>参考</p><p><a href="https://mp.weixin.qq.com/s?__biz=MzA5ODEzMjIyMA==&amp;mid=2247501483&amp;idx=1&amp;sn=9b21f8e62fa2b4b33045900a1e721d30&amp;chksm=9094cf38a7e3462ed5901bd8b0b8ebf99a892b31d75aa6eaf8b3c8cc7698b1d708fd0891ab3e&amp;mpshare=1&amp;scene=1&amp;srcid=08304BRBOlTyXb4qDBM5SGTj&amp;sharer_sharetime=1598771438122&amp;sharer_shareid=2c9f868695c34cf5ff5f7a42eab3d2ed&amp;key=9b9af4fa8e2c96d71311b901f9c755ada338c70880cf596dfe4bc2b5ca69cfb094a0a310cf713fb50591ef0933e5f438e73110d797ab7406eeefa5dd5f4c460076a3e94537447c235df683c3eb24a048c7472ad2cdef063ec759505ebb6902987eb9a08ca55be656525ace69f39c8cdbedf7f2b71fa3d2c7c2c4b0dd2e660589&amp;ascene=1&amp;uin=ODEyNzQwMTM5&amp;devicetype=Windows+10+x64&amp;version=62090529&amp;lang=zh_CN&amp;exportkey=A4y9BBn%2B1GAGlkX0mhK71n0%3D&amp;pass_ticket=tS9Bcx3H%2FQ34yaxv%2F0nHTttU4aZeBoKDlw2k4Zwl5JMpqZkqPjEwcrpqIlAybtka" target="_blank" rel="noopener">沈向阳：读论文的三个层次</a></p><p><a href="https://www.youtube.com/watch?v=Du7qLsToW-o&amp;t=443s" target="_blank" rel="noopener">youtube视频，沈向阳读论文</a></p><p><a href="https://mp.weixin.qq.com/s?subscene=19&amp;__biz=MzIzNjc1NzUzMw==&amp;mid=2247546863&amp;idx=2&amp;sn=275577791d4cee894bd874eedc846f88&amp;chksm=e8d0809ddfa7098b90f2d601d59c1ea11162180387dd9677a96c03e666c1b1e05f8e719d989e&amp;scene=7&amp;ascene=1&amp;devicetype=Windows+10+x64&amp;version=62090529&amp;nettype=cmnet&amp;abtest_cookie=AAACAA%3D%3D&amp;lang=zh_CN&amp;exportkey=Ax%2BhWVV2Xr753%2BtDF%2BAIKRw%3D&amp;pass_ticket=sT%2F05g2Sqp72CoAfTsiZ8TDrxTKg0f%2FTh968brMSrSyOqE%2F1GuTq0PTOveYYBqof&amp;wx_header=0&amp;key=573aef4c1f9b4b5fc4e631a99eb0547e4182bf3ee5dd048cf4487f739b93c9b004f67e751713dea6880a5a922c03ceb30730558ff6be83d973abec53f6fb592491c98a1e205921d9c380c59d6f30c92ea2b1836956318f54b99e962b4d620a7ca074f2e317b259e495570360cc981c43758194fb5e38587a176b8af431cca351&amp;uin=ODEyNzQwMTM5" target="_blank" rel="noopener">吴恩达教你如何读论文：绘制进度表格，论文至少看三遍，还要问自己问题</a></p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      阅读沈向阳教授的《读论文的三个层次》总结
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-08-27-edge还原到旧版本问题</title>
    <link href="http://yoursite.com/2020/08/27/2020-08-27-edge%E8%BF%98%E5%8E%9F%E5%88%B0%E6%97%A7%E7%89%88%E6%9C%AC%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2020/08/27/2020-08-27-edge%E8%BF%98%E5%8E%9F%E5%88%B0%E6%97%A7%E7%89%88%E6%9C%AC%E9%97%AE%E9%A2%98/</id>
    <published>2020-08-27T02:06:02.000Z</published>
    <updated>2020-09-04T07:00:20.595Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言">前言</h3><p>win10自动更新edge，但是新版的edge用的是Chromium内核，新功能添加不少，也全部支持chrome的插件，但是对pdf的支持不友好，和chrome一个德行<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f611.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f611.png?v8">😑</span>。导致我在旧版本edge阅读论文时做的笔记在新版edge体验感极差，于是想着回退到旧版本 （edge不就是用来阅读论文的 ）<span class="github-emoji" style="display:inline;vertical-align:middle;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8">😆</span></p><h3 id="版本回退">版本回退</h3><p>百度后发现将新版本的edge删除，就可以自己回退到旧版本的edge</p><p>geek<code>强制删除</code>新版edge之后，系统回退到旧版edge了。但是同时发现原来的一些设置消失了，系统不太稳定，可能是强制删除了一些系统配置文件。不太清楚具体原因，待解决</p><p>导致如下两个功能消失</p><ul><li>在开始栏中不显示安装的软件</li><li>在文件夹右键不能使用<code>发送到</code>功能</li></ul><p>目前发现这两个不能使用的功能。可能还存在其它故障。平时经常通过<code>开始栏</code>打开软件，不显示之后有点麻烦</p><h3 id="解决">解决</h3><p>用<code>listary</code>软件快速搜索软件名称，（双击ctrl键打开搜索框），然后添加到Rolan中，如图所示</p><p><img src="https://i.loli.net/2020/09/04/Kbk3ERwsMJ9AhlP.png" alt="image-20200904145340602" style="zoom:80%;"></p><h3 id="小结">小结</h3><ul><li>下次还是少用geek强制删除吧，乖乖在<code>程序与功能</code>中卸载删除吧，有可能涉及系统配置文件的就不要轻易删除</li><li>等待新版edge友好支持论文阅读</li></ul><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      edge还原到旧版本出现的问题
    
    </summary>
    
    
    
      <category term="故障排除" scheme="http://yoursite.com/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-25-chrome插件</title>
    <link href="http://yoursite.com/2020/08/25/2020-08-25-chrome%E6%8F%92%E4%BB%B6/"/>
    <id>http://yoursite.com/2020/08/25/2020-08-25-chrome%E6%8F%92%E4%BB%B6/</id>
    <published>2020-08-25T12:21:35.000Z</published>
    <updated>2020-08-31T12:16:47.636Z</updated>
    
    <content type="html"><![CDATA[<h3 id="下载提速"><strong>下载提速</strong></h3><ul><li><h4 id="使用场景"><strong>使用场景</strong></h4></li></ul><p>Chrome的下载速度，有时候确实是慢得可以跟某网盘相媲美了，甚至赶不上某些国产浏览器。</p><p>这是因为，Google为了兼容所有的电脑性能和带宽，在Chrome中采取的是保守<strong>单线程下载机制</strong>，这就导致很多时候下载速度非常慢了。</p><p><img src="https://i.loli.net/2020/08/25/5ZMgPIUfc2YndtE.png" alt="img"></p><p>不过，很多人都不知道的是，Chrome其实也是自带多线程下载功能的。所谓多线程下载，就是可以同时对资源建立多个连接，提升下载速度。</p><p>只是这个功能是默认关闭的，需要用户手动去开启。</p><ul><li><h4 id="使用方法"><strong>使用方法</strong></h4></li></ul><p>在浏览器地址栏输入以下网址并回车：</p><p><strong>chrome://flags/#enable-parallel-downloading</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D1XlU0QfU3GnNfPmPtO4D3rncDTK3kFcCxQMtjnyMUqI5hTIZydfXEDTnp06YjKEBIbdlnvUoFj3ht3ibXUatiaw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img"></p><p>在Parallel downloading的后面选项里，把「default」改为「Enabled」，并按照提示重启浏览器。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D1XlU0QfU3GnNfPmPtO4D3rncDTK3kFcYca3x5SEBJpOky2icdUADwP04jUYiaib6WvUQZ9XlSNHdeiach2RMydRGg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img"></p><p>这样就可以开启多线程下载了，经过实际测试，下载速度至少提高了三倍左右（也有可能下载速度飙升一段时间又跌回去）。</p><h3 id="link-to-text-fragment">Link to Text Fragment</h3><p>实际上就是带锚点功能的网页分享工具。</p><p>所谓锚文本，简单来说就像是关键词的定位，将关键字指向指向另一个页面的链接就是锚文本。这个工具则可以让你将网页上选中的文本片段生成为一个锚文本。</p><p><strong>当你点击这个锚文本时，就会直接跳转到该网页对应标记的锚点上了。</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D1XlU0QfU3FtLAG0sobAP0xrYk6LJk6m3AU0icjVgSjiavYp3msxibjM7D9U6PXFbzm4wUeZ6OkaFibhPXLFeIBLOQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img"></p><h4 id="使用方法-1"><strong>使用方法</strong></h4><h5 id="生成锚文本"><strong>生成锚文本</strong></h5><p>鼠标划词选中文本，在右键菜单中选择【Copy Link to Text Fragment】，然后可以看到该文本被黄色标记。</p><p><img src="https://i.loli.net/2020/08/25/ns29PiDENtvJp3R.gif" alt="img"></p><h5 id="打开锚文本"><strong>打开锚文本</strong></h5><p>此时，锚文本已经自动生成并复制到你的剪贴板上，你可以将它发送给需要分享的好友，或者在浏览器中打开，另存为书签。</p><p>可以看到，在浏览器内打开这个锚文本，网页会自动定位到我们做了锚点的文本部分，再也不需要我们自行阅读查找，非常方便。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/D1XlU0QfU3FtLAG0sobAP0xrYk6LJk6m5F5vhCQoN8IeaxDibdMzqk2jFVjhDDhGMJdY3ZHpibCicN5yWbsRoN9Bg/640?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt="img"></p><p>需要注意的是，这个锚文本也<strong>仅限在安装了Link to Text Fragment插件的浏览器上打开</strong>，若没有安装则不会跳转对应位置。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      记录用到的chrome插件
    
    </summary>
    
    
      <category term="chrome" scheme="http://yoursite.com/categories/chrome/"/>
    
    
      <category term="chrome" scheme="http://yoursite.com/tags/chrome/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-23-google搜索的高效使用</title>
    <link href="http://yoursite.com/2020/08/23/2020-08-23-google%E6%90%9C%E7%B4%A2%E7%9A%84%E9%AB%98%E6%95%88%E4%BD%BF%E7%94%A8/"/>
    <id>http://yoursite.com/2020/08/23/2020-08-23-google%E6%90%9C%E7%B4%A2%E7%9A%84%E9%AB%98%E6%95%88%E4%BD%BF%E7%94%A8/</id>
    <published>2020-08-23T09:04:44.000Z</published>
    <updated>2020-08-24T11:51:36.784Z</updated>
    
    <content type="html"><![CDATA[<h3 id="section">“”</h3><p>以整个短语作为搜索关键词，而不是拆开成每个词。</p><p>表示完全匹配，结果中必须出现与搜索文本完全相同的内容。</p><h3 id="a--b">A -B</h3><p>搜索包含A但不包含B的结果（请注意A后面的<strong>空格不能省略</strong>）</p><p><img src="https://i.loli.net/2020/08/23/pjDWIreKGtJU7Oa.png" alt="image-20200823173525379" style="zoom: 67%;"></p><p>当加上 <code>-poweredge</code> 时，就可以屏蔽掉机架式服务器关键字中所有含有poweredge的内容</p><p><img src="https://i.loli.net/2020/08/23/k2vbVtdCMBYzJfQ.png" alt="image-20200823173614387" style="zoom:67%;"></p><h3 id="filetype">filetype</h3><p>搜索对应类型的文件。例如：<code>时间简史 filetype:pdf</code>，即为搜索包含关键字时间简史的pdf文件。（请注意<strong>使用英文的冒号</strong>） （一般不加filetype也可以）</p><p><img src="https://i.loli.net/2020/08/23/UBJHv4YmfiGRhuy.png" alt="image-20200823174000514" style="zoom:67%;"></p><h3 id="site">site</h3><p>在某个网站内搜索，比如：site:<a href="https://link.zhihu.com/?target=http%3A//pan.baidu.com">http://pan.baidu.com</a> 特别好用，用来搜百度云里的资源。再如：</p><p>在我们实验室网站查找<code>招生</code>关键字，则 <code>招生 site:http://www.ubinec.org/</code>，十分便捷。</p><p>（直接招生 site:ubinec.org/ 也可以 ，中间不要加空格 ）</p><p><img src="https://i.loli.net/2020/08/24/aypbHTDAnF79CIi.png" alt="image-20200824160653772" style="zoom:67%;"></p><h3 id="section-1">*</h3><p>很多时候想搜一个东西但是不确定具体名字，可以用星号代替忘了的字，可以代替多个字</p><h3 id="define">define</h3><p><strong>当字典或快速查找意思</strong>，如[define:right]，还能看到单词在书籍中出现频率的年代变化，词源等；</p><p><img src="https://i.loli.net/2020/08/24/skUBwAFtVMm6OWJ.png" alt="image-20200824162755266" style="zoom:67%;"></p><h3 id="section-2">~</h3><p>同时搜索近义词。如搜“higher education” 和 “university”</p><h3 id="or-或逻辑">OR (或)逻辑</h3><p>通过<em>OR</em> 搜索, 可以得到和两个关键词分别相关的结果, 而不仅仅是和两个关键词都同时相关的结果.</p><p><img src="E:\myBlog\source\_posts\image-20200824193744947.png" alt="image-20200824193744947" style="zoom:67%;"></p><p><img src="E:\myBlog\source\_posts\image-20200824193731306.png" alt="image-20200824193731306" style="zoom:67%;"></p><h3 id="限定年份">限定年份</h3><ol type="1"><li>在google工具选项中可以选择时间</li></ol><p><img src="E:\myBlog\source\_posts\image-20200824194504266.png" alt="image-20200824194504266" style="zoom:67%;"></p><ol start="2" type="1"><li><code>世界杯 2010..2014</code></li></ol><h3 id="参考">参考</h3><p><img src="https://i.loli.net/2020/08/24/uqRyUOdYnGJbxHN.jpg" alt="preview"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      高效利用google搜索，记录使用技巧
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-08-19-期望、方差、协方差及相关系数的基本运算</title>
    <link href="http://yoursite.com/2020/08/19/2020-08-19-%E6%9C%9F%E6%9C%9B%E3%80%81%E6%96%B9%E5%B7%AE%E3%80%81%E5%8D%8F%E6%96%B9%E5%B7%AE%E5%8F%8A%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%BF%90%E7%AE%97/"/>
    <id>http://yoursite.com/2020/08/19/2020-08-19-%E6%9C%9F%E6%9C%9B%E3%80%81%E6%96%B9%E5%B7%AE%E3%80%81%E5%8D%8F%E6%96%B9%E5%B7%AE%E5%8F%8A%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%BF%90%E7%AE%97/</id>
    <published>2020-08-19T12:17:59.000Z</published>
    <updated>2020-08-19T13:21:26.236Z</updated>
    
    <content type="html"><![CDATA[<p>链接</p><p>https://blog.csdn.net/touristman5/article/details/56281887</p><p>https://developer.aliyun.com/article/65262</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;链接&lt;/p&gt;
&lt;p&gt;https://blog.csdn.net/touristman5/article/details/56281887&lt;/p&gt;
&lt;p&gt;https://developer.aliyun.com/article/65262&lt;/p&gt;
&lt;script&gt;
     
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>2020-08-19-解读卡尔曼滤波[第二部分]</title>
    <link href="http://yoursite.com/2020/08/19/2020-08-19-%E8%A7%A3%E8%AF%BB%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86/"/>
    <id>http://yoursite.com/2020/08/19/2020-08-19-%E8%A7%A3%E8%AF%BB%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86/</id>
    <published>2020-08-19T06:41:38.000Z</published>
    <updated>2020-08-30T07:21:51.102Z</updated>
    
    <content type="html"><![CDATA[<p>在开始之前，我想解释几个基本术语，如方差（variance）、标准差（standard deviation）、估计值（estimate）、准确度（accuracy）、精度（precision）、平均值（mean）和期望值（expected value）。</p><p>我想本教程的许多读者都熟悉基本统计学知识。但是，在本教程的开头，我承诺提供理解卡尔曼滤波器操作所需的必要背景知识。如果您熟悉这个主题，可以跳过它。</p><ul><li><strong>平均值与期望值</strong></li></ul><p>虽然<strong>平均值(mean)</strong>与<strong>期望值（expected value）</strong>是密切相关的术语。但是，它们是不同的。</p><p>例如，假设有五种不同的硬币——两个5美分的硬币和三个10美分的硬币，我们可以通过平均硬币的价值来轻松计算硬币的平均值。</p><p><img src="https://i.loli.net/2020/08/19/JxTbfDa2QOrz4oj.png" alt="image-20200819144207768"></p><p>上述结果不能被定义为期望值，因为系统状态（硬币值）没有被隐藏（想要表达的是确定的，此处没有任何不确定性），我们已经使用了所有的population（所有5枚硬币）来计算平均值。</p><p><strong>译者补充：因为很多同学经常混淆平均值与期望值的概念，因此，我在此特别解释一下。在解释两个概念之前，先说一下“大数法则”。</strong></p><ul><li>先说一下大数法则：</li></ul><p><img src="https://i.loli.net/2020/08/19/cHPovqVb2RFOS3r.jpg" alt="img"></p><ul><li>思考一下为什么会用到期望值？</li></ul><p><img src="https://i.loli.net/2020/08/19/F6K9M4aPrJxgnOS.jpg" alt="img"></p><p><img src="https://i.loli.net/2020/08/19/1QKexZgmNF6STPt.jpg" alt="img"></p><p>期望值也就是每个数*对应的概率值，再求和</p><p><strong>译者补充完毕。</strong></p><p>现在假设同一个人的五个不同的体重测量值：79.8kg，80kg，80.1kg，79.8kg和80.2kg。</p><p>由于秤的随机测量误差，称重测量值不同。 我们不知道准确的重量值是多少，因为它是一个<strong>隐藏变量Hidden Variable</strong>。 但是，我们可以通过平均尺度测量来估计重量。 （准确测量值不可知）</p><p><img src="https://i.loli.net/2020/08/19/PjARubvWoLmEV5U.png" alt="image-20200819145014158"></p><p>估计的结果是体重的期望值。</p><p>平均数经常使用希腊字母：<strong>μ</strong></p><p>期望值使用字母：<strong>E</strong></p><ul><li><strong>方差与标准差</strong></li></ul><p>方差用来度量随机变量与其期望值（即随机变量的期望值）之间的离散程度。</p><p>标准差是方差的平方根。标准差： <img src="https://www.zhihu.com/equation?tex=%5Csigma" alt="[公式]"> ，方差： <img src="https://www.zhihu.com/equation?tex=%5Csigma%5E%7B2%7D" alt="[公式]"></p><p>例如，我们想比较两个高中篮球队的身高。下表提供了两支球队的球员身高及其平均值。</p><p><img src="https://pic4.zhimg.com/80/v2-d6b2fea25722ffe4774167c3ca530177_1440w.png" alt="img"></p><p>如我们所见，两队的平均身高是一样的。现在让我们检查一下高度变化height variance。</p><p>由于方差用来度量随机变量与其期望值（即随机变量的期望值）之间的离散程度，我们想知道数据集偏离其平均值的情况。我们可以通过从每个变量中减去平均值来计算每个变量与平均值之间的距离。</p><p>我们将用x表示高度，用希腊字母μ表示高度的平均值。每个变量与平均值的距离为：</p><p><img src="https://pic1.zhimg.com/80/v2-8aeb370b55ec20c81cd6fb0ea1581a60_1440w.jpg" alt="img"></p><p>下表给出了每个变量与平均值之间的距离。</p><p><img src="https://picb.zhimg.com/80/v2-47a3cbd7c92a22bc2c1b532557d90609_1440w.png" alt="img"></p><p>下表给出了每个变量与平均值的平方距离。</p><p>有些值是负数。为了消除负值影响，让我们将高度与平均值的距离平方：</p><p><img src="https://picb.zhimg.com/80/v2-2bcc387a3d7e0da6267b04936c845c17_1440w.jpg" alt="img"></p><p><img src="https://pic4.zhimg.com/80/v2-759cb19ebbc545066259cfefb22237fb_1440w.png" alt="img"></p><p>为了计算数据集的离散程度，我们需要从中找出所有平方距离的平均值：</p><p><img src="https://pic2.zhimg.com/80/v2-0d382cddfdce473dfc744a382782c5ac_1440w.jpg" alt="img"></p><p>A队的方差是：</p><p><img src="https://pic3.zhimg.com/80/v2-9cc05c08921aab36b395d5b42134c911_1440w.png" alt="img"></p><p>B队的方差是：</p><p><img src="https://pic2.zhimg.com/80/v2-2b935f764b16ebf4b3420fd0f25574a5_1440w.png" alt="img"></p><p>我们可以看出，虽然两队的平均值相同，但A队的身高分布值高于B队的身高分布值，这意味着A队在控球员、中锋和后卫等不同位置有不同的球员，而B队球员则技能相差无几。</p><p>方差的单位是平方的；查看标准差更方便。正如我已经提到的，标准差是方差的平方根。</p><p><img src="https://pic1.zhimg.com/80/v2-4e5b9f3338566969fe0523fa06731489_1440w.jpg" alt="img"></p><p>A队运动员身高的标准差为0.12米。</p><p>B队运动员身高的标准差为0.036米。</p><p>进一步的，现在，假设我们要计算所有高中篮球运动员的平均值和方差。这是一项非常艰巨的任务，我们需要收集所有高中运动员的数据。</p><p>但是，我们可以通过选择一个大的数据集并对这个数据集进行计算来估计参与者的平均值和方差。（样本估计全局）</p><p>随机选取的100名选手的数据集足以进行准确的估计。</p><p>然而，当我们<strong>估计方差</strong>时，方差计算公式略有不同。我们不用N因子归一化，而是用N - 1因子归一化:</p><p><img src="https://pic1.zhimg.com/80/v2-9045e0012dc9592019009cca6c64f97f_1440w.jpg" alt="img"></p><p>你可以在以下资源中看到这个方程的数学证明：<a href="https://link.zhihu.com/?target=http%3A//www.visiondummy.com/2014/03/divide-variance-n-1/">http://www.visiondummy.com/2014/03/divide-variance-n-1/</a></p><hr><ul><li><strong>正态分布</strong></li></ul><p>事实证明，许多自然现象服从正态分布。继续以篮球运动员身高为例，如果随机选取运动员，构建大数据集，绘制身高VS.身高（heights vs. heights）的频率曲线图，得到“钟形”曲线，如下图所示:</p><p><img src="https://pic4.zhimg.com/80/v2-ca75549d80903118ac9a6ac08b58debc_1440w.jpg" alt="img"></p><p>正如你所看到的，这条曲线关于平均值（平均值是1.9米）对称。平均值附近值的频率高于远处值的频率。</p><p>高度的标准差等于0.2米。68.26%的值在平均值的一个标准差内。如下图所示，68.26%的值介于1.7米和2.1米之间（绿色区域占曲线下总面积的68.26%）。</p><p><img src="https://pic2.zhimg.com/80/v2-0f51f3a38d61049e8dc5dd18e363c114_1440w.jpg" alt="img"></p><p>95.44%的值在距离平均值的两个标准差内。</p><p>99.74%的值在距离平均值的三个标准差内。</p><p>正态分布，也称为高斯分布（它以数学家Carl Friedrich Gauss的名字命名），由以下方程描述：</p><p><img src="https://pic4.zhimg.com/80/v2-e4aee9ac01b76d9d688929e3d07ae69e_1440w.jpg" alt="img"></p><p>通常，测量误差是正态分布的，因此<code>卡尔曼滤波器设计基于测量误差是正态分布的假设。</code></p><hr><ul><li><strong>估计、准确度与精度</strong></li></ul><p><strong>— 估计（Estimate）：</strong>评估系统的隐藏状态。飞机的真实位置对观察者来说是隐藏的。我们可以用雷达等传感器来估计飞机的位置。采用多传感器和先进的估计跟踪算法（如卡尔曼滤波），可以显著提高估计精度。每一个测量或计算参数都是一个估计值。</p><p><strong>— 准确度（Accuracy）：</strong>表明测量值与真实值的接近程度。</p><p><strong>— 精度（Precision）：</strong>描述同一参数的许多 度量值中有多少可变性。准确度和精度是估算的基础。</p><p>下图说明了准确度和精度。</p><p><img src="https://pic3.zhimg.com/80/v2-7a1dfe3f5186ade70b8937099fb180a8_1440w.jpg" alt="img"></p><p><strong>高精度系统的测量方差较低</strong>（即不确定度/离散程度/变化程度较低），而低精度系统的测量方差较大（即不确定度/离散程度/变化程度较高）。方差是由随机测量误差产生的。</p><p>低精度系统被称为偏差系统，因为它们的测量具有内置的系统误差（偏差）。</p><p>通过<strong>平均或平滑测量</strong>可以显著降低方差的影响。例如，如果我们使用一个具有随机测量误差的温度计来测量温度，我们可以进行多次测量并对测量的值进行平均。由于误差是随机的，所以有些测量值会高于真实值，而另一些测量值会低于真实值。我们做的测量越多，估计就越接近。</p><p>另一方面，如果温度计有偏差，估计将包括一个恒定的系统误差。</p><p>本教程中的所有示例都假定系统是无偏差的。</p><p><img src="E:\myBlog\source_posts\image-20200819194609812.png" alt="image-20200819194609812"></p><p>极小化性能指标： 最优解</p><p><img src="E:\myBlog\source_posts\image-20200819195511498.png" alt="image-20200819195511498"></p><p>J就是选择能够令方差 <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%7B%28%7BX_%7Bi%7D%7D%28%5Ctheta_%7Bhat%7D%29-%5Cmu%29%5E2%7D" alt="[公式]"> 最小的的参数。 X^就是最优解</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      对卡尔曼滤波知识点的总结
    
    </summary>
    
    
      <category term="研究方向" scheme="http://yoursite.com/categories/%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91/"/>
    
    
      <category term="卡尔曼滤波" scheme="http://yoursite.com/tags/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2/"/>
    
      <category term="RKN" scheme="http://yoursite.com/tags/RKN/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-18-解决hexo发布文章报错</title>
    <link href="http://yoursite.com/2020/08/18/2020-08-18-%E8%A7%A3%E5%86%B3hexo%E5%8F%91%E5%B8%83%E6%96%87%E7%AB%A0%E6%8A%A5%E9%94%99/"/>
    <id>http://yoursite.com/2020/08/18/2020-08-18-%E8%A7%A3%E5%86%B3hexo%E5%8F%91%E5%B8%83%E6%96%87%E7%AB%A0%E6%8A%A5%E9%94%99/</id>
    <published>2020-08-17T18:35:28.000Z</published>
    <updated>2020-09-04T15:35:27.152Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言">前言</h3><p>在进行<code>hexo s -g</code> 发布文章时，出现如下错误</p><p><img src="https://i.loli.net/2020/08/18/p17vthyDgEBlukC.png" alt="image-20200818023730784"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      解决hexo发布文章报错can not read a block mapping entry
    
    </summary>
    
    
      <category term="故障排除" scheme="http://yoursite.com/categories/%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4/"/>
    
    
      <category term="故障排除" scheme="http://yoursite.com/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4/"/>
    
      <category term="next" scheme="http://yoursite.com/tags/next/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-18-解决图片caption出现多次</title>
    <link href="http://yoursite.com/2020/08/18/2020-08-18-%E8%A7%A3%E5%86%B3%E5%9B%BE%E7%89%87caption%E5%87%BA%E7%8E%B0%E5%A4%9A%E6%AC%A1/"/>
    <id>http://yoursite.com/2020/08/18/2020-08-18-%E8%A7%A3%E5%86%B3%E5%9B%BE%E7%89%87caption%E5%87%BA%E7%8E%B0%E5%A4%9A%E6%AC%A1/</id>
    <published>2020-08-17T18:19:41.000Z</published>
    <updated>2020-08-18T03:01:15.026Z</updated>
    
    <content type="html"><![CDATA[<p>大部分参考自<a href="https://wylu.github.io/posts/7bd83fc5/" target="_blank" rel="noopener">Hexo NexT 图片caption出现多次</a></p><p>在使用 Hexo + NexT 搭建个人博客的过程中一直有个问题没有解决，直到今天才找到了解决方法。问题就是在展示同一张图片中，caption出现了两次，如图：</p><p><a href="https://cdn.jsdelivr.net/gh/wylu/cdn/post/Tool/Hexo/Hexo-NexT-图片caption出现多次/multiple-captions.png" target="_blank" rel="noopener"><img src="https://cdn.jsdelivr.net/gh/wylu/cdn/post/Tool/Hexo/Hexo-NexT-图片caption出现多次/multiple-captions.png" alt="multiple-captions"></a></p><h3 id="问题分析">问题分析</h3><p>图片正下方的 image-caption 是 NexT 给 fancybox 加上的；而图片左下方的 figcaption 是因为使用了 hexo-renderer-pandoc Markdown 渲染器导致的，hexo-renderer-pandoc 将 Markdown 文件渲染成 HTML 时，会对图片进行渲染，然后生成一个 figcaption 的标签。</p><p>很多人可能不会有这样的问题，因为 Hexo 默认的 Markdown 渲染器是 hexo-renderer-marked，hexo-renderer-marked 渲染图片时不会生成 figcaption。</p><p>如果你使用的是 hexo-renderer-marked 渲染器，就不会有这样的问题，但是相信很多人都是因为需要使用 mathjax，所以都将默认的 Hexo 默认的 Markdown 渲染器换成了 hexo-renderer-pandoc，hexo-renderer-pandoc 功能强大（依赖与 pandoc 自身强大的功能），它对数学公式的渲染简直可以说是吊打 hexo-renderer-marked，这也是我一直使用它的原因。</p><p>所以为了在使用 hexo-renderer-pandoc 的同时，把图片 caption 出现了两次的问题解决，我提过 issue，查阅了许多资料，终于找到了解决的方法。</p><h3 id="解决方法">解决方法</h3><p>编辑站点配置文件 <code>_config.yml</code>，添加如下内容：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pandoc:</span><br><span class="line">  extensions:</span><br><span class="line">    - '-implicit_figures'</span><br></pre></td></tr></tbody></table></figure><p>执行下列命令重新生成站点，展示效果如下：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo clean &amp;&amp; hexo g &amp;&amp; hexo s -o</span><br></pre></td></tr></tbody></table></figure><p><a href="https://cdn.jsdelivr.net/gh/wylu/cdn/post/Tool/Hexo/Hexo-NexT-图片caption出现多次/single-caption.png" target="_blank" rel="noopener"><img src="https://cdn.jsdelivr.net/gh/wylu/cdn/post/Tool/Hexo/Hexo-NexT-图片caption出现多次/single-caption.png" alt="single-caption"></a></p><h3 id="隐藏-fancybox-的-caption">隐藏 fancybox 的 caption</h3><p>以 NexT v7.7.0 为例，通过查看 hexo-theme-next/source/js/utils.js 源码，发现 NexT 在使用 fancybox 时，如果图片 title 或 alt 属性不为空时，就会 fancybox 添加一个子标签展示图片的 title 或 alt 属性值。</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">var imageTitle = $image.attr('title') || $image.attr('alt');</span><br><span class="line">if (imageTitle) {</span><br><span class="line">  $imageWrapLink.append(`&lt;p class="image-caption"&gt;${imageTitle}&lt;/p&gt;`);</span><br><span class="line">  // Make sure img title tag will show correctly in fancybox</span><br><span class="line">  $imageWrapLink.attr('title', imageTitle).attr('data-caption', imageTitle);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>如果想通过配置支持选择是否展示 caption，可以参考下方的方法（在 NexT v7.7.0 已测试过），其实不管 NexT 的版本如何，解决方法的思路基本是一致的。</p><p>首先修改主题配置文件 <code>_config.yml</code>，找到 fancybox 的配置，将 fancybox 的配置改成如下所示内容：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># FancyBox is a tool that offers a nice and elegant way to add zooming functionality for images.</span><br><span class="line"># For more information: https://fancyapps.com/fancybox</span><br><span class="line">fancybox: </span><br><span class="line">  enable: true</span><br><span class="line">  caption: false</span><br></pre></td></tr></tbody></table></figure><p>其中，enable 控制是否启用 fancybox，而 caption 控制是否展示 caption (当然只有在 enable 为 true 时，caption 配置才有效)，如果你不启用 fancybox 自然也不会有 caption。</p><p>然后，编辑 hexo-theme-next/source/js/utils.js 文件，将上面的代码修改成如下内容：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">var imageTitle = $image.attr('title') || $image.attr('alt');</span><br><span class="line">if (imageTitle) {</span><br><span class="line">  if (CONFIG.fancybox.caption) {</span><br><span class="line">    $imageWrapLink.append(`&lt;p class="image-caption"&gt;${imageTitle}&lt;/p&gt;`);</span><br><span class="line">  }</span><br><span class="line">  // Make sure img title tag will show correctly in fancybox</span><br><span class="line">  $imageWrapLink.attr('title', imageTitle).attr('data-caption', imageTitle);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p>接着，编辑 hexo-theme-next/source/js/next-boot.js 文件，将 <code>CONFIG.fancybox &amp;&amp; NexT.utils.wrapImageWithFancyBox();</code> 替换成如下内容：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Register JS handlers by condition option.</span><br><span class="line"> * Need to add config option in Front-End at 'layout/_partials/head.swig' file.</span><br><span class="line"> */</span><br><span class="line">CONFIG.fancybox.enable &amp;&amp; NexT.utils.wrapImageWithFancyBox();</span><br></pre></td></tr></tbody></table></figure><p>相信你可以发现，我们这里将 <code>CONFIG.fancybox</code> 替换成 <code>CONFIG.fancybox.enable</code>，正是因为我们自定义的配置是通过 fancybox 下的 enable 的值来确定是否启用的。另外从源码上方的注释可以看到，CONFIG 下的配置项需要在前端文件 'layout/_partials/head.swig' （实际上该文件在'layout/_partials/head/head.swig'）中加上。</p><p>所以最后，我们需要在 <code>layout/_partials/head/head.swig</code> 中修改一下上面我们所使用 <code>CONFIG.fancybox.caption</code> 配置。参照其它配置，这里需要将 <code>fancybox:</code>，修改成如下内容：</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fancybox: {{ theme.fancybox | json }}</span><br></pre></td></tr></tbody></table></figure><p>重新生成，效果如下：</p><p><a href="https://cdn.jsdelivr.net/gh/wylu/cdn/post/Tool/Hexo/Hexo-NexT-图片caption出现多次/no-caption.png" target="_blank" rel="noopener"><img src="https://cdn.jsdelivr.net/gh/wylu/cdn/post/Tool/Hexo/Hexo-NexT-%E5%9B%BE%E7%89%87caption%E5%87%BA%E7%8E%B0%E5%A4%9A%E6%AC%A1/no-caption.png" alt="no-caption"></a></p><blockquote><h3 id="references">References</h3><p>https://github.com/wzpan/hexo-renderer-pandoc/issues/34</p><p>https://github.com/theme-next/hexo-theme-next/issues/857</p></blockquote><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      解决fancybox中图片的标题出现多次
    
    </summary>
    
    
      <category term="故障排除" scheme="http://yoursite.com/categories/%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4/"/>
    
    
      <category term="故障排除" scheme="http://yoursite.com/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4/"/>
    
      <category term="next" scheme="http://yoursite.com/tags/next/"/>
    
  </entry>
  
  <entry>
    <title>2020-08-16-服务器检修</title>
    <link href="http://yoursite.com/2020/08/16/2020-08-16-%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%A3%80%E4%BF%AE/"/>
    <id>http://yoursite.com/2020/08/16/2020-08-16-%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%A3%80%E4%BF%AE/</id>
    <published>2020-08-16T07:27:19.000Z</published>
    <updated>2020-09-08T15:22:34.883Z</updated>
    
    <content type="html"><![CDATA[<h3 id="前言">前言</h3><p>实验室的服务器总是出故障，于是和师兄一起考虑将实验室重装系统，并进行一系列操作。因为之前接触的少，这次是一个很好的实践机会，过程中记录笔记如下</p><h3 id="服务器检修">服务器检修</h3><h4 id="实验室的服务器">实验室的服务器</h4><p>实验室有三台机架式服务器</p><table><thead><tr class="header"><th></th><th>Dell poweredge R730</th><th>Dell poweredge R740</th><th>thinkserver rd650</th></tr></thead><tbody><tr class="odd"><td>系统</td><td>ubuntu 16.04</td><td>ubuntu 18.04</td><td>windows server 2008</td></tr></tbody></table><h4 id="制作ubuntu安装u盘">制作ubuntu安装U盘</h4><p>大部分内容参考自<a href="https://blog.csdn.net/zjx2014430/article/details/49303785" target="_blank" rel="noopener">使用UltraISO制作ubuntu安装u盘启动盘图文教程</a>，内容很详细，我的操作就是按照博客里的步骤</p><p>Ubuntu基于Debian发行版和GNOME桌面环境，在下载得到Ubuntu的光盘镜像后，可以选择刻盘引导安装或利用unetbootin工具用U盘引导安装。</p><p><strong>如何用u盘装ubuntu？</strong></p><p>先在网上下载<code>ubuntu16.04镜像</code> 和 <code>UltraISO软件</code></p><p>1、首先打开UltraISO软件，尽量下载最新版的，旧版可能会不能识别磁盘，安装失败!</p><p><img src="https://i.loli.net/2020/08/26/xim8TtON9MqyIYH.jpg" alt="点击查看大图" style="zoom:67%;"></p><p>2、点击工具栏中的第二个打开镜像文件工具，如图红色方框标志按钮，然后在打开的“打开ISO文件”对话框中找到我们下载好的Ubuntu镜像文件，之后点右下方的“打开”按钮</p><p><img src="https://i.loli.net/2020/08/26/hpUG4TbYoAHdDLQ.jpg" alt="点击查看大图" style="zoom:67%;"></p><p>3、打开镜像文件之后，在上方的列表中就会出现对打开的镜像文件的预览左边显示的是具体的目录，右边显示的目录和具体文件</p><p><img src="https://i.loli.net/2020/08/26/kzGMHAhBT1Y3tVg.jpg" alt="点击查看大图" style="zoom:67%;"></p><p>4、下面就开始制作启动盘了，点击菜单栏的“启动”，然后再弹出才按中选择“写入硬盘映像...”，打开“写入硬盘映像”对话框</p><p><img src="https://i.loli.net/2020/08/26/PuEeokUWv7qyhrd.jpg" alt="点击查看大图" style="zoom:67%;"></p><p>5、在写入硬盘映像对话框中，硬盘驱动器选择我们要写入的U盘，写入方式可以选择USB-HDD也可以选择USB-HDD+，两种方式小编都有尝试过，均可以</p><p><img src="https://i.loli.net/2020/08/26/28JSil4sBk9pCxO.jpg" alt="点击查看大图" style="zoom:67%;"></p><p>6、现在的这一步是非常关键的，关系到我们最后制作的硬盘映像能否启动电脑并安装系统，点击“便捷启动”，然后再弹出的菜单中依次选择“写入新的驱动器引导扇区”，再选择“Syslinux”，这一步的没有选择的话，那么我们最后制作的U盘映像将不能识别硬盘，不能安装系统</p><p><img src="https://i.loli.net/2020/08/26/HEQYiB7gqk4ep61.jpg" alt="点击查看大图" style="zoom:67%;"></p><p>7、在选择“Syslinux”后，会弹出如下图所示的提示框，毫无疑问，这里我们应该选择“是”</p><p><img src="https://i.loli.net/2020/08/26/tdT2jmYGVAMQhpN.jpg" alt="点击查看大图" style="zoom:67%;"></p><p>8、将Syslinux引导神曲写入设置的过程非常快，写入完成后，会弹出写入成功的提示框，若是没有写入成功，那么我们要重复上面的6、7步</p><p><img src="https://i.loli.net/2020/08/26/I8rhwpq3iVfCFsv.jpg" alt="点击查看大图" style="zoom:67%;"></p><p>9、现在就到了将ISO内的文件写入到U盘的时候了，点击下面的“写入”按钮，会弹出警告提示框，点击“是”就开始U盘安装盘的写入了</p><p><img src="https://i.loli.net/2020/08/26/HrdAoOFwvIg8SmP.jpg" alt="点击查看大图" style="zoom:67%;"></p><p>10、做完上面一些设置后，点击下面的“写入”按钮，这样就开始了U盘安装盘的制作过程，小编这里用的DVD的镜像文件，文件比较大，所以也比较耗时，在制作完成后，会自动关闭这个“写入硬盘映像”的对话框</p><p><img src="https://i.loli.net/2020/08/26/1DnsEjZBrzQtAc8.jpg" alt="点击查看大图" style="zoom:67%;"></p><p>11、制作完成，打开我的电脑，我们可以看到U盘的磁盘图标和名称都已经改变，其实这些信息是从我们的镜像文件中提取出来的</p><p>制作完成，现在安全弹出U盘，重启电脑，设置冲U盘启动就可以从U盘安装Ubuntu了，具体安装过程请看小编手续的经验文档</p><p><img src="https://i.loli.net/2020/08/26/OEzD8hnmBUrkj2J.jpg" alt="点击查看大图" style="zoom:67%;"></p><ol type="1"><li><p>在进行U盘安装系统之前，我们还需要设置BIOS选项，因为默认的是硬盘启动，因此我们需要进行设置为U盘启动，不同的主板设置U盘启动的方式也不同，因此小编就不在此详述怎么更改BIOS设置，大家查找自己的主板型号然后在网上找相关的设置教程即可。</p><p><a href="http://jingyan.baidu.com/album/a3761b2b66fe141577f9aa51.html?picindex=8" target="_blank" rel="noopener"><img src="https://i.loli.net/2020/08/26/pD2yrl37uQwefsa.jpg" alt="怎么用u盘安装ubuntu"></a></p></li><li><p>完成BIOS设置后我们就可以插入U盘，重启电脑了，我们就可以使用U盘进行Ubuntu操作系统的安装了，具体的安装步骤小编就不在详述了，网上有很多相关的教程，大家可以参考下。</p><p><a href="http://jingyan.baidu.com/album/a3761b2b66fe141577f9aa51.html?picindex=9" target="_blank" rel="noopener"><img src="https://i.loli.net/2020/08/26/wbGayoYzurPMnkR.png" alt="怎么用u盘安装ubuntu"></a></p></li></ol><h4 id="安装系统流程">安装系统流程</h4><p>在bios界面选择USB：data traveler字样的设备，就是U盘，点击就可以进入U盘的ubuntu系统 在ubuntu界面里，选择try ubuntu，就可以在U盘里暂时不安装系统就可以体验。 在try ubuntu中，左侧文件夹目录会显示各个硬盘和U盘的项目。其中computer选项，/home就是U盘里的。可以正常的进行ubuntu操作。 好像会重启格式化还原，也就是向里面拷数据，重启之后再通过U盘进入ubuntu界面，拷的数据就不存在了。而且在自己笔记本上打开U盘，里面的目录是和ubuntu目录不一样的，也没有拷的数据。</p><p>因为要将系统安装在新的硬盘里，所以考虑将新硬盘里的数据拷出来。然而拷进U盘会重置无法读取，旧的硬盘又无法操作（无法在旧硬盘新建文件夹）所以最后就用了另一个数据U盘，找到U盘路径，最终将数据拷到U盘里，再对新硬盘格式化。</p><p>安装ubuntu过程中，在ubuntu主界面正常选择硬盘安装即可。 我们选择的是清空硬盘数据安装（对硬盘格式化）。安装完毕会重启</p><p>在bios界面里，可以调整开机默认启动项（默认进入的系统）。我们想要将新装的系统设为默认。</p><p>F11： boot manager。一般在这里面进行操作。 选择one-shot 启动（U盘系统启动），以及调整默认启动项。</p><ul><li>显示不出挂载的硬盘。 硬盘没插好。需要用劲将硬盘按进去 ，使其完全固定，才会插好。并且在开机的时候，硬盘位置处会亮灯的</li></ul><p>服务器上硬盘是有顺序的。根据服务器版面上的提示，按照从上到下，从左到右依次编号为0,1,2...， 优先级也是依次降低的。所以在启动界面，会优先加载优先级高的硬盘里的系统。 因为旧硬盘之前在上面。新硬盘在下面，后来更换位置，就可以正常加载新装的ubuntu系统。</p><p>sudo -i ： 升级到最高权限。 一些提示没有权限的操作需要进行升级 在文件/夹中， 右键属性，可以看到绝对位置路径。这样方便进行命令行操作。</p><h4 id="配置网络以及远程ssh连接">配置网络以及远程ssh连接</h4><p>本章节的大部分内容参考自<a href="https://blog.51cto.com/tangyade/2330627" target="_blank" rel="noopener">ubuntu16.04的网络配置</a></p><p>截图来自于实际服务器操作</p><p>参考博客 <a href="https://blog.csdn.net/weixin_43162402/article/details/88419024" target="_blank" rel="noopener">远程ssh连接ubuntu</a></p><h5 id="配置网络">配置网络</h5><p>打开ubuntu网络设置</p><p>在IPv4设置中，增加地址和DNS服务器</p><p><img src="https://i.loli.net/2020/08/25/zFQvdOa4rJZ8NCM.png" alt="image-20200825000649093"></p><p>重启系统 <code>shutdown  -r  now</code></p><p>如下 <code>ping www.baidu.com</code> , 如果可以ping通，则网络配置正确</p><p><img src="https://i.loli.net/2020/08/25/sNwuUrzBJ354xAd.png" alt="image-20200825000941898"></p><h5 id="配置ssh">配置ssh</h5><h6 id="检查ssh服务并安装">检查ssh服务，并安装</h6><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ps -e|grep ssh <span class="comment">#抓取是否有ssh运行程序</span></span><br><span class="line">sudo apt-get update <span class="comment">#更新依赖</span></span><br><span class="line">sudo apt-get install openssh-sever  <span class="comment"># 安装ssh服务</span></span><br></pre></td></tr></tbody></table></figure><p><img src="https://i.loli.net/2020/08/25/cfUBayIj59q7OSY.png" alt="image-20200825002257791"></p><p><img src="https://i.loli.net/2020/08/25/Xn8RufD3AlKEhBC.png" alt="image-20200825002523612"></p><h6 id="启动ssh">启动ssh</h6><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/ssh start  <span class="comment">#启动ssh</span></span><br><span class="line">sudo netstat -tlp</span><br></pre></td></tr></tbody></table></figure><p><img src="https://i.loli.net/2020/08/25/HJWKQDbFqnUCk9f.png" alt="image-20200825002331284"></p><p><img src="https://i.loli.net/2020/08/25/1zbncv7DyP43mHN.png" alt="image-20200825002625207"></p><h6 id="重启系统">重启系统</h6><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutdown  -r  now</span><br></pre></td></tr></tbody></table></figure><h4 id="语言设置">语言设置</h4><p>参考<a href="https://zhuanlan.zhihu.com/p/40755318" target="_blank" rel="noopener">ubuntu的语言设置（中文-&gt;英文）</a></p><h4 id="安装软件">安装软件</h4><h5 id="下载">下载</h5><p>浏览器搜狗输入法的linux版本安装包。 选择<code>save file</code>选项</p><h5 id="安装">安装</h5><ul><li><p>首先找到安装包所在文件夹，复制路径 。如路径<code>/home/dell2/Downloads/</code></p></li><li><p>在安装包右键属性，复制文件名，如 ：<code>sougou_64.deb</code></p></li><li><p>在terminal中命令行 <code>cd /home/dell2/Downloads/</code> 切换到当前文件夹，便于操作</p></li><li><p>继续执行 <code>sudo dpkg -i sougou_64.deb</code> 需要root权限，所以要输入密码</p><blockquote><p>dpkg是linux的deb包管理。</p><p>dpkg： 是Debian packager的简称，是由Debian开发出来的包管理器，软件包在发布时打包成.deb格式</p><p>适用于Dpkg (Debian系)：Ubuntu 注：RPM (Red Hat系)：CentOS、Fedora</p><p>dpkg支持 tar 包。 tar 只是一种压缩文件格式，所以，它只是把文件压缩打包而已</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dpkg -i *.deb     deb文件的安装</span><br><span class="line">dpkg -r *.deb     deb文件的卸载</span><br><span class="line">dpkg -l           查看当前系统中已经安装的软件包的信息</span><br></pre></td></tr></tbody></table></figure></blockquote></li></ul><h5 id="更新依赖">更新依赖</h5><blockquote><p>dpkg常用命令行dpkg和rpm命令虽然可以解决安装，卸载和查询，但是对于软件包直接的依赖，比如安装的软件包依赖于很多其他的软件包，这两个软件只会将依赖打印出来告诉用户，需要用户一个一个的手动去先安装依赖，当依赖包又依赖其他包时，对于用户实在是不够友好，于是apt和yum出现了，他们的能够自动将依赖下载安装</p><p>apt的全称是Advanced Packaging Tool是Linux系统下的一款安装包管理工具。</p></blockquote><p>一般如果提示软件安装失败，那么应该就是缺少依赖。这时候应该更新依赖并且修复依赖。</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update  <span class="comment">#更新依赖</span></span><br><span class="line">sudo apt-get install -f  <span class="comment">#修复依赖.使用此命令可修复依赖关系，假如有软件因依赖关系不满足而无法安装，就可以运行此命令自动修复安装程序包所依赖的包。特别是在使用dpkg命令安装deb软件包时出现依赖问题常需要此命令来修复。</span></span><br><span class="line"><span class="comment">#修复依赖之后如果还是出错，那么就再次运行此命令。注意提示</span></span><br></pre></td></tr></tbody></table></figure><h5 id="安装完毕">安装完毕</h5><p>打开ubuntu搜索栏就可以搜索到软件，就可以使用啦</p><h4 id="卸载软件">卸载软件</h4><p>参考自<a href="https://blog.csdn.net/luckydog612/article/details/80877179" target="_blank" rel="noopener">ubuntu命令卸载</a></p><p>打开终端，输入<code>dpkg --list</code> ,按下Enter键，终端输出以下内容，显示的是你电脑上安装的所有软件。</p><p>2.在终端中找到你需要卸载的软件的名称，列表是按照首字母排序的。 <img src="https://i.loli.net/2020/08/25/I8ctzH3LJlbNS4p.jpg" alt="找到要卸载的软件包"> 3.在终端上输入命令<code>sudo apt-get --purge remove 包名</code>（<code>--purge</code>是可选项，写上这个属性是将软件及其配置文件一并删除，如不需要删除配置文件，可执行<code>sudo apt-get remove 包名</code>） ，此处我要删除的是<code>polipo</code> ，那么在终端输入<code>sudo apt-get --purge remove polipo</code>，按下回车，输入密码，再次回车。</p><p>4.执行过程中，会提示你是否真的要删除（继续执行删除命令），在终端输入<code>y</code> ，然后回车，删除程序继续执行。 <img src="https://i.loli.net/2020/08/25/zt1kIJoTsn7AlFf.png" alt="确认删除"></p><p>5.正常情况下，再次出现输入命令行删除成功。 <img src="https://i.loli.net/2020/08/25/PRcrVmlbD3NOf65.png" alt="删除成功"></p><p>总结如下：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dpkg --list  <span class="comment"># 找到要删除的软件 按顺序排列</span></span><br><span class="line">sudo apt-get --purge remove polipo  <span class="comment">#配置文件一起删除</span></span><br></pre></td></tr></tbody></table></figure><h4 id="解决向日葵连接断开问题">解决向日葵连接断开问题</h4><p>实验室740服务器本来是ubuntu16.04，之后升级到ubuntu18.04，在windows上连接ubuntu的向日葵，总是显示正在连接，马上就是连接已断开，于是记录下解决方案。向日葵的客服的官方解答如下：</p><p>1、检查桌面环境是否有启动，若没有请先启动。需开启显示器使用</p><p>2、需要安装lightdm插件否则会提示连接停止</p><p>3、设备终端运行 xhost +再重新发起远程桌面测试能否显示画面</p><p>本次是方案2解决的。</p><blockquote><p>猜测：之前版本是ubuntu16.04支持的是lightdm，所以向日葵是可以正常运行的。而Ubuntu 16.10和更高版本中的默认显示管理器gdm，导致向日葵总是连接断开。所以切换到lightdm就可以了。</p></blockquote><p>将Display Manager切换为lightdm，<strong>重新启动系统</strong>即可：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update </span><br><span class="line">sudo apt-get upgrade </span><br><span class="line">sudo apt-get install lightdm #安装lightdm</span><br><span class="line">sudo dpkg-reconfigure lightdm # 将Display Manage从gdm3切换为lightdm</span><br></pre></td></tr></tbody></table></figure><p>输入用户名和密码后，将出现以下窗口，大致了解显示管理器在系统中的运行方式。</p><p><img src="https://i.loli.net/2020/08/26/VXeSndcL2ybKsW5.jpg" alt="Switch to gdm3" style="zoom:67%;"></p><p>按Enter键确定；将出现以下窗口。可以通过向上和向下箭头键配置新的显示管理器，然后按Enter进行确定。</p><p><img src="https://i.loli.net/2020/08/26/C6mfYuHpz1JyxX8.jpg" alt="Set default display manager"></p><p>重新启动系统时，选择的显示管理器将被配置为默认显示管理器。</p><hr><p>也可再切换为gdm3，并将lightdm删除</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg-reconfigure gdm3 #也可切换为gdm3</span><br><span class="line">sudo apt-get remove lightdm #删除lightdm</span><br></pre></td></tr></tbody></table></figure><p>要检查当前正在使用哪个显示管理器，请运行以下命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/X11/default-display-manager</span><br></pre></td></tr></tbody></table></figure><blockquote><p><code>gdm3</code>，<code>kdm</code>和<code>lightdm</code>都是<strong>显示管理器</strong>（Display Manager），它们提供图形化登录，并且处理用户身份验证。</p><p>显示管理器：向用户显示登录屏幕，当用户成功输入用户名和密码的有效组合时，会话开始。</p><p><img src="https://i.loli.net/2020/08/26/uoEHl4bhSxaF2gj.jpg" alt="Ubuntu LightDM Display manager" style="zoom: 67%;"></p><p>LightDM的登录屏幕</p></blockquote><h4 id="将向日葵设置为开机自启动">将向日葵设置为开机自启动</h4><p>想将向日葵设置为自启动，这样以后重启服务器之后，就可以直接连接向日葵。在向日葵软件里设置并没有效果，于是想着在ubuntu开机启动项里设置。参考自<a href="https://www.cnblogs.com/end/archive/2012/10/12/2721059.html" target="_blank" rel="noopener">linux开机自启动</a></p><blockquote><p>linux随机启动的服务程序都在/etc/init.d这个文件夹里，里面的文件全部都是脚本文件（脚本程序简单的说就是把要运行的程序写到一个文件里让系统能够按顺序执行，类似windows下的autorun.dat文件）</p><p>另外在/etc这个文件夹里还有诸如名为rc1.d, rc2.d一直到rc6.d的文件夹，这些都是linux不同的runlevel，我们一般进入的X windows多用户的运行级别是第5级，也就是rc5.d，在这个文件夹下的脚本文件就是运行第5级时要随机启动的服务程序。</p><p>需要注意的是，在每个rc (1-6).d文件夹下的文件其实都是/etc/init.d文件夹下的文件的一个软连接（类似windows中的快捷方式），也就是说，<strong>在 /etc/init.d文件夹下是全部的服务程序，而每个rc(1-6).d只链接它自己启动需要的相应的服务程序！</strong></p><p>在本次操作中，目的就是写入运行向日葵脚本到/etc/init.d，然后软链接到rc5.d中即可开机自启动</p></blockquote><h5 id="找到系统中名字">找到系统中名字</h5><p>我们不确定向日葵（sunlogin）在系统中的名字，于是如下操作：</p><p>打开终端，输入<code>dpkg --list</code> ,按下Enter键，终端输出以下内容，显示的是你电脑上安装的所有软件。（按照首字母排列的）</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dpkg --list <span class="comment"># 显示所有的软件名称</span></span><br></pre></td></tr></tbody></table></figure><p>找到向日葵名称，为<code>sunloginclient</code></p><h5 id="确定向日葵的位置">确定向日葵的位置</h5><p>要知道<code>sunloginclient</code>在哪里，用locate命令可以找到。</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">locate sunloginclient</span><br></pre></td></tr></tbody></table></figure><p><img src="https://i.loli.net/2020/08/26/AGgtMOySf2jd5ca.png" alt="image-20200826221019492"></p><p>选择<code>/usr/local/sunlogin/bin/sunloginclient</code>,这就是向日葵执行文件位置所在。</p><p>其中usr表 示是属于用户的，bin在linux里表示可以执行的程序。</p><h5 id="验证文件位置可忽略">验证文件位置（可忽略）</h5><p>验证是否这个位置可以打开向日葵，ubuntu用命令行的方式启动向日葵</p><ul><li>绝对路径：</li></ul><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/sunlogin/bin/sunloginclient <span class="comment">#直接在终端输入绝对路径即可</span></span><br></pre></td></tr></tbody></table></figure><p>如果可以启动向日葵，则表明路径正确</p><ul><li>如果已经在执行文件所在的文件夹，如<code>/usr/local/sunlogin/bin</code>，则</li></ul><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./sunloginclient  <span class="comment"># 执行文件</span></span><br></pre></td></tr></tbody></table></figure><h5 id="编写sh脚本">编写sh脚本</h5><p>这样，我就可以编写一个脚本程序，把它放到<code>/etc/init.d</code>里，然后在<code>rc5.d</code>里做一个相应的软链接就可以了。</p><p>在<code>/etc/init.d</code>里新建sunlogin.sh脚本，</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/init.d <span class="comment">#cd到该目录下</span></span><br><span class="line">sudo vim sunlogin.sh <span class="comment">#新建脚本</span></span><br></pre></td></tr></tbody></table></figure><p>脚本内容如下：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh </span></span><br><span class="line">/usr/<span class="built_in">local</span>/sunlogin/bin</span><br></pre></td></tr></tbody></table></figure><p>第一行<strong>#!/bin/sh</strong>是指此脚本使用<strong>/bin/sh</strong>来解释执行，<strong>#!</strong>是特殊的表示符，其后面根的是此解释此脚本的shell的路径。</p><p>第二行就是要运行的命令，也就是打开向日葵。</p><blockquote><p>才开始用的是<code>#!/bin/bash</code> ，发现没有效果。后参照rc5.d里sh文件里格式是sh，于是将其改为<code>#!/bin/sh</code> 。重启有效果。</p><p>#!/bin/sh 和 #!/bin/bash 的区别可以参考<a href="https://www.cnblogs.com/EasonJim/p/6850319.html" target="_blank" rel="noopener">区别</a></p></blockquote><h5 id="建立软链接">建立软链接</h5><p>建立启动项从<code>/etc/init.d</code>到<code>/etc/rc5.d</code>的软链接</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s  /etc/init.d/sunlogin.sh  /etc/rc5.d/S04sunlogin.sh</span><br></pre></td></tr></tbody></table></figure><p><img src="https://i.loli.net/2020/08/26/Xeo5zuxMsv8nkba.png" alt="rc5.d中内容"></p><blockquote><p>建立软链接： ln -s 原目录 映射目录</p><p>删除软链接的方法： sudo rm -rf 映射目录</p></blockquote><blockquote><p>软链接相当于windows中的快捷方式，不必重复的占用磁盘空间</p><p>ln命令会保持每一处链接文件的同步性，和快捷方式一样</p><p>当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在 其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。</p><p>具体参考<a href="https://www.runoob.com/linux/linux-comm-ln.html" target="_blank" rel="noopener">链接</a></p><p>还需要注意的一点是，在rc5.d里，每个链接的名字都是以S或者K开头的，S开头的表示是系统启动是要随机启动的，K开头的是不随机启动的。</p><p>如果我要哪个服务随机启动，就把它名字第一个字母K改成S就可以了，当然，把S改成K后，这个服务就不能随机启动了。因此，我这个链接 还要起名为SXXX，这样系统才能让它随机启动。</p></blockquote><h5 id="完成开机自启动">完成开机自启动</h5><p>重启系统后，等一下就可以启动向日葵，完成操作</p><h4 id="挂载硬盘">挂载硬盘</h4><h3 id="计算机启动过程boot">计算机启动过程（boot）</h3><p>计算机启动过程分成四个阶段。 大部分内容参考自博客<a href="http://www.ruanyifeng.com/blog/2013/02/booting.html" target="_blank" rel="noopener">计算机是如何启动的？</a></p><h4 id="一第一阶段bios"><strong>一、第一阶段：BIOS</strong></h4><p>是一组<strong>固化到计算机内主板上一个ROM芯片上的程序</strong>，计算机通电后，第一件事就是读取它。</p><p>它保存着计算机最重要的基本输入输出的程序、系统设置信息、开机后自检程序和系统自启动程序。其主要功能是为计算机提供最底层的、最直接的硬件设置和控制。</p><p>一般设置都是在这个过程中进行的</p><p><img src="https://i.loli.net/2020/08/25/KVNMtAZLJSs5c3H.jpg" alt="img"></p><p>这块芯片里的程序叫做"<strong>基本输入输出系统</strong>"（Basic Input/Output System），简称为<a href="http://en.wikipedia.org/wiki/BIOS" target="_blank" rel="noopener">BIOS</a>。</p><h5 id="硬件自检"><strong>1.1 硬件自检</strong></h5><p>BIOS程序首先检查，计算机硬件能否满足运行的基本条件，这叫做"硬件自检"（Power-On Self-Test），缩写为<a href="http://en.wikipedia.org/wiki/Power-on_self-test" target="_blank" rel="noopener">POST</a>。</p><p>如果硬件出现问题，主板会发出不同含义的<a href="http://en.wikipedia.org/wiki/Power-on_self-test#Original_IBM_POST_beep_codes" target="_blank" rel="noopener">蜂鸣</a>，启动中止。<strong>如果没有问题，屏幕就会显示出CPU、内存、硬盘等信息。</strong></p><p><img src="https://i.loli.net/2020/08/25/Atdr1chebHjRwpM.png" alt="img"></p><h5 id="启动顺序"><strong>1.2 启动顺序</strong></h5><p>硬件自检完成后，BIOS把控制权转交给下一阶段的启动程序。</p><p>这时，BIOS需要知道，"下一阶段的启动程序"具体存放在哪一个设备。也就是说，BIOS需要有一个<strong>外部储存设备</strong>的排序，排在前面的设备就是优先转交控制权的设备。这种排序叫做<strong>"启动顺序"（Boot Sequence）</strong>。</p><p>打开BIOS的操作界面，里面有一项就是"设定启动顺序"。 （可以自己设置）</p><p><img src="http://www.ruanyifeng.com/blogimg/asset/201302/bg2013021504.jpg" alt="img"></p><h4 id="二第二阶段主引导记录mbr"><strong>二、第二阶段：主引导记录</strong>（MBR）</h4><p>BIOS按照"启动顺序"，把控制权转交给排在第一位的储存设备。（已安装的硬盘/U盘）</p><p>这时，计算机读取该设备的第一个扇区，也就是读取最前面的512个字节。如果这512个字节的最后两个字节是0x55和0xAA，表明这个设备可以用于启动；如果不是，表明设备不能用于启动，控制权于是被转交给"启动顺序"中的下一个设备。</p><p>这最前面的512个字节，就叫做<a href="http://en.wikipedia.org/wiki/Master_boot_record" target="_blank" rel="noopener">"主引导记录"</a>（Master boot record，缩写为MBR）。</p><h5 id="主引导记录的结构"><strong>2.1 主引导记录的结构</strong></h5><p>"主引导记录"只有512个字节，放不了太多东西。它的<strong>主要作用是，告诉计算机到硬盘的哪一个位置去找操作系统。</strong></p><p>主引导记录由三个部分组成：</p><blockquote><p>　　（1） 第1-446字节：调用操作系统的机器码。</p><p>　　（2） 第447-510字节：分区表（Partition table）。</p><p>　　（3） 第511-512字节：主引导记录签名（0x55和0xAA）。</p></blockquote><p>其中，第二部分"分区表"的作用，是将硬盘分成若干个区。</p><h5 id="分区表"><strong>2.2 分区表</strong></h5><p>硬盘分区有很多<a href="http://en.wikipedia.org/wiki/Disk_partitioning#Benefits_of_multiple_partitions" target="_blank" rel="noopener">好处</a>。考虑到<strong>每个区可以安装不同的操作系统</strong>，"主引导记录"因此必须知道将控制权转交给哪个区。</p><p>分区表的长度只有64个字节，里面又分成四项，每项16个字节。所以，<strong>一个硬盘最多只能分四个一级分区</strong>，又叫做<strong>"主分区"</strong>。</p><p>每个主分区代表一个操作系统，最多只能装4个操作系统。 在操作系统中的区划分是在该主分区下进行的。</p><p>每个主分区的16个字节，由6个部分组成：</p><blockquote><p>　　（1） 第1个字节：如果为0x80，就表示该主分区是激活分区，控制权要转交给这个分区。四个主分区里面只能有一个是激活的。</p><p>　　（2） 第2-4个字节：主分区第一个扇区的物理位置（柱面、磁头、扇区号等等）。</p><p>　　（3） 第5个字节：<a href="http://en.wikipedia.org/wiki/Partition_type" target="_blank" rel="noopener">主分区类型</a>。</p><p>　　（4） 第6-8个字节：主分区最后一个扇区的物理位置。</p><p>　　（5） 第9-12字节：该主分区第一个扇区的逻辑地址。</p><p>　　（6） 第13-16字节：主分区的扇区总数。</p></blockquote><p>最后的四个字节（"主分区的扇区总数"），决定了这个主分区的长度。也就是说，一个主分区的扇区总数最多不超过2的32次方。</p><p>如果每个扇区为512个字节，就意味着单个分区最大不超过2TB。再考虑到扇区的逻辑地址也是32位，所以单个硬盘可利用的空间最大也不超过2TB。如果想使用更大的硬盘，只有2个方法：一是提高每个扇区的字节数，二是<a href="http://en.wikipedia.org/wiki/GUID_Partition_Table" target="_blank" rel="noopener">增加扇区总数</a>。</p><h4 id="三第三阶段硬盘启动"><strong>三、第三阶段：硬盘启动</strong></h4><p>这时，计算机的控制权就要转交给硬盘的某个分区了，这里又分成三种情况。</p><h5 id="情况a卷引导记录"><strong>3.1 情况A：卷引导记录</strong></h5><p>上一节提到，四个主分区里面，只有一个是激活的。计算机会<strong>读取激活分区的第一个扇区</strong>，叫做<a href="http://en.wikipedia.org/wiki/Volume_Boot_Record" target="_blank" rel="noopener">"卷引导记录</a>"（Volume boot record，缩写为VBR）。</p><p>"卷引导记录"的主要作用是，告诉计算机，操作系统在这个分区里的位置。然后，计算机就会加载操作系统了。</p><h5 id="情况b扩展分区和逻辑分区"><strong>3.2 情况B：扩展分区和逻辑分区</strong></h5><p>主分区的其中一个被定义为<strong>扩展分区</strong>，扩展分区下可以设置多个分区，被称为<strong>逻辑分区</strong></p><p>随着硬盘越来越大，四个主分区已经不够了，需要更多的分区。但是，<strong>分区表只有四项，因此规定有且仅有一个区可以被定义成"扩展分区"（Extended partition）。</strong></p><p>所谓<strong>"扩展分区"，就是指这个区里面又分成多个区</strong>。这种分区里面的分区，就叫做"<strong>逻辑分区</strong>"（logical partition）。</p><p>计算机先读取扩展分区的第一个扇区，叫做<a href="http://en.wikipedia.org/wiki/Extended_partition" target="_blank" rel="noopener">"扩展引导记录"</a>（Extended boot record，缩写为EBR）。它里面也包含一张64字节的分区表，但是最多只有两项（也就是两个逻辑分区）。</p><p>计算机接着读取第二个逻辑分区的第一个扇区，再从里面的分区表中找到第三个逻辑分区的位置，以此类推，直到某个逻辑分区的分区表只包含它自身为止（即只有一个分区项）。因此，<strong>扩展分区可以包含无数个逻辑分区。</strong></p><p>但是，似乎很少通过这种方式启动操作系统。如果操作系统确实安装在扩展分区，一般采用下一种方式启动。</p><h5 id="情况c启动管理器常用"><strong>3.3 情况C：启动管理器</strong>（常用）</h5><p>在这种情况下，计算机读取"主引导记录"前面446字节的机器码之后，不再把控制权转交给某一个分区，而是运行事先安装的<a href="http://en.wikipedia.org/wiki/Boot_loader#Modern_boot_loaders" target="_blank" rel="noopener">"启动管理器"</a>（boot loader），由用户选择启动哪一个操作系统。</p><p>Linux环境中，目前最流行的启动管理器是<a href="http://en.wikipedia.org/wiki/GNU_GRUB" target="_blank" rel="noopener">Grub</a>。</p><p><img src="https://i.loli.net/2020/08/25/Ao5JqKFpgmXWOfw.png" alt="img"></p><h4 id="四第四阶段操作系统"><strong>四、第四阶段：操作系统</strong></h4><p>控制权转交给操作系统后，操作系统的内核首先被载入内存。</p><p>以Linux系统为例，先载入<strong>/boot目录下面的kernel</strong>。内核加载成功后，第一个运行的程序是<strong>/sbin/init</strong>。它根据配置文件（Debian系统是/etc/initab）产生init进程。这是Linux启动后的第一个进程，pid进程编号为1，其他进程都是它的后代。</p><p><strong>然后，init线程加载系统的各个模块，比如窗口程序和网络程序，直至执行/bin/login程序，跳出登录界面，等待用户输入用户名和密码。</strong></p><p>至此，全部启动过程完成。</p><h3 id="bios和uefi的区别">BIOS和UEFI的区别</h3><blockquote><p>BOOT设置是说电脑一按开机键后，出现那段黑屏界面BOOT运行时，你按<strong>快捷键</strong>调出各种BOOT后的程序，例如BIOS的这个按键过程。</p><p><a href="http://www.udangjia.com/bios/" target="_blank" rel="noopener">BIOS设置</a>是，你必须按对快捷键，<strong>从BOOT进入BIOS程序后</strong>，在BIOS程序中的设置的这个过程。</p></blockquote><blockquote><p><strong>UEFI</strong>它其实和BIOS是同一个性质的东西，同一种程序，是随着发展出现的BIOS升级版。因为硬件发展迅速，传统式（<strong>Legacy</strong>）BIOS成为进步的包袱，现在已发展出最新的UEFI。理论上说是比BIOS更先进的UEFI，却还是诸多支持不足，往往很多是UEFI启动电脑，到头来还是切换回BIOS。</p></blockquote><p><img src="https://i.loli.net/2020/08/17/dkj8VXRMyTQ1UsI.png" alt="image-20200817235333172"></p><p><strong>现在的笔记本默认是UEFI+GPT</strong>，主流趋势也是使用UEFI进行引导。如果改legacy，必须在Security选项，找到Secure Boot，关闭。</p><h3 id="bios设置">BIOS设置</h3><h4 id="u盘启动">U盘启动</h4><p>按下电源键后,按照显示器上的提示进入BIOS，例如：按F2、F9、F11、F12或者Delete键。</p><p>方法1.直接选择带有USB：data traveler字样的enter进入即可。只是一次进入，下次还需要选择</p><p>方法2.将U盘项设置为First Boot，默认进入。一般在<strong>boot（启动）选项</strong>中进入设置</p><p>有的需要<strong>F10保存</strong>并退出</p><blockquote><p>参考</p><p><a href="https://blog.csdn.net/yuk1007/article/details/95217457" target="_blank" rel="noopener">基础的BIOS操作</a></p><p><a href="http://www.kqidong.com/bios/2771.html" target="_blank" rel="noopener">常见bios设置操作教程</a></p></blockquote><h3 id="计算机存储术语-扇区磁盘块页">计算机存储术语: 扇区，磁盘块，页</h3><blockquote><p><strong>扇区（sector）</strong>：硬盘的读写以扇区为基本单位。</p><p>磁盘上的每个磁道被等分为若干个弧段，这些弧段称之为扇区。</p><p>通常情况下每个扇区的大小是 512 字节。linux 下可以使用 <code>fdisk -l</code> 了解扇区大小</p><p>注意，扇区是磁盘物理层面的概念，操作系统是不直接与扇区交互的，而是与多个连续扇区组成的磁盘块交互。由于扇区是物理层面的概念，所以无法在系统中进行大小的更改。</p></blockquote><blockquote><p>簇：由于操作系统无法对数目众多的扇区进行寻址，所以操作系统就将相邻的扇区组合在一起，形成一个<strong>簇</strong>，然后再对簇进行管理。每个簇可以包括2、4、8、16、32或64个扇区。<strong>操作系统是通过块簇来做为单位读取等操作数据的</strong>。</p><p>为了更好地管理磁盘空间和更高效地从硬盘读取数据，操作系统规定<strong>一个簇中只能放置一个文件的内容</strong>，因此文件所占用的空间，只能是簇的整数倍；而如果文件实际大小小于一簇，它也要占一簇的空间。</p><p>所以，一般情况下文件所占空间要略大于文件的实际大小</p></blockquote><blockquote><p><strong>磁盘块（IO Block）</strong>：<strong>文件系统</strong>读写数据的最小单位，也叫磁盘簇。磁盘块的大小可以通过命令 <code>stat /boot</code> 来查看。</p><p>在Windows下如NTFS等文件系统中叫做簇；在Linux下如Ext4等文件系统中叫做块（block）。</p></blockquote><blockquote><p><strong>页，page</strong></p><p>内存的最小存储单位。页的大小通常为磁盘块大小的 2^n 倍，可以通过命令 <code>getconf PAGE_SIZE</code> 来获取页的大小</p><p>总结也就是</p><ul><li>页，内存操作的基本单位</li><li>磁盘块，磁盘操作的基本单位</li></ul></blockquote><blockquote><p><strong>命令索引</strong></p><ul><li>扇区大小，<code>fdisk -l</code> 查看磁盘分区情况</li><li>磁盘块大小，<code>stat /boot</code></li><li>内存页大小，<code>getconf PAGE_SIZE</code></li></ul></blockquote><h3 id="linux磁盘分区">linux磁盘分区</h3><p>更多内容参考自</p><p><a href="https://wizardforcel.gitbooks.io/vbird-linux-basic-4e/content/20.html" target="_blank" rel="noopener">鸟哥的linux私房菜 | 磁盘分区</a></p><p><a href="https://jasonhzy.github.io/2019/02/07/linux-mount/" target="_blank" rel="noopener">Linux分区与挂载</a></p><h3 id="poweredge-r740-机架式服务器基本操作">PowerEdge R740 机架式服务器基本操作</h3><h4 id="设置开机启动顺序">设置开机启动顺序</h4><p>开机按F2进入系统启动设置，也可以<strong>按F11进入快速启动配置</strong></p><p><img src="https://i.loli.net/2020/08/18/XZFykAOdgmHjJDe.png" alt="image-20200818151126884"></p><p><img src="https://i.loli.net/2020/08/18/OCK5cRzksAWIhyp.png" alt="image-20200818151216211"></p><p><img src="https://i.loli.net/2020/08/18/FpgEyq8vGzBlPXD.png" alt="image-20200818151323442"></p><p><img src="https://i.loli.net/2020/08/18/Rdf19rWcvAOHSp7.png" alt="image-20200818151824019"></p><p>在<strong>Boot Sequence</strong>处将<strong>Hard drive C</strong>设置到第一位，即优先级最高</p><h4 id="运行硬件检测">运行硬件检测</h4><p>怀疑硬件故障了，运行了一下硬件检测。可以看到有哪些硬件。来验证所连接的硬件是否正常工作，排除故障。</p><p>1.开机出现DELL LOGO标志时按2下F10键，等待大概5分钟会进入lifecycle controller界面；</p><p>2.鼠标单击选择左侧的“Hardware Diagnostics”硬件诊断，再单击右侧的“Run Hardware Diagnostics”运行硬件诊断；</p><p><img src="https://i.loli.net/2020/08/18/FNegH5CnmJiRWAa.jpg" alt="img"></p><p>3.自动进入检测</p><p><img src="https://i.loli.net/2020/08/18/oEsxlPruV6DmSw2.jpg" alt="img"></p><p>4.大概5分钟后完成快速检测，出现如下界面，再单击“YES”继续完整检测，大概需要几个小时</p><p><img src="https://i.loli.net/2020/08/18/DKRFHVjpEZo27kW.jpg" alt="img"></p><ol start="5" type="1"><li>检测完成后请单击“Result”结果一列，拍照这个页面，可能需要拖动滚动条拍照未在一屏显示出的其他内容。</li></ol><p><img src="https://i.loli.net/2020/08/18/Yij4DdNxZ3w6RBF.jpg" alt="img"></p><p>6、如果检测出现问题，会弹出红框，点击继续，最后查看一下原因。</p><p><img src="https://i.loli.net/2020/08/18/tYB8e7lsuUyP9fc.jpg" alt="img"></p><p>查一下ERROR CODE，应该是事件日志有历史告警导致的，清除告警之后，再次运行检测程序，没有告警了。</p><h3 id="交换空间">交换空间</h3><p>当今无论什么操作系统 <em>交换(Swap)</em>空间是非常常见的。Linux 使用交换空间来增加主机可用的虚拟内存。</p><p>典型计算机中有<strong>两种基本类型的内存</strong>。第一种类型，<strong>随机存取存储器 (RAM)</strong>，用于存储计算机使用的数据和程序。只有程序和数据存储在 RAM 中，计算机才能使用它们。</p><p><strong>交换空间</strong>是现代 Linux 系统中的第二种内存类型。交换空间的主要功能是当全部的 RAM 被占用并且需要更多内存时，用磁盘空间代替 RAM 内存。</p><p>例如，假设你有一个 8GB RAM 的计算机。如果你启动的程序没有填满 RAM，一切都好，不需要交换。假设你在处理电子表格，当添加更多的行时，你电子表格会增长，加上所有正在运行的程序，将会占用全部的 RAM 。如果这时没有可用的交换空间，你将不得不停止处理电子表格，直到关闭一些其他程序来释放一些 RAM 。</p><p>内核使用一个内存管理程序来检测最近没有使用的内存块（内存页）。内存管理程序将这些相对不经常使用的内存页交换到硬盘上专门指定用于“分页”或交换的特殊分区。这会释放 RAM，为输入电子表格更多数据腾出了空间。那些换出到硬盘的内存页面被内核的内存管理代码跟踪，如果需要，可以被分页回 RAM。</p><p>Linux 计算机中的内存总量是 RAM + 交换分区，交换分区被称为虚拟内存.</p><h4 id="什么是swap"><strong>什么是swap?</strong></h4><p>swap space是磁盘上的一块区域，可以是一个分区，也可以是一个文件，或者是他们的组合。简单点说，当系统物理内存吃紧时，Linux会将内存中不常访问的数据保存到swap上，这样系统就有更多的物理内存为各个进程服务，而当系统需要访问swap上存储的内容时，再将swap上的数据加载到内存中，这就是我们常说的swap out和swap in。</p><p>很多发行版(如ubuntu)的休眠功能依赖于swap分区，当系统休眠的时候，会将内存中的数据保存到swap分区上，等下次系统启动的时候，再将数据加载到内存中，这样可以加快系统的启动速度，所以如果要使用休眠的功能，必须要配置swap分区，并且大小一定要大于等于物理内存</p><p>swap是存放在磁盘上的，磁盘的速度和内存比较起来慢了好几个数量级，如果不停的读写swap，那么对系统的性能肯定有影响，尤其是当系统内存很吃紧的时候，读写swap空间发生的频率会很高，导致系统运行很慢，像死了一样，这个时候添加物理内存是唯一的解决办法。</p><h4 id="参考">参考</h4><blockquote><p><a href="https://segmentfault.com/a/1190000008125116" target="_blank" rel="noopener">Linux交换空间（swap space）</a></p></blockquote><h3 id="服务器ubuntu基本操作">服务器ubuntu基本操作</h3><h4 id="关机">关机</h4><p>立即关机</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># shutdown -h now</span><br></pre></td></tr></tbody></table></figure><p>指定 10 分钟后关机</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># shutdown -h 10</span><br></pre></td></tr></tbody></table></figure><p>重新启动计算机</p><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># shutdown -r now</span><br></pre></td></tr></tbody></table></figure><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      实验室服务器故障处理
    
    </summary>
    
    
      <category term="服务器" scheme="http://yoursite.com/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    
    
      <category term="服务器" scheme="http://yoursite.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    
      <category term="故障排除" scheme="http://yoursite.com/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4/"/>
    
  </entry>
  
</feed>
